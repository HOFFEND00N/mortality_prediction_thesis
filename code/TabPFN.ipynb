{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd85dda0-2c2a-4bf0-86a9-e1c48619f721",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297845f0-ec0c-4e56-b19d-9a2de148ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd62a86-72b3-48ee-8b9f-f68309c14c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2x/tx689lxn54ngmttr2b89rvg00000gn/T/ipykernel_58577/3738330455.py:2: DtypeWarning: Columns (264) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r\"InternationalBifurca_DATA_2025-04-20_0932.csv\", sep=',')\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(r\"InternationalBifurca_DATA_2023-10-30_0629.csv\", sep=',')\n",
    "df = pd.read_csv(r\"InternationalBifurca_DATA_2025-04-20_0932.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bc76cd3-aee7-4244-afc2-f50a151b8227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>time_from_mi_symptoms_onse</th>\n",
       "      <th>...</th>\n",
       "      <th>time_to_death_f5</th>\n",
       "      <th>time_to_acs_f5</th>\n",
       "      <th>time_to_stroke_f5</th>\n",
       "      <th>time_to_pci_f5</th>\n",
       "      <th>time_to_cabg_f5</th>\n",
       "      <th>hospitalization_f5</th>\n",
       "      <th>bleeding_f5</th>\n",
       "      <th>angio_follow_f5</th>\n",
       "      <th>restenosis_f5</th>\n",
       "      <th>side_branch_restenosis_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>MNRI-2018-0001</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>MNRI-2018-0002</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>MNRI-2018-0003</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>MNRI-2018-0004</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>MNRI-2018-0005</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>TRCH-2019-0026</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>TRCH-2019-0027</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>TRCH-2019-0028</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>TRCH-2019-0029</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>TRCH-2019-0030</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id      identifier        date  adhoc_pci  sex   age  weight  \\\n",
       "0     MNRI0001  MNRI-2018-0001  2018-02-01        1.0  2.0  77.0    84.0   \n",
       "1     MNRI0002  MNRI-2018-0002  2018-01-24        0.0  1.0  68.0    81.0   \n",
       "2     MNRI0003  MNRI-2018-0003  2018-01-24        0.0  1.0  62.0    74.0   \n",
       "3     MNRI0004  MNRI-2018-0004  2018-01-30        1.0  1.0  67.0    84.0   \n",
       "4     MNRI0005  MNRI-2018-0005  2018-01-30        0.0  1.0  57.0   103.0   \n",
       "...        ...             ...         ...        ...  ...   ...     ...   \n",
       "2139  TRCH0026  TRCH-2019-0026  2019-03-11        1.0  1.0  67.0    90.0   \n",
       "2140  TRCH0027  TRCH-2019-0027  2019-03-18        1.0  1.0  69.0    60.0   \n",
       "2141  TRCH0028  TRCH-2019-0028  2019-03-19        0.0  2.0  81.0    50.0   \n",
       "2142  TRCH0029  TRCH-2019-0029  2019-03-28        1.0  1.0  86.0    74.0   \n",
       "2143  TRCH0030  TRCH-2019-0030  2019-03-20        1.0  2.0  85.0    60.0   \n",
       "\n",
       "      height  clinical_presentation  time_from_mi_symptoms_onse  ...  \\\n",
       "0      165.0                    5.0                         4.0  ...   \n",
       "1      171.0                    1.0                         NaN  ...   \n",
       "2      180.0                    4.0                         NaN  ...   \n",
       "3      167.0                    2.0                         NaN  ...   \n",
       "4      174.0                    1.0                         NaN  ...   \n",
       "...      ...                    ...                         ...  ...   \n",
       "2139   174.0                    2.0                         NaN  ...   \n",
       "2140   174.0                    3.0                         1.0  ...   \n",
       "2141   160.0                    2.0                         NaN  ...   \n",
       "2142   170.0                    3.0                         1.0  ...   \n",
       "2143   165.0                    3.0                         1.0  ...   \n",
       "\n",
       "      time_to_death_f5  time_to_acs_f5  time_to_stroke_f5  time_to_pci_f5  \\\n",
       "0                  NaN             NaN                NaN             NaN   \n",
       "1                  NaN             NaN                NaN             NaN   \n",
       "2                  NaN             NaN                NaN             NaN   \n",
       "3                  NaN             NaN                NaN             NaN   \n",
       "4                  NaN             NaN                NaN             NaN   \n",
       "...                ...             ...                ...             ...   \n",
       "2139               NaN             NaN                NaN             NaN   \n",
       "2140               NaN             NaN                NaN             NaN   \n",
       "2141               NaN             NaN                NaN             NaN   \n",
       "2142               NaN             NaN                NaN             NaN   \n",
       "2143               NaN             NaN                NaN             NaN   \n",
       "\n",
       "      time_to_cabg_f5  hospitalization_f5  bleeding_f5  angio_follow_f5  \\\n",
       "0                 NaN                 NaN          NaN              NaN   \n",
       "1                 NaN                 NaN          NaN              NaN   \n",
       "2                 NaN                 NaN          NaN              NaN   \n",
       "3                 NaN                 NaN          NaN              NaN   \n",
       "4                 NaN                 NaN          NaN              NaN   \n",
       "...               ...                 ...          ...              ...   \n",
       "2139              NaN                 NaN          NaN              NaN   \n",
       "2140              NaN                 NaN          NaN              NaN   \n",
       "2141              NaN                 NaN          NaN              NaN   \n",
       "2142              NaN                 NaN          NaN              NaN   \n",
       "2143              NaN                 NaN          NaN              NaN   \n",
       "\n",
       "      restenosis_f5  side_branch_restenosis_5  \n",
       "0               NaN                       NaN  \n",
       "1               NaN                       NaN  \n",
       "2               NaN                       NaN  \n",
       "3               NaN                       NaN  \n",
       "4               NaN                       NaN  \n",
       "...             ...                       ...  \n",
       "2139            NaN                       NaN  \n",
       "2140            NaN                       NaN  \n",
       "2141            NaN                       NaN  \n",
       "2142            NaN                       NaN  \n",
       "2143            NaN                       NaN  \n",
       "\n",
       "[2073 rows x 283 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['sex'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "774f8d65-3829-4d17-b328-b3ab69e93907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stent_distal_vessel_size    inf\n",
       "sb_stent_sb_diametr         inf\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anyInf = df[df == np.inf].sum()\n",
    "anyInf[anyInf != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68fbb8f3-c020-46ea-8d42-5c5e6ddad81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info_cols = ['record_id', 'date', 'sex', 'age', 'adhoc_pci', 'weight', 'height', \n",
    "                     'clinical_presentation', 'time_from_mi_symptoms_onse', \n",
    "                     'ccs_class', 'diabet', 'insulin_diabetes', 'hypertension', 'smoking', \n",
    "                     'dyslipidemia', 'anemia', 'atrial_fibrilation', 'oac_use', 'valvular_disease', \n",
    "                     'valvular_disease_was_previ', 'if_yes_what_type___1', 'if_yes_what_type___2', \n",
    "                     'if_yes_what_type___3', 'if_yes_what_type___4', 'if_yes_what_type___5', \n",
    "                     'if_yes_what_type___6', 'if_yes_what_type___7', 'ef', 'creatinine', 'ckd', \n",
    "                     'mi_history', 'cerebrovascular_disease', 'previously_treated_cerebro', 'previous_stroke_tia', \n",
    "                     'peripheral_artery_disease', 'previously_treated_periphe', 'copd', 'history_of_cancer', \n",
    "                     'previous_pci', 'previous_cabg']\n",
    "\n",
    "intervention_cols = ['single_vessel', 'trifurcation', 'bifurcation_location', \n",
    "                  'lesion_ivolves', 'angle', 'calcium', 'trombosis', \n",
    "                  'total_trobotic_occlusion', 'restenosis_reocclusion', 'cto_bifurc', \n",
    "                  'medina_proximal', 'medina_distal', 'medina_side', 'mb_length_proximal', \n",
    "                  'sb_length', 'proximal_diametr', 'distal_diametr', 'side_diametr', 'stenosis_proximal', \n",
    "                  'stenosis_distal', 'timi_flow_main_branch', 'side_stenosis', 'timi_flow_side_branch', \n",
    "                  'major_lm', 'major_non_lm', 'minor_criteria', 'main_branch_rvd', 'def', 'def_2']\n",
    "\n",
    "operation_cols = ['side_protection', 'main_predilatation', 'side_predilat', \n",
    "                  'stent_was_implated_from_lm', 'stent_number', 'stent_number_bif', 'stent_technique', \n",
    "                  'first_stent_impanted', 'provisional_2_stent_techni', 'stent_direction', 'defered_stenting', \n",
    "                  'stent_diameter', 'stent_length', 'stent_type___1', 'stent_type___2', 'stent_type___3', \n",
    "                  'stent_type___4', 'stent_type___5', 'stent_type___6', 'stent_type___7', 'stent_type___9', \n",
    "                  'stent_type___8', 'dstent2', 'stent_length2', 'stent_distal_vessel_size', \n",
    "                  'sb_stent_side_branch_diametr', 'sb_stent_sb_diametr', 'twostent_technique', \n",
    "                  'sb_dilatation', 'stent_postdilatation', 'proximal_optimization', 'pot', \n",
    "                  'pot_balloon_diametr', 'kissing_post', 'modified_kis', 'several_kissing']\n",
    "\n",
    "new_cols = ['adverse_event_followup_f2_v2', 'angio_follow_f5', 'antiplatalet_drug_was_chan',\n",
    "            'attempt_to_dilate_stenting', 'ballooon_size_for_postdila', 'complete_revascularisation',\n",
    "            'currently_on_dialysis', 'followup_1_year_do_not_complete_if_2nd_bifurcation_complete',\n",
    "            'identifier', 'ishemia_test___1', 'ishemia_test___2', 'ishemia_test___3', 'ishemia_test___4',\n",
    "            'kissing_post_2stent___1', 'kissing_post_2stent___2', 'left_main_stent_direction',\n",
    "            'main_branch_calcification', 'mb_stenosis_f2', 'medina_side_branch_2', 'myocardial_ischemia',\n",
    "            'myocardial_ishemia_was_det', 'number_of_kissing', 'number_of_kissing_2',\n",
    "            'other_lesions_in_main_bran', 'other_lesions_in_side_brach',\n",
    "            'patient_information_do_not_complete_if_2nd_bifurca_complete', 'pot_2', 'pot_balloon_diametr_2',\n",
    "            'pot_balloon_length', 'pot_balloon_length_2', 'pressure2', 'reson_for_change_stopped___1',\n",
    "            'reson_for_change_stopped___2', 'reson_for_change_stopped___3', 'restenosis_f5', 'sb_length_2',\n",
    "            'sb_stenosis_f2', 'side_branch_calcification_2', 'side_branch_restenosis',\n",
    "            'side_branch_restenosis_3', 'side_branch_restenosis_5', 'stent_pressure', 'stent_type_2___1',\n",
    "            'stent_type_2___2', 'stent_type_2___3', 'stent_type_2___4', 'stent_type_2___5', 'stent_type_2___6',\n",
    "            'stent_type_2___7', 'stent_type_2___8', 'stent_type_2___9', 'thrombolysis', 'uncross_strategy___1',\n",
    "            'uncross_strategy___2', 'uncross_strategy___3', 'uncross_strategy___4', 'uncross_strategy___5',\n",
    "            'uncross_strategy___6', 'uncross_strategy___7', 'uncross_strategy___8', 'uncross_strategy___9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f17f5b-f845-4cc7-a1ed-11412eff10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vascular_deaths = ['MNRI1054', 'MNRI1191', 'MNRI1351', 'MNRI1352', 'MNRI1473', 'MNRI1670', 'MNRI0637', 'MNRI0656', 'MNRI0751', 'MNRI0758',\n",
    "                      'MNRI0805', 'MNRI0818', 'MNRI1054', 'MNRI0087', 'MNRI1191', 'MNRI0108', 'MNRI0307', 'MNRI0215', 'MNRI0322', 'MNRI0293',\n",
    "                      'MNRI0156', 'MNRI0215', 'MNRI0488', 'MNRI0612', 'MNRI0708', 'MNRI0767', 'MNRI0772', 'MNRI0786', 'MNRI1105', 'MNRI1186',\n",
    "                      'MNRI1462', 'MNRI1633']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919b17e8-d213-4c3f-a9e5-8d2830232086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['record_id'].isin(non_vascular_deaths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0036d868-3fbc-41a9-8233-74f2b4bfa68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>time_from_mi_symptoms_onse</th>\n",
       "      <th>...</th>\n",
       "      <th>time_to_death_f5</th>\n",
       "      <th>time_to_acs_f5</th>\n",
       "      <th>time_to_stroke_f5</th>\n",
       "      <th>time_to_pci_f5</th>\n",
       "      <th>time_to_cabg_f5</th>\n",
       "      <th>hospitalization_f5</th>\n",
       "      <th>bleeding_f5</th>\n",
       "      <th>angio_follow_f5</th>\n",
       "      <th>restenosis_f5</th>\n",
       "      <th>side_branch_restenosis_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>MNRI-2018-0001</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>MNRI-2018-0002</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>MNRI-2018-0003</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>MNRI-2018-0004</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>MNRI-2018-0005</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>TRCH-2019-0026</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>TRCH-2019-0027</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>TRCH-2019-0028</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>TRCH-2019-0029</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>TRCH-2019-0030</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id      identifier        date  adhoc_pci  sex   age  weight  \\\n",
       "0     MNRI0001  MNRI-2018-0001  2018-02-01        1.0  2.0  77.0    84.0   \n",
       "1     MNRI0002  MNRI-2018-0002  2018-01-24        0.0  1.0  68.0    81.0   \n",
       "2     MNRI0003  MNRI-2018-0003  2018-01-24        0.0  1.0  62.0    74.0   \n",
       "3     MNRI0004  MNRI-2018-0004  2018-01-30        1.0  1.0  67.0    84.0   \n",
       "4     MNRI0005  MNRI-2018-0005  2018-01-30        0.0  1.0  57.0   103.0   \n",
       "...        ...             ...         ...        ...  ...   ...     ...   \n",
       "2139  TRCH0026  TRCH-2019-0026  2019-03-11        1.0  1.0  67.0    90.0   \n",
       "2140  TRCH0027  TRCH-2019-0027  2019-03-18        1.0  1.0  69.0    60.0   \n",
       "2141  TRCH0028  TRCH-2019-0028  2019-03-19        0.0  2.0  81.0    50.0   \n",
       "2142  TRCH0029  TRCH-2019-0029  2019-03-28        1.0  1.0  86.0    74.0   \n",
       "2143  TRCH0030  TRCH-2019-0030  2019-03-20        1.0  2.0  85.0    60.0   \n",
       "\n",
       "      height  clinical_presentation  time_from_mi_symptoms_onse  ...  \\\n",
       "0      165.0                    5.0                         4.0  ...   \n",
       "1      171.0                    1.0                         NaN  ...   \n",
       "2      180.0                    4.0                         NaN  ...   \n",
       "3      167.0                    2.0                         NaN  ...   \n",
       "4      174.0                    1.0                         NaN  ...   \n",
       "...      ...                    ...                         ...  ...   \n",
       "2139   174.0                    2.0                         NaN  ...   \n",
       "2140   174.0                    3.0                         1.0  ...   \n",
       "2141   160.0                    2.0                         NaN  ...   \n",
       "2142   170.0                    3.0                         1.0  ...   \n",
       "2143   165.0                    3.0                         1.0  ...   \n",
       "\n",
       "      time_to_death_f5  time_to_acs_f5  time_to_stroke_f5  time_to_pci_f5  \\\n",
       "0                  NaN             NaN                NaN             NaN   \n",
       "1                  NaN             NaN                NaN             NaN   \n",
       "2                  NaN             NaN                NaN             NaN   \n",
       "3                  NaN             NaN                NaN             NaN   \n",
       "4                  NaN             NaN                NaN             NaN   \n",
       "...                ...             ...                ...             ...   \n",
       "2139               NaN             NaN                NaN             NaN   \n",
       "2140               NaN             NaN                NaN             NaN   \n",
       "2141               NaN             NaN                NaN             NaN   \n",
       "2142               NaN             NaN                NaN             NaN   \n",
       "2143               NaN             NaN                NaN             NaN   \n",
       "\n",
       "      time_to_cabg_f5  hospitalization_f5  bleeding_f5  angio_follow_f5  \\\n",
       "0                 NaN                 NaN          NaN              NaN   \n",
       "1                 NaN                 NaN          NaN              NaN   \n",
       "2                 NaN                 NaN          NaN              NaN   \n",
       "3                 NaN                 NaN          NaN              NaN   \n",
       "4                 NaN                 NaN          NaN              NaN   \n",
       "...               ...                 ...          ...              ...   \n",
       "2139              NaN                 NaN          NaN              NaN   \n",
       "2140              NaN                 NaN          NaN              NaN   \n",
       "2141              NaN                 NaN          NaN              NaN   \n",
       "2142              NaN                 NaN          NaN              NaN   \n",
       "2143              NaN                 NaN          NaN              NaN   \n",
       "\n",
       "      restenosis_f5  side_branch_restenosis_5  \n",
       "0               NaN                       NaN  \n",
       "1               NaN                       NaN  \n",
       "2               NaN                       NaN  \n",
       "3               NaN                       NaN  \n",
       "4               NaN                       NaN  \n",
       "...             ...                       ...  \n",
       "2139            NaN                       NaN  \n",
       "2140            NaN                       NaN  \n",
       "2141            NaN                       NaN  \n",
       "2142            NaN                       NaN  \n",
       "2143            NaN                       NaN  \n",
       "\n",
       "[2044 rows x 283 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54ed796c-3a11-4ae5-9a06-ce34a86ef85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_present_cols = patient_info_cols + intervention_cols + operation_cols + new_cols\n",
    "patient_present_df = pd.DataFrame({col_name: df[col_name] for col_name in patient_present_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d40ace-88e7-42a4-9bbe-8bba2ee2cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>time_from_mi_symptoms_onse</th>\n",
       "      <th>ccs_class</th>\n",
       "      <th>...</th>\n",
       "      <th>thrombolysis</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___5</th>\n",
       "      <th>uncross_strategy___6</th>\n",
       "      <th>uncross_strategy___7</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id        date  sex   age  adhoc_pci  weight  height  \\\n",
       "0     MNRI0001  2018-02-01  2.0  77.0        1.0    84.0   165.0   \n",
       "1     MNRI0002  2018-01-24  1.0  68.0        0.0    81.0   171.0   \n",
       "2     MNRI0003  2018-01-24  1.0  62.0        0.0    74.0   180.0   \n",
       "3     MNRI0004  2018-01-30  1.0  67.0        1.0    84.0   167.0   \n",
       "4     MNRI0005  2018-01-30  1.0  57.0        0.0   103.0   174.0   \n",
       "...        ...         ...  ...   ...        ...     ...     ...   \n",
       "2139  TRCH0026  2019-03-11  1.0  67.0        1.0    90.0   174.0   \n",
       "2140  TRCH0027  2019-03-18  1.0  69.0        1.0    60.0   174.0   \n",
       "2141  TRCH0028  2019-03-19  2.0  81.0        0.0    50.0   160.0   \n",
       "2142  TRCH0029  2019-03-28  1.0  86.0        1.0    74.0   170.0   \n",
       "2143  TRCH0030  2019-03-20  2.0  85.0        1.0    60.0   165.0   \n",
       "\n",
       "      clinical_presentation  time_from_mi_symptoms_onse  ccs_class  ...  \\\n",
       "0                       5.0                         4.0        NaN  ...   \n",
       "1                       1.0                         NaN        1.0  ...   \n",
       "2                       4.0                         NaN        NaN  ...   \n",
       "3                       2.0                         NaN        NaN  ...   \n",
       "4                       1.0                         NaN        2.0  ...   \n",
       "...                     ...                         ...        ...  ...   \n",
       "2139                    2.0                         NaN        NaN  ...   \n",
       "2140                    3.0                         1.0        NaN  ...   \n",
       "2141                    2.0                         NaN        NaN  ...   \n",
       "2142                    3.0                         1.0        NaN  ...   \n",
       "2143                    3.0                         1.0        NaN  ...   \n",
       "\n",
       "      thrombolysis  uncross_strategy___1  uncross_strategy___2  \\\n",
       "0              0.0                     0                     0   \n",
       "1              NaN                     0                     0   \n",
       "2              NaN                     0                     0   \n",
       "3              NaN                     0                     0   \n",
       "4              NaN                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "2139           0.0                     0                     0   \n",
       "2140           1.0                     0                     0   \n",
       "2141           0.0                     0                     0   \n",
       "2142           0.0                     0                     0   \n",
       "2143           0.0                     0                     0   \n",
       "\n",
       "      uncross_strategy___3  uncross_strategy___4  uncross_strategy___5  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___6  uncross_strategy___7  uncross_strategy___8  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___9  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "2139                     0  \n",
       "2140                     0  \n",
       "2141                     0  \n",
       "2142                     0  \n",
       "2143                     0  \n",
       "\n",
       "[2044 rows x 166 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_present_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8476c240-9824-49c9-90d8-62e1b6b9637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preserve = ['valvular_disease', 'previous_stroke_tia', 'twostent_technique']\n",
    "\n",
    "def remove_columns_with_nan_threshold(df, threshold=250):\n",
    "    nan_counts = df.isnull().sum()\n",
    "    \n",
    "    columns_to_drop = [col for col in nan_counts[nan_counts > threshold].index \n",
    "                      if col not in columns_to_preserve]\n",
    "    \n",
    "    print(columns_to_drop)\n",
    "    \n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c4ca11-6dd2-4d63-bab1-e512fb1885e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_from_mi_symptoms_onse', 'ccs_class', 'insulin_diabetes', 'valvular_disease_was_previ', 'previously_treated_cerebro', 'previously_treated_periphe', 'lesion_ivolves', 'total_trobotic_occlusion', 'sb_length', 'timi_flow_main_branch', 'timi_flow_side_branch', 'stent_was_implated_from_lm', 'first_stent_impanted', 'provisional_2_stent_techni', 'dstent2', 'stent_length2', 'sb_stent_side_branch_diametr', 'proximal_optimization', 'pot', 'pot_balloon_diametr', 'several_kissing', 'adverse_event_followup_f2_v2', 'angio_follow_f5', 'antiplatalet_drug_was_chan', 'attempt_to_dilate_stenting', 'ballooon_size_for_postdila', 'complete_revascularisation', 'left_main_stent_direction', 'main_branch_calcification', 'mb_stenosis_f2', 'medina_side_branch_2', 'myocardial_ischemia', 'myocardial_ishemia_was_det', 'number_of_kissing', 'number_of_kissing_2', 'other_lesions_in_main_bran', 'other_lesions_in_side_brach', 'pot_2', 'pot_balloon_diametr_2', 'pot_balloon_length', 'pot_balloon_length_2', 'pressure2', 'restenosis_f5', 'sb_length_2', 'sb_stenosis_f2', 'side_branch_calcification_2', 'side_branch_restenosis', 'side_branch_restenosis_3', 'side_branch_restenosis_5', 'stent_pressure', 'thrombolysis']\n"
     ]
    }
   ],
   "source": [
    "patient_present_df = remove_columns_with_nan_threshold(patient_present_df, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d3b8e0-25ea-46a4-82de-2a9aad43fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_type_2___9</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___5</th>\n",
       "      <th>uncross_strategy___6</th>\n",
       "      <th>uncross_strategy___7</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  sex   age  adhoc_pci  weight  height  clinical_presentation  \\\n",
       "0     MNRI0001  2.0  77.0        1.0    84.0   165.0                    5.0   \n",
       "1     MNRI0002  1.0  68.0        0.0    81.0   171.0                    1.0   \n",
       "2     MNRI0003  1.0  62.0        0.0    74.0   180.0                    4.0   \n",
       "3     MNRI0004  1.0  67.0        1.0    84.0   167.0                    2.0   \n",
       "4     MNRI0005  1.0  57.0        0.0   103.0   174.0                    1.0   \n",
       "...        ...  ...   ...        ...     ...     ...                    ...   \n",
       "2139  TRCH0026  1.0  67.0        1.0    90.0   174.0                    2.0   \n",
       "2140  TRCH0027  1.0  69.0        1.0    60.0   174.0                    3.0   \n",
       "2141  TRCH0028  2.0  81.0        0.0    50.0   160.0                    2.0   \n",
       "2142  TRCH0029  1.0  86.0        1.0    74.0   170.0                    3.0   \n",
       "2143  TRCH0030  2.0  85.0        1.0    60.0   165.0                    3.0   \n",
       "\n",
       "      diabet  hypertension  smoking  ...  stent_type_2___9  \\\n",
       "0        0.0           1.0      0.0  ...                 0   \n",
       "1        0.0           1.0      0.0  ...                 0   \n",
       "2        0.0           1.0      1.0  ...                 0   \n",
       "3        0.0           1.0      0.0  ...                 0   \n",
       "4        0.0           1.0      0.0  ...                 0   \n",
       "...      ...           ...      ...  ...               ...   \n",
       "2139     2.0           1.0      0.0  ...                 0   \n",
       "2140     1.0           1.0      0.0  ...                 0   \n",
       "2141     2.0           1.0      0.0  ...                 0   \n",
       "2142     1.0           1.0      0.0  ...                 0   \n",
       "2143     1.0           1.0      0.0  ...                 0   \n",
       "\n",
       "      uncross_strategy___1  uncross_strategy___2  uncross_strategy___3  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___4  uncross_strategy___5  uncross_strategy___6  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___7  uncross_strategy___8  uncross_strategy___9  \n",
       "0                        0                     0                     0  \n",
       "1                        0                     0                     0  \n",
       "2                        0                     0                     0  \n",
       "3                        0                     0                     0  \n",
       "4                        0                     0                     0  \n",
       "...                    ...                   ...                   ...  \n",
       "2139                     0                     0                     0  \n",
       "2140                     0                     0                     0  \n",
       "2141                     0                     0                     0  \n",
       "2142                     0                     0                     0  \n",
       "2143                     0                     0                     0  \n",
       "\n",
       "[2044 rows x 114 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# patient_present_df = patient_present_df.drop(['record_id', 'date'], axis = 1)\n",
    "patient_present_df = patient_present_df.drop(['date'], axis = 1)\n",
    "patient_present_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4530ff9c-7647-4b92-bcfe-f32827dfd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_present_df.replace(to_replace = [np.inf, -np.inf], value= None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e4c1360-60bd-4e4c-a121-104724859e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_type_2___5</th>\n",
       "      <th>stent_type_2___6</th>\n",
       "      <th>stent_type_2___7</th>\n",
       "      <th>stent_type_2___8</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  sex   age adhoc_pci weight height clinical_presentation  \\\n",
       "0     MNRI0001  2.0  77.0       1.0   84.0  165.0                   5.0   \n",
       "1     MNRI0002  1.0  68.0       0.0   81.0  171.0                   1.0   \n",
       "2     MNRI0003  1.0  62.0       0.0   74.0  180.0                   4.0   \n",
       "3     MNRI0004  1.0  67.0       1.0   84.0  167.0                   2.0   \n",
       "4     MNRI0005  1.0  57.0       0.0  103.0  174.0                   1.0   \n",
       "...        ...  ...   ...       ...    ...    ...                   ...   \n",
       "2139  TRCH0026  1.0  67.0       1.0   90.0  174.0                   2.0   \n",
       "2140  TRCH0027  1.0  69.0       1.0   60.0  174.0                   3.0   \n",
       "2141  TRCH0028  2.0  81.0       0.0   50.0  160.0                   2.0   \n",
       "2142  TRCH0029  1.0  86.0       1.0   74.0  170.0                   3.0   \n",
       "2143  TRCH0030  2.0  85.0       1.0   60.0  165.0                   3.0   \n",
       "\n",
       "     diabet hypertension smoking  ... stent_type_2___5 stent_type_2___6  \\\n",
       "0       0.0          1.0     0.0  ...                0                0   \n",
       "1       0.0          1.0     0.0  ...                0                0   \n",
       "2       0.0          1.0     1.0  ...                0                0   \n",
       "3       0.0          1.0     0.0  ...                0                0   \n",
       "4       0.0          1.0     0.0  ...                0                0   \n",
       "...     ...          ...     ...  ...              ...              ...   \n",
       "2139    2.0          1.0     0.0  ...                0                0   \n",
       "2140    1.0          1.0     0.0  ...                0                0   \n",
       "2141    2.0          1.0     0.0  ...                0                0   \n",
       "2142    1.0          1.0     0.0  ...                0                0   \n",
       "2143    1.0          1.0     0.0  ...                0                0   \n",
       "\n",
       "     stent_type_2___7 stent_type_2___8 uncross_strategy___1  \\\n",
       "0                   0                0                    0   \n",
       "1                   0                0                    0   \n",
       "2                   0                0                    0   \n",
       "3                   0                0                    0   \n",
       "4                   0                0                    0   \n",
       "...               ...              ...                  ...   \n",
       "2139                0                0                    0   \n",
       "2140                0                0                    0   \n",
       "2141                0                0                    0   \n",
       "2142                0                0                    0   \n",
       "2143                0                0                    0   \n",
       "\n",
       "      uncross_strategy___2  uncross_strategy___3  uncross_strategy___4  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___8  uncross_strategy___9  \n",
       "0                        0                     0  \n",
       "1                        0                     0  \n",
       "2                        0                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  \n",
       "...                    ...                   ...  \n",
       "2139                     0                     0  \n",
       "2140                     0                     0  \n",
       "2141                     0                     0  \n",
       "2142                     0                     0  \n",
       "2143                     0                     0  \n",
       "\n",
       "[2044 rows x 106 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = patient_present_df.columns[patient_present_df.nunique() <= 1]\n",
    "patient_present_df = patient_present_df.drop(cols_to_drop, axis=1)\n",
    "patient_present_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac363f7d-c2e1-454b-ade5-647b07eea73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'weight', 'height', 'ef', 'creatinine', 'ckd', 'angle', 'mb_length_proximal', \n",
    "            'proximal_diametr', 'distal_diametr', 'side_diametr', 'stenosis_proximal', \n",
    "            'stenosis_distal', 'side_stenosis', 'minor_criteria', 'main_branch_rvd', \n",
    "            'stent_diameter', 'stent_length', 'stent_distal_vessel_size', 'sb_stent_sb_diametr',\n",
    "            'ballooon_size_for_postdila', \n",
    "            'left_main_stent_direction',\n",
    "            'mb_stenosis_f2',\n",
    "            'myocardial_ischemia',\n",
    "            'number_of_kissing_2',\n",
    "            'pot_balloon_diametr_2',\n",
    "            'pot_balloon_length',\n",
    "            'pot_balloon_length_2',\n",
    "            'pressure2',\n",
    "            'sb_length_2',\n",
    "            'sb_stenosis_f2',\n",
    "            'stent_pressure']\n",
    "\n",
    "categorical = ['sex', 'clinical_presentation', 'bifurcation_location', 'stent_number', \n",
    "              'stent_number_bif', 'stent_technique', 'stent_direction']\n",
    "\n",
    "binary = ['diabet', 'adhoc_pci', 'hypertension', 'smoking', 'dyslipidemia', 'anemia', \n",
    "         'atrial_fibrilation', 'oac_use', 'if_yes_what_type___1', 'if_yes_what_type___2',\n",
    "         'if_yes_what_type___3', 'if_yes_what_type___4', 'if_yes_what_type___6', \n",
    "         'mi_history', 'cerebrovascular_disease', 'peripheral_artery_disease', 'copd', \n",
    "         'history_of_cancer', 'previous_pci', 'previous_cabg', 'single_vessel', 'trifurcation',\n",
    "         'calcium', 'trombosis', 'restenosis_reocclusion', 'cto_bifurc', \n",
    "         'medina_proximal', 'medina_distal', 'medina_side', 'major_lm', 'major_non_lm',\n",
    "         'def', 'def_2', 'side_protection', 'main_predilatation', 'side_predilat',\n",
    "         'defered_stenting', 'stent_type___1', 'stent_type___2', 'stent_type___3', 'stent_type___4',\n",
    "         'stent_type___5', 'stent_type___6', 'stent_type___7', 'stent_type___9', 'stent_type___8', \n",
    "         'sb_dilatation', 'stent_postdilatation', 'kissing_post', 'modified_kis',\n",
    "         'currently_on_dialysis',\n",
    "         'ishemia_test___1',\n",
    "         'ishemia_test___2',\n",
    "         'ishemia_test___3',\n",
    "         'kissing_post_2stent___1',\n",
    "         'kissing_post_2stent___2',\n",
    "         'reson_for_change_stopped___1',\n",
    "         'reson_for_change_stopped___2',\n",
    "         'reson_for_change_stopped___3',\n",
    "         'stent_type_2___1',\n",
    "         'stent_type_2___3',\n",
    "         'stent_type_2___4',\n",
    "         'stent_type_2___5',\n",
    "         'stent_type_2___6',\n",
    "         'stent_type_2___7',\n",
    "         'stent_type_2___8',\n",
    "         'uncross_strategy___1',\n",
    "         'uncross_strategy___2',\n",
    "         'uncross_strategy___3',\n",
    "         'uncross_strategy___4',\n",
    "         'uncross_strategy___8',\n",
    "         'uncross_strategy___9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "682e6eba-c34d-4403-8c8a-0b18b8524eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "2044\n"
     ]
    }
   ],
   "source": [
    "without_second_bif = df\n",
    "adverse_events = without_second_bif['event_type_followup_f2___1'] \\\n",
    "| without_second_bif['event_type_followup_f2___2'] \\\n",
    "| without_second_bif['event_type_followup_f2_v2___1'] \\\n",
    "| without_second_bif['event_type_followup_f2_v2___2']\n",
    "print(sum(adverse_events))\n",
    "print(len(adverse_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392297cc-7b3c-4163-aab4-3fe78b238a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = zip(without_second_bif['event_type_followup_f2___1'],  \n",
    "               without_second_bif['event_type_followup_f2___2'] * 2,\n",
    "               without_second_bif['event_type_followup_f2_v2___1'] * 3, \n",
    "               without_second_bif['event_type_followup_f2_v2___2'] * 4)\n",
    "\n",
    "combined_adverse_events = np.array([max(t) for t in combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e150a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1886, 1: 53, 2: 18, 3: 51, 4: 36}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(combined_adverse_events, return_counts=True)\n",
    "value_counts = dict(zip(unique, counts))\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90f2ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = patient_present_df['record_id']\n",
    "patient_present_df = patient_present_df.drop(['record_id', 'identifier'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c564a98-2d4b-441b-8bd9-02e28b1ada94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(patient_present_df, combined_adverse_events, test_size=0.4, stratify=combined_adverse_events, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a3a02b-88af-47bf-8034-6b01e6a6e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train != 0] = 1\n",
    "y_test[y_test != 0] = 1\n",
    "y_val[y_val != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9790db4c-5a0c-43dd-835f-fa1b8350cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_type_2___5</th>\n",
       "      <th>stent_type_2___6</th>\n",
       "      <th>stent_type_2___7</th>\n",
       "      <th>stent_type_2___8</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.535524</td>\n",
       "      <td>172.093993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  adhoc_pci      weight      height  clinical_presentation  \\\n",
       "0     1.0  41.0        0.0  100.000000  177.000000                    5.0   \n",
       "1     1.0  56.0        1.0   81.000000  172.000000                    4.0   \n",
       "2     1.0  55.0        1.0   87.535524  172.093993                    3.0   \n",
       "3     1.0  79.0        0.0   61.000000  160.000000                    1.0   \n",
       "4     1.0  61.0        1.0   84.000000  179.000000                    2.0   \n",
       "...   ...   ...        ...         ...         ...                    ...   \n",
       "1221  2.0  69.0        0.0  111.000000  159.000000                    1.0   \n",
       "1222  1.0  57.0        0.0   96.000000  178.000000                    1.0   \n",
       "1223  1.0  63.0        0.0   80.000000  162.000000                    1.0   \n",
       "1224  1.0  75.0        0.0  165.000000   71.000000                    1.0   \n",
       "1225  1.0  46.0        0.0  107.000000  179.000000                    2.0   \n",
       "\n",
       "      diabet  hypertension  smoking  dyslipidemia  ...  stent_type_2___5  \\\n",
       "0        0.0           1.0      0.0           0.0  ...               0.0   \n",
       "1        0.0           1.0      0.0           0.0  ...               0.0   \n",
       "2        0.0           1.0      0.0           1.0  ...               0.0   \n",
       "3        0.0           1.0      0.0           0.0  ...               0.0   \n",
       "4        1.0           1.0      0.0           0.0  ...               0.0   \n",
       "...      ...           ...      ...           ...  ...               ...   \n",
       "1221     2.0           0.0      0.0           0.0  ...               0.0   \n",
       "1222     1.0           1.0      0.0           0.0  ...               0.0   \n",
       "1223     1.0           1.0      0.0           0.0  ...               0.0   \n",
       "1224     0.0           1.0      1.0           1.0  ...               0.0   \n",
       "1225     1.0           1.0      0.0           0.0  ...               0.0   \n",
       "\n",
       "      stent_type_2___6  stent_type_2___7  stent_type_2___8  \\\n",
       "0                  0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0   \n",
       "2                  0.0               0.0               0.0   \n",
       "3                  0.0               0.0               0.0   \n",
       "4                  0.0               0.0               0.0   \n",
       "...                ...               ...               ...   \n",
       "1221               1.0               0.0               0.0   \n",
       "1222               0.0               0.0               0.0   \n",
       "1223               0.0               0.0               0.0   \n",
       "1224               0.0               0.0               0.0   \n",
       "1225               0.0               0.0               0.0   \n",
       "\n",
       "      uncross_strategy___1  uncross_strategy___2  uncross_strategy___3  \\\n",
       "0                      0.0                   0.0                   0.0   \n",
       "1                      0.0                   0.0                   0.0   \n",
       "2                      0.0                   0.0                   0.0   \n",
       "3                      1.0                   0.0                   0.0   \n",
       "4                      0.0                   0.0                   0.0   \n",
       "...                    ...                   ...                   ...   \n",
       "1221                   0.0                   0.0                   0.0   \n",
       "1222                   0.0                   0.0                   0.0   \n",
       "1223                   0.0                   0.0                   0.0   \n",
       "1224                   0.0                   0.0                   0.0   \n",
       "1225                   0.0                   0.0                   0.0   \n",
       "\n",
       "      uncross_strategy___4  uncross_strategy___8  uncross_strategy___9  \n",
       "0                      0.0                   0.0                   0.0  \n",
       "1                      0.0                   0.0                   0.0  \n",
       "2                      0.0                   0.0                   0.0  \n",
       "3                      0.0                   0.0                   0.0  \n",
       "4                      0.0                   0.0                   0.0  \n",
       "...                    ...                   ...                   ...  \n",
       "1221                   0.0                   0.0                   0.0  \n",
       "1222                   0.0                   0.0                   0.0  \n",
       "1223                   0.0                   0.0                   0.0  \n",
       "1224                   0.0                   0.0                   0.0  \n",
       "1225                   0.0                   0.0                   0.0  \n",
       "\n",
       "[1226 rows x 104 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "X_train[categorical + binary] = imputer_categorical.fit_transform(X_train[categorical + binary])\n",
    "X_test[categorical + binary] = imputer_categorical.transform(X_test[categorical + binary])\n",
    "X_val[categorical + binary] = imputer_categorical.transform(X_val[categorical + binary])\n",
    "\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "columns = list(X_train.columns)\n",
    "X_train = pd.DataFrame(data = imputer.fit_transform(X_train), columns = columns)\n",
    "X_test = pd.DataFrame(data = imputer.transform(X_test), columns = columns)\n",
    "X_val = pd.DataFrame(data = imputer.transform(X_val), columns = columns)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81e4d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_ID = X_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2248445-abc7-459d-a11d-b96aaaf3a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(sparse_output=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse_output=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "df_for_ohe = pd.concat([X_train[categorical], X_test[categorical], X_val[categorical]], ignore_index=True)\n",
    "ohe.fit(df_for_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79bb5945-57d1-419b-86d7-b3e30ead8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ohe(dataframe, cat_cols, encoder):\n",
    "    encoded_columns = pd.DataFrame(encoder.transform(dataframe[cat_cols]))\n",
    "\n",
    "    encoded_columns.columns = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, encoded_columns], axis=1)\n",
    "\n",
    "    dataframe.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5646ef41-c36f-44a8-9c7f-fa0380d3a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = process_ohe(X_train, categorical, ohe)\n",
    "# X_test = process_ohe(X_test, categorical, ohe)\n",
    "# X_val = process_ohe(X_val, categorical, ohe)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d657171-41bf-45cc-b1c5-8351f3ee4e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [84] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=40)\n",
    "X_feature_selection = feature_selector.fit_transform(X_train, y_train)\n",
    "X_feature_selection.shape\n",
    "\n",
    "strong_cols = []\n",
    "\n",
    "feature_scores = feature_selector.scores_\n",
    "features = X_train.columns\n",
    "features_scores_sorted = sorted(zip(features, feature_scores), key=lambda x: x[1], reverse=True)\n",
    "for col in features_scores_sorted[:30]:\n",
    "    strong_cols.append(col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da096ae3-3e61-4712-b392-b4bd6c2c3739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>ckd</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>...</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>valvular_disease</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>major_lm</th>\n",
       "      <th>mi_history</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.130343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.132035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.364633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.542788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.329657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.608441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048430</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.707072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.111321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.979615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.632809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  anemia    ef  cerebrovascular_disease         ckd  \\\n",
       "0     41.0     0.0  49.0                      0.0   91.130343   \n",
       "1     56.0     0.0  68.0                      0.0   83.132035   \n",
       "2     55.0     0.0  70.0                      0.0   78.364633   \n",
       "3     79.0     0.0  73.0                      1.0   64.542788   \n",
       "4     61.0     0.0  62.0                      0.0   87.329657   \n",
       "...    ...     ...   ...                      ...         ...   \n",
       "1221  69.0     0.0  60.0                      0.0   69.608441   \n",
       "1222  57.0     0.0  39.0                      0.0   53.707072   \n",
       "1223  63.0     1.0  71.0                      0.0   86.111321   \n",
       "1224  75.0     0.0  69.0                      1.0   68.979615   \n",
       "1225  46.0     0.0  64.0                      0.0  103.632809   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  creatinine  \\\n",
       "0                           0.0                   0.0        90.0   \n",
       "1                           0.0                   0.0        89.0   \n",
       "2                           0.0                   0.0        94.0   \n",
       "3                           0.0                   0.0        96.0   \n",
       "4                           0.0                   0.0        83.0   \n",
       "...                         ...                   ...         ...   \n",
       "1221                        0.0                   0.0        97.0   \n",
       "1222                        0.0                   0.0       127.0   \n",
       "1223                        0.0                   0.0        83.0   \n",
       "1224                        1.0                   0.0        93.0   \n",
       "1225                        0.0                   0.0        76.0   \n",
       "\n",
       "      single_vessel  calcium  ...  adhoc_pci  previous_pci  cto_bifurc  \\\n",
       "0               0.0      0.0  ...        0.0           1.0         0.0   \n",
       "1               1.0      0.0  ...        1.0           1.0         0.0   \n",
       "2               1.0      0.0  ...        1.0           0.0         0.0   \n",
       "3               0.0      1.0  ...        0.0           0.0         0.0   \n",
       "4               0.0      0.0  ...        1.0           0.0         0.0   \n",
       "...             ...      ...  ...        ...           ...         ...   \n",
       "1221            1.0      0.0  ...        0.0           1.0         0.0   \n",
       "1222            0.0      0.0  ...        0.0           0.0         0.0   \n",
       "1223            1.0      0.0  ...        0.0           1.0         0.0   \n",
       "1224            1.0      0.0  ...        0.0           1.0         0.0   \n",
       "1225            1.0      0.0  ...        0.0           1.0         0.0   \n",
       "\n",
       "      valvular_disease  side_diametr  major_lm  mi_history  trifurcation  \\\n",
       "0             0.000000           2.4       0.0         1.0           0.0   \n",
       "1             0.000000           3.0       0.0         1.0           0.0   \n",
       "2             0.000000           2.4       0.0         0.0           0.0   \n",
       "3             0.000000           3.1       0.0         0.0           0.0   \n",
       "4             0.000000           2.5       0.0         0.0           0.0   \n",
       "...                ...           ...       ...         ...           ...   \n",
       "1221         -0.048430           2.7       0.0         0.0           0.0   \n",
       "1222          0.005881           2.4       0.0         0.0           1.0   \n",
       "1223          0.000000           2.2       0.0         0.0           0.0   \n",
       "1224          0.000000           2.4       0.0         0.0           0.0   \n",
       "1225          0.000000           2.6       0.0         1.0           0.0   \n",
       "\n",
       "      dyslipidemia  smoking  \n",
       "0              0.0      0.0  \n",
       "1              0.0      0.0  \n",
       "2              1.0      0.0  \n",
       "3              0.0      0.0  \n",
       "4              0.0      0.0  \n",
       "...            ...      ...  \n",
       "1221           0.0      0.0  \n",
       "1222           0.0      0.0  \n",
       "1223           0.0      0.0  \n",
       "1224           1.0      1.0  \n",
       "1225           0.0      0.0  \n",
       "\n",
       "[1226 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[strong_cols]\n",
    "X_test = X_test[strong_cols]\n",
    "X_val = X_val[strong_cols]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d3e931-a486-4727-bb1b-b0d6d637b31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ckd',\n",
       " 'creatinine',\n",
       " 'side_stenosis',\n",
       " 'minor_criteria',\n",
       " 'adhoc_pci',\n",
       " 'valvular_disease',\n",
       " 'major_lm',\n",
       " 'mi_history']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "threshold = 0.4\n",
    "\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "079afc5b-4582-4b78-95b6-db4228fe6771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  anemia    ef  cerebrovascular_disease  peripheral_artery_disease  \\\n",
       "0     41.0     0.0  49.0                      0.0                        0.0   \n",
       "1     56.0     0.0  68.0                      0.0                        0.0   \n",
       "2     55.0     0.0  70.0                      0.0                        0.0   \n",
       "3     79.0     0.0  73.0                      1.0                        0.0   \n",
       "4     61.0     0.0  62.0                      0.0                        0.0   \n",
       "...    ...     ...   ...                      ...                        ...   \n",
       "1221  69.0     0.0  60.0                      0.0                        0.0   \n",
       "1222  57.0     0.0  39.0                      0.0                        0.0   \n",
       "1223  63.0     1.0  71.0                      0.0                        0.0   \n",
       "1224  75.0     0.0  69.0                      1.0                        1.0   \n",
       "1225  46.0     0.0  64.0                      0.0                        0.0   \n",
       "\n",
       "      if_yes_what_type___1  single_vessel  calcium  stent_type___3  \\\n",
       "0                      0.0            0.0      0.0             1.0   \n",
       "1                      0.0            1.0      0.0             0.0   \n",
       "2                      0.0            1.0      0.0             0.0   \n",
       "3                      0.0            0.0      1.0             0.0   \n",
       "4                      0.0            0.0      0.0             0.0   \n",
       "...                    ...            ...      ...             ...   \n",
       "1221                   0.0            1.0      0.0             0.0   \n",
       "1222                   0.0            0.0      0.0             1.0   \n",
       "1223                   0.0            1.0      0.0             1.0   \n",
       "1224                   0.0            1.0      0.0             1.0   \n",
       "1225                   0.0            1.0      0.0             0.0   \n",
       "\n",
       "      medina_side  ...  def  history_of_cancer  previous_stroke_tia  \\\n",
       "0             0.0  ...  0.0                0.0             0.477395   \n",
       "1             1.0  ...  0.0                1.0             0.313995   \n",
       "2             0.0  ...  0.0                0.0             0.478905   \n",
       "3             0.0  ...  0.0                0.0             0.000000   \n",
       "4             0.0  ...  0.0                1.0             0.448962   \n",
       "...           ...  ...  ...                ...                  ...   \n",
       "1221          0.0  ...  0.0                0.0             0.525775   \n",
       "1222          0.0  ...  0.0                0.0             0.616766   \n",
       "1223          0.0  ...  0.0                0.0             0.429977   \n",
       "1224          0.0  ...  0.0                0.0             1.000000   \n",
       "1225          1.0  ...  0.0                1.0             0.317877   \n",
       "\n",
       "      clinical_presentation  previous_pci  cto_bifurc  side_diametr  \\\n",
       "0                       5.0           1.0         0.0           2.4   \n",
       "1                       4.0           1.0         0.0           3.0   \n",
       "2                       3.0           0.0         0.0           2.4   \n",
       "3                       1.0           0.0         0.0           3.1   \n",
       "4                       2.0           0.0         0.0           2.5   \n",
       "...                     ...           ...         ...           ...   \n",
       "1221                    1.0           1.0         0.0           2.7   \n",
       "1222                    1.0           0.0         0.0           2.4   \n",
       "1223                    1.0           1.0         0.0           2.2   \n",
       "1224                    1.0           1.0         0.0           2.4   \n",
       "1225                    2.0           1.0         0.0           2.6   \n",
       "\n",
       "      trifurcation  dyslipidemia  smoking  \n",
       "0              0.0           0.0      0.0  \n",
       "1              0.0           0.0      0.0  \n",
       "2              0.0           1.0      0.0  \n",
       "3              0.0           0.0      0.0  \n",
       "4              0.0           0.0      0.0  \n",
       "...            ...           ...      ...  \n",
       "1221           0.0           0.0      0.0  \n",
       "1222           1.0           0.0      0.0  \n",
       "1223           0.0           0.0      0.0  \n",
       "1224           0.0           1.0      1.0  \n",
       "1225           0.0           0.0      0.0  \n",
       "\n",
       "[1226 rows x 22 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "X_val = X_val.drop(columns=to_drop)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91cd1931-9181-4f79-a8c1-6c41c5987479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226, 22)\n",
      "(409, 22)\n",
      "(409, 22)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d644311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anemia', 'ef', 'cerebrovascular_disease',\n",
      "       'peripheral_artery_disease', 'if_yes_what_type___1', 'single_vessel',\n",
      "       'calcium', 'stent_type___3', 'medina_side', 'atrial_fibrilation',\n",
      "       'height', 'def', 'history_of_cancer', 'previous_stroke_tia',\n",
      "       'clinical_presentation', 'previous_pci', 'cto_bifurc', 'side_diametr',\n",
      "       'trifurcation', 'dyslipidemia', 'smoking'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b42b25c",
   "metadata": {},
   "source": [
    "# Syntentic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "023b9903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1221</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   age  anemia    ef  cerebrovascular_disease  \\\n",
       "0         0  41.0     0.0  49.0                      0.0   \n",
       "1         1  56.0     0.0  68.0                      0.0   \n",
       "2         2  55.0     0.0  70.0                      0.0   \n",
       "3         3  79.0     0.0  73.0                      1.0   \n",
       "4         4  61.0     0.0  62.0                      0.0   \n",
       "...     ...   ...     ...   ...                      ...   \n",
       "1221   1221  69.0     0.0  60.0                      0.0   \n",
       "1222   1222  57.0     0.0  39.0                      0.0   \n",
       "1223   1223  63.0     1.0  71.0                      0.0   \n",
       "1224   1224  75.0     0.0  69.0                      1.0   \n",
       "1225   1225  46.0     0.0  64.0                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      0.0   \n",
       "1                           0.0                   0.0            1.0      0.0   \n",
       "2                           0.0                   0.0            1.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      0.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "1221                        0.0                   0.0            1.0      0.0   \n",
       "1222                        0.0                   0.0            0.0      0.0   \n",
       "1223                        0.0                   0.0            1.0      0.0   \n",
       "1224                        1.0                   0.0            1.0      0.0   \n",
       "1225                        0.0                   0.0            1.0      0.0   \n",
       "\n",
       "      stent_type___3  ...  def  history_of_cancer  previous_stroke_tia  \\\n",
       "0                1.0  ...  0.0                0.0             0.477395   \n",
       "1                0.0  ...  0.0                1.0             0.313995   \n",
       "2                0.0  ...  0.0                0.0             0.478905   \n",
       "3                0.0  ...  0.0                0.0             0.000000   \n",
       "4                0.0  ...  0.0                1.0             0.448962   \n",
       "...              ...  ...  ...                ...                  ...   \n",
       "1221             0.0  ...  0.0                0.0             0.525775   \n",
       "1222             1.0  ...  0.0                0.0             0.616766   \n",
       "1223             1.0  ...  0.0                0.0             0.429977   \n",
       "1224             1.0  ...  0.0                0.0             1.000000   \n",
       "1225             0.0  ...  0.0                1.0             0.317877   \n",
       "\n",
       "      clinical_presentation  previous_pci  cto_bifurc  side_diametr  \\\n",
       "0                       5.0           1.0         0.0           2.4   \n",
       "1                       4.0           1.0         0.0           3.0   \n",
       "2                       3.0           0.0         0.0           2.4   \n",
       "3                       1.0           0.0         0.0           3.1   \n",
       "4                       2.0           0.0         0.0           2.5   \n",
       "...                     ...           ...         ...           ...   \n",
       "1221                    1.0           1.0         0.0           2.7   \n",
       "1222                    1.0           0.0         0.0           2.4   \n",
       "1223                    1.0           1.0         0.0           2.2   \n",
       "1224                    1.0           1.0         0.0           2.4   \n",
       "1225                    2.0           1.0         0.0           2.6   \n",
       "\n",
       "      trifurcation  dyslipidemia  smoking  \n",
       "0              0.0           0.0      0.0  \n",
       "1              0.0           0.0      0.0  \n",
       "2              0.0           1.0      0.0  \n",
       "3              0.0           0.0      0.0  \n",
       "4              0.0           0.0      0.0  \n",
       "...            ...           ...      ...  \n",
       "1221           0.0           0.0      0.0  \n",
       "1222           1.0           0.0      0.0  \n",
       "1223           0.0           0.0      0.0  \n",
       "1224           0.0           1.0      1.0  \n",
       "1225           0.0           0.0      0.0  \n",
       "\n",
       "[1226 rows x 23 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_with_ID = X_train.copy().reset_index(drop=False)\n",
    "X_train_with_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25652ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>...</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1221</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   age  anemia    ef  cerebrovascular_disease  \\\n",
       "0         0  41.0     0.0  49.0                      0.0   \n",
       "1         1  56.0     0.0  68.0                      0.0   \n",
       "2         2  55.0     0.0  70.0                      0.0   \n",
       "3         3  79.0     0.0  73.0                      1.0   \n",
       "4         4  61.0     0.0  62.0                      0.0   \n",
       "...     ...   ...     ...   ...                      ...   \n",
       "1221   1221  69.0     0.0  60.0                      0.0   \n",
       "1222   1222  57.0     0.0  39.0                      0.0   \n",
       "1223   1223  63.0     1.0  71.0                      0.0   \n",
       "1224   1224  75.0     0.0  69.0                      1.0   \n",
       "1225   1225  46.0     0.0  64.0                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      0.0   \n",
       "1                           0.0                   0.0            1.0      0.0   \n",
       "2                           0.0                   0.0            1.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      0.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "1221                        0.0                   0.0            1.0      0.0   \n",
       "1222                        0.0                   0.0            0.0      0.0   \n",
       "1223                        0.0                   0.0            1.0      0.0   \n",
       "1224                        1.0                   0.0            1.0      0.0   \n",
       "1225                        0.0                   0.0            1.0      0.0   \n",
       "\n",
       "      stent_type___3  ...  history_of_cancer  previous_stroke_tia  \\\n",
       "0                1.0  ...                0.0             0.477395   \n",
       "1                0.0  ...                1.0             0.313995   \n",
       "2                0.0  ...                0.0             0.478905   \n",
       "3                0.0  ...                0.0             0.000000   \n",
       "4                0.0  ...                1.0             0.448962   \n",
       "...              ...  ...                ...                  ...   \n",
       "1221             0.0  ...                0.0             0.525775   \n",
       "1222             1.0  ...                0.0             0.616766   \n",
       "1223             1.0  ...                0.0             0.429977   \n",
       "1224             1.0  ...                0.0             1.000000   \n",
       "1225             0.0  ...                1.0             0.317877   \n",
       "\n",
       "      clinical_presentation  previous_pci  cto_bifurc  side_diametr  \\\n",
       "0                       5.0           1.0         0.0           2.4   \n",
       "1                       4.0           1.0         0.0           3.0   \n",
       "2                       3.0           0.0         0.0           2.4   \n",
       "3                       1.0           0.0         0.0           3.1   \n",
       "4                       2.0           0.0         0.0           2.5   \n",
       "...                     ...           ...         ...           ...   \n",
       "1221                    1.0           1.0         0.0           2.7   \n",
       "1222                    1.0           0.0         0.0           2.4   \n",
       "1223                    1.0           1.0         0.0           2.2   \n",
       "1224                    1.0           1.0         0.0           2.4   \n",
       "1225                    2.0           1.0         0.0           2.6   \n",
       "\n",
       "      trifurcation  dyslipidemia  smoking  target  \n",
       "0              0.0           0.0      0.0       0  \n",
       "1              0.0           0.0      0.0       0  \n",
       "2              0.0           1.0      0.0       0  \n",
       "3              0.0           0.0      0.0       0  \n",
       "4              0.0           0.0      0.0       0  \n",
       "...            ...           ...      ...     ...  \n",
       "1221           0.0           0.0      0.0       1  \n",
       "1222           1.0           0.0      0.0       0  \n",
       "1223           0.0           0.0      0.0       0  \n",
       "1224           0.0           1.0      1.0       0  \n",
       "1225           0.0           0.0      0.0       0  \n",
       "\n",
       "[1226 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_with_ID_and_target = X_train_with_ID.copy()\n",
    "X_train_with_ID_and_target['target'] = y_train\n",
    "X_train_with_ID_and_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d34d7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.metadata import Metadata\n",
    "\n",
    "metadata = Metadata.detect_from_dataframe(data=X_train_with_ID_and_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac75cded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sdv/single_table/base.py:104: UserWarning:\n",
      "\n",
      "We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>...</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12053904</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.149562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447572</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13010658</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.247410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9912584</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.998898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.549007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2797363</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.874420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225474</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13661511</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.591785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.811912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>4519439</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.661519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>657099</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3822342</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.890679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222976</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2301487</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.502722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2181678</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.371074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   age  anemia         ef  cerebrovascular_disease  \\\n",
       "0     12053904  70.0     0.0  59.149562                      0.0   \n",
       "1     13010658  49.0     0.0  44.247410                      0.0   \n",
       "2      9912584  66.0     0.0  71.998898                      0.0   \n",
       "3      2797363  93.0     1.0  28.874420                      0.0   \n",
       "4     13661511  85.0     1.0  52.591785                      0.0   \n",
       "...        ...   ...     ...        ...                      ...   \n",
       "9995   4519439  76.0     0.0  19.661519                      0.0   \n",
       "9996    657099  39.0     0.0  17.000000                      0.0   \n",
       "9997   3822342  62.0     0.0  56.890679                      1.0   \n",
       "9998   2301487  67.0     1.0  63.502722                      0.0   \n",
       "9999   2181678  28.0     0.0  50.371074                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      1.0   \n",
       "1                           0.0                   0.0            0.0      0.0   \n",
       "2                           0.0                   0.0            0.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      1.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "9995                        0.0                   0.0            0.0      1.0   \n",
       "9996                        0.0                   0.0            1.0      0.0   \n",
       "9997                        0.0                   0.0            0.0      1.0   \n",
       "9998                        0.0                   0.0            1.0      1.0   \n",
       "9999                        0.0                   0.0            0.0      0.0   \n",
       "\n",
       "      stent_type___3  ...  history_of_cancer  previous_stroke_tia  \\\n",
       "0                0.0  ...                0.0             0.447572   \n",
       "1                1.0  ...                0.0             0.197412   \n",
       "2                0.0  ...                0.0             0.549007   \n",
       "3                1.0  ...                0.0             0.225474   \n",
       "4                1.0  ...                0.0             0.811912   \n",
       "...              ...  ...                ...                  ...   \n",
       "9995             1.0  ...                0.0             0.216220   \n",
       "9996             1.0  ...                0.0             0.483891   \n",
       "9997             0.0  ...                0.0             0.222976   \n",
       "9998             0.0  ...                0.0             0.537988   \n",
       "9999             0.0  ...                0.0             0.206481   \n",
       "\n",
       "      clinical_presentation  previous_pci  cto_bifurc  side_diametr  \\\n",
       "0                       2.0           0.0         0.0          2.19   \n",
       "1                       1.0           1.0         0.0          2.79   \n",
       "2                       1.0           1.0         1.0          2.49   \n",
       "3                       2.0           1.0         0.0          2.31   \n",
       "4                       1.0           1.0         0.0          2.77   \n",
       "...                     ...           ...         ...           ...   \n",
       "9995                    1.0           1.0         0.0          3.23   \n",
       "9996                    1.0           0.0         0.0          3.18   \n",
       "9997                    1.0           1.0         0.0          2.86   \n",
       "9998                    1.0           0.0         1.0          4.73   \n",
       "9999                    1.0           1.0         1.0          2.31   \n",
       "\n",
       "      trifurcation  dyslipidemia  smoking  target  \n",
       "0              0.0           0.0      1.0       0  \n",
       "1              0.0           0.0      0.0       0  \n",
       "2              0.0           1.0      0.0       0  \n",
       "3              0.0           0.0      0.0       0  \n",
       "4              0.0           0.0      0.0       0  \n",
       "...            ...           ...      ...     ...  \n",
       "9995           0.0           1.0      0.0       0  \n",
       "9996           0.0           0.0      0.0       0  \n",
       "9997           1.0           0.0      0.0       0  \n",
       "9998           0.0           1.0      1.0       1  \n",
       "9999           1.0           0.0      0.0       0  \n",
       "\n",
       "[10000 rows x 24 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "\n",
    "# synthesizer = GaussianCopulaSynthesizer(metadata, default_distribution='norm')\n",
    "synthesizer = CTGANSynthesizer(metadata, epochs=500)\n",
    "# synthesizer = TVAESynthesizer(metadata, epochs=500)\n",
    "# synthesizer = CopulaGANSynthesizer(metadata, epochs=500, default_distribution='norm')\n",
    "synthesizer.fit(X_train_with_ID_and_target)\n",
    "\n",
    "synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13ccf6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 9047, 1: 953}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(synthetic_data['target'], return_counts=True)\n",
    "value_counts = dict(zip(unique, counts))\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfb2a12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>...</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2160786</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.014005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282830</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14581378</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15998352</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.169243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9724348</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.907187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>11316388</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.080214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947</th>\n",
       "      <td>1081656</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.898453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>8610861</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.751177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535373</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>12348922</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.148507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>1830277</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.513859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2301487</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.502722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index   age  anemia         ef  cerebrovascular_disease  \\\n",
       "21     2160786  67.0     1.0  50.014005                      0.0   \n",
       "24    14581378  68.0     0.0  17.000000                      0.0   \n",
       "30    15998352  33.0     0.0  52.169243                      0.0   \n",
       "46     9724348  79.0     0.0  76.907187                      0.0   \n",
       "53    11316388  56.0     0.0  48.080214                      1.0   \n",
       "...        ...   ...     ...        ...                      ...   \n",
       "9947   1081656  74.0     0.0  47.898453                      1.0   \n",
       "9949   8610861  65.0     0.0  66.751177                      0.0   \n",
       "9964  12348922  78.0     1.0  74.148507                      0.0   \n",
       "9978   1830277  55.0     0.0  54.513859                      0.0   \n",
       "9998   2301487  67.0     1.0  63.502722                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "21                          1.0                   0.0            1.0      1.0   \n",
       "24                          0.0                   0.0            0.0      1.0   \n",
       "30                          0.0                   0.0            0.0      0.0   \n",
       "46                          0.0                   0.0            0.0      0.0   \n",
       "53                          0.0                   0.0            0.0      1.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "9947                        1.0                   0.0            0.0      0.0   \n",
       "9949                        0.0                   0.0            1.0      0.0   \n",
       "9964                        0.0                   0.0            1.0      1.0   \n",
       "9978                        0.0                   0.0            1.0      0.0   \n",
       "9998                        0.0                   0.0            1.0      1.0   \n",
       "\n",
       "      stent_type___3  ...  history_of_cancer  previous_stroke_tia  \\\n",
       "21               1.0  ...                0.0             0.282830   \n",
       "24               0.0  ...                0.0             0.283295   \n",
       "30               0.0  ...                0.0             0.248009   \n",
       "46               0.0  ...                0.0             0.476200   \n",
       "53               1.0  ...                0.0             0.263232   \n",
       "...              ...  ...                ...                  ...   \n",
       "9947             0.0  ...                0.0             0.204095   \n",
       "9949             1.0  ...                0.0             0.535373   \n",
       "9964             0.0  ...                0.0             0.171623   \n",
       "9978             0.0  ...                0.0             0.316144   \n",
       "9998             0.0  ...                0.0             0.537988   \n",
       "\n",
       "      clinical_presentation  previous_pci  cto_bifurc  side_diametr  \\\n",
       "21                      3.0           1.0         0.0          4.60   \n",
       "24                      1.0           1.0         0.0          1.32   \n",
       "30                      1.0           1.0         0.0          2.53   \n",
       "46                      1.0           1.0         0.0          2.57   \n",
       "53                      1.0           0.0         0.0          2.01   \n",
       "...                     ...           ...         ...           ...   \n",
       "9947                    3.0           0.0         0.0          2.53   \n",
       "9949                    5.0           1.0         0.0          2.37   \n",
       "9964                    1.0           1.0         0.0          2.39   \n",
       "9978                    1.0           1.0         0.0          3.09   \n",
       "9998                    1.0           0.0         1.0          4.73   \n",
       "\n",
       "      trifurcation  dyslipidemia  smoking  target  \n",
       "21             0.0           0.0      0.0       1  \n",
       "24             0.0           0.0      0.0       1  \n",
       "30             0.0           0.0      0.0       1  \n",
       "46             0.0           0.0      0.0       1  \n",
       "53             0.0           0.0      0.0       1  \n",
       "...            ...           ...      ...     ...  \n",
       "9947           0.0           0.0      0.0       1  \n",
       "9949           0.0           0.0      0.0       1  \n",
       "9964           0.0           1.0      0.0       1  \n",
       "9978           0.0           0.0      0.0       1  \n",
       "9998           0.0           1.0      1.0       1  \n",
       "\n",
       "[953 rows x 24 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "minority_synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55c348de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.014005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282830</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.169243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.907187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.476200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.080214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263232</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.898453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.751177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535373</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.148507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.513859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.502722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>953 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  anemia         ef  cerebrovascular_disease  \\\n",
       "21    67.0     1.0  50.014005                      0.0   \n",
       "24    68.0     0.0  17.000000                      0.0   \n",
       "30    33.0     0.0  52.169243                      0.0   \n",
       "46    79.0     0.0  76.907187                      0.0   \n",
       "53    56.0     0.0  48.080214                      1.0   \n",
       "...    ...     ...        ...                      ...   \n",
       "9947  74.0     0.0  47.898453                      1.0   \n",
       "9949  65.0     0.0  66.751177                      0.0   \n",
       "9964  78.0     1.0  74.148507                      0.0   \n",
       "9978  55.0     0.0  54.513859                      0.0   \n",
       "9998  67.0     1.0  63.502722                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "21                          1.0                   0.0            1.0      1.0   \n",
       "24                          0.0                   0.0            0.0      1.0   \n",
       "30                          0.0                   0.0            0.0      0.0   \n",
       "46                          0.0                   0.0            0.0      0.0   \n",
       "53                          0.0                   0.0            0.0      1.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "9947                        1.0                   0.0            0.0      0.0   \n",
       "9949                        0.0                   0.0            1.0      0.0   \n",
       "9964                        0.0                   0.0            1.0      1.0   \n",
       "9978                        0.0                   0.0            1.0      0.0   \n",
       "9998                        0.0                   0.0            1.0      1.0   \n",
       "\n",
       "      stent_type___3  medina_side  ...  def  history_of_cancer  \\\n",
       "21               1.0          0.0  ...  0.0                0.0   \n",
       "24               0.0          1.0  ...  0.0                0.0   \n",
       "30               0.0          0.0  ...  0.0                0.0   \n",
       "46               0.0          0.0  ...  0.0                0.0   \n",
       "53               1.0          0.0  ...  0.0                0.0   \n",
       "...              ...          ...  ...  ...                ...   \n",
       "9947             0.0          1.0  ...  0.0                0.0   \n",
       "9949             1.0          1.0  ...  0.0                0.0   \n",
       "9964             0.0          1.0  ...  0.0                0.0   \n",
       "9978             0.0          0.0  ...  0.0                0.0   \n",
       "9998             0.0          0.0  ...  0.0                0.0   \n",
       "\n",
       "      previous_stroke_tia  clinical_presentation  previous_pci  cto_bifurc  \\\n",
       "21               0.282830                    3.0           1.0         0.0   \n",
       "24               0.283295                    1.0           1.0         0.0   \n",
       "30               0.248009                    1.0           1.0         0.0   \n",
       "46               0.476200                    1.0           1.0         0.0   \n",
       "53               0.263232                    1.0           0.0         0.0   \n",
       "...                   ...                    ...           ...         ...   \n",
       "9947             0.204095                    3.0           0.0         0.0   \n",
       "9949             0.535373                    5.0           1.0         0.0   \n",
       "9964             0.171623                    1.0           1.0         0.0   \n",
       "9978             0.316144                    1.0           1.0         0.0   \n",
       "9998             0.537988                    1.0           0.0         1.0   \n",
       "\n",
       "      side_diametr  trifurcation  dyslipidemia  smoking  \n",
       "21            4.60           0.0           0.0      0.0  \n",
       "24            1.32           0.0           0.0      0.0  \n",
       "30            2.53           0.0           0.0      0.0  \n",
       "46            2.57           0.0           0.0      0.0  \n",
       "53            2.01           0.0           0.0      0.0  \n",
       "...            ...           ...           ...      ...  \n",
       "9947          2.53           0.0           0.0      0.0  \n",
       "9949          2.37           0.0           0.0      0.0  \n",
       "9964          2.39           0.0           1.0      0.0  \n",
       "9978          3.09           0.0           0.0      0.0  \n",
       "9998          4.73           0.0           1.0      1.0  \n",
       "\n",
       "[953 rows x 22 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntetic_minority_dropped = minority_synthetic_data.copy().drop(['target', 'index'], axis=1)\n",
    "syntetic_minority_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f01c588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21      1\n",
       "24      1\n",
       "30      1\n",
       "46      1\n",
       "53      1\n",
       "       ..\n",
       "9947    1\n",
       "9949    1\n",
       "9964    1\n",
       "9978    1\n",
       "9998    1\n",
       "Name: target, Length: 953, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntetic_target = minority_synthetic_data['target']\n",
    "syntetic_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e494aac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947</th>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.898453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.751177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535373</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9964</th>\n",
       "      <td>78.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.148507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.513859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.316144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.502722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2179 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  anemia         ef  cerebrovascular_disease  \\\n",
       "0     41.0     0.0  49.000000                      0.0   \n",
       "1     56.0     0.0  68.000000                      0.0   \n",
       "2     55.0     0.0  70.000000                      0.0   \n",
       "3     79.0     0.0  73.000000                      1.0   \n",
       "4     61.0     0.0  62.000000                      0.0   \n",
       "...    ...     ...        ...                      ...   \n",
       "9947  74.0     0.0  47.898453                      1.0   \n",
       "9949  65.0     0.0  66.751177                      0.0   \n",
       "9964  78.0     1.0  74.148507                      0.0   \n",
       "9978  55.0     0.0  54.513859                      0.0   \n",
       "9998  67.0     1.0  63.502722                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      0.0   \n",
       "1                           0.0                   0.0            1.0      0.0   \n",
       "2                           0.0                   0.0            1.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      0.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "9947                        1.0                   0.0            0.0      0.0   \n",
       "9949                        0.0                   0.0            1.0      0.0   \n",
       "9964                        0.0                   0.0            1.0      1.0   \n",
       "9978                        0.0                   0.0            1.0      0.0   \n",
       "9998                        0.0                   0.0            1.0      1.0   \n",
       "\n",
       "      stent_type___3  medina_side  ...  def  history_of_cancer  \\\n",
       "0                1.0          0.0  ...  0.0                0.0   \n",
       "1                0.0          1.0  ...  0.0                1.0   \n",
       "2                0.0          0.0  ...  0.0                0.0   \n",
       "3                0.0          0.0  ...  0.0                0.0   \n",
       "4                0.0          0.0  ...  0.0                1.0   \n",
       "...              ...          ...  ...  ...                ...   \n",
       "9947             0.0          1.0  ...  0.0                0.0   \n",
       "9949             1.0          1.0  ...  0.0                0.0   \n",
       "9964             0.0          1.0  ...  0.0                0.0   \n",
       "9978             0.0          0.0  ...  0.0                0.0   \n",
       "9998             0.0          0.0  ...  0.0                0.0   \n",
       "\n",
       "      previous_stroke_tia  clinical_presentation  previous_pci  cto_bifurc  \\\n",
       "0                0.477395                    5.0           1.0         0.0   \n",
       "1                0.313995                    4.0           1.0         0.0   \n",
       "2                0.478905                    3.0           0.0         0.0   \n",
       "3                0.000000                    1.0           0.0         0.0   \n",
       "4                0.448962                    2.0           0.0         0.0   \n",
       "...                   ...                    ...           ...         ...   \n",
       "9947             0.204095                    3.0           0.0         0.0   \n",
       "9949             0.535373                    5.0           1.0         0.0   \n",
       "9964             0.171623                    1.0           1.0         0.0   \n",
       "9978             0.316144                    1.0           1.0         0.0   \n",
       "9998             0.537988                    1.0           0.0         1.0   \n",
       "\n",
       "      side_diametr  trifurcation  dyslipidemia  smoking  \n",
       "0             2.40           0.0           0.0      0.0  \n",
       "1             3.00           0.0           0.0      0.0  \n",
       "2             2.40           0.0           1.0      0.0  \n",
       "3             3.10           0.0           0.0      0.0  \n",
       "4             2.50           0.0           0.0      0.0  \n",
       "...            ...           ...           ...      ...  \n",
       "9947          2.53           0.0           0.0      0.0  \n",
       "9949          2.37           0.0           0.0      0.0  \n",
       "9964          2.39           0.0           1.0      0.0  \n",
       "9978          3.09           0.0           0.0      0.0  \n",
       "9998          4.73           0.0           1.0      1.0  \n",
       "\n",
       "[2179 rows x 22 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new = pd.concat([X_train, syntetic_minority_dropped])\n",
    "X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8fad563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new = np.concatenate((y_train, syntetic_target))\n",
    "y_train_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff2db7-0de1-4985-a9e0-41a99a84242d",
   "metadata": {},
   "source": [
    "# Оптимизация TabPFN на auc-roc для 10 фолдов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "264524cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaller = StandardScaler()\n",
    "scaller.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8ee37c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scaler.save']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaller, \"./scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a7a47db-2788-4f5d-a04e-396cf6a4988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds = pd.concat([X_train, X_val])\n",
    "y_train_k_fold = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a071acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaller.transform(X_train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3fc6e505-490e-4609-81eb-6b09c0c1fb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>trifurcation</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>smoking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.317888</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>-0.659638</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>-0.926054</td>\n",
       "      <td>-0.517531</td>\n",
       "      <td>1.297194</td>\n",
       "      <td>-0.708838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>0.162955</td>\n",
       "      <td>2.292618</td>\n",
       "      <td>1.163257</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>-0.417415</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.791826</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>1.121135</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>1.079851</td>\n",
       "      <td>-0.517531</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>1.410760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>4.296547</td>\n",
       "      <td>-0.730225</td>\n",
       "      <td>1.534186</td>\n",
       "      <td>1.163257</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>0.684941</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.893563</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>1.308584</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>1.079851</td>\n",
       "      <td>-0.517531</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>-0.708838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>0.171210</td>\n",
       "      <td>0.775754</td>\n",
       "      <td>-0.859655</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>-0.417415</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>1.211116</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.548135</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>1.589759</td>\n",
       "      <td>2.638378</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>-0.926054</td>\n",
       "      <td>1.932250</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>-0.708838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>-2.446583</td>\n",
       "      <td>-0.741111</td>\n",
       "      <td>-0.859655</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.283139</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>0.558786</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>-0.926054</td>\n",
       "      <td>-0.517531</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>-0.708838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>4.296547</td>\n",
       "      <td>0.007535</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>-0.859655</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>-0.233689</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>-0.690089</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>1.079851</td>\n",
       "      <td>-0.517531</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>1.410760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>0.080058</td>\n",
       "      <td>-0.741111</td>\n",
       "      <td>1.163257</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>-0.766494</td>\n",
       "      <td>4.704474</td>\n",
       "      <td>1.211116</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>1.649873</td>\n",
       "      <td>4.370167</td>\n",
       "      <td>-0.940812</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>-0.926054</td>\n",
       "      <td>1.932250</td>\n",
       "      <td>1.297194</td>\n",
       "      <td>-0.708838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>1.474545</td>\n",
       "      <td>2.292618</td>\n",
       "      <td>1.163257</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>1.971022</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>0.429023</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>0.652510</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>-0.926054</td>\n",
       "      <td>1.932250</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>-0.708838</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>4.296547</td>\n",
       "      <td>-0.326126</td>\n",
       "      <td>-0.741111</td>\n",
       "      <td>1.163257</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>0.133763</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>-0.283139</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>0.090161</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>6.424629</td>\n",
       "      <td>1.079851</td>\n",
       "      <td>1.932250</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>1.410760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>-0.335178</td>\n",
       "      <td>0.017321</td>\n",
       "      <td>1.163257</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>0.133763</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.225548</td>\n",
       "      <td>-0.228824</td>\n",
       "      <td>0.090161</td>\n",
       "      <td>-0.379021</td>\n",
       "      <td>-0.288165</td>\n",
       "      <td>-0.155651</td>\n",
       "      <td>-0.926054</td>\n",
       "      <td>-0.517531</td>\n",
       "      <td>-0.770894</td>\n",
       "      <td>1.410760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075779</td>\n",
       "      <td>-0.232745</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>2.292618</td>\n",
       "      <td>-0.859655</td>\n",
       "      <td>-0.286501</td>\n",
       "      <td>0.868667</td>\n",
       "      <td>-0.212564</td>\n",
       "      <td>-0.825685</td>\n",
       "      <td>-0.516264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age    anemia        ef  cerebrovascular_disease  \\\n",
       "0    -2.317888 -0.228824 -0.659638                -0.379021   \n",
       "1    -0.791826 -0.228824  1.121135                -0.379021   \n",
       "2    -0.893563 -0.228824  1.308584                -0.379021   \n",
       "3     1.548135 -0.228824  1.589759                 2.638378   \n",
       "4    -0.283139 -0.228824  0.558786                -0.379021   \n",
       "...        ...       ...       ...                      ...   \n",
       "1630 -0.690089 -0.228824  0.465061                -0.379021   \n",
       "1631  1.649873  4.370167 -0.940812                -0.379021   \n",
       "1632  0.429023 -0.228824  0.652510                -0.379021   \n",
       "1633 -0.283139 -0.228824  0.090161                -0.379021   \n",
       "1634  0.225548 -0.228824  0.090161                -0.379021   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  \\\n",
       "0                     -0.288165             -0.155651      -0.926054   \n",
       "1                     -0.288165             -0.155651       1.079851   \n",
       "2                     -0.288165             -0.155651       1.079851   \n",
       "3                     -0.288165             -0.155651      -0.926054   \n",
       "4                     -0.288165             -0.155651      -0.926054   \n",
       "...                         ...                   ...            ...   \n",
       "1630                  -0.288165             -0.155651       1.079851   \n",
       "1631                  -0.288165             -0.155651      -0.926054   \n",
       "1632                  -0.288165             -0.155651      -0.926054   \n",
       "1633                  -0.288165              6.424629       1.079851   \n",
       "1634                  -0.288165             -0.155651      -0.926054   \n",
       "\n",
       "       calcium  stent_type___3  medina_side  ...       def  history_of_cancer  \\\n",
       "0    -0.517531        1.297194    -0.708838  ... -0.075779          -0.232745   \n",
       "1    -0.517531       -0.770894     1.410760  ... -0.075779           4.296547   \n",
       "2    -0.517531       -0.770894    -0.708838  ... -0.075779          -0.232745   \n",
       "3     1.932250       -0.770894    -0.708838  ... -0.075779          -0.232745   \n",
       "4    -0.517531       -0.770894    -0.708838  ... -0.075779           4.296547   \n",
       "...        ...             ...          ...  ...       ...                ...   \n",
       "1630 -0.517531       -0.770894     1.410760  ... -0.075779          -0.232745   \n",
       "1631  1.932250        1.297194    -0.708838  ... -0.075779          -0.232745   \n",
       "1632  1.932250       -0.770894    -0.708838  ... -0.075779           4.296547   \n",
       "1633  1.932250       -0.770894     1.410760  ... -0.075779          -0.232745   \n",
       "1634 -0.517531       -0.770894     1.410760  ... -0.075779          -0.232745   \n",
       "\n",
       "      previous_stroke_tia  clinical_presentation  previous_pci  cto_bifurc  \\\n",
       "0                0.162955               2.292618      1.163257   -0.286501   \n",
       "1               -0.730225               1.534186      1.163257   -0.286501   \n",
       "2                0.171210               0.775754     -0.859655   -0.286501   \n",
       "3               -2.446583              -0.741111     -0.859655   -0.286501   \n",
       "4                0.007535               0.017321     -0.859655   -0.286501   \n",
       "...                   ...                    ...           ...         ...   \n",
       "1630             0.080058              -0.741111      1.163257   -0.286501   \n",
       "1631             1.474545               2.292618      1.163257   -0.286501   \n",
       "1632            -0.326126              -0.741111      1.163257   -0.286501   \n",
       "1633            -0.335178               0.017321      1.163257   -0.286501   \n",
       "1634            -0.003333               2.292618     -0.859655   -0.286501   \n",
       "\n",
       "      side_diametr  trifurcation  dyslipidemia   smoking  \n",
       "0        -0.417415     -0.212564     -0.825685 -0.516264  \n",
       "1         0.684941     -0.212564     -0.825685 -0.516264  \n",
       "2        -0.417415     -0.212564      1.211116 -0.516264  \n",
       "3         0.868667     -0.212564     -0.825685 -0.516264  \n",
       "4        -0.233689     -0.212564     -0.825685 -0.516264  \n",
       "...            ...           ...           ...       ...  \n",
       "1630     -0.766494      4.704474      1.211116 -0.516264  \n",
       "1631      1.971022     -0.212564     -0.825685 -0.516264  \n",
       "1632      0.133763     -0.212564     -0.825685 -0.516264  \n",
       "1633      0.133763     -0.212564     -0.825685 -0.516264  \n",
       "1634      0.868667     -0.212564     -0.825685 -0.516264  \n",
       "\n",
       "[1635 rows x 22 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(data=scaled_features, columns=X_train_folds.columns)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a26b1456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new = scaller.transform(X_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "baa47d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "import pickle\n",
    "from tabpfn_extensions.post_hoc_ensembles.sklearn_interface import AutoTabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88bdfc5f-9d72-457d-b40b-a1e98103ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 12:10:02 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:10:02 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:10:02 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:10:02 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:10:04 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:10:04 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:10:04 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:10:04 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:10:31 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:10:57 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:10:57 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:10:57 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:10:57 INFO     Order of selections: [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "2025-05-22 12:10:57 INFO     Val loss over iterations: [-0.6354558270676692, -0.6354558270676692, -0.6354558270676692, -0.6354558270676692, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.6359257518796992, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203, -0.635984492481203]\n",
      "2025-05-22 12:10:57 INFO     Model losses: [-0.63545583 -0.6343985 ]\n",
      "2025-05-22 12:10:57 INFO     Best weights: [0.8125 0.1875]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:13:23 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:13:23 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:13:23 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:13:23 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:13:25 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:13:25 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:13:25 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:13:25 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:13:52 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:14:16 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:14:16 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:14:16 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:14:16 INFO     Order of selections: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2025-05-22 12:14:16 INFO     Val loss over iterations: [-0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187, -0.6565437030075187]\n",
      "2025-05-22 12:14:16 INFO     Model losses: [-0.6565437  -0.64802632]\n",
      "2025-05-22 12:14:16 INFO     Best weights: [1. 0.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:15:26 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:15:26 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:15:26 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:15:26 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:15:29 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:15:29 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:15:29 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:15:29 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:15:56 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:16:21 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:16:21 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:16:21 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:16:21 INFO     Order of selections: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "2025-05-22 12:16:21 INFO     Val loss over iterations: [-0.5724271616541353, -0.5724271616541353, -0.5724271616541353, -0.5724271616541353, -0.5724271616541353, -0.5724271616541353, -0.5724271616541353, -0.5724271616541354, -0.5724271616541354, -0.5724271616541354, -0.5724271616541354, -0.5727208646616542, -0.5727208646616542, -0.5727208646616542, -0.5727208646616542, -0.5727796052631579, -0.572779605263158, -0.572779605263158, -0.572779605263158, -0.572779605263158, -0.572779605263158, -0.572779605263158, -0.572779605263158, -0.572779605263158, -0.572779605263158]\n",
      "2025-05-22 12:16:21 INFO     Model losses: [-0.57242716 -0.57013628]\n",
      "2025-05-22 12:16:21 INFO     Best weights: [0.94117647 0.05882353]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:18:49 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:18:49 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:18:49 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:18:49 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:18:51 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:18:51 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:18:51 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:18:51 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:19:18 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:19:43 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:19:43 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:19:43 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:19:43 INFO     Order of selections: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
      "2025-05-22 12:19:43 INFO     Val loss over iterations: [-0.6685267857142857, -0.6703477443609023, -0.6705239661654135, -0.6705239661654135, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6712875939849624, -0.6715225563909775, -0.6715225563909775, -0.6715225563909775]\n",
      "2025-05-22 12:19:43 INFO     Model losses: [-0.66852679 -0.6621828 ]\n",
      "2025-05-22 12:19:43 INFO     Best weights: [0.60869565 0.39130435]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:22:11 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:22:11 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:22:11 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:22:11 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:22:14 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:22:14 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:22:14 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:22:14 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:22:41 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:23:05 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:23:05 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:23:05 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:23:05 INFO     Order of selections: [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "2025-05-22 12:23:05 INFO     Val loss over iterations: [-0.6315202067669173, -0.6315202067669173, -0.6315202067669173, -0.6318726503759399, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6322838345864661, -0.6324013157894737, -0.6324013157894737, -0.6324013157894737, -0.6324013157894737, -0.6324013157894737, -0.6324013157894737, -0.6324013157894737]\n",
      "2025-05-22 12:23:05 INFO     Model losses: [-0.63152021 -0.62018327]\n",
      "2025-05-22 12:23:05 INFO     Best weights: [0.78947368 0.21052632]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:25:28 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:25:28 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:25:28 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:25:28 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:25:30 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:25:30 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:25:30 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:25:30 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:25:56 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:26:20 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:26:20 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:26:20 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:26:20 INFO     Order of selections: [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "2025-05-22 12:26:20 INFO     Val loss over iterations: [-0.6812147556390976, -0.6815084586466165, -0.6816846804511278, -0.6816846804511278, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6819196428571429, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542, -0.6820958646616542]\n",
      "2025-05-22 12:26:20 INFO     Model losses: [-0.68121476 -0.67957002]\n",
      "2025-05-22 12:26:20 INFO     Best weights: [0.64705882 0.35294118]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:28:43 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:28:43 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:28:43 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:28:43 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:28:45 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:28:45 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:28:45 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:28:45 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:29:11 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:29:36 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:29:36 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:29:36 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:29:36 INFO     Order of selections: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "2025-05-22 12:29:36 INFO     Val loss over iterations: [-0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933388157894737, -0.5933975563909775, -0.5934562969924813, -0.5934562969924813, -0.5934562969924813]\n",
      "2025-05-22 12:29:36 INFO     Model losses: [-0.59333882 -0.58834586]\n",
      "2025-05-22 12:29:36 INFO     Best weights: [0.95652174 0.04347826]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:32:00 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:32:00 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:32:00 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:32:00 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:32:02 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:32:02 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:32:02 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:32:02 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:32:29 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:32:55 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:32:55 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:32:55 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:32:55 INFO     Order of selections: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "2025-05-22 12:32:55 INFO     Val loss over iterations: [-0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6342222744360902, -0.6344572368421053, -0.6344572368421053, -0.6344572368421053, -0.6344572368421053, -0.6344572368421053, -0.6344572368421053, -0.6344572368421053, -0.6344572368421053]\n",
      "2025-05-22 12:32:55 INFO     Model losses: [-0.63422227 -0.61783365]\n",
      "2025-05-22 12:32:55 INFO     Best weights: [0.94444444 0.05555556]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:35:18 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:35:18 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:35:18 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:35:18 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:35:20 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:35:20 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:35:20 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:35:20 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:35:48 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:36:13 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:36:13 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:36:13 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:36:13 INFO     Order of selections: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "2025-05-22 12:36:13 INFO     Val loss over iterations: [-0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6710526315789475, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549, -0.6711701127819549]\n",
      "2025-05-22 12:36:13 INFO     Model losses: [-0.67105263 -0.66012688]\n",
      "2025-05-22 12:36:13 INFO     Best weights: [0.9 0.1]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 12:38:36 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:38:36 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:38:36 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:38:36 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:38:38 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:38:38 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:38:38 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:38:38 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:39:05 INFO     Yield data for model random_tabpfn_model_1 and split 0 (repeat=1).\n",
      "2025-05-22 12:39:32 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:39:32 INFO     Stop validation of all models after 2 models in repeat 1.\n",
      "2025-05-22 12:39:32 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:39:32 INFO     Order of selections: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "2025-05-22 12:39:32 INFO     Val loss over iterations: [-0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414, -0.7272086466165414]\n",
      "2025-05-22 12:39:32 INFO     Model losses: [-0.72720865 -0.72198073]\n",
      "2025-05-22 12:39:32 INFO     Best weights: [1. 0.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and evaluation metrics saved to JSON and pickle files.\n",
      "Results: {'loss': -0.6873664459161148, 'best_score': 0.8084988962472406}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch  # Required for saving the model\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def objective(X_train_folds, y_train_k_fold):\n",
    "    best_score = -np.inf\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get train and test data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index] if hasattr(X_train_folds, 'iloc') else X_train_folds[train_index]\n",
    "        X_test_fold = X_train_folds.iloc[test_index] if hasattr(X_train_folds, 'iloc') else X_train_folds[test_index]\n",
    "        y_train = y_train_k_fold[train_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Apply StandardScaler to training data only, then transform test data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_fold)\n",
    "        X_test = scaler.transform(X_test_fold)\n",
    "\n",
    "        # Initialize TabPFN classifier\n",
    "        classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "        \n",
    "        # Fit classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities and classes\n",
    "        y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        \n",
    "        if roc_auc > best_score:\n",
    "            best_score = roc_auc\n",
    "    \n",
    "    # Create a dictionary with all the metrics\n",
    "    results = {\n",
    "        \"roc_auc\": {\n",
    "            \"scores\": [float(score) for score in roc_auc_scores],\n",
    "            \"mean\": float(np.mean(roc_auc_scores))\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"scores\": [float(score) for score in f1_scores],\n",
    "            \"mean\": float(np.mean(f1_scores))\n",
    "        },\n",
    "        \"precision\": {\n",
    "            \"scores\": [float(score) for score in precision_scores],\n",
    "            \"mean\": float(np.mean(precision_scores))\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"scores\": [float(score) for score in recall_scores],\n",
    "            \"mean\": float(np.mean(recall_scores))\n",
    "        },\n",
    "        \"accuracy\": {\n",
    "            \"scores\": [float(score) for score in accuracy_scores],\n",
    "            \"mean\": float(np.mean(accuracy_scores))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save metrics results to JSON file\n",
    "    with open('scores_AutoTabFPN_CV.json', 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "    # Save the model\n",
    "    with open('AutoTabFPN_CV.pkl', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print(\"Model and evaluation metrics saved to JSON and pickle files.\")\n",
    "    \n",
    "    return {'loss': -np.mean(roc_auc_scores), 'best_score': best_score}\n",
    "\n",
    "result = objective(X_train_folds, y_train_k_fold)\n",
    "\n",
    "print(\"Results:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f01e62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 12:58:05 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 12:58:05 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 12:58:05 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 12:58:05 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 12:58:08 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 12:58:08 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 12:58:08 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 12:58:08 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 12:58:43 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 12:58:43 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 12:58:43 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 12:58:43 INFO     Order of selections: [0]\n",
      "2025-05-22 12:58:43 INFO     Val loss over iterations: [-0.6841174220692293]\n",
      "2025-05-22 12:58:43 INFO     Model losses: [-0.68411742]\n",
      "2025-05-22 12:58:43 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_final_test_results_20250522_130030.json\n",
      "Visualization saved to tabpfn_final_test_results_20250522_130030.png\n",
      "Test metrics:\n",
      "  roc_auc: 0.8169\n",
      "  f1: 0.0000\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  accuracy: 0.9242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_folds)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the full training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_k_fold)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Save results to JSON\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_filename = f'tabpfn_final_test_results_{timestamp}.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Negative', 'Positive'])\n",
    "plt.yticks(tick_marks, ['Negative', 'Positive'])\n",
    "\n",
    "# Add text annotations to confusion matrix\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'tabpfn_final_test_results_{timestamp}.png')\n",
    "plt.show()\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(f\"Visualization saved to tabpfn_final_test_results_{timestamp}.png\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5e2de",
   "metadata": {},
   "source": [
    "# TABPFN + edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a03e3f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>restenosis_reocclusion</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>main_predilatation</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>mortality</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.166695</td>\n",
       "      <td>158.513893</td>\n",
       "      <td>5</td>\n",
       "      <td>17.383818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.725508</td>\n",
       "      <td>37.844611</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.963835</td>\n",
       "      <td>168.368143</td>\n",
       "      <td>4</td>\n",
       "      <td>24.838871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.465256</td>\n",
       "      <td>29.799415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.509236</td>\n",
       "      <td>151.994317</td>\n",
       "      <td>4</td>\n",
       "      <td>19.705380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.457795</td>\n",
       "      <td>36.585190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.807009</td>\n",
       "      <td>160.203405</td>\n",
       "      <td>5</td>\n",
       "      <td>15.757748</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.309615</td>\n",
       "      <td>34.232300</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.239502</td>\n",
       "      <td>164.039686</td>\n",
       "      <td>5</td>\n",
       "      <td>21.961974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.660538</td>\n",
       "      <td>30.051020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>99.510905</td>\n",
       "      <td>166.976362</td>\n",
       "      <td>4</td>\n",
       "      <td>25.370961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.554469</td>\n",
       "      <td>29.944907</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>95.281470</td>\n",
       "      <td>143.160827</td>\n",
       "      <td>5</td>\n",
       "      <td>21.892076</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.626765</td>\n",
       "      <td>28.857971</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>96.440095</td>\n",
       "      <td>154.721375</td>\n",
       "      <td>5</td>\n",
       "      <td>20.963266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.371528</td>\n",
       "      <td>28.248528</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>96.731001</td>\n",
       "      <td>160.466720</td>\n",
       "      <td>5</td>\n",
       "      <td>19.938365</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.020478</td>\n",
       "      <td>34.580807</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>98.918187</td>\n",
       "      <td>163.330163</td>\n",
       "      <td>5</td>\n",
       "      <td>29.795418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.528102</td>\n",
       "      <td>34.970761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      height  clinical_presentation         ef  \\\n",
       "0    85.166695  158.513893                      5  17.383818   \n",
       "1    95.963835  168.368143                      4  24.838871   \n",
       "2    88.509236  151.994317                      4  19.705380   \n",
       "3    92.807009  160.203405                      5  15.757748   \n",
       "4    96.239502  164.039686                      5  21.961974   \n",
       "..         ...         ...                    ...        ...   \n",
       "145  99.510905  166.976362                      4  25.370961   \n",
       "146  95.281470  143.160827                      5  21.892076   \n",
       "147  96.440095  154.721375                      5  20.963266   \n",
       "148  96.731001  160.466720                      5  19.938365   \n",
       "149  98.918187  163.330163                      5  29.795418   \n",
       "\n",
       "     cerebrovascular_disease  peripheral_artery_disease  if_yes_what_type___1  \\\n",
       "0                          1                          1                     0   \n",
       "1                          1                          1                     1   \n",
       "2                          1                          1                     1   \n",
       "3                          0                          1                     0   \n",
       "4                          1                          1                     1   \n",
       "..                       ...                        ...                   ...   \n",
       "145                        1                          0                     1   \n",
       "146                        1                          1                     1   \n",
       "147                        1                          1                     1   \n",
       "148                        1                          1                     1   \n",
       "149                        1                          1                     1   \n",
       "\n",
       "     single_vessel  calcium  medina_side  ...  restenosis_reocclusion  \\\n",
       "0                1        1            1  ...                       1   \n",
       "1                1        1            1  ...                       1   \n",
       "2                1        1            1  ...                       1   \n",
       "3                1        1            1  ...                       1   \n",
       "4                1        1            1  ...                       1   \n",
       "..             ...      ...          ...  ...                     ...   \n",
       "145              1        1            1  ...                       1   \n",
       "146              1        0            1  ...                       1   \n",
       "147              1        1            1  ...                       1   \n",
       "148              1        1            1  ...                       1   \n",
       "149              0        1            0  ...                       1   \n",
       "\n",
       "     adhoc_pci  main_predilatation  stent_diameter  stent_length  mortality  \\\n",
       "0            1                   0        2.725508     37.844611          1   \n",
       "1            1                   1        2.465256     29.799415          1   \n",
       "2            1                   1        2.457795     36.585190          1   \n",
       "3            1                   1        2.309615     34.232300          1   \n",
       "4            0                   1        2.660538     30.051020          1   \n",
       "..         ...                 ...             ...           ...        ...   \n",
       "145          1                   1        2.554469     29.944907          1   \n",
       "146          1                   0        2.626765     28.857971          1   \n",
       "147          0                   1        2.371528     28.248528          1   \n",
       "148          1                   1        2.020478     34.580807          1   \n",
       "149          0                   0        2.528102     34.970761          1   \n",
       "\n",
       "     smoking  dyslipidemia  anemia  atrial_fibrilation  \n",
       "0          1             1       1                   1  \n",
       "1          1             1       1                   1  \n",
       "2          0             1       1                   1  \n",
       "3          1             1       1                   1  \n",
       "4          1             1       1                   1  \n",
       "..       ...           ...     ...                 ...  \n",
       "145        1             1       1                   1  \n",
       "146        1             1       1                   1  \n",
       "147        1             1       1                   1  \n",
       "148        1             1       1                   1  \n",
       "149        1             1       1                   1  \n",
       "\n",
       "[150 rows x 30 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import edge_case\n",
    "importlib.reload(edge_case)\n",
    "from edge_case import generate_edge_cases\n",
    "\n",
    "edge_cases = generate_edge_cases(num_samples=150)\n",
    "edge_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54ef5a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON OF COLUMNS:\n",
      "\n",
      "Total columns in edge_cases: 30\n",
      "Total columns in X_train: 22\n",
      "Number of common columns: 22\n",
      "\n",
      "--- COMMON COLUMNS ---\n",
      "- age\n",
      "- anemia\n",
      "- atrial_fibrilation\n",
      "- calcium\n",
      "- cerebrovascular_disease\n",
      "- clinical_presentation\n",
      "- cto_bifurc\n",
      "- def\n",
      "- dyslipidemia\n",
      "- ef\n",
      "- height\n",
      "- history_of_cancer\n",
      "- if_yes_what_type___1\n",
      "- medina_side\n",
      "- peripheral_artery_disease\n",
      "- previous_pci\n",
      "- previous_stroke_tia\n",
      "- side_diametr\n",
      "- single_vessel\n",
      "- smoking\n",
      "- stent_type___3\n",
      "- trifurcation\n",
      "\n",
      "--- COLUMNS ONLY IN EDGE CASES ---\n",
      "- adhoc_pci\n",
      "- main_predilatation\n",
      "- mortality\n",
      "- restenosis_reocclusion\n",
      "- stent_diameter\n",
      "- stent_length\n",
      "- stent_type___4\n",
      "- stent_type___5\n",
      "\n",
      "--- COLUMNS ONLY IN X_TRAIN ---\n"
     ]
    }
   ],
   "source": [
    "edge_case_cols = set(edge_cases.columns)\n",
    "x_train_cols = set(X_train.columns)\n",
    "\n",
    "common_cols = edge_case_cols.intersection(x_train_cols)\n",
    "only_in_edge_cases = edge_case_cols - x_train_cols\n",
    "only_in_x_train = x_train_cols - edge_case_cols\n",
    "\n",
    "print(f\"COMPARISON OF COLUMNS:\")\n",
    "print(f\"\\nTotal columns in edge_cases: {len(edge_case_cols)}\")\n",
    "print(f\"Total columns in X_train: {len(x_train_cols)}\")\n",
    "print(f\"Number of common columns: {len(common_cols)}\")\n",
    "\n",
    "print(\"\\n--- COMMON COLUMNS ---\")\n",
    "for col in sorted(common_cols):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\n--- COLUMNS ONLY IN EDGE CASES ---\")\n",
    "for col in sorted(only_in_edge_cases):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\n--- COLUMNS ONLY IN X_TRAIN ---\")\n",
    "for col in sorted(only_in_x_train):\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "189a08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_cases_target = edge_cases['mortality']\n",
    "edge_cases_features = edge_cases.copy().drop('mortality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5328c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.166695</td>\n",
       "      <td>158.513893</td>\n",
       "      <td>5</td>\n",
       "      <td>17.383818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.205518</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.963835</td>\n",
       "      <td>168.368143</td>\n",
       "      <td>4</td>\n",
       "      <td>24.838871</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.761979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.509236</td>\n",
       "      <td>151.994317</td>\n",
       "      <td>4</td>\n",
       "      <td>19.705380</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.021064</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.807009</td>\n",
       "      <td>160.203405</td>\n",
       "      <td>5</td>\n",
       "      <td>15.757748</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.078804</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96.239502</td>\n",
       "      <td>164.039686</td>\n",
       "      <td>5</td>\n",
       "      <td>21.961974</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.385241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>99.510905</td>\n",
       "      <td>166.976362</td>\n",
       "      <td>4</td>\n",
       "      <td>25.370961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.109599</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>95.281470</td>\n",
       "      <td>143.160827</td>\n",
       "      <td>5</td>\n",
       "      <td>21.892076</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.921698</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>96.440095</td>\n",
       "      <td>154.721375</td>\n",
       "      <td>5</td>\n",
       "      <td>20.963266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.012680</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>96.731001</td>\n",
       "      <td>160.466720</td>\n",
       "      <td>5</td>\n",
       "      <td>19.938365</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.241588</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>98.918187</td>\n",
       "      <td>163.330163</td>\n",
       "      <td>5</td>\n",
       "      <td>29.795418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.307811</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      height  clinical_presentation         ef  \\\n",
       "0    85.166695  158.513893                      5  17.383818   \n",
       "1    95.963835  168.368143                      4  24.838871   \n",
       "2    88.509236  151.994317                      4  19.705380   \n",
       "3    92.807009  160.203405                      5  15.757748   \n",
       "4    96.239502  164.039686                      5  21.961974   \n",
       "..         ...         ...                    ...        ...   \n",
       "145  99.510905  166.976362                      4  25.370961   \n",
       "146  95.281470  143.160827                      5  21.892076   \n",
       "147  96.440095  154.721375                      5  20.963266   \n",
       "148  96.731001  160.466720                      5  19.938365   \n",
       "149  98.918187  163.330163                      5  29.795418   \n",
       "\n",
       "     cerebrovascular_disease  peripheral_artery_disease  if_yes_what_type___1  \\\n",
       "0                          1                          1                     0   \n",
       "1                          1                          1                     1   \n",
       "2                          1                          1                     1   \n",
       "3                          0                          1                     0   \n",
       "4                          1                          1                     1   \n",
       "..                       ...                        ...                   ...   \n",
       "145                        1                          0                     1   \n",
       "146                        1                          1                     1   \n",
       "147                        1                          1                     1   \n",
       "148                        1                          1                     1   \n",
       "149                        1                          1                     1   \n",
       "\n",
       "     single_vessel  calcium  medina_side  ...  def  history_of_cancer  \\\n",
       "0                1        1            1  ...    1                  1   \n",
       "1                1        1            1  ...    1                  0   \n",
       "2                1        1            1  ...    1                  0   \n",
       "3                1        1            1  ...    1                  1   \n",
       "4                1        1            1  ...    1                  0   \n",
       "..             ...      ...          ...  ...  ...                ...   \n",
       "145              1        1            1  ...    0                  0   \n",
       "146              1        0            1  ...    1                  0   \n",
       "147              1        1            1  ...    1                  1   \n",
       "148              1        1            1  ...    1                  1   \n",
       "149              0        1            0  ...    1                  1   \n",
       "\n",
       "     previous_pci  previous_stroke_tia  side_diametr  stent_type___3  smoking  \\\n",
       "0               1                    1      1.205518               0        1   \n",
       "1               1                    1      1.761979               1        1   \n",
       "2               1                    0      1.021064               0        0   \n",
       "3               1                    0      1.078804               0        1   \n",
       "4               1                    0      1.385241               1        1   \n",
       "..            ...                  ...           ...             ...      ...   \n",
       "145             1                    1      1.109599               0        1   \n",
       "146             1                    0      1.921698               0        1   \n",
       "147             1                    0      1.012680               0        1   \n",
       "148             1                    1      1.241588               0        1   \n",
       "149             0                    0      1.307811               1        1   \n",
       "\n",
       "     dyslipidemia  anemia  atrial_fibrilation  \n",
       "0               1       1                   1  \n",
       "1               1       1                   1  \n",
       "2               1       1                   1  \n",
       "3               1       1                   1  \n",
       "4               1       1                   1  \n",
       "..            ...     ...                 ...  \n",
       "145             1       1                   1  \n",
       "146             1       1                   1  \n",
       "147             1       1                   1  \n",
       "148             1       1                   1  \n",
       "149             1       1                   1  \n",
       "\n",
       "[150 rows x 22 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_cases_features_names = [feature for feature in edge_cases.columns if feature in X_train.columns]\n",
    "edge_cases_features = pd.DataFrame(edge_cases, columns=edge_cases_features_names)\n",
    "edge_cases_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3758ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds = pd.concat([X_train, X_val, edge_cases_features])\n",
    "y_train_k_fold = np.concatenate((y_train, y_val, edge_cases_target), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f90a489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 15:10:20 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:10:20 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:10:20 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:10:20 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:10:22 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:10:22 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:10:22 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:10:22 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:10:54 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:10:54 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:10:54 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:10:54 INFO     Order of selections: [0]\n",
      "2025-05-22 15:10:54 INFO     Val loss over iterations: [-0.8544751742160278]\n",
      "2025-05-22 15:10:54 INFO     Model losses: [-0.85447517]\n",
      "2025-05-22 15:10:54 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 15:12:21 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:12:21 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:12:21 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:12:21 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:12:24 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:12:24 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:12:24 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:12:24 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:12:56 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:12:56 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:12:56 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:12:56 INFO     Order of selections: [0]\n",
      "2025-05-22 15:12:56 INFO     Val loss over iterations: [-0.8697462979094076]\n",
      "2025-05-22 15:12:56 INFO     Model losses: [-0.8697463]\n",
      "2025-05-22 15:12:56 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 15:14:25 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:14:25 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:14:25 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:14:25 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:14:27 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:14:27 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:14:27 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:14:27 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:14:59 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:14:59 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:14:59 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:14:59 INFO     Order of selections: [0]\n",
      "2025-05-22 15:14:59 INFO     Val loss over iterations: [-0.8800903745644598]\n",
      "2025-05-22 15:14:59 INFO     Model losses: [-0.88009037]\n",
      "2025-05-22 15:14:59 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "2025-05-22 15:16:34 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:16:34 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:16:34 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:16:34 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:16:37 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:16:37 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:16:37 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:16:37 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:17:15 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:17:15 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:17:15 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:17:15 INFO     Order of selections: [0]\n",
      "2025-05-22 15:17:15 INFO     Val loss over iterations: [-0.8781032229965156]\n",
      "2025-05-22 15:17:15 INFO     Model losses: [-0.87810322]\n",
      "2025-05-22 15:17:15 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:18:49 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:18:49 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:18:49 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:18:49 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:18:51 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:18:51 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:18:51 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:18:51 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:19:22 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:19:22 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:19:22 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:19:22 INFO     Order of selections: [0]\n",
      "2025-05-22 15:19:22 INFO     Val loss over iterations: [-0.8423889372822301]\n",
      "2025-05-22 15:19:22 INFO     Model losses: [-0.84238894]\n",
      "2025-05-22 15:19:22 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:20:51 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:20:51 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:20:51 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:20:51 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:20:54 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:20:54 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:20:54 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:20:54 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:21:26 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:21:26 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:21:26 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:21:27 INFO     Order of selections: [0]\n",
      "2025-05-22 15:21:27 INFO     Val loss over iterations: [-0.8546363191916996]\n",
      "2025-05-22 15:21:27 INFO     Model losses: [-0.85463632]\n",
      "2025-05-22 15:21:27 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:22:56 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:22:56 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:22:56 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:22:56 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:22:58 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:22:58 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:22:58 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:22:58 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:23:33 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:23:33 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:23:33 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:23:33 INFO     Order of selections: [0]\n",
      "2025-05-22 15:23:33 INFO     Val loss over iterations: [-0.8275571731218426]\n",
      "2025-05-22 15:23:33 INFO     Model losses: [-0.82755717]\n",
      "2025-05-22 15:23:33 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:25:11 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:25:11 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:25:11 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:25:11 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:25:13 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:25:13 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:25:13 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:25:13 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:25:47 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:25:47 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:25:47 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:25:47 INFO     Order of selections: [0]\n",
      "2025-05-22 15:25:47 INFO     Val loss over iterations: [-0.8559943505893857]\n",
      "2025-05-22 15:25:47 INFO     Model losses: [-0.85599435]\n",
      "2025-05-22 15:25:47 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:27:23 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:27:23 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:27:23 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:27:23 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:27:25 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:27:25 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:27:25 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:27:25 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:28:01 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:28:01 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:28:01 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:28:01 INFO     Order of selections: [0]\n",
      "2025-05-22 15:28:01 INFO     Val loss over iterations: [-0.8099570862078331]\n",
      "2025-05-22 15:28:01 INFO     Model losses: [-0.80995709]\n",
      "2025-05-22 15:28:01 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:29:34 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:29:34 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:29:34 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:29:34 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:29:36 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:29:36 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:29:36 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:29:36 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:30:10 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:30:10 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:30:10 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:30:10 INFO     Order of selections: [0]\n",
      "2025-05-22 15:30:10 INFO     Val loss over iterations: [-0.8548264435873757]\n",
      "2025-05-22 15:30:10 INFO     Model losses: [-0.85482644]\n",
      "2025-05-22 15:30:10 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and evaluation metrics saved to JSON and pickle files.\n",
      "Results: {'loss': -0.8595027856617261, 'best_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch  # Required for saving the model\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "def objective(X_train_folds, y_train_k_fold):\n",
    "    best_score = -np.inf\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10)\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get train and test data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index] if hasattr(X_train_folds, 'iloc') else X_train_folds[train_index]\n",
    "        X_test_fold = X_train_folds.iloc[test_index] if hasattr(X_train_folds, 'iloc') else X_train_folds[test_index]\n",
    "        y_train = y_train_k_fold[train_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Apply StandardScaler to training data only, then transform test data\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_fold)\n",
    "        X_test = scaler.transform(X_test_fold)\n",
    "\n",
    "        # Initialize TabPFN classifier\n",
    "        classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "        \n",
    "        # Fit classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict probabilities and classes\n",
    "        y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        \n",
    "        if roc_auc > best_score:\n",
    "            best_score = roc_auc\n",
    "    \n",
    "    # Create a dictionary with all the metrics\n",
    "    results = {\n",
    "        \"roc_auc\": {\n",
    "            \"scores\": [float(score) for score in roc_auc_scores],\n",
    "            \"mean\": float(np.mean(roc_auc_scores))\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"scores\": [float(score) for score in f1_scores],\n",
    "            \"mean\": float(np.mean(f1_scores))\n",
    "        },\n",
    "        \"precision\": {\n",
    "            \"scores\": [float(score) for score in precision_scores],\n",
    "            \"mean\": float(np.mean(precision_scores))\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"scores\": [float(score) for score in recall_scores],\n",
    "            \"mean\": float(np.mean(recall_scores))\n",
    "        },\n",
    "        \"accuracy\": {\n",
    "            \"scores\": [float(score) for score in accuracy_scores],\n",
    "            \"mean\": float(np.mean(accuracy_scores))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save metrics results to JSON file\n",
    "    with open('scores_AutoTabFPN_CV_edge_cases.json', 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "    # Save the model\n",
    "    with open('AutoTabFPN_CV_edge_cases.pkl', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print(\"Model and evaluation metrics saved to JSON and pickle files.\")\n",
    "    \n",
    "    return {'loss': -np.mean(roc_auc_scores), 'best_score': best_score}\n",
    "\n",
    "result = objective(X_train_folds, y_train_k_fold)\n",
    "\n",
    "print(\"Results:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fe98467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 15:49:50 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-22 15:49:50 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "2025-05-22 15:49:50 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-22 15:49:50 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-22 15:49:52 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-22 15:49:52 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-22 15:49:52 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-22 15:49:52 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-22 15:50:32 INFO     Likely not enough time left for another model.\n",
      "2025-05-22 15:50:32 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-22 15:50:32 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-22 15:50:32 INFO     Order of selections: [0]\n",
      "2025-05-22 15:50:32 INFO     Val loss over iterations: [-0.8641899182981347]\n",
      "2025-05-22 15:50:32 INFO     Model losses: [-0.86418992]\n",
      "2025-05-22 15:50:32 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning:\n",
      "\n",
      "'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_final_test_results_20250522_155223.json\n",
      "Visualization saved to tabpfn_final_test_results_20250522_155223.png\n",
      "Test metrics:\n",
      "  roc_auc: 0.8225\n",
      "  f1: 0.0625\n",
      "  precision: 1.0000\n",
      "  recall: 0.0323\n",
      "  accuracy: 0.9267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_folds)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the full training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_k_fold)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_final_model_edge_cases.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Save results to JSON\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "result_filename = f'tabpfn_final_test_results_{timestamp}.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Negative', 'Positive'])\n",
    "plt.yticks(tick_marks, ['Negative', 'Positive'])\n",
    "\n",
    "# Add text annotations to confusion matrix\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(f'tabpfn_final_test_results_{timestamp}.png')\n",
    "plt.show()\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(f\"Visualization saved to tabpfn_final_test_results_{timestamp}.png\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4f391",
   "metadata": {},
   "source": [
    "# TABFPN + edge cases + synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27381585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-22 16:11:23 INFO     PyTorch version 2.2.2 available.\n",
      "2025-05-22 16:11:23 INFO     Duckdb version 1.2.1 available.\n",
      "2025-05-22 16:11:23 INFO     TensorFlow version 2.19.0 available.\n",
      "[2025-05-22T16:11:23.450769+0400][19399][CRITICAL] load failed: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "[2025-05-22T16:11:23.450769+0400][19399][CRITICAL] load failed: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "[2025-05-22T16:11:23.451630+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:11:23.451630+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:11:23.452142+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:11:23.452142+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:11:23.620291+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-22T16:11:23.620291+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7462640099626401\n",
      "Iteration number 1 reached accuracy of 0.4255915317559153.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:13:55.030656+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:13:55.031117+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:13:55.031379+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:13:55.031641+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7577833125778332\n",
      "Iteration number 1 reached accuracy of 0.4290161892901619.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:16:23.439640+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:16:23.440120+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:16:23.440413+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:16:23.440717+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7400373599003736\n",
      "Iteration number 1 reached accuracy of 0.42714819427148193.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:18:50.035633+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:18:50.036079+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:18:50.036349+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:18:50.036680+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7471980074719801\n",
      "Iteration number 1 reached accuracy of 0.451120797011208.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:21:15.398137+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:21:15.398603+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:21:15.398979+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:21:15.399322+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7665006226650062\n",
      "Iteration number 1 reached accuracy of 0.4374221668742217.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:23:37.201251+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:23:37.201708+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:23:37.201989+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:23:37.202328+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7398879900435594\n",
      "Iteration number 1 reached accuracy of 0.43217174859987556.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:26:02.501359+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:26:02.501845+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:26:02.502111+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:26:02.502403+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7386434349719975\n",
      "Iteration number 1 reached accuracy of 0.44119477286869946.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:28:27.351357+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:28:27.351804+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:28:27.352119+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:28:27.352393+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7514001244555072\n",
      "Iteration number 1 reached accuracy of 0.4387056627255756.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:30:49.851762+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:30:49.852202+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:30:49.852500+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:30:49.852796+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7411325451151214\n",
      "Iteration number 1 reached accuracy of 0.4492843808338519.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T16:33:13.788436+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:33:13.788876+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T16:33:13.789155+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T16:33:13.789468+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7364654635967641\n",
      "Iteration number 1 reached accuracy of 0.4144368388301182.\n",
      "Model and evaluation metrics saved to JSON and pickle files.\n",
      "Results: {'loss': -0.8437287571393531, 'best_score': 0.9174550614947966}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import torch  # Required for saving the model\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "class AutoTabPFNClassifier(TabPFNClassifier):\n",
    "    def __init__(self, device='auto', max_time=60, **kwargs):\n",
    "        super().__init__(device=device, **kwargs)\n",
    "        self.max_time = max_time\n",
    "\n",
    "def objective(X_train_folds, y_train_k_fold):\n",
    "    best_score = -np.inf\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "    \n",
    "    # Initialize scaler for consistent transformations\n",
    "    scaler = StandardScaler()\n",
    "    X_train_folds_scaled = scaler.fit_transform(X_train_folds)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get original train and test data for this fold\n",
    "        not_scaled_X_train = X_train_folds.iloc[train_index] if hasattr(X_train_folds, 'iloc') else pd.DataFrame(X_train_folds[train_index])\n",
    "        X_test_fold = X_train_folds_scaled[test_index]\n",
    "        y_train = y_train_k_fold[train_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Prepare train data with target for synthetic generation\n",
    "        train_df = not_scaled_X_train.copy().reset_index(drop=True)\n",
    "        train_df['target'] = y_train\n",
    "        \n",
    "        # Create GenericDataLoader as per documentation\n",
    "        loader = GenericDataLoader(\n",
    "            train_df,\n",
    "            target_column=\"target\",\n",
    "        )\n",
    "        \n",
    "        # Generate synthetic data using synthcity's ARF\n",
    "        syn_model = Plugins().get(\"arf\")\n",
    "        syn_model.fit(loader)\n",
    "        \n",
    "        # Generate synthetic samples\n",
    "        synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "        \n",
    "        # Extract minority class samples\n",
    "        minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "        if len(minority_synthetic_data) > 600:\n",
    "            minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "        \n",
    "        # Drop target column from synthetic data\n",
    "        syntetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "        syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "        # Combine original and synthetic data\n",
    "        X_train_combined = pd.concat([not_scaled_X_train, syntetic_minority_features])\n",
    "        X_train = scaler.transform(X_train_combined)\n",
    "        y_train_combined = np.concatenate((y_train, syntetic_target.values), axis=0)\n",
    "\n",
    "        # Initialize TabPFN classifier\n",
    "        classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "        \n",
    "        # Fit classifier\n",
    "        classifier.fit(X_train, y_train_combined)\n",
    "        \n",
    "        # Predict probabilities and classes\n",
    "        y_pred_prob = classifier.predict_proba(X_test_fold)[:, 1]\n",
    "        y_pred = classifier.predict(X_test_fold)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "        \n",
    "        if roc_auc > best_score:\n",
    "            best_score = roc_auc\n",
    "            best_classifier = classifier\n",
    "    \n",
    "    # Create a dictionary with all the metrics\n",
    "    results = {\n",
    "        \"roc_auc\": {\n",
    "            \"scores\": [float(score) for score in roc_auc_scores],\n",
    "            \"mean\": float(np.mean(roc_auc_scores))\n",
    "        },\n",
    "        \"f1\": {\n",
    "            \"scores\": [float(score) for score in f1_scores],\n",
    "            \"mean\": float(np.mean(f1_scores))\n",
    "        },\n",
    "        \"precision\": {\n",
    "            \"scores\": [float(score) for score in precision_scores],\n",
    "            \"mean\": float(np.mean(precision_scores))\n",
    "        },\n",
    "        \"recall\": {\n",
    "            \"scores\": [float(score) for score in recall_scores],\n",
    "            \"mean\": float(np.mean(recall_scores))\n",
    "        },\n",
    "        \"accuracy\": {\n",
    "            \"scores\": [float(score) for score in accuracy_scores],\n",
    "            \"mean\": float(np.mean(accuracy_scores))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save metrics results to JSON file\n",
    "    with open('scores_AutoTabFPN_ARF_CV_edge_cases.json', 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "    # Save the model\n",
    "    with open('AutoTabFPN_ARF_CV_edge_cases.pkl', 'wb') as f:\n",
    "        pickle.dump(best_classifier, f)\n",
    "    \n",
    "    print(\"Model and evaluation metrics saved to JSON and pickle files.\")\n",
    "    \n",
    "    return {'loss': -np.mean(roc_auc_scores), 'best_score': best_score}\n",
    "\n",
    "result = objective(X_train_folds, y_train_k_fold)\n",
    "\n",
    "print(\"Results:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1230751a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T17:40:51.501997+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T17:40:51.501997+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T17:40:51.503356+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T17:40:51.503356+0400][19399][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-22T17:40:51.504012+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T17:40:51.504012+0400][19399][CRITICAL] module plugin_great load failed\n",
      "[2025-05-22T17:40:51.504712+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-22T17:40:51.504712+0400][19399][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7518207282913165\n",
      "Iteration number 1 reached accuracy of 0.438375350140056.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-22T17:41:02.043049+0400][19399][INFO] [side_diametr] quality loss for constraints ge = 0.4. Remaining 9995. prev length 10000. Original dtype float64.\n",
      "[2025-05-22T17:41:02.044751+0400][19399][INFO] [previous_stroke_tia] quality loss for constraints le = 1.541114238227274. Remaining 9988. prev length 9995. Original dtype float64.\n",
      "[2025-05-22T17:41:02.045268+0400][19399][INFO] [previous_stroke_tia] quality loss for constraints ge = 0.0. Remaining 9682. prev length 9988. Original dtype float64.\n",
      "[2025-05-22T17:41:02.046403+0400][19399][INFO] [height] quality loss for constraints le = 196.0. Remaining 9626. prev length 9682. Original dtype float64.\n",
      "[2025-05-22T17:41:02.046989+0400][19399][INFO] [height] quality loss for constraints ge = 65.0. Remaining 9621. prev length 9626. Original dtype float64.\n",
      "[2025-05-22T17:41:02.048329+0400][19399][INFO] [ef] quality loss for constraints le = 82.0. Remaining 9585. prev length 9621. Original dtype float64.\n",
      "[2025-05-22T17:41:02.048745+0400][19399][INFO] [ef] quality loss for constraints ge = 15.057001905843372. Remaining 9521. prev length 9585. Original dtype float64.\n",
      "[2025-05-22T17:41:02.051016+0400][19399][INFO] [age] quality loss for constraints le = 99.98914851580363. Remaining 9464. prev length 9521. Original dtype float64.\n",
      "[2025-05-22T17:41:02.051504+0400][19399][INFO] [age] quality loss for constraints ge = 28.0. Remaining 9457. prev length 9464. Original dtype float64.\n",
      "[2025-05-22T17:41:08.472233+0400][19399][INFO] [side_diametr] quality loss for constraints ge = 0.4. Remaining 9994. prev length 10000. Original dtype float64.\n",
      "[2025-05-22T17:41:08.473595+0400][19399][INFO] [previous_stroke_tia] quality loss for constraints le = 1.541114238227274. Remaining 9988. prev length 9994. Original dtype float64.\n",
      "[2025-05-22T17:41:08.474330+0400][19399][INFO] [previous_stroke_tia] quality loss for constraints ge = 0.0. Remaining 9696. prev length 9988. Original dtype float64.\n",
      "[2025-05-22T17:41:08.475383+0400][19399][INFO] [height] quality loss for constraints le = 196.0. Remaining 9642. prev length 9696. Original dtype float64.\n",
      "[2025-05-22T17:41:08.476199+0400][19399][INFO] [height] quality loss for constraints ge = 65.0. Remaining 9636. prev length 9642. Original dtype float64.\n",
      "[2025-05-22T17:41:08.477801+0400][19399][INFO] [ef] quality loss for constraints le = 82.0. Remaining 9598. prev length 9636. Original dtype float64.\n",
      "[2025-05-22T17:41:08.478316+0400][19399][INFO] [ef] quality loss for constraints ge = 15.057001905843372. Remaining 9540. prev length 9598. Original dtype float64.\n",
      "[2025-05-22T17:41:08.480515+0400][19399][INFO] [age] quality loss for constraints le = 99.98914851580363. Remaining 9503. prev length 9540. Original dtype float64.\n",
      "[2025-05-22T17:41:08.481004+0400][19399][INFO] [age] quality loss for constraints ge = 28.0. Remaining 9495. prev length 9503. Original dtype float64.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_arf_edge_cases.json\n",
      "Visualization saved to tabpfn_arf_edge_cases.png\n",
      "Test metrics:\n",
      "  roc_auc: 0.7387\n",
      "  f1: 0.1463\n",
      "  precision: 0.3000\n",
      "  recall: 0.0968\n",
      "  accuracy: 0.9144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data with target for synthetic generation\n",
    "train_df = X_train_folds.copy().reset_index(drop=True)\n",
    "train_df['target'] = y_train_k_fold\n",
    "\n",
    "# Create GenericDataLoader as per documentation\n",
    "loader = GenericDataLoader(\n",
    "    train_df,\n",
    "    target_column=\"target\",\n",
    ")\n",
    "\n",
    "# Generate synthetic data using synthcity's ARF\n",
    "syn_model = Plugins().get(\"arf\")\n",
    "syn_model.fit(loader)\n",
    "\n",
    "# Generate synthetic samples\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority class samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Drop target column from synthetic data\n",
    "syntetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data\n",
    "X_train_combined = pd.concat([X_train_folds, syntetic_minority_features])\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "y_train_combined = np.concatenate((y_train_k_fold, syntetic_target.values), axis=0)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the combined training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_combined)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_ARF_edge_cases.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_arf_edge_cases.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Visualizations\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {metrics[\"roc_auc\"]:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Negative', 'Positive'])\n",
    "plt.yticks(tick_marks, ['Negative', 'Positive'])\n",
    "\n",
    "# Add text annotations to confusion matrix\n",
    "thresh = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.show()\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(f\"Visualization saved to tabpfn_arf_edge_cases.png\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ac22c",
   "metadata": {},
   "source": [
    "# NO cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch  # Required for saving the model\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def objective(X_train, y_train, X_test, y_test):\n",
    "    # Preprocess and generate synthetic data\n",
    "    not_scaled_X_train = X_train.copy()\n",
    "    train = not_scaled_X_train.copy().reset_index(drop=True)\n",
    "    train['index'] = np.arange(1, len(train) + 1)\n",
    "    train['target'] = y_train\n",
    "    synthesizer = CopulaGANSynthesizer(metadata, epochs=500, default_distribution='norm')\n",
    "    synthesizer.fit(train)\n",
    "    synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "    minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "    if len(minority_synthetic_data) > 600:\n",
    "      minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "    syntetic_minority_dropped = minority_synthetic_data.copy().drop(['target', 'index'], axis=1)\n",
    "    syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "    # Combine real and synthetic data\n",
    "    X_train_combined = pd.concat([not_scaled_X_train, syntetic_minority_dropped])\n",
    "    X_train_combined = scaller.transform(X_train_combined)\n",
    "    y_train_combined = np.concatenate((y_train, syntetic_target), axis=0)\n",
    "\n",
    "    classifier = AutoTabPFNClassifier(device='auto', max_time=120)\n",
    "    \n",
    "    classifier.fit(X_train_combined, y_train_combined)\n",
    "    \n",
    "    y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    with open('scores_AutoTabFPN_syntetic_noCV_CopulaGAN.txt', 'w') as file:\n",
    "        file.write(f\"ROC AUC: {roc_auc}\\n\")\n",
    "        file.write(f\"F1: {f1}\\n\")\n",
    "        file.write(f\"Precision: {precision}\\n\")\n",
    "        file.write(f\"Recall: {recall}\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    with open('AutoTabFPN_syntetic_noCV_CopulaGAN.pkl', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print(\"Model and evaluation metrics saved.\")\n",
    "\n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "result = objective(X_train_folds, y_train_k_fold, X_test, y_test)\n",
    "\n",
    "print(\"Results:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7000a05",
   "metadata": {},
   "source": [
    "# No CV and no Syntetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73ab36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 13:00:18 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-03-09 13:00:18 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "2025-03-09 13:00:18 INFO     Using task type: TaskType.BINARY\n",
      "2025-03-09 13:00:18 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-03-09 13:00:20 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-03-09 13:00:20 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-03-09 13:00:20 INFO     Set time limit to 30 seconds. We will early stop validation if needed.\n",
      "2025-03-09 13:00:20 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-03-09 13:00:50 INFO     Likely not enough time left for another model.\n",
      "2025-03-09 13:00:50 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-03-09 13:00:50 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-03-09 13:00:50 INFO     Order of selections: [0]\n",
      "2025-03-09 13:00:50 INFO     Val loss over iterations: [-0.7090091536855628]\n",
      "2025-03-09 13:00:50 INFO     Model losses: [-0.70900915]\n",
      "2025-03-09 13:00:50 INFO     Best weights: [1.]\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and evaluation metrics saved.\n",
      "Results: {'roc_auc': 0.6943918150814702, 'f1': 0.06060606060606061, 'precision': 0.25, 'recall': 0.034482758620689655, 'accuracy': 0.9211195928753181}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch  # Required for saving the model\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def objective(X_train, y_train, X_test, y_test):\n",
    "    classifier = AutoTabPFNClassifier()\n",
    "    \n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    with open('scores_AutoTabFPN_syntetic_noCV_noSyntetic.txt', 'w') as file:\n",
    "        file.write(f\"ROC AUC: {roc_auc}\\n\")\n",
    "        file.write(f\"F1: {f1}\\n\")\n",
    "        file.write(f\"Precision: {precision}\\n\")\n",
    "        file.write(f\"Recall: {recall}\\n\")\n",
    "        file.write(f\"Accuracy: {accuracy}\\n\")\n",
    "\n",
    "    with open('AutoTabFPN_syntetic_noCV_noSyntetic.pkl', 'wb') as f:\n",
    "        pickle.dump(classifier, f)\n",
    "    \n",
    "    print(\"Model and evaluation metrics saved.\")\n",
    "\n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "result = objective(X_train_folds, y_train_k_fold, X_test, y_test)\n",
    "\n",
    "print(\"Results:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5fbc66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_syntetic(X_train, y_train, num_rows=10000):\n",
    "  not_scaled_X_train = X_train.copy()\n",
    "  train = not_scaled_X_train.copy().reset_index(drop=True)\n",
    "  train['index'] = np.arange(1, len(train) + 1)\n",
    "  train['target'] = y_train\n",
    "  synthesizer = CTGANSynthesizer(metadata, epochs=500)\n",
    "  synthesizer.fit(train)\n",
    "  synthetic_data = synthesizer.sample(num_rows)\n",
    "  minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "\n",
    "  # Enforce constraint\n",
    "  if len(minority_synthetic_data) > 600:\n",
    "      minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "  syntetic_minority_dropped = minority_synthetic_data.copy().drop(['target', 'index'], axis=1)\n",
    "  syntetic_target = minority_synthetic_data['target']\n",
    "  return [syntetic_minority_dropped, syntetic_target, synthetic_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "afcbbab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 13:31:32 INFO     {'EVENT': 'Instance', 'TIMESTAMP': datetime.datetime(2025, 3, 9, 13, 31, 32, 916606), 'SYNTHESIZER CLASS NAME': 'CTGANSynthesizer', 'SYNTHESIZER ID': 'CTGANSynthesizer_1.17.4_4d51b1bc6acf44fba0a965b680ddad73'}\n",
      "2025-03-09 13:31:32 INFO     {'EVENT': 'Fit', 'TIMESTAMP': datetime.datetime(2025, 3, 9, 13, 31, 32, 917156), 'SYNTHESIZER CLASS NAME': 'CTGANSynthesizer', 'SYNTHESIZER ID': 'CTGANSynthesizer_1.17.4_4d51b1bc6acf44fba0a965b680ddad73', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 1568, 'TOTAL NUMBER OF COLUMNS': 27}\n",
      "2025-03-09 13:31:32 INFO     Fitting table  metadata\n",
      "2025-03-09 13:31:32 INFO     Fitting formatters for table \n",
      "2025-03-09 13:31:32 INFO     No rounding scheme detected for column 'ef'. Data will not be rounded.\n",
      "2025-03-09 13:31:32 INFO     No rounding scheme detected for column 'ckd'. Data will not be rounded.\n",
      "2025-03-09 13:31:32 INFO     No rounding scheme detected for column 'stent_length'. Data will not be rounded.\n",
      "2025-03-09 13:31:32 INFO     Fitting constraints for table \n",
      "2025-03-09 13:31:32 INFO     Setting the configuration for the ``HyperTransformer`` for table \n",
      "2025-03-09 13:31:32 INFO     Fitting HyperTransformer for table \n",
      "2025-03-09 13:31:32 INFO     No rounding scheme detected for column 'ef'. Data will not be rounded.\n",
      "2025-03-09 13:31:32 INFO     No rounding scheme detected for column 'ckd'. Data will not be rounded.\n",
      "2025-03-09 13:31:32 INFO     No rounding scheme detected for column 'stent_length'. Data will not be rounded.\n",
      "2025-03-09 13:31:32 INFO     {'EVENT': 'Fit processed data', 'TIMESTAMP': datetime.datetime(2025, 3, 9, 13, 31, 32, 998209), 'SYNTHESIZER CLASS NAME': 'CTGANSynthesizer', 'SYNTHESIZER ID': 'CTGANSynthesizer_1.17.4_4d51b1bc6acf44fba0a965b680ddad73', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 1568, 'TOTAL NUMBER OF COLUMNS': 26}\n",
      "2025-03-09 13:31:33 INFO     Guidance: There are no missing values in column ef. Extra column not created.\n",
      "2025-03-09 13:31:33 INFO     Guidance: There are no missing values in column age. Extra column not created.\n",
      "2025-03-09 13:31:33 INFO     Guidance: There are no missing values in column ckd. Extra column not created.\n",
      "2025-03-09 13:31:33 INFO     Guidance: There are no missing values in column stent_length. Extra column not created.\n",
      "2025-03-09 13:31:33 INFO     Guidance: There are no missing values in column distal_diametr. Extra column not created.\n",
      "2025-03-09 13:32:22 INFO     {'EVENT': 'Sample', 'TIMESTAMP': datetime.datetime(2025, 3, 9, 13, 32, 22, 744406), 'SYNTHESIZER CLASS NAME': 'CTGANSynthesizer', 'SYNTHESIZER ID': 'CTGANSynthesizer_1.17.4_4d51b1bc6acf44fba0a965b680ddad73', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 10000, 'TOTAL NUMBER OF COLUMNS': 27}\n"
     ]
    }
   ],
   "source": [
    "res = generate_syntetic(X_train_folds, y_train_k_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "701fe901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 9373, 1: 627}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(res[2]['target'], return_counts=True)\n",
    "value_counts = dict(zip(unique, counts))\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c7685daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 600}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(res[1], return_counts=True)\n",
    "value_counts = dict(zip(unique, counts))\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc040d26",
   "metadata": {},
   "source": [
    "# TABPFN + GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f54071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:32:03 INFO     PyTorch version 2.2.2 available.\n",
      "2025-05-26 17:32:03 INFO     Duckdb version 1.2.1 available.\n",
      "2025-05-26 17:32:03 INFO     TensorFlow version 2.19.0 available.\n",
      "[2025-05-26T17:32:03.318809+0400][21741][CRITICAL] load failed: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "[2025-05-26T17:32:03.318809+0400][21741][CRITICAL] load failed: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "[2025-05-26T17:32:03.319580+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:32:03.319580+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:32:03.319978+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:32:03.319978+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:32:03.430173+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-26T17:32:03.430173+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "100%|██████████| 100/100 [00:25<00:00,  3.90it/s]\n",
      "2025-05-26 17:32:30 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-26 17:32:30 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "2025-05-26 17:32:30 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-26 17:32:30 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-26 17:32:33 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-26 17:32:33 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-26 17:32:33 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-26 17:32:33 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-26 17:33:23 INFO     Likely not enough time left for another model.\n",
      "2025-05-26 17:33:23 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-26 17:33:23 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-26 17:33:23 INFO     Order of selections: [0]\n",
      "2025-05-26 17:33:23 INFO     Val loss over iterations: [-0.920456827309237]\n",
      "2025-05-26 17:33:23 INFO     Model losses: [-0.92045683]\n",
      "2025-05-26 17:33:23 INFO     Best weights: [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_ctgan.json\n",
      "Test metrics:\n",
      "  roc_auc: 0.6208\n",
      "  f1: 0.0000\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  accuracy: 0.8998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data with target for synthetic generation\n",
    "train_df = X_train_folds.copy().reset_index(drop=True)\n",
    "train_df['target'] = y_train_k_fold\n",
    "\n",
    "# Create GenericDataLoader as per documentation\n",
    "loader = GenericDataLoader(\n",
    "    train_df,\n",
    "    target_column=\"target\",\n",
    ")\n",
    "\n",
    "# Generate synthetic data using synthcity's ctgan\n",
    "syn_model = Plugins().get(\"ctgan\", n_iter=100, random_state=42)\n",
    "syn_model.fit(loader)\n",
    "\n",
    "# Generate synthetic samples\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority class samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Drop target column from synthetic data\n",
    "syntetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data\n",
    "X_train_combined = pd.concat([X_train_folds, syntetic_minority_features])\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "y_train_combined = np.concatenate((y_train_k_fold, syntetic_target.values), axis=0)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the combined training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_combined)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_ctgan.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_ctgan.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5339ee42",
   "metadata": {},
   "source": [
    "# TABPFN + ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e866e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-26T17:39:53.382233+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:39:53.382233+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:39:53.383339+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:39:53.383339+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:39:53.384095+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:39:53.384095+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:39:53.385599+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-26T17:39:53.385599+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.6107033639143731\n",
      "Iteration number 1 reached accuracy of 0.42415902140672784.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-26T17:40:03.944027+0400][21741][INFO] [ef] quality loss for constraints le = 82.0. Remaining 9962. prev length 10000. Original dtype float64.\n",
      "[2025-05-26T17:40:03.944727+0400][21741][INFO] [ef] quality loss for constraints ge = 17.0. Remaining 9939. prev length 9962. Original dtype float64.\n",
      "[2025-05-26T17:40:03.946472+0400][21741][INFO] [age] quality loss for constraints le = 97.0. Remaining 9937. prev length 9939. Original dtype float64.\n",
      "[2025-05-26T17:40:03.947087+0400][21741][INFO] [age] quality loss for constraints ge = 28.0. Remaining 9928. prev length 9937. Original dtype float64.\n",
      "[2025-05-26T17:40:03.949126+0400][21741][INFO] [height] quality loss for constraints le = 196.0. Remaining 9874. prev length 9928. Original dtype float64.\n",
      "[2025-05-26T17:40:03.949575+0400][21741][INFO] [height] quality loss for constraints ge = 65.0. Remaining 9869. prev length 9874. Original dtype float64.\n",
      "[2025-05-26T17:40:03.952014+0400][21741][INFO] [previous_stroke_tia] quality loss for constraints le = 1.541114238227274. Remaining 9868. prev length 9869. Original dtype float64.\n",
      "[2025-05-26T17:40:03.952421+0400][21741][INFO] [previous_stroke_tia] quality loss for constraints ge = 0.0. Remaining 9729. prev length 9868. Original dtype float64.\n",
      "[2025-05-26T17:40:10.219057+0400][21741][INFO] [ef] quality loss for constraints le = 82.0. Remaining 9971. prev length 10000. Original dtype float64.\n",
      "[2025-05-26T17:40:10.219597+0400][21741][INFO] [ef] quality loss for constraints ge = 17.0. Remaining 9956. prev length 9971. Original dtype float64.\n",
      "[2025-05-26T17:40:10.221392+0400][21741][INFO] [age] quality loss for constraints le = 97.0. Remaining 9951. prev length 9956. Original dtype float64.\n",
      "[2025-05-26T17:40:10.221875+0400][21741][INFO] [age] quality loss for constraints ge = 28.0. Remaining 9947. prev length 9951. Original dtype float64.\n",
      "[2025-05-26T17:40:10.223540+0400][21741][INFO] [side_diametr] quality loss for constraints ge = 0.4. Remaining 9945. prev length 9947. Original dtype float64.\n",
      "[2025-05-26T17:40:10.224893+0400][21741][INFO] [height] quality loss for constraints le = 196.0. Remaining 9910. prev length 9945. Original dtype float64.\n",
      "[2025-05-26T17:40:10.225496+0400][21741][INFO] [height] quality loss for constraints ge = 65.0. Remaining 9906. prev length 9910. Original dtype float64.\n",
      "[2025-05-26T17:40:10.227940+0400][21741][INFO] [previous_stroke_tia] quality loss for constraints le = 1.541114238227274. Remaining 9905. prev length 9906. Original dtype float64.\n",
      "[2025-05-26T17:40:10.228389+0400][21741][INFO] [previous_stroke_tia] quality loss for constraints ge = 0.0. Remaining 9789. prev length 9905. Original dtype float64.\n",
      "2025-05-26 17:40:10 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-26 17:40:10 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "2025-05-26 17:40:10 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-26 17:40:10 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-26 17:40:12 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-26 17:40:12 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-26 17:40:12 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-26 17:40:12 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-26 17:41:04 INFO     Likely not enough time left for another model.\n",
      "2025-05-26 17:41:04 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-26 17:41:04 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-26 17:41:04 INFO     Order of selections: [0]\n",
      "2025-05-26 17:41:04 INFO     Val loss over iterations: [-0.9475234270414994]\n",
      "2025-05-26 17:41:04 INFO     Model losses: [-0.94752343]\n",
      "2025-05-26 17:41:04 INFO     Best weights: [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_arf.json\n",
      "Test metrics:\n",
      "  roc_auc: 0.7467\n",
      "  f1: 0.1304\n",
      "  precision: 0.2000\n",
      "  recall: 0.0968\n",
      "  accuracy: 0.9022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data with target for synthetic generation\n",
    "train_df = X_train_folds.copy().reset_index(drop=True)\n",
    "train_df['target'] = y_train_k_fold\n",
    "\n",
    "# Create GenericDataLoader as per documentation\n",
    "loader = GenericDataLoader(\n",
    "    train_df,\n",
    "    target_column=\"target\",\n",
    ")\n",
    "\n",
    "# Generate synthetic data using synthcity's ctgan\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)\n",
    "syn_model.fit(loader)\n",
    "\n",
    "# Generate synthetic samples\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority class samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Drop target column from synthetic data\n",
    "syntetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data\n",
    "X_train_combined = pd.concat([X_train_folds, syntetic_minority_features])\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "y_train_combined = np.concatenate((y_train_k_fold, syntetic_target.values), axis=0)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the combined training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_combined)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_arf.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_arf.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4533e",
   "metadata": {},
   "source": [
    "# TABPFN + TVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a52ac30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-26T17:45:17.068557+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:45:17.068557+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:45:17.068557+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:45:17.069845+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:45:17.069845+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:45:17.069845+0400][21741][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-26T17:45:17.070722+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:45:17.070722+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:45:17.070722+0400][21741][CRITICAL] module plugin_great load failed\n",
      "[2025-05-26T17:45:17.071787+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-26T17:45:17.071787+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-26T17:45:17.071787+0400][21741][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-26T17:45:17.091758+0400][21741][INFO] Encoding age 4599033839310999646\n",
      "[2025-05-26T17:45:17.091758+0400][21741][INFO] Encoding age 4599033839310999646\n",
      "[2025-05-26T17:45:17.273286+0400][21741][INFO] Encoding anemia 10559117052477474126\n",
      "[2025-05-26T17:45:17.273286+0400][21741][INFO] Encoding anemia 10559117052477474126\n",
      "[2025-05-26T17:45:17.277061+0400][21741][INFO] Encoding ef 6615323294479750638\n",
      "[2025-05-26T17:45:17.277061+0400][21741][INFO] Encoding ef 6615323294479750638\n",
      "[2025-05-26T17:45:17.377072+0400][21741][INFO] Encoding cerebrovascular_disease 13617125194766918586\n",
      "[2025-05-26T17:45:17.377072+0400][21741][INFO] Encoding cerebrovascular_disease 13617125194766918586\n",
      "[2025-05-26T17:45:17.379694+0400][21741][INFO] Encoding peripheral_artery_disease 12124056530535611716\n",
      "[2025-05-26T17:45:17.379694+0400][21741][INFO] Encoding peripheral_artery_disease 12124056530535611716\n",
      "[2025-05-26T17:45:17.382407+0400][21741][INFO] Encoding if_yes_what_type___1 17047599837648605068\n",
      "[2025-05-26T17:45:17.382407+0400][21741][INFO] Encoding if_yes_what_type___1 17047599837648605068\n",
      "[2025-05-26T17:45:17.385263+0400][21741][INFO] Encoding single_vessel 5354042705469234827\n",
      "[2025-05-26T17:45:17.385263+0400][21741][INFO] Encoding single_vessel 5354042705469234827\n",
      "[2025-05-26T17:45:17.387797+0400][21741][INFO] Encoding calcium 8494275627813327626\n",
      "[2025-05-26T17:45:17.387797+0400][21741][INFO] Encoding calcium 8494275627813327626\n",
      "[2025-05-26T17:45:17.390956+0400][21741][INFO] Encoding stent_type___3 8605259638086352251\n",
      "[2025-05-26T17:45:17.390956+0400][21741][INFO] Encoding stent_type___3 8605259638086352251\n",
      "[2025-05-26T17:45:17.394145+0400][21741][INFO] Encoding medina_side 9308473413688876616\n",
      "[2025-05-26T17:45:17.394145+0400][21741][INFO] Encoding medina_side 9308473413688876616\n",
      "[2025-05-26T17:45:17.396828+0400][21741][INFO] Encoding atrial_fibrilation 17542092499358454\n",
      "[2025-05-26T17:45:17.396828+0400][21741][INFO] Encoding atrial_fibrilation 17542092499358454\n",
      "[2025-05-26T17:45:17.399225+0400][21741][INFO] Encoding height 17786270714220274840\n",
      "[2025-05-26T17:45:17.399225+0400][21741][INFO] Encoding height 17786270714220274840\n",
      "[2025-05-26T17:45:17.498277+0400][21741][INFO] Encoding def 13382059486605798505\n",
      "[2025-05-26T17:45:17.498277+0400][21741][INFO] Encoding def 13382059486605798505\n",
      "[2025-05-26T17:45:17.501178+0400][21741][INFO] Encoding history_of_cancer 14906960464923656652\n",
      "[2025-05-26T17:45:17.501178+0400][21741][INFO] Encoding history_of_cancer 14906960464923656652\n",
      "[2025-05-26T17:45:17.503869+0400][21741][INFO] Encoding previous_stroke_tia 10526545155890236776\n",
      "[2025-05-26T17:45:17.503869+0400][21741][INFO] Encoding previous_stroke_tia 10526545155890236776\n",
      "[2025-05-26T17:45:17.602150+0400][21741][INFO] Encoding clinical_presentation 12698391255331745904\n",
      "[2025-05-26T17:45:17.602150+0400][21741][INFO] Encoding clinical_presentation 12698391255331745904\n",
      "[2025-05-26T17:45:17.605278+0400][21741][INFO] Encoding previous_pci 14800258385984570268\n",
      "[2025-05-26T17:45:17.605278+0400][21741][INFO] Encoding previous_pci 14800258385984570268\n",
      "[2025-05-26T17:45:17.607971+0400][21741][INFO] Encoding cto_bifurc 12365891733355262309\n",
      "[2025-05-26T17:45:17.607971+0400][21741][INFO] Encoding cto_bifurc 12365891733355262309\n",
      "[2025-05-26T17:45:17.610571+0400][21741][INFO] Encoding side_diametr 5066735528654317935\n",
      "[2025-05-26T17:45:17.610571+0400][21741][INFO] Encoding side_diametr 5066735528654317935\n",
      "[2025-05-26T17:45:17.707284+0400][21741][INFO] Encoding trifurcation 16313365494927145407\n",
      "[2025-05-26T17:45:17.707284+0400][21741][INFO] Encoding trifurcation 16313365494927145407\n",
      "[2025-05-26T17:45:17.710271+0400][21741][INFO] Encoding dyslipidemia 2904488549995553879\n",
      "[2025-05-26T17:45:17.710271+0400][21741][INFO] Encoding dyslipidemia 2904488549995553879\n",
      "[2025-05-26T17:45:17.712945+0400][21741][INFO] Encoding smoking 5526658874358360227\n",
      "[2025-05-26T17:45:17.712945+0400][21741][INFO] Encoding smoking 5526658874358360227\n",
      "[2025-05-26T17:45:17.715065+0400][21741][INFO] Encoding target 18209673397749911990\n",
      "[2025-05-26T17:45:17.715065+0400][21741][INFO] Encoding target 18209673397749911990\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.09it/s]\n",
      "2025-05-26 17:45:42 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-26 17:45:42 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "2025-05-26 17:45:42 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-26 17:45:42 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-26 17:45:44 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-26 17:45:44 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-26 17:45:44 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-26 17:45:44 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-26 17:46:32 INFO     Likely not enough time left for another model.\n",
      "2025-05-26 17:46:32 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-26 17:46:32 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-26 17:46:32 INFO     Order of selections: [0]\n",
      "2025-05-26 17:46:32 INFO     Val loss over iterations: [-0.9246267366115178]\n",
      "2025-05-26 17:46:32 INFO     Model losses: [-0.92462674]\n",
      "2025-05-26 17:46:32 INFO     Best weights: [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_tvae.json\n",
      "Test metrics:\n",
      "  roc_auc: 0.5773\n",
      "  f1: 0.0000\n",
      "  precision: 0.0000\n",
      "  recall: 0.0000\n",
      "  accuracy: 0.8924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data with target for synthetic generation\n",
    "train_df = X_train_folds.copy().reset_index(drop=True)\n",
    "train_df['target'] = y_train_k_fold\n",
    "\n",
    "# Create GenericDataLoader as per documentation\n",
    "loader = GenericDataLoader(\n",
    "    train_df,\n",
    "    target_column=\"target\",\n",
    ")\n",
    "\n",
    "# Generate synthetic data using synthcity's ctgan\n",
    "syn_model = Plugins().get(\"tvae\", n_iter=100, random_state=42)\n",
    "syn_model.fit(loader)\n",
    "\n",
    "# Generate synthetic samples\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority class samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Drop target column from synthetic data\n",
    "syntetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data\n",
    "X_train_combined = pd.concat([X_train_folds, syntetic_minority_features])\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "y_train_combined = np.concatenate((y_train_k_fold, syntetic_target.values), axis=0)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the combined training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_combined)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_tvae.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_tvae.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43de42cf",
   "metadata": {},
   "source": [
    "# TABPFN + GAUSSIAN COPULA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ea52eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:52:47 INFO     {'EVENT': 'Instance', 'TIMESTAMP': datetime.datetime(2025, 5, 26, 17, 52, 47, 811771), 'SYNTHESIZER CLASS NAME': 'GaussianCopulaSynthesizer', 'SYNTHESIZER ID': 'GaussianCopulaSynthesizer_1.17.4_c31baf511d554a6bbf8aeb6b4eb567d5'}\n",
      "2025-05-26 17:52:47 INFO     {'EVENT': 'Fit', 'TIMESTAMP': datetime.datetime(2025, 5, 26, 17, 52, 47, 814922), 'SYNTHESIZER CLASS NAME': 'GaussianCopulaSynthesizer', 'SYNTHESIZER ID': 'GaussianCopulaSynthesizer_1.17.4_c31baf511d554a6bbf8aeb6b4eb567d5', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 1635, 'TOTAL NUMBER OF COLUMNS': 24}\n",
      "2025-05-26 17:52:47 INFO     Fitting table  metadata\n",
      "2025-05-26 17:52:47 INFO     Fitting formatters for table \n",
      "2025-05-26 17:52:47 INFO     No rounding scheme detected for column 'ef'. Data will not be rounded.\n",
      "2025-05-26 17:52:47 INFO     No rounding scheme detected for column 'previous_stroke_tia'. Data will not be rounded.\n",
      "2025-05-26 17:52:47 INFO     Fitting constraints for table \n",
      "2025-05-26 17:52:47 INFO     Setting the configuration for the ``HyperTransformer`` for table \n",
      "2025-05-26 17:52:47 INFO     Fitting HyperTransformer for table \n",
      "2025-05-26 17:52:47 INFO     No rounding scheme detected for column 'ef'. Data will not be rounded.\n",
      "2025-05-26 17:52:47 INFO     No rounding scheme detected for column 'previous_stroke_tia'. Data will not be rounded.\n",
      "2025-05-26 17:52:48 INFO     {'EVENT': 'Fit processed data', 'TIMESTAMP': datetime.datetime(2025, 5, 26, 17, 52, 48, 11196), 'SYNTHESIZER CLASS NAME': 'GaussianCopulaSynthesizer', 'SYNTHESIZER ID': 'GaussianCopulaSynthesizer_1.17.4_c31baf511d554a6bbf8aeb6b4eb567d5', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 1635, 'TOTAL NUMBER OF COLUMNS': 23}\n",
      "2025-05-26 17:52:48 INFO     Fitting GaussianMultivariate(distribution=\"{'age': <class 'copulas.univariate.beta.BetaUnivariate'>, 'anemia': <class 'copulas.univariate.beta.BetaUnivariate'>, 'ef': <class 'copulas.univariate.beta.BetaUnivariate'>, 'cerebrovascular_disease': <class 'copulas.univariate.beta.BetaUnivariate'>, 'peripheral_artery_disease': <class 'copulas.univariate.beta.BetaUnivariate'>, 'if_yes_what_type___1': <class 'copulas.univariate.beta.BetaUnivariate'>, 'single_vessel': <class 'copulas.univariate.beta.BetaUnivariate'>, 'calcium': <class 'copulas.univariate.beta.BetaUnivariate'>, 'stent_type___3': <class 'copulas.univariate.beta.BetaUnivariate'>, 'medina_side': <class 'copulas.univariate.beta.BetaUnivariate'>, 'atrial_fibrilation': <class 'copulas.univariate.beta.BetaUnivariate'>, 'height': <class 'copulas.univariate.beta.BetaUnivariate'>, 'def': <class 'copulas.univariate.beta.BetaUnivariate'>, 'history_of_cancer': <class 'copulas.univariate.beta.BetaUnivariate'>, 'previous_stroke_tia': <class 'copulas.univariate.beta.BetaUnivariate'>, 'clinical_presentation': <class 'copulas.univariate.beta.BetaUnivariate'>, 'previous_pci': <class 'copulas.univariate.beta.BetaUnivariate'>, 'cto_bifurc': <class 'copulas.univariate.beta.BetaUnivariate'>, 'side_diametr': <class 'copulas.univariate.beta.BetaUnivariate'>, 'trifurcation': <class 'copulas.univariate.beta.BetaUnivariate'>, 'dyslipidemia': <class 'copulas.univariate.beta.BetaUnivariate'>, 'smoking': <class 'copulas.univariate.beta.BetaUnivariate'>, 'target': <class 'copulas.univariate.beta.BetaUnivariate'>}\")\n",
      "2025-05-26 17:52:48 INFO     {'EVENT': 'Sample', 'TIMESTAMP': datetime.datetime(2025, 5, 26, 17, 52, 48, 609160), 'SYNTHESIZER CLASS NAME': 'GaussianCopulaSynthesizer', 'SYNTHESIZER ID': 'GaussianCopulaSynthesizer_1.17.4_c31baf511d554a6bbf8aeb6b4eb567d5', 'TOTAL NUMBER OF TABLES': 1, 'TOTAL NUMBER OF ROWS': 10000, 'TOTAL NUMBER OF COLUMNS': 24}\n",
      "2025-05-26 17:52:48 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-26 17:52:48 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "2025-05-26 17:52:48 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-26 17:52:48 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-26 17:52:51 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-26 17:52:51 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-26 17:52:51 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-26 17:52:51 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-26 17:53:41 INFO     Likely not enough time left for another model.\n",
      "2025-05-26 17:53:41 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-26 17:53:41 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-26 17:53:41 INFO     Order of selections: [0]\n",
      "2025-05-26 17:53:41 INFO     Val loss over iterations: [-0.9345799866131191]\n",
      "2025-05-26 17:53:41 INFO     Model losses: [-0.93457999]\n",
      "2025-05-26 17:53:41 INFO     Best weights: [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_gaussian_copula.json\n",
      "Test metrics:\n",
      "  roc_auc: 0.6814\n",
      "  f1: 0.1974\n",
      "  precision: 0.1240\n",
      "  recall: 0.4839\n",
      "  accuracy: 0.7017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data with target for synthetic generation\n",
    "if not isinstance(X_train_folds, pd.DataFrame):\n",
    "    X_train_df = pd.DataFrame(X_train_folds)\n",
    "else:\n",
    "    X_train_df = X_train_folds.copy()\n",
    "\n",
    "# Add target column to the training data\n",
    "X_train_df['target'] = y_train_k_fold\n",
    "X_train_df['index'] = np.arange(1, len(X_train_df) + 1)\n",
    "\n",
    "# Generate synthetic data using Gaussian Copula\n",
    "synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "synthesizer.fit(X_train_df)\n",
    "synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Extract features and target from synthetic data\n",
    "syntetic_minority_dropped = minority_synthetic_data.copy().drop(['target', 'index'], axis=1)\n",
    "syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data\n",
    "X_train_combined = pd.concat([X_train_df.drop(['target', 'index'], axis=1), syntetic_minority_dropped])\n",
    "y_train_combined = np.concatenate((y_train_k_fold, syntetic_target), axis=0)\n",
    "\n",
    "# Scale the combined training data\n",
    "X_train_combined_scaled = scaler.fit_transform(X_train_combined)\n",
    "\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_combined_scaled, y_train_combined)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_gaussian_copula.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_gaussian_copula.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196a1dc",
   "metadata": {},
   "source": [
    "# TABPFN + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "609d2d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 18:03:25 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-26 18:03:25 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "2025-05-26 18:03:25 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-26 18:03:25 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-26 18:03:27 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-26 18:03:27 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-26 18:03:27 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-26 18:03:27 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n",
      "2025-05-26 18:05:02 INFO     Time limit reached.\n",
      "2025-05-26 18:05:02 INFO     Stop validation of all models after 1 models in repeat 1.\n",
      "2025-05-26 18:05:02 INFO     As this is the first repeat, we trim down the models to all so-far run models!\n",
      "2025-05-26 18:05:02 INFO     Order of selections: [0]\n",
      "2025-05-26 18:05:02 INFO     Val loss over iterations: [-0.9810890146933114]\n",
      "2025-05-26 18:05:02 INFO     Model losses: [-0.98108901]\n",
      "2025-05-26 18:05:02 INFO     Best weights: [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics saved to tabpfn_simplicial_smote.json\n",
      "Test metrics:\n",
      "  roc_auc: 0.3892\n",
      "  f1: 0.1409\n",
      "  precision: 0.0758\n",
      "  recall: 1.0000\n",
      "  accuracy: 0.0758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "from simplical_smote_kdd.ssmote import BorderlineSimplicialSMOTE, SimplicialSMOTE\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Convert DataFrame to NumPy array if needed\n",
    "if isinstance(X_train_folds, pd.DataFrame):\n",
    "    X_train_folds_np = X_train_folds.values\n",
    "else:\n",
    "    X_train_folds_np = X_train_folds\n",
    "\n",
    "if isinstance(y_train_k_fold, pd.Series):\n",
    "    y_train_k_fold_np = y_train_k_fold.values\n",
    "else:\n",
    "    y_train_k_fold_np = y_train_k_fold\n",
    "\n",
    "# Now use the NumPy arrays with SimplicialSMOTE\n",
    "X_res, y_res = SimplicialSMOTE(random_state=42).fit_resample(X_train_folds_np, y_train_k_fold_np)\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the combined training data\n",
    "X_train_res_scaled = scaler.fit_transform(X_res)\n",
    "\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_res_scaled, y_res)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_simplicial_smote.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_simplicial_smote.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e583c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbf59195",
   "metadata": {},
   "source": [
    "# TabPFN + ARF + EDGE CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8dc8a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>restenosis_reocclusion</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>main_predilatation</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>mortality</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.692608</td>\n",
       "      <td>154.098475</td>\n",
       "      <td>5</td>\n",
       "      <td>20.013035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.251928</td>\n",
       "      <td>35.843477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.047766</td>\n",
       "      <td>157.876507</td>\n",
       "      <td>4</td>\n",
       "      <td>23.191234</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.407627</td>\n",
       "      <td>32.689461</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.899237</td>\n",
       "      <td>162.817555</td>\n",
       "      <td>5</td>\n",
       "      <td>15.705469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.131580</td>\n",
       "      <td>35.612648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.611771</td>\n",
       "      <td>141.655335</td>\n",
       "      <td>5</td>\n",
       "      <td>20.042240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.711981</td>\n",
       "      <td>29.622981</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.126266</td>\n",
       "      <td>169.752470</td>\n",
       "      <td>5</td>\n",
       "      <td>22.975668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.669322</td>\n",
       "      <td>32.912135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>87.137148</td>\n",
       "      <td>140.557859</td>\n",
       "      <td>5</td>\n",
       "      <td>27.248375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.735354</td>\n",
       "      <td>29.382213</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>87.744911</td>\n",
       "      <td>161.799988</td>\n",
       "      <td>5</td>\n",
       "      <td>17.857095</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.202047</td>\n",
       "      <td>28.605845</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>86.262454</td>\n",
       "      <td>146.269984</td>\n",
       "      <td>4</td>\n",
       "      <td>19.876380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.337757</td>\n",
       "      <td>37.134505</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>99.217685</td>\n",
       "      <td>140.040983</td>\n",
       "      <td>4</td>\n",
       "      <td>20.891875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.171117</td>\n",
       "      <td>32.586449</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>92.121559</td>\n",
       "      <td>167.711774</td>\n",
       "      <td>4</td>\n",
       "      <td>23.249293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.332699</td>\n",
       "      <td>29.326876</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      height  clinical_presentation         ef  \\\n",
       "0    91.692608  154.098475                      5  20.013035   \n",
       "1    98.047766  157.876507                      4  23.191234   \n",
       "2    93.899237  162.817555                      5  15.705469   \n",
       "3    96.611771  141.655335                      5  20.042240   \n",
       "4    90.126266  169.752470                      5  22.975668   \n",
       "..         ...         ...                    ...        ...   \n",
       "145  87.137148  140.557859                      5  27.248375   \n",
       "146  87.744911  161.799988                      5  17.857095   \n",
       "147  86.262454  146.269984                      4  19.876380   \n",
       "148  99.217685  140.040983                      4  20.891875   \n",
       "149  92.121559  167.711774                      4  23.249293   \n",
       "\n",
       "     cerebrovascular_disease  peripheral_artery_disease  if_yes_what_type___1  \\\n",
       "0                          1                          1                     1   \n",
       "1                          1                          1                     0   \n",
       "2                          1                          1                     1   \n",
       "3                          1                          1                     1   \n",
       "4                          1                          0                     0   \n",
       "..                       ...                        ...                   ...   \n",
       "145                        1                          1                     1   \n",
       "146                        1                          1                     1   \n",
       "147                        1                          0                     0   \n",
       "148                        1                          1                     1   \n",
       "149                        1                          1                     1   \n",
       "\n",
       "     single_vessel  calcium  medina_side  ...  restenosis_reocclusion  \\\n",
       "0                0        1            1  ...                       1   \n",
       "1                1        1            1  ...                       1   \n",
       "2                1        1            1  ...                       1   \n",
       "3                1        1            0  ...                       1   \n",
       "4                1        1            1  ...                       1   \n",
       "..             ...      ...          ...  ...                     ...   \n",
       "145              1        1            1  ...                       1   \n",
       "146              1        1            0  ...                       1   \n",
       "147              1        1            1  ...                       1   \n",
       "148              0        1            1  ...                       1   \n",
       "149              0        1            1  ...                       1   \n",
       "\n",
       "     adhoc_pci  main_predilatation  stent_diameter  stent_length  mortality  \\\n",
       "0            0                   1        2.251928     35.843477          1   \n",
       "1            1                   1        2.407627     32.689461          1   \n",
       "2            1                   0        2.131580     35.612648          1   \n",
       "3            1                   0        2.711981     29.622981          1   \n",
       "4            0                   0        2.669322     32.912135          1   \n",
       "..         ...                 ...             ...           ...        ...   \n",
       "145          1                   1        2.735354     29.382213          1   \n",
       "146          1                   1        2.202047     28.605845          1   \n",
       "147          1                   1        2.337757     37.134505          1   \n",
       "148          1                   0        2.171117     32.586449          1   \n",
       "149          1                   1        2.332699     29.326876          1   \n",
       "\n",
       "     smoking  dyslipidemia  anemia  atrial_fibrilation  \n",
       "0          1             1       1                   1  \n",
       "1          0             1       1                   1  \n",
       "2          0             1       1                   1  \n",
       "3          1             1       1                   1  \n",
       "4          0             1       1                   0  \n",
       "..       ...           ...     ...                 ...  \n",
       "145        1             1       1                   1  \n",
       "146        1             1       1                   1  \n",
       "147        0             1       1                   1  \n",
       "148        1             1       1                   1  \n",
       "149        1             1       1                   1  \n",
       "\n",
       "[150 rows x 30 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import edge_case\n",
    "importlib.reload(edge_case)\n",
    "from edge_case import generate_edge_cases\n",
    "\n",
    "edge_cases = generate_edge_cases(num_samples=150)\n",
    "edge_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17d82a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON OF COLUMNS:\n",
      "\n",
      "Total columns in edge_cases: 30\n",
      "Total columns in X_train: 22\n",
      "Number of common columns: 22\n",
      "\n",
      "--- COMMON COLUMNS ---\n",
      "- age\n",
      "- anemia\n",
      "- atrial_fibrilation\n",
      "- calcium\n",
      "- cerebrovascular_disease\n",
      "- clinical_presentation\n",
      "- cto_bifurc\n",
      "- def\n",
      "- dyslipidemia\n",
      "- ef\n",
      "- height\n",
      "- history_of_cancer\n",
      "- if_yes_what_type___1\n",
      "- medina_side\n",
      "- peripheral_artery_disease\n",
      "- previous_pci\n",
      "- previous_stroke_tia\n",
      "- side_diametr\n",
      "- single_vessel\n",
      "- smoking\n",
      "- stent_type___3\n",
      "- trifurcation\n",
      "\n",
      "--- COLUMNS ONLY IN EDGE CASES ---\n",
      "- adhoc_pci\n",
      "- main_predilatation\n",
      "- mortality\n",
      "- restenosis_reocclusion\n",
      "- stent_diameter\n",
      "- stent_length\n",
      "- stent_type___4\n",
      "- stent_type___5\n",
      "\n",
      "--- COLUMNS ONLY IN X_TRAIN ---\n"
     ]
    }
   ],
   "source": [
    "edge_case_cols = set(edge_cases.columns)\n",
    "x_train_cols = set(X_train.columns)\n",
    "\n",
    "common_cols = edge_case_cols.intersection(x_train_cols)\n",
    "only_in_edge_cases = edge_case_cols - x_train_cols\n",
    "only_in_x_train = x_train_cols - edge_case_cols\n",
    "\n",
    "print(f\"COMPARISON OF COLUMNS:\")\n",
    "print(f\"\\nTotal columns in edge_cases: {len(edge_case_cols)}\")\n",
    "print(f\"Total columns in X_train: {len(x_train_cols)}\")\n",
    "print(f\"Number of common columns: {len(common_cols)}\")\n",
    "\n",
    "print(\"\\n--- COMMON COLUMNS ---\")\n",
    "for col in sorted(common_cols):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\n--- COLUMNS ONLY IN EDGE CASES ---\")\n",
    "for col in sorted(only_in_edge_cases):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\n--- COLUMNS ONLY IN X_TRAIN ---\")\n",
    "for col in sorted(only_in_x_train):\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62fd165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_cases_target = edge_cases['mortality']\n",
    "edge_cases_features = edge_cases.copy().drop('mortality', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7fe8c909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.692608</td>\n",
       "      <td>154.098475</td>\n",
       "      <td>5</td>\n",
       "      <td>20.013035</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.686656</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.047766</td>\n",
       "      <td>157.876507</td>\n",
       "      <td>4</td>\n",
       "      <td>23.191234</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.958402</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.899237</td>\n",
       "      <td>162.817555</td>\n",
       "      <td>5</td>\n",
       "      <td>15.705469</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.255181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.611771</td>\n",
       "      <td>141.655335</td>\n",
       "      <td>5</td>\n",
       "      <td>20.042240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.781142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.126266</td>\n",
       "      <td>169.752470</td>\n",
       "      <td>5</td>\n",
       "      <td>22.975668</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.717308</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>87.137148</td>\n",
       "      <td>140.557859</td>\n",
       "      <td>5</td>\n",
       "      <td>27.248375</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.265116</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>87.744911</td>\n",
       "      <td>161.799988</td>\n",
       "      <td>5</td>\n",
       "      <td>17.857095</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.867154</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>86.262454</td>\n",
       "      <td>146.269984</td>\n",
       "      <td>4</td>\n",
       "      <td>19.876380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.694251</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>99.217685</td>\n",
       "      <td>140.040983</td>\n",
       "      <td>4</td>\n",
       "      <td>20.891875</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.740156</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>92.121559</td>\n",
       "      <td>167.711774</td>\n",
       "      <td>4</td>\n",
       "      <td>23.249293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.740478</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      height  clinical_presentation         ef  \\\n",
       "0    91.692608  154.098475                      5  20.013035   \n",
       "1    98.047766  157.876507                      4  23.191234   \n",
       "2    93.899237  162.817555                      5  15.705469   \n",
       "3    96.611771  141.655335                      5  20.042240   \n",
       "4    90.126266  169.752470                      5  22.975668   \n",
       "..         ...         ...                    ...        ...   \n",
       "145  87.137148  140.557859                      5  27.248375   \n",
       "146  87.744911  161.799988                      5  17.857095   \n",
       "147  86.262454  146.269984                      4  19.876380   \n",
       "148  99.217685  140.040983                      4  20.891875   \n",
       "149  92.121559  167.711774                      4  23.249293   \n",
       "\n",
       "     cerebrovascular_disease  peripheral_artery_disease  if_yes_what_type___1  \\\n",
       "0                          1                          1                     1   \n",
       "1                          1                          1                     0   \n",
       "2                          1                          1                     1   \n",
       "3                          1                          1                     1   \n",
       "4                          1                          0                     0   \n",
       "..                       ...                        ...                   ...   \n",
       "145                        1                          1                     1   \n",
       "146                        1                          1                     1   \n",
       "147                        1                          0                     0   \n",
       "148                        1                          1                     1   \n",
       "149                        1                          1                     1   \n",
       "\n",
       "     single_vessel  calcium  medina_side  ...  def  history_of_cancer  \\\n",
       "0                0        1            1  ...    1                  1   \n",
       "1                1        1            1  ...    1                  1   \n",
       "2                1        1            1  ...    1                  1   \n",
       "3                1        1            0  ...    1                  1   \n",
       "4                1        1            1  ...    1                  1   \n",
       "..             ...      ...          ...  ...  ...                ...   \n",
       "145              1        1            1  ...    1                  0   \n",
       "146              1        1            0  ...    1                  1   \n",
       "147              1        1            1  ...    0                  1   \n",
       "148              0        1            1  ...    0                  1   \n",
       "149              0        1            1  ...    1                  0   \n",
       "\n",
       "     previous_pci  previous_stroke_tia  side_diametr  stent_type___3  smoking  \\\n",
       "0               1                    1      1.686656               1        1   \n",
       "1               0                    0      1.958402               1        0   \n",
       "2               1                    1      1.255181               0        0   \n",
       "3               1                    1      1.781142               0        1   \n",
       "4               1                    1      1.717308               0        0   \n",
       "..            ...                  ...           ...             ...      ...   \n",
       "145             1                    0      1.265116               1        1   \n",
       "146             1                    1      1.867154               0        1   \n",
       "147             0                    0      1.694251               1        0   \n",
       "148             1                    0      1.740156               0        1   \n",
       "149             1                    1      1.740478               0        1   \n",
       "\n",
       "     dyslipidemia  anemia  atrial_fibrilation  \n",
       "0               1       1                   1  \n",
       "1               1       1                   1  \n",
       "2               1       1                   1  \n",
       "3               1       1                   1  \n",
       "4               1       1                   0  \n",
       "..            ...     ...                 ...  \n",
       "145             1       1                   1  \n",
       "146             1       1                   1  \n",
       "147             1       1                   1  \n",
       "148             1       1                   1  \n",
       "149             1       1                   1  \n",
       "\n",
       "[150 rows x 22 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_cases_features_names = [feature for feature in edge_cases.columns if feature in X_train.columns]\n",
    "edge_cases_features = pd.DataFrame(edge_cases, columns=edge_cases_features_names)\n",
    "edge_cases_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f73a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds = pd.concat([X_train, X_val, edge_cases_features])\n",
    "y_train_k_fold = np.concatenate((y_train, y_val, edge_cases_target), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "09312158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : omp.h header is not in the path, disabling OpenMP. To fix this, you can set the environment\n",
      "                  variable OMP_PATH to the location of the header before importing keopscore or pykeops,\n",
      "                  e.g. using os.environ: import os; os.environ['OMP_PATH'] = '/path/to/omp/header'\n",
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 18:34:15 INFO     PyTorch version 2.2.2 available.\n",
      "2025-05-27 18:34:15 INFO     Duckdb version 1.2.1 available.\n",
      "2025-05-27 18:34:15 INFO     TensorFlow version 2.19.0 available.\n",
      "[2025-05-27T18:34:15.710703+0400][58577][CRITICAL] load failed: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "[2025-05-27T18:34:15.710703+0400][58577][CRITICAL] load failed: Failed to import transformers.trainer because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\n",
      "Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\n",
      "Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.\n",
      "[2025-05-27T18:34:15.711425+0400][58577][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-27T18:34:15.711425+0400][58577][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-27T18:34:15.711790+0400][58577][CRITICAL] module plugin_great load failed\n",
      "[2025-05-27T18:34:15.711790+0400][58577][CRITICAL] module plugin_great load failed\n",
      "[2025-05-27T18:34:15.844804+0400][58577][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "[2025-05-27T18:34:15.844804+0400][58577][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7448179271708684\n",
      "Iteration number 1 reached accuracy of 0.42661064425770306.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 18:34:33 INFO     Using `default` preset for Post Hoc Ensemble.\n",
      "2025-05-27 18:34:33 INFO     No categorical_feature_indices given. Assuming no categorical features.\n",
      "2025-05-27 18:34:33 INFO     Using task type: TaskType.BINARY\n",
      "2025-05-27 18:34:33 INFO     Obtaining TabPFN models from a random portfolio.\n",
      "2025-05-27 18:34:35 INFO     Using 100 base models: ['default_tabpfn_model_0', 'random_tabpfn_model_1', 'random_rf_pfn_model_2', 'random_rf_pfn_model_3', 'random_rf_pfn_model_4', 'random_rf_pfn_model_5', 'random_tabpfn_model_6', 'random_tabpfn_model_7', 'random_rf_pfn_model_8', 'random_tabpfn_model_9', 'random_rf_pfn_model_10', 'random_rf_pfn_model_11', 'random_tabpfn_model_12', 'random_tabpfn_model_13', 'random_rf_pfn_model_14', 'random_rf_pfn_model_15', 'random_rf_pfn_model_16', 'random_tabpfn_model_17', 'random_rf_pfn_model_18', 'random_tabpfn_model_19', 'random_rf_pfn_model_20', 'random_rf_pfn_model_21', 'random_tabpfn_model_22', 'random_rf_pfn_model_23', 'random_rf_pfn_model_24', 'random_tabpfn_model_25', 'random_rf_pfn_model_26', 'random_tabpfn_model_27', 'random_tabpfn_model_28', 'random_tabpfn_model_29', 'random_tabpfn_model_30', 'random_tabpfn_model_31', 'random_tabpfn_model_32', 'random_tabpfn_model_33', 'random_tabpfn_model_34', 'random_tabpfn_model_35', 'random_rf_pfn_model_36', 'random_tabpfn_model_37', 'random_rf_pfn_model_38', 'random_tabpfn_model_39', 'random_tabpfn_model_40', 'random_rf_pfn_model_41', 'random_tabpfn_model_42', 'random_tabpfn_model_43', 'random_tabpfn_model_44', 'random_tabpfn_model_45', 'random_rf_pfn_model_46', 'random_tabpfn_model_47', 'random_rf_pfn_model_48', 'random_tabpfn_model_49', 'random_tabpfn_model_50', 'random_rf_pfn_model_51', 'random_tabpfn_model_52', 'random_rf_pfn_model_53', 'random_rf_pfn_model_54', 'random_rf_pfn_model_55', 'random_tabpfn_model_56', 'random_tabpfn_model_57', 'random_rf_pfn_model_58', 'random_rf_pfn_model_59', 'random_tabpfn_model_60', 'random_tabpfn_model_61', 'random_rf_pfn_model_62', 'random_tabpfn_model_63', 'random_tabpfn_model_64', 'random_rf_pfn_model_65', 'random_tabpfn_model_66', 'random_tabpfn_model_67', 'random_tabpfn_model_68', 'random_rf_pfn_model_69', 'random_rf_pfn_model_70', 'random_tabpfn_model_71', 'random_tabpfn_model_72', 'random_rf_pfn_model_73', 'random_rf_pfn_model_74', 'random_rf_pfn_model_75', 'random_tabpfn_model_76', 'random_tabpfn_model_77', 'random_tabpfn_model_78', 'random_tabpfn_model_79', 'random_tabpfn_model_80', 'random_rf_pfn_model_81', 'random_rf_pfn_model_82', 'random_tabpfn_model_83', 'random_tabpfn_model_84', 'random_rf_pfn_model_85', 'random_rf_pfn_model_86', 'random_tabpfn_model_87', 'random_rf_pfn_model_88', 'random_tabpfn_model_89', 'random_tabpfn_model_90', 'random_tabpfn_model_91', 'random_rf_pfn_model_92', 'random_rf_pfn_model_93', 'random_tabpfn_model_94', 'random_tabpfn_model_95', 'random_rf_pfn_model_96', 'random_tabpfn_model_97', 'random_tabpfn_model_98', 'random_tabpfn_model_99']\n",
      "2025-05-27 18:34:35 INFO     Starting 80-repeated holdout validation with holdout_frac=0.33.\n",
      "2025-05-27 18:34:35 INFO     Set time limit to 60 seconds. We will early stop validation if needed.\n",
      "2025-05-27 18:34:35 INFO     Yield data for model default_tabpfn_model_0 and split 0 (repeat=1).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Initialize and train final TabPFN classifier on the combined training data\u001b[39;00m\n\u001b[1;32m     60\u001b[0m final_classifier \u001b[38;5;241m=\u001b[39m AutoTabPFNClassifier(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m, max_time\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mfinal_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoTabFPN_arf_edge_cases.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/sklearn_interface.py:112\u001b[0m, in \u001b[0;36mAutoTabPFNClassifier.fit\u001b[0;34m(self, X, y, categorical_feature_indices)\u001b[0m\n\u001b[1;32m     97\u001b[0m task_type \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     98\u001b[0m     TaskType\u001b[38;5;241m.\u001b[39mMULTICLASS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_labels(y)) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m TaskType\u001b[38;5;241m.\u001b[39mBINARY\n\u001b[1;32m     99\u001b[0m )\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_ \u001b[38;5;241m=\u001b[39m AutoPostHocEnsemblePredictor(\n\u001b[1;32m    101\u001b[0m     preset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreset,\n\u001b[1;32m    102\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mtask_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphe_init_args_,\n\u001b[1;32m    110\u001b[0m )\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# -- Sklearn required values\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_\u001b[38;5;241m.\u001b[39m_label_encoder\u001b[38;5;241m.\u001b[39mclasses_\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/pfn_phe.py:333\u001b[0m, in \u001b[0;36mAutoPostHocEnsemblePredictor.fit\u001b[0;34m(self, X, y, categorical_feature_indices)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimators, model_family_per_estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_base_models(\n\u001b[1;32m    317\u001b[0m     categorical_feature_indices\u001b[38;5;241m=\u001b[39mcategorical_feature_indices,\n\u001b[1;32m    318\u001b[0m )\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ens_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ens_model(\n\u001b[1;32m    321\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimators,\n\u001b[1;32m    322\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mges_random_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     model_family_per_estimator\u001b[38;5;241m=\u001b[39mmodel_family_per_estimator,\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ens_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/greedy_weighted_ensemble.py:234\u001b[0m, in \u001b[0;36mGreedyWeightedEnsemble.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m--> 234\u001b[0m     weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     final_weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    237\u001b[0m     base_models \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/greedy_weighted_ensemble.py:173\u001b[0m, in \u001b[0;36mGreedyWeightedEnsemble.get_weights\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m--> 173\u001b[0m     oof_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_oof_per_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_family_per_estimator \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_family_per_estimator\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_family_per_estimator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimators)\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_family_per_estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_family_per_estimator[\n\u001b[1;32m    180\u001b[0m         : \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_estimators)\n\u001b[1;32m    181\u001b[0m     ]\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/abstract_validation_utils.py:372\u001b[0m, in \u001b[0;36mAbstractValidationUtils.get_oof_per_estimator\u001b[0;34m(self, X, y, return_loss_per_estimator, impute_dropped_instances, _extra_processing)\u001b[0m\n\u001b[1;32m    369\u001b[0m     to_pass_holdout_index_hits \u001b[38;5;241m=\u001b[39m holdout_index_hits\n\u001b[1;32m    370\u001b[0m     holdout_index_hit_counts \u001b[38;5;241m=\u001b[39m current_repeat\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill_predictions_in_place\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43moof_proba_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moof_proba_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_per_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_per_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mholdout_index_hits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_pass_holdout_index_hits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_extra_processing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_extra_processing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_for_repeat_early_stopping:  \u001b[38;5;66;03m# True after every repeat.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     ran_repeats \u001b[38;5;241m=\u001b[39m current_repeat\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/abstract_validation_utils.py:129\u001b[0m, in \u001b[0;36mAbstractValidationUtils._fill_predictions_in_place\u001b[0;34m(self, model_i, base_model, oof_proba_list, X, y, train_index, test_index, loss_per_estimator, holdout_index_hits, _extra_processing, split_i)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# base_model = copy.deepcopy(base_model) # FIXME: think about adding this for safety but will likely slow down (due to having to load model again)\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Default base models case\u001b[39;00m\n\u001b[1;32m    127\u001b[0m base_model\u001b[38;5;241m.\u001b[39mfit(fold_X_train, fold_y_train)\n\u001b[0;32m--> 129\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_oof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_X_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m oof_proba_list[model_i][test_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m holdout_index_hits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn_extensions/post_hoc_ensembles/abstract_validation_utils.py:556\u001b[0m, in \u001b[0;36mAbstractValidationUtilsClassification._predict_oof\u001b[0;34m(self, base_model, X)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_predict_oof\u001b[39m(\u001b[38;5;28mself\u001b[39m, base_model, X):\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/classifier.py:538\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    534\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor_\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    536\u001b[0m outputs: \u001b[38;5;28mlist\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 538\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutor_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautocast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_autocast_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mClassifierEnsembleConfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Cut out logits for classes which do not exist\u001b[39;49;00m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/inference.py:332\u001b[0m, in \u001b[0;36mInferenceEngineCachePreprocessing.iter_outputs\u001b[0;34m(self, X, device, autocast, only_return_standard_out)\u001b[0m\n\u001b[1;32m    326\u001b[0m style \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m    329\u001b[0m     torch\u001b[38;5;241m.\u001b[39mautocast(device\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39mautocast),\n\u001b[1;32m    330\u001b[0m     torch\u001b[38;5;241m.\u001b[39minference_mode(),\n\u001b[1;32m    331\u001b[0m ):\n\u001b[0;32m--> 332\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_return_standard_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_return_standard_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_inds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_ix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m output \u001b[38;5;241m=\u001b[39m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m output, config\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/transformer.py:416\u001b[0m, in \u001b[0;36mPerFeatureTransformer.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    415\u001b[0m     style, x, y \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized input. Please follow the doc string.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/transformer.py:628\u001b[0m, in \u001b[0;36mPerFeatureTransformer._forward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere should be no NaNs in the encoded x and y.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    622\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck that you do not feed NaNs or use a NaN-handling enocder.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour embedded x and y returned the following:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    624\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39misnan(embedded_x)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch\u001b[38;5;241m.\u001b[39misnan(embedded_y)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m embedded_y, embedded_x\n\u001b[0;32m--> 628\u001b[0m encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedded_input\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_decoder\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43membedded_input\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos_\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhalf_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhalf_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# b s f+1 e -> b s f+1 e\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# If we are using a decoder\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_decoder:\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/transformer.py:89\u001b[0m, in \u001b[0;36mLayerStack.forward\u001b[0;34m(self, x, half_layers, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint(partial(layer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), x, use_reentrant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/layer.py:449\u001b[0m, in \u001b[0;36mPerFeatureEncoderLayer.forward\u001b[0;34m(self, state, single_eval_pos, cache_trainset_representation, att_src)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre-norm implementation is wrong, as the residual should never\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be layer normed here.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    443\u001b[0m     state \u001b[38;5;241m=\u001b[39m layer_norm(\n\u001b[1;32m    444\u001b[0m         state,\n\u001b[1;32m    445\u001b[0m         allow_inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    446\u001b[0m         save_peak_mem_factor\u001b[38;5;241m=\u001b[39msave_peak_mem_factor,\n\u001b[1;32m    447\u001b[0m     )\n\u001b[0;32m--> 449\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43msublayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_norm:\n\u001b[1;32m    451\u001b[0m     state \u001b[38;5;241m=\u001b[39m layer_norm(\n\u001b[1;32m    452\u001b[0m         state,\n\u001b[1;32m    453\u001b[0m         allow_inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    454\u001b[0m         save_peak_mem_factor\u001b[38;5;241m=\u001b[39msave_peak_mem_factor,\n\u001b[1;32m    455\u001b[0m     )\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/layer.py:363\u001b[0m, in \u001b[0;36mPerFeatureEncoderLayer.forward.<locals>.attn_between_items\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    360\u001b[0m     new_x_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_eval_pos:\n\u001b[0;32m--> 363\u001b[0m     new_x_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn_between_items\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43msingle_eval_pos\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_trainset_representation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_cache_first_head_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     new_x_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/multi_head_attention.py:355\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, x, x_kv, cache_kv, add_input, allow_inplace, save_peak_mem_factor, reuse_first_head_kv, only_cache_first_head_kv, use_cached_kv, use_second_set_of_queries)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_k_cache \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    339\u001b[0m             batch_size,\n\u001b[1;32m    340\u001b[0m             seqlen_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    345\u001b[0m         )\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_cache \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty(\n\u001b[1;32m    347\u001b[0m             batch_size,\n\u001b[1;32m    348\u001b[0m             seqlen_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    353\u001b[0m         )\n\u001b[0;32m--> 355\u001b[0m output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_k_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_v_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kv_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cached_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cached_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_inplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_inplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_peak_mem_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreuse_first_head_kv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_second_set_of_queries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_second_set_of_queries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mreshape(x_shape_after_transpose[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:])\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/memory.py:94\u001b[0m, in \u001b[0;36msupport_save_peak_mem_factor.<locals>.method_\u001b[0;34m(self, x, add_input, allow_inplace, save_peak_mem_factor, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_, \u001b[38;5;241m*\u001b[39margs_ \u001b[38;5;129;01min\u001b[39;00m split_args:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m add_input:\n\u001b[0;32m---> 94\u001b[0m         x_[:] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m         x_[:] \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, x_, \u001b[38;5;241m*\u001b[39margs_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/multi_head_attention.py:504\u001b[0m, in \u001b[0;36mMultiHeadAttention._compute\u001b[0;34m(self, x, x_kv, k_cache, v_cache, kv_cache, cache_kv, use_cached_kv, reuse_first_head_kv, use_second_set_of_queries)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Attention computation.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03mCalled by 'forward', potentially on shards, once shapes have been normalized.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m q, k, v, kv, qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_qkv(\n\u001b[1;32m    494\u001b[0m     x,\n\u001b[1;32m    495\u001b[0m     x_kv,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m     use_second_set_of_queries\u001b[38;5;241m=\u001b[39muse_second_set_of_queries,\n\u001b[1;32m    503\u001b[0m )\n\u001b[0;32m--> 504\u001b[0m attention_head_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mMultiHeadAttention\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_attention_heads\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqkv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39meinsum(\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... h d, h d s -> ... s\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    515\u001b[0m     attention_head_outputs,\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w_out,\n\u001b[1;32m    517\u001b[0m )\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/tabpfn/model/multi_head_attention.py:729\u001b[0m, in \u001b[0;36mMultiHeadAttention.compute_attention_heads\u001b[0;34m(q, k, v, kv, qkv, dropout_p, softmax_scale)\u001b[0m\n\u001b[1;32m    727\u001b[0m     ps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    728\u001b[0m     ps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdropout(ps, dropout_p, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 729\u001b[0m     attention_head_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb q k h, b k h d -> b q h d\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attention_head_outputs\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    732\u001b[0m     batch_size,\n\u001b[1;32m    733\u001b[0m     seqlen_q,\n\u001b[1;32m    734\u001b[0m     nhead,\n\u001b[1;32m    735\u001b[0m     d_v,\n\u001b[1;32m    736\u001b[0m )\n",
      "File \u001b[0;32m~/HSE/.venv/lib/python3.12/site-packages/torch/functional.py:380\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    382\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import synthcity components if not already imported\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n",
    "\n",
    "log.add(sink=sys.stderr, level=\"INFO\")\n",
    "\n",
    "# Apply StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Prepare training data with target for synthetic generation\n",
    "train_df = X_train_folds.copy().reset_index(drop=True)\n",
    "train_df['target'] = y_train_k_fold\n",
    "\n",
    "# Create GenericDataLoader as per documentation\n",
    "loader = GenericDataLoader(\n",
    "    train_df,\n",
    "    target_column=\"target\",\n",
    ")\n",
    "\n",
    "# Generate synthetic data using synthcity's ctgan\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)\n",
    "syn_model.fit(loader)\n",
    "\n",
    "# Generate synthetic samples\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority class samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Drop target column from synthetic data\n",
    "syntetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "syntetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data\n",
    "X_train_combined = pd.concat([X_train_folds, syntetic_minority_features])\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "y_train_combined = np.concatenate((y_train_k_fold, syntetic_target.values), axis=0)\n",
    "\n",
    "# Apply the same transformation to test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train final TabPFN classifier on the combined training data\n",
    "final_classifier = AutoTabPFNClassifier(device='auto', max_time=60)\n",
    "final_classifier.fit(X_train_scaled, y_train_combined)\n",
    "\n",
    "# Save the final model\n",
    "with open('AutoTabFPN_arf_edge_cases.pkl', 'wb') as f:\n",
    "    pickle.dump(final_classifier, f)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_prob = final_classifier.predict_proba(X_test_scaled)[:, 1]\n",
    "y_pred = final_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = {\n",
    "    \"roc_auc\": float(roc_auc_score(y_test, y_pred_prob)),\n",
    "    \"f1\": float(f1_score(y_test, y_pred)),\n",
    "    \"precision\": float(precision_score(y_test, y_pred)),\n",
    "    \"recall\": float(recall_score(y_test, y_pred)),\n",
    "    \"accuracy\": float(accuracy_score(y_test, y_pred))\n",
    "}\n",
    "\n",
    "# Save results to JSON\n",
    "result_filename = f'tabpfn_arf_edge_cases.json'\n",
    "\n",
    "with open(result_filename, 'w') as f:\n",
    "    json.dump(metrics, f, indent=4)\n",
    "\n",
    "# Print metrics summary\n",
    "print(f\"Test metrics saved to {result_filename}\")\n",
    "print(\"Test metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6822cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
