{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd85dda0-2c2a-4bf0-86a9-e1c48619f721",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "297845f0-ec0c-4e56-b19d-9a2de148ba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4fd62a86-72b3-48ee-8b9f-f68309c14c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"InternationalBifurca_DATA_2023-10-30_0629.csv\", sep=',')\n",
    "df = pd.read_csv(r\"InternationalBifurca_DATA_2025-04-20_0932.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c6ad10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6bc76cd3-aee7-4244-afc2-f50a151b8227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>time_from_mi_symptoms_onse</th>\n",
       "      <th>...</th>\n",
       "      <th>time_to_death_f5</th>\n",
       "      <th>time_to_acs_f5</th>\n",
       "      <th>time_to_stroke_f5</th>\n",
       "      <th>time_to_pci_f5</th>\n",
       "      <th>time_to_cabg_f5</th>\n",
       "      <th>hospitalization_f5</th>\n",
       "      <th>bleeding_f5</th>\n",
       "      <th>angio_follow_f5</th>\n",
       "      <th>restenosis_f5</th>\n",
       "      <th>side_branch_restenosis_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>MNRI-2018-0001</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>MNRI-2018-0002</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>MNRI-2018-0003</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>MNRI-2018-0004</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>MNRI-2018-0005</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>TRCH-2019-0026</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>TRCH-2019-0027</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>TRCH-2019-0028</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>TRCH-2019-0029</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>TRCH-2019-0030</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2073 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id      identifier        date  adhoc_pci  sex   age  weight  \\\n",
       "0     MNRI0001  MNRI-2018-0001  2018-02-01        1.0  2.0  77.0    84.0   \n",
       "1     MNRI0002  MNRI-2018-0002  2018-01-24        0.0  1.0  68.0    81.0   \n",
       "2     MNRI0003  MNRI-2018-0003  2018-01-24        0.0  1.0  62.0    74.0   \n",
       "3     MNRI0004  MNRI-2018-0004  2018-01-30        1.0  1.0  67.0    84.0   \n",
       "4     MNRI0005  MNRI-2018-0005  2018-01-30        0.0  1.0  57.0   103.0   \n",
       "...        ...             ...         ...        ...  ...   ...     ...   \n",
       "2139  TRCH0026  TRCH-2019-0026  2019-03-11        1.0  1.0  67.0    90.0   \n",
       "2140  TRCH0027  TRCH-2019-0027  2019-03-18        1.0  1.0  69.0    60.0   \n",
       "2141  TRCH0028  TRCH-2019-0028  2019-03-19        0.0  2.0  81.0    50.0   \n",
       "2142  TRCH0029  TRCH-2019-0029  2019-03-28        1.0  1.0  86.0    74.0   \n",
       "2143  TRCH0030  TRCH-2019-0030  2019-03-20        1.0  2.0  85.0    60.0   \n",
       "\n",
       "      height  clinical_presentation  time_from_mi_symptoms_onse  ...  \\\n",
       "0      165.0                    5.0                         4.0  ...   \n",
       "1      171.0                    1.0                         NaN  ...   \n",
       "2      180.0                    4.0                         NaN  ...   \n",
       "3      167.0                    2.0                         NaN  ...   \n",
       "4      174.0                    1.0                         NaN  ...   \n",
       "...      ...                    ...                         ...  ...   \n",
       "2139   174.0                    2.0                         NaN  ...   \n",
       "2140   174.0                    3.0                         1.0  ...   \n",
       "2141   160.0                    2.0                         NaN  ...   \n",
       "2142   170.0                    3.0                         1.0  ...   \n",
       "2143   165.0                    3.0                         1.0  ...   \n",
       "\n",
       "      time_to_death_f5  time_to_acs_f5  time_to_stroke_f5  time_to_pci_f5  \\\n",
       "0                  NaN             NaN                NaN             NaN   \n",
       "1                  NaN             NaN                NaN             NaN   \n",
       "2                  NaN             NaN                NaN             NaN   \n",
       "3                  NaN             NaN                NaN             NaN   \n",
       "4                  NaN             NaN                NaN             NaN   \n",
       "...                ...             ...                ...             ...   \n",
       "2139               NaN             NaN                NaN             NaN   \n",
       "2140               NaN             NaN                NaN             NaN   \n",
       "2141               NaN             NaN                NaN             NaN   \n",
       "2142               NaN             NaN                NaN             NaN   \n",
       "2143               NaN             NaN                NaN             NaN   \n",
       "\n",
       "      time_to_cabg_f5  hospitalization_f5  bleeding_f5  angio_follow_f5  \\\n",
       "0                 NaN                 NaN          NaN              NaN   \n",
       "1                 NaN                 NaN          NaN              NaN   \n",
       "2                 NaN                 NaN          NaN              NaN   \n",
       "3                 NaN                 NaN          NaN              NaN   \n",
       "4                 NaN                 NaN          NaN              NaN   \n",
       "...               ...                 ...          ...              ...   \n",
       "2139              NaN                 NaN          NaN              NaN   \n",
       "2140              NaN                 NaN          NaN              NaN   \n",
       "2141              NaN                 NaN          NaN              NaN   \n",
       "2142              NaN                 NaN          NaN              NaN   \n",
       "2143              NaN                 NaN          NaN              NaN   \n",
       "\n",
       "      restenosis_f5  side_branch_restenosis_5  \n",
       "0               NaN                       NaN  \n",
       "1               NaN                       NaN  \n",
       "2               NaN                       NaN  \n",
       "3               NaN                       NaN  \n",
       "4               NaN                       NaN  \n",
       "...             ...                       ...  \n",
       "2139            NaN                       NaN  \n",
       "2140            NaN                       NaN  \n",
       "2141            NaN                       NaN  \n",
       "2142            NaN                       NaN  \n",
       "2143            NaN                       NaN  \n",
       "\n",
       "[2073 rows x 283 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=['sex'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "774f8d65-3829-4d17-b328-b3ab69e93907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stent_distal_vessel_size    inf\n",
       "sb_stent_sb_diametr         inf\n",
       "dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anyInf = df[df == np.inf].sum()\n",
    "anyInf[anyInf != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68fbb8f3-c020-46ea-8d42-5c5e6ddad81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info_cols = ['record_id', 'date', 'sex', 'age', 'adhoc_pci', 'weight', 'height', \n",
    "                     'clinical_presentation', 'time_from_mi_symptoms_onse', \n",
    "                     'ccs_class', 'diabet', 'insulin_diabetes', 'hypertension', 'smoking', \n",
    "                     'dyslipidemia', 'anemia', 'atrial_fibrilation', 'oac_use', 'valvular_disease', \n",
    "                     'valvular_disease_was_previ', 'if_yes_what_type___1', 'if_yes_what_type___2', \n",
    "                     'if_yes_what_type___3', 'if_yes_what_type___4', 'if_yes_what_type___5', \n",
    "                     'if_yes_what_type___6', 'if_yes_what_type___7', 'ef', 'creatinine', 'ckd', \n",
    "                     'mi_history', 'cerebrovascular_disease', 'previously_treated_cerebro', 'previous_stroke_tia', \n",
    "                     'peripheral_artery_disease', 'previously_treated_periphe', 'copd', 'history_of_cancer', \n",
    "                     'previous_pci', 'previous_cabg']\n",
    "\n",
    "intervention_cols = ['single_vessel', 'trifurcation', 'bifurcation_location', \n",
    "                  'lesion_ivolves', 'angle', 'calcium', 'trombosis', \n",
    "                  'total_trobotic_occlusion', 'restenosis_reocclusion', 'cto_bifurc', \n",
    "                  'medina_proximal', 'medina_distal', 'medina_side', 'mb_length_proximal', \n",
    "                  'sb_length', 'proximal_diametr', 'distal_diametr', 'side_diametr', 'stenosis_proximal', \n",
    "                  'stenosis_distal', 'timi_flow_main_branch', 'side_stenosis', 'timi_flow_side_branch', \n",
    "                  'major_lm', 'major_non_lm', 'minor_criteria', 'main_branch_rvd', 'def', 'def_2']\n",
    "\n",
    "operation_cols = ['side_protection', 'main_predilatation', 'side_predilat', \n",
    "                  'stent_was_implated_from_lm', 'stent_number', 'stent_number_bif', 'stent_technique', \n",
    "                  'first_stent_impanted', 'provisional_2_stent_techni', 'stent_direction', 'defered_stenting', \n",
    "                  'stent_diameter', 'stent_length', 'stent_type___1', 'stent_type___2', 'stent_type___3', \n",
    "                  'stent_type___4', 'stent_type___5', 'stent_type___6', 'stent_type___7', 'stent_type___9', \n",
    "                  'stent_type___8', 'dstent2', 'stent_length2', 'stent_distal_vessel_size', \n",
    "                  'sb_stent_side_branch_diametr', 'sb_stent_sb_diametr', 'twostent_technique', \n",
    "                  'sb_dilatation', 'stent_postdilatation', 'proximal_optimization', 'pot', \n",
    "                  'pot_balloon_diametr', 'kissing_post', 'modified_kis', 'several_kissing']\n",
    "\n",
    "new_cols = ['adverse_event_followup_f2_v2', 'angio_follow_f5', 'antiplatalet_drug_was_chan',\n",
    "            'attempt_to_dilate_stenting', 'ballooon_size_for_postdila', 'complete_revascularisation',\n",
    "            'currently_on_dialysis', 'followup_1_year_do_not_complete_if_2nd_bifurcation_complete',\n",
    "            'identifier', 'ishemia_test___1', 'ishemia_test___2', 'ishemia_test___3', 'ishemia_test___4',\n",
    "            'kissing_post_2stent___1', 'kissing_post_2stent___2', 'left_main_stent_direction',\n",
    "            'main_branch_calcification', 'mb_stenosis_f2', 'medina_side_branch_2', 'myocardial_ischemia',\n",
    "            'myocardial_ishemia_was_det', 'number_of_kissing', 'number_of_kissing_2',\n",
    "            'other_lesions_in_main_bran', 'other_lesions_in_side_brach',\n",
    "            'patient_information_do_not_complete_if_2nd_bifurca_complete', 'pot_2', 'pot_balloon_diametr_2',\n",
    "            'pot_balloon_length', 'pot_balloon_length_2', 'pressure2', 'reson_for_change_stopped___1',\n",
    "            'reson_for_change_stopped___2', 'reson_for_change_stopped___3', 'restenosis_f5', 'sb_length_2',\n",
    "            'sb_stenosis_f2', 'side_branch_calcification_2', 'side_branch_restenosis',\n",
    "            'side_branch_restenosis_3', 'side_branch_restenosis_5', 'stent_pressure', 'stent_type_2___1',\n",
    "            'stent_type_2___2', 'stent_type_2___3', 'stent_type_2___4', 'stent_type_2___5', 'stent_type_2___6',\n",
    "            'stent_type_2___7', 'stent_type_2___8', 'stent_type_2___9', 'thrombolysis', 'uncross_strategy___1',\n",
    "            'uncross_strategy___2', 'uncross_strategy___3', 'uncross_strategy___4', 'uncross_strategy___5',\n",
    "            'uncross_strategy___6', 'uncross_strategy___7', 'uncross_strategy___8', 'uncross_strategy___9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d5f17f5b-f845-4cc7-a1ed-11412eff10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_vascular_deaths = ['MNRI1054', 'MNRI1191', 'MNRI1351', 'MNRI1352', 'MNRI1473', 'MNRI1670', 'MNRI0637', 'MNRI0656', 'MNRI0751', 'MNRI0758',\n",
    "                      'MNRI0805', 'MNRI0818', 'MNRI1054', 'MNRI0087', 'MNRI1191', 'MNRI0108', 'MNRI0307', 'MNRI0215', 'MNRI0322', 'MNRI0293',\n",
    "                      'MNRI0156', 'MNRI0215', 'MNRI0488', 'MNRI0612', 'MNRI0708', 'MNRI0767', 'MNRI0772', 'MNRI0786', 'MNRI1105', 'MNRI1186',\n",
    "                      'MNRI1462', 'MNRI1633']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "919b17e8-d213-4c3f-a9e5-8d2830232086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['record_id'].isin(non_vascular_deaths)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0036d868-3fbc-41a9-8233-74f2b4bfa68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>identifier</th>\n",
       "      <th>date</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>time_from_mi_symptoms_onse</th>\n",
       "      <th>...</th>\n",
       "      <th>time_to_death_f5</th>\n",
       "      <th>time_to_acs_f5</th>\n",
       "      <th>time_to_stroke_f5</th>\n",
       "      <th>time_to_pci_f5</th>\n",
       "      <th>time_to_cabg_f5</th>\n",
       "      <th>hospitalization_f5</th>\n",
       "      <th>bleeding_f5</th>\n",
       "      <th>angio_follow_f5</th>\n",
       "      <th>restenosis_f5</th>\n",
       "      <th>side_branch_restenosis_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>MNRI-2018-0001</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>MNRI-2018-0002</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>MNRI-2018-0003</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>MNRI-2018-0004</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>MNRI-2018-0005</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>TRCH-2019-0026</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>TRCH-2019-0027</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>TRCH-2019-0028</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>TRCH-2019-0029</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>TRCH-2019-0030</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 283 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id      identifier        date  adhoc_pci  sex   age  weight  \\\n",
       "0     MNRI0001  MNRI-2018-0001  2018-02-01        1.0  2.0  77.0    84.0   \n",
       "1     MNRI0002  MNRI-2018-0002  2018-01-24        0.0  1.0  68.0    81.0   \n",
       "2     MNRI0003  MNRI-2018-0003  2018-01-24        0.0  1.0  62.0    74.0   \n",
       "3     MNRI0004  MNRI-2018-0004  2018-01-30        1.0  1.0  67.0    84.0   \n",
       "4     MNRI0005  MNRI-2018-0005  2018-01-30        0.0  1.0  57.0   103.0   \n",
       "...        ...             ...         ...        ...  ...   ...     ...   \n",
       "2139  TRCH0026  TRCH-2019-0026  2019-03-11        1.0  1.0  67.0    90.0   \n",
       "2140  TRCH0027  TRCH-2019-0027  2019-03-18        1.0  1.0  69.0    60.0   \n",
       "2141  TRCH0028  TRCH-2019-0028  2019-03-19        0.0  2.0  81.0    50.0   \n",
       "2142  TRCH0029  TRCH-2019-0029  2019-03-28        1.0  1.0  86.0    74.0   \n",
       "2143  TRCH0030  TRCH-2019-0030  2019-03-20        1.0  2.0  85.0    60.0   \n",
       "\n",
       "      height  clinical_presentation  time_from_mi_symptoms_onse  ...  \\\n",
       "0      165.0                    5.0                         4.0  ...   \n",
       "1      171.0                    1.0                         NaN  ...   \n",
       "2      180.0                    4.0                         NaN  ...   \n",
       "3      167.0                    2.0                         NaN  ...   \n",
       "4      174.0                    1.0                         NaN  ...   \n",
       "...      ...                    ...                         ...  ...   \n",
       "2139   174.0                    2.0                         NaN  ...   \n",
       "2140   174.0                    3.0                         1.0  ...   \n",
       "2141   160.0                    2.0                         NaN  ...   \n",
       "2142   170.0                    3.0                         1.0  ...   \n",
       "2143   165.0                    3.0                         1.0  ...   \n",
       "\n",
       "      time_to_death_f5  time_to_acs_f5  time_to_stroke_f5  time_to_pci_f5  \\\n",
       "0                  NaN             NaN                NaN             NaN   \n",
       "1                  NaN             NaN                NaN             NaN   \n",
       "2                  NaN             NaN                NaN             NaN   \n",
       "3                  NaN             NaN                NaN             NaN   \n",
       "4                  NaN             NaN                NaN             NaN   \n",
       "...                ...             ...                ...             ...   \n",
       "2139               NaN             NaN                NaN             NaN   \n",
       "2140               NaN             NaN                NaN             NaN   \n",
       "2141               NaN             NaN                NaN             NaN   \n",
       "2142               NaN             NaN                NaN             NaN   \n",
       "2143               NaN             NaN                NaN             NaN   \n",
       "\n",
       "      time_to_cabg_f5  hospitalization_f5  bleeding_f5  angio_follow_f5  \\\n",
       "0                 NaN                 NaN          NaN              NaN   \n",
       "1                 NaN                 NaN          NaN              NaN   \n",
       "2                 NaN                 NaN          NaN              NaN   \n",
       "3                 NaN                 NaN          NaN              NaN   \n",
       "4                 NaN                 NaN          NaN              NaN   \n",
       "...               ...                 ...          ...              ...   \n",
       "2139              NaN                 NaN          NaN              NaN   \n",
       "2140              NaN                 NaN          NaN              NaN   \n",
       "2141              NaN                 NaN          NaN              NaN   \n",
       "2142              NaN                 NaN          NaN              NaN   \n",
       "2143              NaN                 NaN          NaN              NaN   \n",
       "\n",
       "      restenosis_f5  side_branch_restenosis_5  \n",
       "0               NaN                       NaN  \n",
       "1               NaN                       NaN  \n",
       "2               NaN                       NaN  \n",
       "3               NaN                       NaN  \n",
       "4               NaN                       NaN  \n",
       "...             ...                       ...  \n",
       "2139            NaN                       NaN  \n",
       "2140            NaN                       NaN  \n",
       "2141            NaN                       NaN  \n",
       "2142            NaN                       NaN  \n",
       "2143            NaN                       NaN  \n",
       "\n",
       "[2044 rows x 283 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "54ed796c-3a11-4ae5-9a06-ce34a86ef85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_present_cols = patient_info_cols + intervention_cols + operation_cols + new_cols\n",
    "patient_present_df = pd.DataFrame({col_name: df[col_name] for col_name in patient_present_cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2d40ace-88e7-42a4-9bbe-8bba2ee2cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>time_from_mi_symptoms_onse</th>\n",
       "      <th>ccs_class</th>\n",
       "      <th>...</th>\n",
       "      <th>thrombolysis</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___5</th>\n",
       "      <th>uncross_strategy___6</th>\n",
       "      <th>uncross_strategy___7</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>2018-01-24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>2018-01-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>2019-03-19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id        date  sex   age  adhoc_pci  weight  height  \\\n",
       "0     MNRI0001  2018-02-01  2.0  77.0        1.0    84.0   165.0   \n",
       "1     MNRI0002  2018-01-24  1.0  68.0        0.0    81.0   171.0   \n",
       "2     MNRI0003  2018-01-24  1.0  62.0        0.0    74.0   180.0   \n",
       "3     MNRI0004  2018-01-30  1.0  67.0        1.0    84.0   167.0   \n",
       "4     MNRI0005  2018-01-30  1.0  57.0        0.0   103.0   174.0   \n",
       "...        ...         ...  ...   ...        ...     ...     ...   \n",
       "2139  TRCH0026  2019-03-11  1.0  67.0        1.0    90.0   174.0   \n",
       "2140  TRCH0027  2019-03-18  1.0  69.0        1.0    60.0   174.0   \n",
       "2141  TRCH0028  2019-03-19  2.0  81.0        0.0    50.0   160.0   \n",
       "2142  TRCH0029  2019-03-28  1.0  86.0        1.0    74.0   170.0   \n",
       "2143  TRCH0030  2019-03-20  2.0  85.0        1.0    60.0   165.0   \n",
       "\n",
       "      clinical_presentation  time_from_mi_symptoms_onse  ccs_class  ...  \\\n",
       "0                       5.0                         4.0        NaN  ...   \n",
       "1                       1.0                         NaN        1.0  ...   \n",
       "2                       4.0                         NaN        NaN  ...   \n",
       "3                       2.0                         NaN        NaN  ...   \n",
       "4                       1.0                         NaN        2.0  ...   \n",
       "...                     ...                         ...        ...  ...   \n",
       "2139                    2.0                         NaN        NaN  ...   \n",
       "2140                    3.0                         1.0        NaN  ...   \n",
       "2141                    2.0                         NaN        NaN  ...   \n",
       "2142                    3.0                         1.0        NaN  ...   \n",
       "2143                    3.0                         1.0        NaN  ...   \n",
       "\n",
       "      thrombolysis  uncross_strategy___1  uncross_strategy___2  \\\n",
       "0              0.0                     0                     0   \n",
       "1              NaN                     0                     0   \n",
       "2              NaN                     0                     0   \n",
       "3              NaN                     0                     0   \n",
       "4              NaN                     0                     0   \n",
       "...            ...                   ...                   ...   \n",
       "2139           0.0                     0                     0   \n",
       "2140           1.0                     0                     0   \n",
       "2141           0.0                     0                     0   \n",
       "2142           0.0                     0                     0   \n",
       "2143           0.0                     0                     0   \n",
       "\n",
       "      uncross_strategy___3  uncross_strategy___4  uncross_strategy___5  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___6  uncross_strategy___7  uncross_strategy___8  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___9  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "2139                     0  \n",
       "2140                     0  \n",
       "2141                     0  \n",
       "2142                     0  \n",
       "2143                     0  \n",
       "\n",
       "[2044 rows x 166 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_present_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8476c240-9824-49c9-90d8-62e1b6b9637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_preserve = ['valvular_disease', 'previous_stroke_tia', 'twostent_technique']\n",
    "\n",
    "def remove_columns_with_nan_threshold(df, threshold=250):\n",
    "    nan_counts = df.isnull().sum()\n",
    "    \n",
    "    columns_to_drop = [col for col in nan_counts[nan_counts > threshold].index \n",
    "                      if col not in columns_to_preserve]\n",
    "    \n",
    "    print(columns_to_drop)\n",
    "    \n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    return df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a1c4ca11-6dd2-4d63-bab1-e512fb1885e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_from_mi_symptoms_onse', 'ccs_class', 'insulin_diabetes', 'valvular_disease_was_previ', 'previously_treated_cerebro', 'previously_treated_periphe', 'lesion_ivolves', 'total_trobotic_occlusion', 'sb_length', 'timi_flow_main_branch', 'timi_flow_side_branch', 'stent_was_implated_from_lm', 'first_stent_impanted', 'provisional_2_stent_techni', 'dstent2', 'stent_length2', 'sb_stent_side_branch_diametr', 'proximal_optimization', 'pot', 'pot_balloon_diametr', 'several_kissing', 'adverse_event_followup_f2_v2', 'angio_follow_f5', 'antiplatalet_drug_was_chan', 'attempt_to_dilate_stenting', 'ballooon_size_for_postdila', 'complete_revascularisation', 'left_main_stent_direction', 'main_branch_calcification', 'mb_stenosis_f2', 'medina_side_branch_2', 'myocardial_ischemia', 'myocardial_ishemia_was_det', 'number_of_kissing', 'number_of_kissing_2', 'other_lesions_in_main_bran', 'other_lesions_in_side_brach', 'pot_2', 'pot_balloon_diametr_2', 'pot_balloon_length', 'pot_balloon_length_2', 'pressure2', 'restenosis_f5', 'sb_length_2', 'sb_stenosis_f2', 'side_branch_calcification_2', 'side_branch_restenosis', 'side_branch_restenosis_3', 'side_branch_restenosis_5', 'stent_pressure', 'thrombolysis']\n"
     ]
    }
   ],
   "source": [
    "patient_present_df = remove_columns_with_nan_threshold(patient_present_df, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f3d3b8e0-25ea-46a4-82de-2a9aad43fc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_type_2___9</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___5</th>\n",
       "      <th>uncross_strategy___6</th>\n",
       "      <th>uncross_strategy___7</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  sex   age  adhoc_pci  weight  height  clinical_presentation  \\\n",
       "0     MNRI0001  2.0  77.0        1.0    84.0   165.0                    5.0   \n",
       "1     MNRI0002  1.0  68.0        0.0    81.0   171.0                    1.0   \n",
       "2     MNRI0003  1.0  62.0        0.0    74.0   180.0                    4.0   \n",
       "3     MNRI0004  1.0  67.0        1.0    84.0   167.0                    2.0   \n",
       "4     MNRI0005  1.0  57.0        0.0   103.0   174.0                    1.0   \n",
       "...        ...  ...   ...        ...     ...     ...                    ...   \n",
       "2139  TRCH0026  1.0  67.0        1.0    90.0   174.0                    2.0   \n",
       "2140  TRCH0027  1.0  69.0        1.0    60.0   174.0                    3.0   \n",
       "2141  TRCH0028  2.0  81.0        0.0    50.0   160.0                    2.0   \n",
       "2142  TRCH0029  1.0  86.0        1.0    74.0   170.0                    3.0   \n",
       "2143  TRCH0030  2.0  85.0        1.0    60.0   165.0                    3.0   \n",
       "\n",
       "      diabet  hypertension  smoking  ...  stent_type_2___9  \\\n",
       "0        0.0           1.0      0.0  ...                 0   \n",
       "1        0.0           1.0      0.0  ...                 0   \n",
       "2        0.0           1.0      1.0  ...                 0   \n",
       "3        0.0           1.0      0.0  ...                 0   \n",
       "4        0.0           1.0      0.0  ...                 0   \n",
       "...      ...           ...      ...  ...               ...   \n",
       "2139     2.0           1.0      0.0  ...                 0   \n",
       "2140     1.0           1.0      0.0  ...                 0   \n",
       "2141     2.0           1.0      0.0  ...                 0   \n",
       "2142     1.0           1.0      0.0  ...                 0   \n",
       "2143     1.0           1.0      0.0  ...                 0   \n",
       "\n",
       "      uncross_strategy___1  uncross_strategy___2  uncross_strategy___3  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___4  uncross_strategy___5  uncross_strategy___6  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___7  uncross_strategy___8  uncross_strategy___9  \n",
       "0                        0                     0                     0  \n",
       "1                        0                     0                     0  \n",
       "2                        0                     0                     0  \n",
       "3                        0                     0                     0  \n",
       "4                        0                     0                     0  \n",
       "...                    ...                   ...                   ...  \n",
       "2139                     0                     0                     0  \n",
       "2140                     0                     0                     0  \n",
       "2141                     0                     0                     0  \n",
       "2142                     0                     0                     0  \n",
       "2143                     0                     0                     0  \n",
       "\n",
       "[2044 rows x 114 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# patient_present_df = patient_present_df.drop(['record_id', 'date'], axis = 1)\n",
    "patient_present_df = patient_present_df.drop(['date'], axis = 1)\n",
    "patient_present_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4530ff9c-7647-4b92-bcfe-f32827dfd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_present_df.replace(to_replace = [np.inf, -np.inf], value= None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5e4c1360-60bd-4e4c-a121-104724859e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_type_2___5</th>\n",
       "      <th>stent_type_2___6</th>\n",
       "      <th>stent_type_2___7</th>\n",
       "      <th>stent_type_2___8</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNRI0001</td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNRI0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNRI0003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNRI0004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNRI0005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>TRCH0026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>TRCH0027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>TRCH0028</td>\n",
       "      <td>2.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142</th>\n",
       "      <td>TRCH0029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>TRCH0030</td>\n",
       "      <td>2.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2044 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  sex   age adhoc_pci weight height clinical_presentation  \\\n",
       "0     MNRI0001  2.0  77.0       1.0   84.0  165.0                   5.0   \n",
       "1     MNRI0002  1.0  68.0       0.0   81.0  171.0                   1.0   \n",
       "2     MNRI0003  1.0  62.0       0.0   74.0  180.0                   4.0   \n",
       "3     MNRI0004  1.0  67.0       1.0   84.0  167.0                   2.0   \n",
       "4     MNRI0005  1.0  57.0       0.0  103.0  174.0                   1.0   \n",
       "...        ...  ...   ...       ...    ...    ...                   ...   \n",
       "2139  TRCH0026  1.0  67.0       1.0   90.0  174.0                   2.0   \n",
       "2140  TRCH0027  1.0  69.0       1.0   60.0  174.0                   3.0   \n",
       "2141  TRCH0028  2.0  81.0       0.0   50.0  160.0                   2.0   \n",
       "2142  TRCH0029  1.0  86.0       1.0   74.0  170.0                   3.0   \n",
       "2143  TRCH0030  2.0  85.0       1.0   60.0  165.0                   3.0   \n",
       "\n",
       "     diabet hypertension smoking  ... stent_type_2___5 stent_type_2___6  \\\n",
       "0       0.0          1.0     0.0  ...                0                0   \n",
       "1       0.0          1.0     0.0  ...                0                0   \n",
       "2       0.0          1.0     1.0  ...                0                0   \n",
       "3       0.0          1.0     0.0  ...                0                0   \n",
       "4       0.0          1.0     0.0  ...                0                0   \n",
       "...     ...          ...     ...  ...              ...              ...   \n",
       "2139    2.0          1.0     0.0  ...                0                0   \n",
       "2140    1.0          1.0     0.0  ...                0                0   \n",
       "2141    2.0          1.0     0.0  ...                0                0   \n",
       "2142    1.0          1.0     0.0  ...                0                0   \n",
       "2143    1.0          1.0     0.0  ...                0                0   \n",
       "\n",
       "     stent_type_2___7 stent_type_2___8 uncross_strategy___1  \\\n",
       "0                   0                0                    0   \n",
       "1                   0                0                    0   \n",
       "2                   0                0                    0   \n",
       "3                   0                0                    0   \n",
       "4                   0                0                    0   \n",
       "...               ...              ...                  ...   \n",
       "2139                0                0                    0   \n",
       "2140                0                0                    0   \n",
       "2141                0                0                    0   \n",
       "2142                0                0                    0   \n",
       "2143                0                0                    0   \n",
       "\n",
       "      uncross_strategy___2  uncross_strategy___3  uncross_strategy___4  \\\n",
       "0                        0                     0                     0   \n",
       "1                        0                     0                     0   \n",
       "2                        0                     0                     0   \n",
       "3                        0                     0                     0   \n",
       "4                        0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "2139                     0                     0                     0   \n",
       "2140                     0                     0                     0   \n",
       "2141                     0                     0                     0   \n",
       "2142                     0                     0                     0   \n",
       "2143                     0                     0                     0   \n",
       "\n",
       "      uncross_strategy___8  uncross_strategy___9  \n",
       "0                        0                     0  \n",
       "1                        0                     0  \n",
       "2                        0                     0  \n",
       "3                        0                     0  \n",
       "4                        0                     0  \n",
       "...                    ...                   ...  \n",
       "2139                     0                     0  \n",
       "2140                     0                     0  \n",
       "2141                     0                     0  \n",
       "2142                     0                     0  \n",
       "2143                     0                     0  \n",
       "\n",
       "[2044 rows x 106 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = patient_present_df.columns[patient_present_df.nunique() <= 1]\n",
    "patient_present_df = patient_present_df.drop(cols_to_drop, axis=1)\n",
    "patient_present_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ac363f7d-c2e1-454b-ade5-647b07eea73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'weight', 'height', 'ef', 'creatinine', 'ckd', 'angle', 'mb_length_proximal', \n",
    "            'proximal_diametr', 'distal_diametr', 'side_diametr', 'stenosis_proximal', \n",
    "            'stenosis_distal', 'side_stenosis', 'minor_criteria', 'main_branch_rvd', \n",
    "            'stent_diameter', 'stent_length', 'stent_distal_vessel_size', 'sb_stent_sb_diametr',\n",
    "            'ballooon_size_for_postdila', \n",
    "            'left_main_stent_direction',\n",
    "            'mb_stenosis_f2',\n",
    "            'myocardial_ischemia',\n",
    "            'number_of_kissing_2',\n",
    "            'pot_balloon_diametr_2',\n",
    "            'pot_balloon_length',\n",
    "            'pot_balloon_length_2',\n",
    "            'pressure2',\n",
    "            'sb_length_2',\n",
    "            'sb_stenosis_f2',\n",
    "            'stent_pressure']\n",
    "\n",
    "categorical = ['sex', 'clinical_presentation', 'bifurcation_location', 'stent_number', \n",
    "              'stent_number_bif', 'stent_technique', 'stent_direction']\n",
    "\n",
    "binary = ['diabet', 'adhoc_pci', 'hypertension', 'smoking', 'dyslipidemia', 'anemia', \n",
    "         'atrial_fibrilation', 'oac_use', 'if_yes_what_type___1', 'if_yes_what_type___2',\n",
    "         'if_yes_what_type___3', 'if_yes_what_type___4', 'if_yes_what_type___6', \n",
    "         'mi_history', 'cerebrovascular_disease', 'peripheral_artery_disease', 'copd', \n",
    "         'history_of_cancer', 'previous_pci', 'previous_cabg', 'single_vessel', 'trifurcation',\n",
    "         'calcium', 'trombosis', 'restenosis_reocclusion', 'cto_bifurc', \n",
    "         'medina_proximal', 'medina_distal', 'medina_side', 'major_lm', 'major_non_lm',\n",
    "         'def', 'def_2', 'side_protection', 'main_predilatation', 'side_predilat',\n",
    "         'defered_stenting', 'stent_type___1', 'stent_type___2', 'stent_type___3', 'stent_type___4',\n",
    "         'stent_type___5', 'stent_type___6', 'stent_type___7', 'stent_type___9', 'stent_type___8', \n",
    "         'sb_dilatation', 'stent_postdilatation', 'kissing_post', 'modified_kis',\n",
    "         'currently_on_dialysis',\n",
    "         'ishemia_test___1',\n",
    "         'ishemia_test___2',\n",
    "         'ishemia_test___3',\n",
    "         'kissing_post_2stent___1',\n",
    "         'kissing_post_2stent___2',\n",
    "         'reson_for_change_stopped___1',\n",
    "         'reson_for_change_stopped___2',\n",
    "         'reson_for_change_stopped___3',\n",
    "         'stent_type_2___1',\n",
    "         'stent_type_2___3',\n",
    "         'stent_type_2___4',\n",
    "         'stent_type_2___5',\n",
    "         'stent_type_2___6',\n",
    "         'stent_type_2___7',\n",
    "         'stent_type_2___8',\n",
    "         'uncross_strategy___1',\n",
    "         'uncross_strategy___2',\n",
    "         'uncross_strategy___3',\n",
    "         'uncross_strategy___4',\n",
    "         'uncross_strategy___8',\n",
    "         'uncross_strategy___9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "682e6eba-c34d-4403-8c8a-0b18b8524eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "2044\n"
     ]
    }
   ],
   "source": [
    "without_second_bif = df\n",
    "adverse_events = without_second_bif['event_type_followup_f2___1'] \\\n",
    "| without_second_bif['event_type_followup_f2___2'] \\\n",
    "| without_second_bif['event_type_followup_f2_v2___1'] \\\n",
    "| without_second_bif['event_type_followup_f2_v2___2']\n",
    "print(sum(adverse_events))\n",
    "print(len(adverse_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "392297cc-7b3c-4163-aab4-3fe78b238a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = zip(without_second_bif['event_type_followup_f2___1'],  \n",
    "               without_second_bif['event_type_followup_f2___2'] * 2,\n",
    "               without_second_bif['event_type_followup_f2_v2___1'] * 3, \n",
    "               without_second_bif['event_type_followup_f2_v2___2'] * 4)\n",
    "\n",
    "combined_adverse_events = np.array([max(t) for t in combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0e73bb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1886, 1: 53, 2: 18, 3: 51, 4: 36}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(combined_adverse_events, return_counts=True)\n",
    "value_counts = dict(zip(unique, counts))\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6acb5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = patient_present_df['record_id']\n",
    "patient_present_df = patient_present_df.drop(['record_id', 'identifier'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2c564a98-2d4b-441b-8bd9-02e28b1ada94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(patient_present_df, combined_adverse_events, test_size=0.4, stratify=combined_adverse_events, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "37a3a02b-88af-47bf-8034-6b01e6a6e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train != 0] = 1\n",
    "y_test[y_test != 0] = 1\n",
    "y_val[y_val != 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9790db4c-5a0c-43dd-835f-fa1b8350cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_type_2___5</th>\n",
       "      <th>stent_type_2___6</th>\n",
       "      <th>stent_type_2___7</th>\n",
       "      <th>stent_type_2___8</th>\n",
       "      <th>uncross_strategy___1</th>\n",
       "      <th>uncross_strategy___2</th>\n",
       "      <th>uncross_strategy___3</th>\n",
       "      <th>uncross_strategy___4</th>\n",
       "      <th>uncross_strategy___8</th>\n",
       "      <th>uncross_strategy___9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.535524</td>\n",
       "      <td>172.093993</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  adhoc_pci      weight      height  clinical_presentation  \\\n",
       "0     1.0  41.0        0.0  100.000000  177.000000                    5.0   \n",
       "1     1.0  56.0        1.0   81.000000  172.000000                    4.0   \n",
       "2     1.0  55.0        1.0   87.535524  172.093993                    3.0   \n",
       "3     1.0  79.0        0.0   61.000000  160.000000                    1.0   \n",
       "4     1.0  61.0        1.0   84.000000  179.000000                    2.0   \n",
       "...   ...   ...        ...         ...         ...                    ...   \n",
       "1221  2.0  69.0        0.0  111.000000  159.000000                    1.0   \n",
       "1222  1.0  57.0        0.0   96.000000  178.000000                    1.0   \n",
       "1223  1.0  63.0        0.0   80.000000  162.000000                    1.0   \n",
       "1224  1.0  75.0        0.0  165.000000   71.000000                    1.0   \n",
       "1225  1.0  46.0        0.0  107.000000  179.000000                    2.0   \n",
       "\n",
       "      diabet  hypertension  smoking  dyslipidemia  ...  stent_type_2___5  \\\n",
       "0        0.0           1.0      0.0           0.0  ...               0.0   \n",
       "1        0.0           1.0      0.0           0.0  ...               0.0   \n",
       "2        0.0           1.0      0.0           1.0  ...               0.0   \n",
       "3        0.0           1.0      0.0           0.0  ...               0.0   \n",
       "4        1.0           1.0      0.0           0.0  ...               0.0   \n",
       "...      ...           ...      ...           ...  ...               ...   \n",
       "1221     2.0           0.0      0.0           0.0  ...               0.0   \n",
       "1222     1.0           1.0      0.0           0.0  ...               0.0   \n",
       "1223     1.0           1.0      0.0           0.0  ...               0.0   \n",
       "1224     0.0           1.0      1.0           1.0  ...               0.0   \n",
       "1225     1.0           1.0      0.0           0.0  ...               0.0   \n",
       "\n",
       "      stent_type_2___6  stent_type_2___7  stent_type_2___8  \\\n",
       "0                  0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0   \n",
       "2                  0.0               0.0               0.0   \n",
       "3                  0.0               0.0               0.0   \n",
       "4                  0.0               0.0               0.0   \n",
       "...                ...               ...               ...   \n",
       "1221               1.0               0.0               0.0   \n",
       "1222               0.0               0.0               0.0   \n",
       "1223               0.0               0.0               0.0   \n",
       "1224               0.0               0.0               0.0   \n",
       "1225               0.0               0.0               0.0   \n",
       "\n",
       "      uncross_strategy___1  uncross_strategy___2  uncross_strategy___3  \\\n",
       "0                      0.0                   0.0                   0.0   \n",
       "1                      0.0                   0.0                   0.0   \n",
       "2                      0.0                   0.0                   0.0   \n",
       "3                      1.0                   0.0                   0.0   \n",
       "4                      0.0                   0.0                   0.0   \n",
       "...                    ...                   ...                   ...   \n",
       "1221                   0.0                   0.0                   0.0   \n",
       "1222                   0.0                   0.0                   0.0   \n",
       "1223                   0.0                   0.0                   0.0   \n",
       "1224                   0.0                   0.0                   0.0   \n",
       "1225                   0.0                   0.0                   0.0   \n",
       "\n",
       "      uncross_strategy___4  uncross_strategy___8  uncross_strategy___9  \n",
       "0                      0.0                   0.0                   0.0  \n",
       "1                      0.0                   0.0                   0.0  \n",
       "2                      0.0                   0.0                   0.0  \n",
       "3                      0.0                   0.0                   0.0  \n",
       "4                      0.0                   0.0                   0.0  \n",
       "...                    ...                   ...                   ...  \n",
       "1221                   0.0                   0.0                   0.0  \n",
       "1222                   0.0                   0.0                   0.0  \n",
       "1223                   0.0                   0.0                   0.0  \n",
       "1224                   0.0                   0.0                   0.0  \n",
       "1225                   0.0                   0.0                   0.0  \n",
       "\n",
       "[1226 rows x 104 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "X_train[categorical + binary] = imputer_categorical.fit_transform(X_train[categorical + binary])\n",
    "X_test[categorical + binary] = imputer_categorical.transform(X_test[categorical + binary])\n",
    "X_val[categorical + binary] = imputer_categorical.transform(X_val[categorical + binary])\n",
    "\n",
    "imputer = IterativeImputer(random_state=0)\n",
    "columns = list(X_train.columns)\n",
    "X_train = pd.DataFrame(data = imputer.fit_transform(X_train), columns = columns)\n",
    "X_test = pd.DataFrame(data = imputer.transform(X_test), columns = columns)\n",
    "X_val = pd.DataFrame(data = imputer.transform(X_val), columns = columns)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c2248445-abc7-459d-a11d-b96aaaf3a2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(sparse_output=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneHotEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(sparse_output=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(sparse_output=False)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "df_for_ohe = pd.concat([X_train[categorical], X_test[categorical], X_val[categorical]], ignore_index=True)\n",
    "ohe.fit(df_for_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "79bb5945-57d1-419b-86d7-b3e30ead8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ohe(dataframe, cat_cols, encoder):\n",
    "    encoded_columns = pd.DataFrame(encoder.transform(dataframe[cat_cols]))\n",
    "\n",
    "    encoded_columns.columns = encoder.get_feature_names_out(cat_cols)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, encoded_columns], axis=1)\n",
    "\n",
    "    dataframe.drop(cat_cols, axis=1, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5646ef41-c36f-44a8-9c7f-fa0380d3a7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>diabet</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_number_bif_3.0</th>\n",
       "      <th>stent_number_bif_4.0</th>\n",
       "      <th>stent_technique_0.0</th>\n",
       "      <th>stent_technique_1.0</th>\n",
       "      <th>stent_direction_1.0</th>\n",
       "      <th>stent_direction_2.0</th>\n",
       "      <th>stent_direction_3.0</th>\n",
       "      <th>stent_direction_4.0</th>\n",
       "      <th>stent_direction_5.0</th>\n",
       "      <th>stent_direction_6.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>87.535524</td>\n",
       "      <td>172.093993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  adhoc_pci      weight      height  diabet  hypertension  smoking  \\\n",
       "0     41.0        0.0  100.000000  177.000000     0.0           1.0      0.0   \n",
       "1     56.0        1.0   81.000000  172.000000     0.0           1.0      0.0   \n",
       "2     55.0        1.0   87.535524  172.093993     0.0           1.0      0.0   \n",
       "3     79.0        0.0   61.000000  160.000000     0.0           1.0      0.0   \n",
       "4     61.0        1.0   84.000000  179.000000     1.0           1.0      0.0   \n",
       "...    ...        ...         ...         ...     ...           ...      ...   \n",
       "1221  69.0        0.0  111.000000  159.000000     2.0           0.0      0.0   \n",
       "1222  57.0        0.0   96.000000  178.000000     1.0           1.0      0.0   \n",
       "1223  63.0        0.0   80.000000  162.000000     1.0           1.0      0.0   \n",
       "1224  75.0        0.0  165.000000   71.000000     0.0           1.0      1.0   \n",
       "1225  46.0        0.0  107.000000  179.000000     1.0           1.0      0.0   \n",
       "\n",
       "      dyslipidemia  anemia  atrial_fibrilation  ...  stent_number_bif_3.0  \\\n",
       "0              0.0     0.0                 0.0  ...                   0.0   \n",
       "1              0.0     0.0                 0.0  ...                   0.0   \n",
       "2              1.0     0.0                 0.0  ...                   0.0   \n",
       "3              0.0     0.0                 0.0  ...                   0.0   \n",
       "4              0.0     0.0                 0.0  ...                   0.0   \n",
       "...            ...     ...                 ...  ...                   ...   \n",
       "1221           0.0     0.0                 0.0  ...                   0.0   \n",
       "1222           0.0     0.0                 0.0  ...                   0.0   \n",
       "1223           0.0     1.0                 0.0  ...                   0.0   \n",
       "1224           1.0     0.0                 0.0  ...                   0.0   \n",
       "1225           0.0     0.0                 0.0  ...                   0.0   \n",
       "\n",
       "      stent_number_bif_4.0  stent_technique_0.0  stent_technique_1.0  \\\n",
       "0                      0.0                  1.0                  0.0   \n",
       "1                      0.0                  1.0                  0.0   \n",
       "2                      0.0                  1.0                  0.0   \n",
       "3                      0.0                  1.0                  0.0   \n",
       "4                      0.0                  1.0                  0.0   \n",
       "...                    ...                  ...                  ...   \n",
       "1221                   0.0                  0.0                  1.0   \n",
       "1222                   0.0                  1.0                  0.0   \n",
       "1223                   0.0                  1.0                  0.0   \n",
       "1224                   0.0                  1.0                  0.0   \n",
       "1225                   0.0                  1.0                  0.0   \n",
       "\n",
       "      stent_direction_1.0  stent_direction_2.0  stent_direction_3.0  \\\n",
       "0                     1.0                  0.0                  0.0   \n",
       "1                     0.0                  1.0                  0.0   \n",
       "2                     1.0                  0.0                  0.0   \n",
       "3                     1.0                  0.0                  0.0   \n",
       "4                     1.0                  0.0                  0.0   \n",
       "...                   ...                  ...                  ...   \n",
       "1221                  1.0                  0.0                  0.0   \n",
       "1222                  1.0                  0.0                  0.0   \n",
       "1223                  0.0                  0.0                  1.0   \n",
       "1224                  1.0                  0.0                  0.0   \n",
       "1225                  0.0                  1.0                  0.0   \n",
       "\n",
       "      stent_direction_4.0  stent_direction_5.0  stent_direction_6.0  \n",
       "0                     0.0                  0.0                  0.0  \n",
       "1                     0.0                  0.0                  0.0  \n",
       "2                     0.0                  0.0                  0.0  \n",
       "3                     0.0                  0.0                  0.0  \n",
       "4                     0.0                  0.0                  0.0  \n",
       "...                   ...                  ...                  ...  \n",
       "1221                  0.0                  0.0                  0.0  \n",
       "1222                  0.0                  0.0                  0.0  \n",
       "1223                  0.0                  0.0                  0.0  \n",
       "1224                  0.0                  0.0                  0.0  \n",
       "1225                  0.0                  0.0                  0.0  \n",
       "\n",
       "[1226 rows x 128 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = process_ohe(X_train, categorical, ohe)\n",
    "X_test = process_ohe(X_test, categorical, ohe)\n",
    "X_val = process_ohe(X_val, categorical, ohe)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3d657171-41bf-45cc-b1c5-8351f3ee4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_selector = SelectKBest(f_classif, k=40)\n",
    "X_feature_selection = feature_selector.fit_transform(X_train, y_train)\n",
    "X_feature_selection.shape\n",
    "\n",
    "strong_cols = []\n",
    "\n",
    "feature_scores = feature_selector.scores_\n",
    "features = X_train.columns\n",
    "features_scores_sorted = sorted(zip(features, feature_scores), key=lambda x: x[1], reverse=True)\n",
    "for col in features_scores_sorted[:30]:\n",
    "    strong_cols.append(col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "93d9967d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 18.832995073421934),\n",
       " ('anemia', 16.717205657071368),\n",
       " ('ef', 16.02779810067967),\n",
       " ('cerebrovascular_disease', 15.291246683140827),\n",
       " ('ckd', 13.059342742770825),\n",
       " ('peripheral_artery_disease', 12.348400892826742),\n",
       " ('if_yes_what_type___1', 11.245139080836568),\n",
       " ('creatinine', 9.982386784313583),\n",
       " ('single_vessel', 7.625440321013143),\n",
       " ('calcium', 6.779626836419195),\n",
       " ('stent_type___3', 5.486702160236439),\n",
       " ('medina_side', 5.379716758535172),\n",
       " ('atrial_fibrilation', 4.586821879027165),\n",
       " ('height', 4.555676636700379),\n",
       " ('def', 4.278168462441783),\n",
       " ('history_of_cancer', 3.9764387844061435),\n",
       " ('stent_type___5', 3.191634545843104),\n",
       " ('side_stenosis', 3.184180906947414),\n",
       " ('side_predilat', 3.157515104418525),\n",
       " ('previous_stroke_tia', 2.7509022678243142),\n",
       " ('stent_diameter', 2.6440946655521453),\n",
       " ('minor_criteria', 2.5877362829711097),\n",
       " ('stent_length', 2.4037530193895535),\n",
       " ('adhoc_pci', 2.295829874806831),\n",
       " ('previous_pci', 1.8951935400490738),\n",
       " ('stent_type___4', 1.7273906058695083),\n",
       " ('cto_bifurc', 1.6729448283870036),\n",
       " ('valvular_disease', 1.6645118067760527),\n",
       " ('side_diametr', 1.620089946343012),\n",
       " ('major_lm', 1.4948978147960446),\n",
       " ('main_predilatation', 1.3541159161717935),\n",
       " ('mi_history', 1.1842341670831964),\n",
       " ('trifurcation', 0.9879204948580149),\n",
       " ('dyslipidemia', 0.9626314138332309),\n",
       " ('stent_type___1', 0.8390096396308498),\n",
       " ('smoking', 0.6140116406055645),\n",
       " ('distal_diametr', 0.6066933851054224),\n",
       " ('restenosis_reocclusion', 0.5813524141328033),\n",
       " ('stent_type___6', 0.5635702987538821),\n",
       " ('angle', 0.5546742041606606),\n",
       " ('stent_type___2', 0.5330446313143103),\n",
       " ('if_yes_what_type___4', 0.48842617443434005),\n",
       " ('major_non_lm', 0.43650091802805185),\n",
       " ('copd', 0.3907363998062335),\n",
       " ('stent_type___7', 0.3787680435203915),\n",
       " ('hypertension', 0.36996136634099297),\n",
       " ('if_yes_what_type___3', 0.33662830335339994),\n",
       " ('medina_proximal', 0.3182282840501768),\n",
       " ('if_yes_what_type___6', 0.2885133648097206),\n",
       " ('stenosis_distal', 0.2868314066148627),\n",
       " ('main_branch_rvd', 0.25701494062102687),\n",
       " ('medina_distal', 0.23176545594057654),\n",
       " ('if_yes_what_type___2', 0.16655226966540476),\n",
       " ('def_2', 0.16655226966540476),\n",
       " ('defered_stenting', 0.16655226966540476),\n",
       " ('mb_length_proximal', 0.1408604851763905),\n",
       " ('oac_use', 0.10318927841768344),\n",
       " ('stenosis_proximal', 0.08706512361706256),\n",
       " ('trombosis', 0.06500632071463862),\n",
       " ('previous_cabg', 0.05984930583988759),\n",
       " ('proximal_diametr', 0.05285864278627651),\n",
       " ('weight', 0.00712282067462631),\n",
       " ('diabet', 0.0004743327100394048),\n",
       " ('side_protection', 0.0004114472884614206),\n",
       " ('ishemia_test___3', nan),\n",
       " ('clinical_presentation_4.0', 7.183488338031464),\n",
       " ('clinical_presentation_2.0', 4.87298957255603),\n",
       " ('uncross_strategy___3', 4.278168462441783),\n",
       " ('stent_number_4.0', 4.10291625482938),\n",
       " ('kissing_post_2stent___2', 4.0733227535460586),\n",
       " ('stent_direction_2.0', 3.480538780170513),\n",
       " ('sb_dilatation', 3.2681004332515533),\n",
       " ('stent_technique_0.0', 3.0966237753376555),\n",
       " ('stent_technique_1.0', 3.0966237753367545),\n",
       " ('reson_for_change_stopped___3', 3.028810087996091),\n",
       " ('stent_number_bif_3.0', 2.7250405691103188),\n",
       " ('ishemia_test___1', 2.4076706121078666),\n",
       " ('stent_type_2___1', 1.956040340067045),\n",
       " ('stent_direction_1.0', 1.5049348202917363),\n",
       " ('stent_type_2___3', 1.4427245867616993),\n",
       " ('stent_number_bif_2.0', 1.4038132899510174),\n",
       " ('currently_on_dialysis', 1.0533264489403216),\n",
       " ('reson_for_change_stopped___1', 1.0533264489403216),\n",
       " ('stent_number_bif_4.0', 1.0533264489403216),\n",
       " ('followup_1_year_do_not_complete_if_2nd_bifurcation_complete',\n",
       "  0.8765823361076774),\n",
       " ('stent_type_2___4', 0.8457660603704501),\n",
       " ('stent_postdilatation', 0.7112030284149334),\n",
       " ('stent_number_1.0', 0.6685182712541576),\n",
       " ('stent_number_3.0', 0.6430810715412731),\n",
       " ('clinical_presentation_5.0', 0.5850729353615345),\n",
       " ('patient_information_do_not_complete_if_2nd_bifurca_complete',\n",
       "  0.5397547186760887),\n",
       " ('reson_for_change_stopped___2', 0.5058401305057094),\n",
       " ('modified_kis', 0.47100936373368474),\n",
       " ('stent_type___8', 0.42115907846279127),\n",
       " ('stent_type_2___5', 0.42115907846279127),\n",
       " ('uncross_strategy___4', 0.42115907846279127),\n",
       " ('bifurcation_location_1.0', 0.41452897531481975),\n",
       " ('stent_type___9', 0.33662830335339994),\n",
       " ('bifurcation_location_2.0', 0.3163205876131944),\n",
       " ('uncross_strategy___9', 0.2522474055048418),\n",
       " ('stent_number_5.0', 0.2522474055048418),\n",
       " ('bifurcation_location_5.0', 0.2145921501060238),\n",
       " ('sb_stent_sb_diametr', 0.18835630162390946),\n",
       " ('stent_type_2___7', 0.16801598666044365),\n",
       " ('uncross_strategy___1', 0.16801598666044365),\n",
       " ('uncross_strategy___8', 0.16801598666044365),\n",
       " ('stent_direction_6.0', 0.16801598666044365),\n",
       " ('stent_number_bif_1.0', 0.16266911821030622),\n",
       " ('twostent_technique', 0.15269380532410445),\n",
       " ('kissing_post_2stent___1', 0.15023222950717846),\n",
       " ('stent_direction_5.0', 0.15023222950717846),\n",
       " ('ishemia_test___2', 0.1431728717779743),\n",
       " ('uncross_strategy___2', 0.1431728717779743),\n",
       " ('stent_direction_4.0', 0.13066255334854526),\n",
       " ('stent_type_2___8', 0.08393364997329242),\n",
       " ('stent_number_6.0', 0.08393364997329242),\n",
       " ('stent_number_2.0', 0.06837611610049368),\n",
       " ('clinical_presentation_3.0', 0.058141127463301606),\n",
       " ('kissing_post', 0.03734300435551427),\n",
       " ('stent_type_2___6', 0.027925007752811027),\n",
       " ('stent_distal_vessel_size', 0.027313117506689667),\n",
       " ('stent_direction_3.0', 0.02483560650032032),\n",
       " ('clinical_presentation_1.0', 0.021507459737668492),\n",
       " ('bifurcation_location_3.0', 0.0137894116420676),\n",
       " ('bifurcation_location_6.0', 0.005783546469408543),\n",
       " ('bifurcation_location_4.0', 0.0010593431924172073),\n",
       " ('sex_1.0', 7.375157573616262e-05),\n",
       " ('sex_2.0', 7.375157559353854e-05)]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_scores_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "da096ae3-3e61-4712-b392-b4bd6c2c3739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>ckd</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>...</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>minor_criteria</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>valvular_disease</th>\n",
       "      <th>side_diametr</th>\n",
       "      <th>major_lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.130343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.132035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.364633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.542788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.329657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.608441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048430</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.707072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.111321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.979615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>103.632809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  anemia    ef  cerebrovascular_disease         ckd  \\\n",
       "0     41.0     0.0  49.0                      0.0   91.130343   \n",
       "1     56.0     0.0  68.0                      0.0   83.132035   \n",
       "2     55.0     0.0  70.0                      0.0   78.364633   \n",
       "3     79.0     0.0  73.0                      1.0   64.542788   \n",
       "4     61.0     0.0  62.0                      0.0   87.329657   \n",
       "...    ...     ...   ...                      ...         ...   \n",
       "1221  69.0     0.0  60.0                      0.0   69.608441   \n",
       "1222  57.0     0.0  39.0                      0.0   53.707072   \n",
       "1223  63.0     1.0  71.0                      0.0   86.111321   \n",
       "1224  75.0     0.0  69.0                      1.0   68.979615   \n",
       "1225  46.0     0.0  64.0                      0.0  103.632809   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  creatinine  \\\n",
       "0                           0.0                   0.0        90.0   \n",
       "1                           0.0                   0.0        89.0   \n",
       "2                           0.0                   0.0        94.0   \n",
       "3                           0.0                   0.0        96.0   \n",
       "4                           0.0                   0.0        83.0   \n",
       "...                         ...                   ...         ...   \n",
       "1221                        0.0                   0.0        97.0   \n",
       "1222                        0.0                   0.0       127.0   \n",
       "1223                        0.0                   0.0        83.0   \n",
       "1224                        1.0                   0.0        93.0   \n",
       "1225                        0.0                   0.0        76.0   \n",
       "\n",
       "      single_vessel  calcium  ...  stent_diameter  minor_criteria  \\\n",
       "0               0.0      0.0  ...            4.00             1.0   \n",
       "1               1.0      0.0  ...            2.75             0.0   \n",
       "2               1.0      0.0  ...            2.75             2.0   \n",
       "3               0.0      1.0  ...            3.50             3.0   \n",
       "4               0.0      0.0  ...            4.00             2.0   \n",
       "...             ...      ...  ...             ...             ...   \n",
       "1221            1.0      0.0  ...            3.50             0.0   \n",
       "1222            0.0      0.0  ...            3.50             2.0   \n",
       "1223            1.0      0.0  ...            2.75             2.0   \n",
       "1224            1.0      0.0  ...            3.00             0.0   \n",
       "1225            1.0      0.0  ...            2.75             0.0   \n",
       "\n",
       "      stent_length  adhoc_pci  previous_pci  stent_type___4  cto_bifurc  \\\n",
       "0             11.0        0.0           1.0             0.0         0.0   \n",
       "1             18.0        1.0           1.0             1.0         0.0   \n",
       "2             33.0        1.0           0.0             1.0         0.0   \n",
       "3             38.0        0.0           0.0             0.0         0.0   \n",
       "4             28.0        1.0           0.0             0.0         0.0   \n",
       "...            ...        ...           ...             ...         ...   \n",
       "1221          32.0        0.0           1.0             0.0         0.0   \n",
       "1222          23.0        0.0           0.0             0.0         0.0   \n",
       "1223          18.0        0.0           1.0             0.0         0.0   \n",
       "1224          18.0        0.0           1.0             0.0         0.0   \n",
       "1225          16.0        0.0           1.0             0.0         0.0   \n",
       "\n",
       "      valvular_disease  side_diametr  major_lm  \n",
       "0             0.000000           2.4       0.0  \n",
       "1             0.000000           3.0       0.0  \n",
       "2             0.000000           2.4       0.0  \n",
       "3             0.000000           3.1       0.0  \n",
       "4             0.000000           2.5       0.0  \n",
       "...                ...           ...       ...  \n",
       "1221         -0.048430           2.7       0.0  \n",
       "1222          0.005881           2.4       0.0  \n",
       "1223          0.000000           2.2       0.0  \n",
       "1224          0.000000           2.4       0.0  \n",
       "1225          0.000000           2.6       0.0  \n",
       "\n",
       "[1226 rows x 30 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[strong_cols]\n",
    "X_test = X_test[strong_cols]\n",
    "X_val = X_val[strong_cols]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b3f06859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'anemia', 'ef', 'cerebrovascular_disease', 'ckd',\n",
       "       'peripheral_artery_disease', 'if_yes_what_type___1', 'creatinine',\n",
       "       'single_vessel', 'calcium', 'stent_type___3', 'medina_side',\n",
       "       'atrial_fibrilation', 'height', 'def', 'history_of_cancer',\n",
       "       'stent_type___5', 'side_stenosis', 'side_predilat',\n",
       "       'previous_stroke_tia', 'stent_diameter', 'minor_criteria',\n",
       "       'stent_length', 'adhoc_pci', 'previous_pci', 'stent_type___4',\n",
       "       'cto_bifurc', 'valvular_disease', 'side_diametr', 'major_lm'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8b6d3a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['valvular_disease', 'previous_stroke_tia', 'twostent_technique']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_preserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "62d3e931-a486-4727-bb1b-b0d6d637b31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ckd',\n",
       " 'creatinine',\n",
       " 'side_stenosis',\n",
       " 'side_predilat',\n",
       " 'minor_criteria',\n",
       " 'valvular_disease',\n",
       " 'side_diametr',\n",
       " 'major_lm']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "threshold = 0.4\n",
    "\n",
    "to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "079afc5b-4582-4b78-95b6-db4228fe6771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>stent_type___5</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>cto_bifurc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>4.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>2.75</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>4.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>3.50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>3.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429977</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>2.75</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  anemia    ef  cerebrovascular_disease  peripheral_artery_disease  \\\n",
       "0     41.0     0.0  49.0                      0.0                        0.0   \n",
       "1     56.0     0.0  68.0                      0.0                        0.0   \n",
       "2     55.0     0.0  70.0                      0.0                        0.0   \n",
       "3     79.0     0.0  73.0                      1.0                        0.0   \n",
       "4     61.0     0.0  62.0                      0.0                        0.0   \n",
       "...    ...     ...   ...                      ...                        ...   \n",
       "1221  69.0     0.0  60.0                      0.0                        0.0   \n",
       "1222  57.0     0.0  39.0                      0.0                        0.0   \n",
       "1223  63.0     1.0  71.0                      0.0                        0.0   \n",
       "1224  75.0     0.0  69.0                      1.0                        1.0   \n",
       "1225  46.0     0.0  64.0                      0.0                        0.0   \n",
       "\n",
       "      if_yes_what_type___1  single_vessel  calcium  stent_type___3  \\\n",
       "0                      0.0            0.0      0.0             1.0   \n",
       "1                      0.0            1.0      0.0             0.0   \n",
       "2                      0.0            1.0      0.0             0.0   \n",
       "3                      0.0            0.0      1.0             0.0   \n",
       "4                      0.0            0.0      0.0             0.0   \n",
       "...                    ...            ...      ...             ...   \n",
       "1221                   0.0            1.0      0.0             0.0   \n",
       "1222                   0.0            0.0      0.0             1.0   \n",
       "1223                   0.0            1.0      0.0             1.0   \n",
       "1224                   0.0            1.0      0.0             1.0   \n",
       "1225                   0.0            1.0      0.0             0.0   \n",
       "\n",
       "      medina_side  ...  def  history_of_cancer  stent_type___5  \\\n",
       "0             0.0  ...  0.0                0.0             0.0   \n",
       "1             1.0  ...  0.0                1.0             0.0   \n",
       "2             0.0  ...  0.0                0.0             0.0   \n",
       "3             0.0  ...  0.0                0.0             0.0   \n",
       "4             0.0  ...  0.0                1.0             0.0   \n",
       "...           ...  ...  ...                ...             ...   \n",
       "1221          0.0  ...  0.0                0.0             0.0   \n",
       "1222          0.0  ...  0.0                0.0             0.0   \n",
       "1223          0.0  ...  0.0                0.0             0.0   \n",
       "1224          0.0  ...  0.0                0.0             0.0   \n",
       "1225          1.0  ...  0.0                1.0             0.0   \n",
       "\n",
       "      previous_stroke_tia  stent_diameter  stent_length  adhoc_pci  \\\n",
       "0                0.477395            4.00          11.0        0.0   \n",
       "1                0.313995            2.75          18.0        1.0   \n",
       "2                0.478905            2.75          33.0        1.0   \n",
       "3                0.000000            3.50          38.0        0.0   \n",
       "4                0.448962            4.00          28.0        1.0   \n",
       "...                   ...             ...           ...        ...   \n",
       "1221             0.525775            3.50          32.0        0.0   \n",
       "1222             0.616766            3.50          23.0        0.0   \n",
       "1223             0.429977            2.75          18.0        0.0   \n",
       "1224             1.000000            3.00          18.0        0.0   \n",
       "1225             0.317877            2.75          16.0        0.0   \n",
       "\n",
       "      previous_pci  stent_type___4  cto_bifurc  \n",
       "0              1.0             0.0         0.0  \n",
       "1              1.0             1.0         0.0  \n",
       "2              0.0             1.0         0.0  \n",
       "3              0.0             0.0         0.0  \n",
       "4              0.0             0.0         0.0  \n",
       "...            ...             ...         ...  \n",
       "1221           1.0             0.0         0.0  \n",
       "1222           0.0             0.0         0.0  \n",
       "1223           1.0             0.0         0.0  \n",
       "1224           1.0             0.0         0.0  \n",
       "1225           1.0             0.0         0.0  \n",
       "\n",
       "[1226 rows x 22 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop(columns=to_drop)\n",
    "X_test = X_test.drop(columns=to_drop)\n",
    "X_val = X_val.drop(columns=to_drop)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ef04e2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'anemia', 'ef', 'cerebrovascular_disease',\n",
       "       'peripheral_artery_disease', 'if_yes_what_type___1', 'single_vessel',\n",
       "       'calcium', 'stent_type___3', 'medina_side', 'atrial_fibrilation',\n",
       "       'height', 'def', 'history_of_cancer', 'stent_type___5',\n",
       "       'previous_stroke_tia', 'stent_diameter', 'stent_length', 'adhoc_pci',\n",
       "       'previous_pci', 'stent_type___4', 'cto_bifurc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "91cd1931-9181-4f79-a8c1-6c41c5987479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1226, 22)\n",
      "(409, 22)\n",
      "(409, 22)\n",
      "(1226,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d644311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'anemia', 'ef', 'cerebrovascular_disease',\n",
      "       'peripheral_artery_disease', 'if_yes_what_type___1', 'single_vessel',\n",
      "       'calcium', 'stent_type___3', 'medina_side', 'atrial_fibrilation',\n",
      "       'height', 'def', 'history_of_cancer', 'stent_type___5',\n",
      "       'previous_stroke_tia', 'stent_diameter', 'stent_length', 'adhoc_pci',\n",
      "       'previous_pci', 'stent_type___4', 'cto_bifurc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fbf54316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      150.0\n",
       "1      164.0\n",
       "2      176.0\n",
       "3      174.0\n",
       "4      164.0\n",
       "       ...  \n",
       "404    172.0\n",
       "405    160.0\n",
       "406    177.0\n",
       "407    153.0\n",
       "408    168.0\n",
       "Name: height, Length: 409, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['height']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068922f9",
   "metadata": {},
   "source": [
    "# edge case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "736a1a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>clinical_presentation</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>restenosis_reocclusion</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>main_predilatation</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>mortality</th>\n",
       "      <th>smoking</th>\n",
       "      <th>dyslipidemia</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.915675</td>\n",
       "      <td>158.932853</td>\n",
       "      <td>5</td>\n",
       "      <td>22.532092</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.203800</td>\n",
       "      <td>28.790400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.254652</td>\n",
       "      <td>152.770464</td>\n",
       "      <td>5</td>\n",
       "      <td>27.473483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.631838</td>\n",
       "      <td>32.941136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.873062</td>\n",
       "      <td>149.671377</td>\n",
       "      <td>5</td>\n",
       "      <td>22.203660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.587937</td>\n",
       "      <td>36.907801</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.667463</td>\n",
       "      <td>143.408284</td>\n",
       "      <td>5</td>\n",
       "      <td>26.260913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.148615</td>\n",
       "      <td>33.811517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.948758</td>\n",
       "      <td>166.190727</td>\n",
       "      <td>4</td>\n",
       "      <td>27.239543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.549106</td>\n",
       "      <td>35.001648</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>87.795446</td>\n",
       "      <td>159.420133</td>\n",
       "      <td>4</td>\n",
       "      <td>26.406490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.736894</td>\n",
       "      <td>36.332443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>89.379282</td>\n",
       "      <td>144.584974</td>\n",
       "      <td>5</td>\n",
       "      <td>15.941906</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.394632</td>\n",
       "      <td>37.417018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>88.728409</td>\n",
       "      <td>145.131891</td>\n",
       "      <td>5</td>\n",
       "      <td>15.130884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.639743</td>\n",
       "      <td>36.390807</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>89.067582</td>\n",
       "      <td>146.095263</td>\n",
       "      <td>5</td>\n",
       "      <td>24.266571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.607628</td>\n",
       "      <td>30.475761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>97.276788</td>\n",
       "      <td>153.779512</td>\n",
       "      <td>5</td>\n",
       "      <td>17.488966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.322552</td>\n",
       "      <td>32.086462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      height  clinical_presentation         ef  \\\n",
       "0    96.915675  158.932853                      5  22.532092   \n",
       "1    99.254652  152.770464                      5  27.473483   \n",
       "2    91.873062  149.671377                      5  22.203660   \n",
       "3    98.667463  143.408284                      5  26.260913   \n",
       "4    94.948758  166.190727                      4  27.239543   \n",
       "..         ...         ...                    ...        ...   \n",
       "145  87.795446  159.420133                      4  26.406490   \n",
       "146  89.379282  144.584974                      5  15.941906   \n",
       "147  88.728409  145.131891                      5  15.130884   \n",
       "148  89.067582  146.095263                      5  24.266571   \n",
       "149  97.276788  153.779512                      5  17.488966   \n",
       "\n",
       "     cerebrovascular_disease  peripheral_artery_disease  if_yes_what_type___1  \\\n",
       "0                          1                          1                     1   \n",
       "1                          1                          1                     1   \n",
       "2                          1                          0                     0   \n",
       "3                          1                          1                     1   \n",
       "4                          1                          1                     1   \n",
       "..                       ...                        ...                   ...   \n",
       "145                        1                          1                     1   \n",
       "146                        1                          1                     1   \n",
       "147                        1                          1                     0   \n",
       "148                        1                          1                     1   \n",
       "149                        1                          1                     1   \n",
       "\n",
       "     single_vessel  calcium  medina_side  ...  restenosis_reocclusion  \\\n",
       "0                1        1            1  ...                       1   \n",
       "1                1        1            1  ...                       1   \n",
       "2                1        1            1  ...                       1   \n",
       "3                1        1            1  ...                       1   \n",
       "4                1        1            0  ...                       1   \n",
       "..             ...      ...          ...  ...                     ...   \n",
       "145              1        1            0  ...                       0   \n",
       "146              1        1            1  ...                       1   \n",
       "147              1        1            1  ...                       1   \n",
       "148              1        0            1  ...                       1   \n",
       "149              1        1            1  ...                       1   \n",
       "\n",
       "     adhoc_pci  main_predilatation  stent_diameter  stent_length  mortality  \\\n",
       "0            1                   1        2.203800     28.790400          1   \n",
       "1            1                   1        2.631838     32.941136          1   \n",
       "2            1                   1        2.587937     36.907801          1   \n",
       "3            0                   1        2.148615     33.811517          1   \n",
       "4            1                   1        2.549106     35.001648          1   \n",
       "..         ...                 ...             ...           ...        ...   \n",
       "145          1                   1        2.736894     36.332443          1   \n",
       "146          1                   0        2.394632     37.417018          1   \n",
       "147          1                   1        2.639743     36.390807          1   \n",
       "148          0                   1        2.607628     30.475761          1   \n",
       "149          1                   1        2.322552     32.086462          1   \n",
       "\n",
       "     smoking  dyslipidemia  anemia  atrial_fibrilation  \n",
       "0          1             1       1                   1  \n",
       "1          1             1       1                   1  \n",
       "2          1             1       1                   1  \n",
       "3          1             0       1                   1  \n",
       "4          1             1       1                   0  \n",
       "..       ...           ...     ...                 ...  \n",
       "145        1             1       1                   1  \n",
       "146        1             1       1                   1  \n",
       "147        1             1       1                   1  \n",
       "148        1             1       1                   1  \n",
       "149        1             1       1                   1  \n",
       "\n",
       "[150 rows x 30 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import edge_case\n",
    "importlib.reload(edge_case)\n",
    "from edge_case import generate_edge_cases\n",
    "\n",
    "edge_cases = generate_edge_cases(num_samples=150)\n",
    "edge_cases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "997d63e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'height', 'clinical_presentation', 'ef',\n",
       "       'cerebrovascular_disease', 'peripheral_artery_disease',\n",
       "       'if_yes_what_type___1', 'single_vessel', 'calcium', 'medina_side',\n",
       "       'trifurcation', 'cto_bifurc', 'def', 'history_of_cancer',\n",
       "       'previous_pci', 'previous_stroke_tia', 'side_diametr', 'stent_type___3',\n",
       "       'stent_type___4', 'stent_type___5', 'restenosis_reocclusion',\n",
       "       'adhoc_pci', 'main_predilatation', 'stent_diameter', 'stent_length',\n",
       "       'mortality', 'smoking', 'dyslipidemia', 'anemia', 'atrial_fibrilation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_cases.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4d22786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON OF COLUMNS:\n",
      "\n",
      "Total columns in edge_cases: 30\n",
      "Total columns in X_train: 22\n",
      "Number of common columns: 22\n",
      "\n",
      "--- COMMON COLUMNS ---\n",
      "- adhoc_pci\n",
      "- age\n",
      "- anemia\n",
      "- atrial_fibrilation\n",
      "- calcium\n",
      "- cerebrovascular_disease\n",
      "- cto_bifurc\n",
      "- def\n",
      "- ef\n",
      "- height\n",
      "- history_of_cancer\n",
      "- if_yes_what_type___1\n",
      "- medina_side\n",
      "- peripheral_artery_disease\n",
      "- previous_pci\n",
      "- previous_stroke_tia\n",
      "- single_vessel\n",
      "- stent_diameter\n",
      "- stent_length\n",
      "- stent_type___3\n",
      "- stent_type___4\n",
      "- stent_type___5\n",
      "\n",
      "--- COLUMNS ONLY IN EDGE CASES ---\n",
      "- clinical_presentation\n",
      "- dyslipidemia\n",
      "- main_predilatation\n",
      "- mortality\n",
      "- restenosis_reocclusion\n",
      "- side_diametr\n",
      "- smoking\n",
      "- trifurcation\n",
      "\n",
      "--- COLUMNS ONLY IN X_TRAIN ---\n"
     ]
    }
   ],
   "source": [
    "edge_case_cols = set(edge_cases.columns)\n",
    "x_train_cols = set(X_train.columns)\n",
    "\n",
    "common_cols = edge_case_cols.intersection(x_train_cols)\n",
    "only_in_edge_cases = edge_case_cols - x_train_cols\n",
    "only_in_x_train = x_train_cols - edge_case_cols\n",
    "\n",
    "print(f\"COMPARISON OF COLUMNS:\")\n",
    "print(f\"\\nTotal columns in edge_cases: {len(edge_case_cols)}\")\n",
    "print(f\"Total columns in X_train: {len(x_train_cols)}\")\n",
    "print(f\"Number of common columns: {len(common_cols)}\")\n",
    "\n",
    "print(\"\\n--- COMMON COLUMNS ---\")\n",
    "for col in sorted(common_cols):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\n--- COLUMNS ONLY IN EDGE CASES ---\")\n",
    "for col in sorted(only_in_edge_cases):\n",
    "    print(f\"- {col}\")\n",
    "\n",
    "print(\"\\n--- COLUMNS ONLY IN X_TRAIN ---\")\n",
    "for col in sorted(only_in_x_train):\n",
    "    print(f\"- {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9d8653cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_cases_target = edge_cases['mortality']\n",
    "edge_cases_features = edge_cases.copy().drop('mortality', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65561832",
   "metadata": {},
   "source": [
    "# Syntetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "334ebc57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>stent_type___5</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>cto_bifurc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>4.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>2.75</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>4.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1221</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>3.50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>3.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429977</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>2.75</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   age  anemia    ef  cerebrovascular_disease  \\\n",
       "0         0  41.0     0.0  49.0                      0.0   \n",
       "1         1  56.0     0.0  68.0                      0.0   \n",
       "2         2  55.0     0.0  70.0                      0.0   \n",
       "3         3  79.0     0.0  73.0                      1.0   \n",
       "4         4  61.0     0.0  62.0                      0.0   \n",
       "...     ...   ...     ...   ...                      ...   \n",
       "1221   1221  69.0     0.0  60.0                      0.0   \n",
       "1222   1222  57.0     0.0  39.0                      0.0   \n",
       "1223   1223  63.0     1.0  71.0                      0.0   \n",
       "1224   1224  75.0     0.0  69.0                      1.0   \n",
       "1225   1225  46.0     0.0  64.0                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      0.0   \n",
       "1                           0.0                   0.0            1.0      0.0   \n",
       "2                           0.0                   0.0            1.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      0.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "1221                        0.0                   0.0            1.0      0.0   \n",
       "1222                        0.0                   0.0            0.0      0.0   \n",
       "1223                        0.0                   0.0            1.0      0.0   \n",
       "1224                        1.0                   0.0            1.0      0.0   \n",
       "1225                        0.0                   0.0            1.0      0.0   \n",
       "\n",
       "      stent_type___3  ...  def  history_of_cancer  stent_type___5  \\\n",
       "0                1.0  ...  0.0                0.0             0.0   \n",
       "1                0.0  ...  0.0                1.0             0.0   \n",
       "2                0.0  ...  0.0                0.0             0.0   \n",
       "3                0.0  ...  0.0                0.0             0.0   \n",
       "4                0.0  ...  0.0                1.0             0.0   \n",
       "...              ...  ...  ...                ...             ...   \n",
       "1221             0.0  ...  0.0                0.0             0.0   \n",
       "1222             1.0  ...  0.0                0.0             0.0   \n",
       "1223             1.0  ...  0.0                0.0             0.0   \n",
       "1224             1.0  ...  0.0                0.0             0.0   \n",
       "1225             0.0  ...  0.0                1.0             0.0   \n",
       "\n",
       "      previous_stroke_tia  stent_diameter  stent_length  adhoc_pci  \\\n",
       "0                0.477395            4.00          11.0        0.0   \n",
       "1                0.313995            2.75          18.0        1.0   \n",
       "2                0.478905            2.75          33.0        1.0   \n",
       "3                0.000000            3.50          38.0        0.0   \n",
       "4                0.448962            4.00          28.0        1.0   \n",
       "...                   ...             ...           ...        ...   \n",
       "1221             0.525775            3.50          32.0        0.0   \n",
       "1222             0.616766            3.50          23.0        0.0   \n",
       "1223             0.429977            2.75          18.0        0.0   \n",
       "1224             1.000000            3.00          18.0        0.0   \n",
       "1225             0.317877            2.75          16.0        0.0   \n",
       "\n",
       "      previous_pci  stent_type___4  cto_bifurc  \n",
       "0              1.0             0.0         0.0  \n",
       "1              1.0             1.0         0.0  \n",
       "2              0.0             1.0         0.0  \n",
       "3              0.0             0.0         0.0  \n",
       "4              0.0             0.0         0.0  \n",
       "...            ...             ...         ...  \n",
       "1221           1.0             0.0         0.0  \n",
       "1222           0.0             0.0         0.0  \n",
       "1223           1.0             0.0         0.0  \n",
       "1224           1.0             0.0         0.0  \n",
       "1225           1.0             0.0         0.0  \n",
       "\n",
       "[1226 rows x 23 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_with_ID = X_train.copy().reset_index(drop=False)\n",
    "X_train_with_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5e4544f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>...</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>stent_type___5</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>4.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>2.75</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>4.00</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1221</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.525775</td>\n",
       "      <td>3.50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>1222</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>3.50</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1223</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429977</td>\n",
       "      <td>2.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1224</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>1225</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.317877</td>\n",
       "      <td>2.75</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   age  anemia    ef  cerebrovascular_disease  \\\n",
       "0         0  41.0     0.0  49.0                      0.0   \n",
       "1         1  56.0     0.0  68.0                      0.0   \n",
       "2         2  55.0     0.0  70.0                      0.0   \n",
       "3         3  79.0     0.0  73.0                      1.0   \n",
       "4         4  61.0     0.0  62.0                      0.0   \n",
       "...     ...   ...     ...   ...                      ...   \n",
       "1221   1221  69.0     0.0  60.0                      0.0   \n",
       "1222   1222  57.0     0.0  39.0                      0.0   \n",
       "1223   1223  63.0     1.0  71.0                      0.0   \n",
       "1224   1224  75.0     0.0  69.0                      1.0   \n",
       "1225   1225  46.0     0.0  64.0                      0.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      0.0   \n",
       "1                           0.0                   0.0            1.0      0.0   \n",
       "2                           0.0                   0.0            1.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      0.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "1221                        0.0                   0.0            1.0      0.0   \n",
       "1222                        0.0                   0.0            0.0      0.0   \n",
       "1223                        0.0                   0.0            1.0      0.0   \n",
       "1224                        1.0                   0.0            1.0      0.0   \n",
       "1225                        0.0                   0.0            1.0      0.0   \n",
       "\n",
       "      stent_type___3  ...  history_of_cancer  stent_type___5  \\\n",
       "0                1.0  ...                0.0             0.0   \n",
       "1                0.0  ...                1.0             0.0   \n",
       "2                0.0  ...                0.0             0.0   \n",
       "3                0.0  ...                0.0             0.0   \n",
       "4                0.0  ...                1.0             0.0   \n",
       "...              ...  ...                ...             ...   \n",
       "1221             0.0  ...                0.0             0.0   \n",
       "1222             1.0  ...                0.0             0.0   \n",
       "1223             1.0  ...                0.0             0.0   \n",
       "1224             1.0  ...                0.0             0.0   \n",
       "1225             0.0  ...                1.0             0.0   \n",
       "\n",
       "      previous_stroke_tia  stent_diameter  stent_length  adhoc_pci  \\\n",
       "0                0.477395            4.00          11.0        0.0   \n",
       "1                0.313995            2.75          18.0        1.0   \n",
       "2                0.478905            2.75          33.0        1.0   \n",
       "3                0.000000            3.50          38.0        0.0   \n",
       "4                0.448962            4.00          28.0        1.0   \n",
       "...                   ...             ...           ...        ...   \n",
       "1221             0.525775            3.50          32.0        0.0   \n",
       "1222             0.616766            3.50          23.0        0.0   \n",
       "1223             0.429977            2.75          18.0        0.0   \n",
       "1224             1.000000            3.00          18.0        0.0   \n",
       "1225             0.317877            2.75          16.0        0.0   \n",
       "\n",
       "      previous_pci  stent_type___4  cto_bifurc  target  \n",
       "0              1.0             0.0         0.0       0  \n",
       "1              1.0             1.0         0.0       0  \n",
       "2              0.0             1.0         0.0       0  \n",
       "3              0.0             0.0         0.0       0  \n",
       "4              0.0             0.0         0.0       0  \n",
       "...            ...             ...         ...     ...  \n",
       "1221           1.0             0.0         0.0       1  \n",
       "1222           0.0             0.0         0.0       0  \n",
       "1223           1.0             0.0         0.0       0  \n",
       "1224           1.0             0.0         0.0       0  \n",
       "1225           1.0             0.0         0.0       0  \n",
       "\n",
       "[1226 rows x 24 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_with_ID_and_target = X_train_with_ID.copy()\n",
    "X_train_with_ID_and_target['target'] = y_train\n",
    "X_train_with_ID_and_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "31d1464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31T20:45:12.405501+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T20:45:12.406321+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T20:45:12.406697+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-31T20:45:12.407143+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctgan', 'fflows', 'dummy_sampler', 'pategan', 'uniform_sampler', 'rtvae', 'image_cgan', 'decaf', 'privbayes', 'arf', 'nflow', 'radialgan', 'dpgan', 'image_adsgan', 'tvae', 'marginal_distributions', 'timegan', 'survival_gan', 'survae', 'survival_nflow', 'aim', 'adsgan', 'timevae', 'bayesian_network', 'survival_ctgan', 'ddpm']\n"
     ]
    }
   ],
   "source": [
    "from synthcity.plugins import Plugins\n",
    "\n",
    "# Print the list of available plugins\n",
    "print(Plugins().list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bff2db7-0de1-4985-a9e0-41a99a84242d",
   "metadata": {},
   "source": [
    "# Оптимизация MLP на auc-roc для 10 фолдов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new = pd.concat([X_train, syntetic_minority_dropped])\n",
    "# X_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98f46305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_new = np.concatenate((y_train, syntetic_target))\n",
    "# y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "264524cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>StandardScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaller = StandardScaler()\n",
    "scaller.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ee37c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./scaler.save']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(scaller, \"./scaler.save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4a7a47db-2788-4f5d-a04e-396cf6a4988b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds = pd.concat([X_train, X_val])\n",
    "y_train_k_fold = np.concatenate((y_train, y_val), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fc6e505-490e-4609-81eb-6b09c0c1fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaller.transform(X_train_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "142eabaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "31\n",
      "1635\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "print(y_train_k_fold.sum())\n",
    "print(y_test.sum())\n",
    "print(len(y_train_k_fold))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7b997",
   "metadata": {},
   "source": [
    "# Pure MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dee5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2744a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_rate):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        self.layers.append(nn.ReLU())\n",
    "        self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout_rate))\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(hidden_size, 1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.sigmoid(x).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32a66f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), targets.float())\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = outputs.squeeze().cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    return all_probs, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88bdfc5f-9d72-457d-b40b-a1e98103ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5831, Params: {'batch_size': 128, 'dropout_rate': 0.41002235289409283, 'epochs': 30.0, 'hidden_size': 128.0, 'learning_rate': 0.0024427704706541657, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5871, Params: {'batch_size': 16, 'dropout_rate': 0.4056241249305793, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.009544721449724257, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5229, Params: {'batch_size': 128, 'dropout_rate': 0.2697835305005324, 'epochs': 50.0, 'hidden_size': 128.0, 'learning_rate': 0.00710002713644391, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.5631, Params: {'batch_size': 64, 'dropout_rate': 0.35563814017622764, 'epochs': 40.0, 'hidden_size': 192.0, 'learning_rate': 0.002715927099690271, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.5924, Params: {'batch_size': 32, 'dropout_rate': 0.2150090501625242, 'epochs': 10.0, 'hidden_size': 224.0, 'learning_rate': 0.004778876638769452, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.6648, Params: {'batch_size': 64, 'dropout_rate': 0.4885358704436813, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.000700548840047934, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.6020, Params: {'batch_size': 128, 'dropout_rate': 0.32679614968716664, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.004240822784081465, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.6155, Params: {'batch_size': 32, 'dropout_rate': 0.3196433307690336, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.006187090129494996, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.6353, Params: {'batch_size': 32, 'dropout_rate': 0.38779074747316455, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.0030993830702427346, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.5641, Params: {'batch_size': 16, 'dropout_rate': 0.3369863383437883, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.0035121836138048983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.6256, Params: {'batch_size': 16, 'dropout_rate': 0.2405706962687839, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0002074947804580159, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.6194, Params: {'batch_size': 128, 'dropout_rate': 0.11881591776819325, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.001064696631364036, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.6608, Params: {'batch_size': 16, 'dropout_rate': 0.4803623070788168, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.00021204966155286792, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.6723, Params: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.6695, Params: {'batch_size': 128, 'dropout_rate': 0.19090523160868403, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.0003819396553975747, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5867, Params: {'batch_size': 16, 'dropout_rate': 0.40269233643539615, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.001632536491603748, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.6374, Params: {'batch_size': 32, 'dropout_rate': 0.17500042428012758, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.0001250641119149986, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.5866, Params: {'batch_size': 128, 'dropout_rate': 0.23708094921295766, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.0011923090806849653, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.4837, Params: {'batch_size': 128, 'dropout_rate': 0.27786985886740423, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.00019729978031082508, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.6020, Params: {'batch_size': 128, 'dropout_rate': 0.21585090981280444, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00032595628315637565, 'num_layers': 3.0}\n",
      "100%|██████████| 20/20 [02:26<00:00,  7.30s/trial, best loss: -0.6723430123959925]\n",
      "Hyperparameter optimization completed.\n",
      "Best parameters: {'batch_size': 128, 'dropout_rate': 0.46182894034031563, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.0013097735641825455, 'num_layers': 3.0}\n",
      "Best mean AUC: 0.6723\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_folds.iloc[train_index])\n",
    "        X_test = scaler.transform(X_train_folds.iloc[test_index])\n",
    "        y_train = y_train_k_fold[train_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.zeros(X_test_tensor.shape[0]))  # Dummy labels for test set\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        test_loader = DataLoader(TensorDataset(X_test_tensor, torch.zeros(X_test_tensor.shape[0])), batch_size=batch_size)\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_folds)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_k_fold)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'best_MLP_model.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_metrics_and_params.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99181bc2-c28f-4f29-9305-d52c46b19593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.7601\n",
      "F1 Score: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "Accuracy: 0.9242\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_folds)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_k_fold)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'pure_MLP.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Make predictions\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = best_model(X_test_tensor).squeeze().cpu().numpy()\n",
    "    test_pred_class = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('test_scores_MLP.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12afa00e",
   "metadata": {},
   "source": [
    "# MLP + ctgan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dedb10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import synthcity components\n",
    "import synthcity.logger as log\n",
    "from synthcity.plugins import Plugins\n",
    "from synthcity.plugins.core.dataloader import GenericDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0162fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get the original training data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index].copy().reset_index(drop=True)\n",
    "        y_train_fold = y_train_k_fold[train_index]\n",
    "        X_test = X_train_folds.iloc[test_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Generate synthetic data for this fold\n",
    "        train_fold_data = X_train_fold.copy()\n",
    "        train_fold_data['target'] = y_train_fold\n",
    "        \n",
    "        # Create loader for this fold's dataset\n",
    "        fold_loader = GenericDataLoader(\n",
    "            train_fold_data,\n",
    "            target_column=\"target\"\n",
    "        )\n",
    "        \n",
    "        # Generate synthetic data for this fold\n",
    "        syn_model = Plugins().get(\"ctgan\", n_iter=100, random_state=42)  # Reduced iterations for speed during hyperopt\n",
    "        syn_model.fit(fold_loader)\n",
    "        synthetic_data = syn_model.generate(count=10000).dataframe()  # Generate fewer samples during hyperopt\n",
    "        \n",
    "        # Extract minority samples\n",
    "        minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "        if len(minority_synthetic_data) > 600:  # Limit synthetic samples during hyperopt\n",
    "            minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "        synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "        synthetic_target = minority_synthetic_data['target']\n",
    "        \n",
    "        # Combine original and synthetic data for this fold\n",
    "        X_train_combined = pd.concat([X_train_fold, synthetic_minority_features])\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_combined)\n",
    "        y_train = np.concatenate((y_train_fold, synthetic_target.values), axis=0)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset\n",
    "syn_model = Plugins().get(\"ctgan\", n_iter=100, random_state=42)\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'best_MLP_model_with_synthetic_CV.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_with_synthetic_metrics_and_params_CV.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41324bdb",
   "metadata": {},
   "source": [
    "## after CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "197ccc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31T11:37:32.687260+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T11:37:32.688136+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T11:37:32.688485+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-31T11:37:32.689043+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.7017\n",
      "F1 Score: 0.3284\n",
      "Precision: 0.3056\n",
      "Recall: 0.3548\n",
      "Accuracy: 0.8900\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset\n",
    "syn_model = Plugins().get(\"ctgan\", n_iter=100, random_state=42)\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_ctgan2.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_ctgan2.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293a940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-30T17:42:58.608885+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-30T17:42:58.609683+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-30T17:42:58.610074+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-30T17:42:58.610621+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.7262\n",
      "F1 Score: 0.2703\n",
      "Precision: 0.1875\n",
      "Recall: 0.4839\n",
      "Accuracy: 0.8020\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset\n",
    "syn_model = Plugins().get(\"ctgan\", n_iter=100, random_state=42)\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_ctgan.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_ctgan.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4f2792",
   "metadata": {},
   "source": [
    "# MLP + ARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71103a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get the original training data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index].copy().reset_index(drop=True)\n",
    "        y_train_fold = y_train_k_fold[train_index]\n",
    "        X_test = X_train_folds.iloc[test_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Generate synthetic data for this fold\n",
    "        train_fold_data = X_train_fold.copy()\n",
    "        train_fold_data['target'] = y_train_fold\n",
    "        \n",
    "        # Create loader for this fold's dataset\n",
    "        fold_loader = GenericDataLoader(\n",
    "            train_fold_data,\n",
    "            target_column=\"target\"\n",
    "        )\n",
    "        \n",
    "        # Generate synthetic data for this fold using ARF\n",
    "        syn_model = Plugins().get(\"arf\", random_state=42)  # Using ARF instead of CTGAN\n",
    "        syn_model.fit(fold_loader)\n",
    "        synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "        \n",
    "        # Extract minority samples\n",
    "        minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "        if len(minority_synthetic_data) > 600:\n",
    "            minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "        synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "        synthetic_target = minority_synthetic_data['target']\n",
    "        \n",
    "        # Combine original and synthetic data for this fold\n",
    "        X_train_combined = pd.concat([X_train_fold, synthetic_minority_features])\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_combined)\n",
    "        y_train = np.concatenate((y_train_fold, synthetic_target.values), axis=0)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using ARF\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)  # Using ARF instead of CTGAN\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'best_MLP_model_with_arf_CV.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_with_arf_metrics_and_params_CV.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cefcf494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31T12:57:54.902288+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T12:57:54.903054+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T12:57:54.903431+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-31T12:57:54.904002+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.6238532110091743\n",
      "Iteration number 1 reached accuracy of 0.44617737003058106.\n",
      "Test metrics:\n",
      "ROC AUC: 0.7795\n",
      "F1 Score: 0.3011\n",
      "Precision: 0.2258\n",
      "Recall: 0.4516\n",
      "Accuracy: 0.8411\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using ARF\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_arf.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_arf.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500e6cb",
   "metadata": {},
   "source": [
    "# MLP + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d90b3177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.6559\n",
      "F1 Score: 0.2264\n",
      "Precision: 0.1600\n",
      "Recall: 0.3871\n",
      "Accuracy: 0.7995\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Import the SimplicialSMOTE module\n",
    "from simplical_smote_kdd.ssmote import SimplicialSMOTE\n",
    "\n",
    "# Convert DataFrame to NumPy array if needed\n",
    "if isinstance(X_train_folds, pd.DataFrame):\n",
    "    X_train_folds_np = X_train_folds.values\n",
    "else:\n",
    "    X_train_folds_np = X_train_folds\n",
    "\n",
    "if isinstance(y_train_k_fold, pd.Series):\n",
    "    y_train_k_fold_np = y_train_k_fold.values\n",
    "else:\n",
    "    y_train_k_fold_np = y_train_k_fold\n",
    "\n",
    "X_res, y_res = SimplicialSMOTE(random_state=42).fit_resample(X_train_folds_np, y_train_k_fold_np)\n",
    "\n",
    "# Apply StandardScaler to the resampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_res)\n",
    "y_train_final = y_res\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_simplicial_smote.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_simplicial_smote.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab986372",
   "metadata": {},
   "source": [
    "# MLP + TVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab98edef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, criterion, device, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            outputs = outputs.view(-1)  # Reshape to [batch_size] instead of squeezing\n",
    "            targets = targets.float()\n",
    "            \n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            probs = outputs.view(-1).cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "    \n",
    "    return all_probs, all_preds, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get the original training data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index].copy().reset_index(drop=True)\n",
    "        y_train_fold = y_train_k_fold[train_index]\n",
    "        X_test = X_train_folds.iloc[test_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Generate synthetic data for this fold\n",
    "        train_fold_data = X_train_fold.copy()\n",
    "        train_fold_data['target'] = y_train_fold\n",
    "        \n",
    "        # Create loader for this fold's dataset\n",
    "        fold_loader = GenericDataLoader(\n",
    "            train_fold_data,\n",
    "            target_column=\"target\"\n",
    "        )\n",
    "        \n",
    "        # Generate synthetic data for this fold using TVAE\n",
    "        # TVAE (Tabular Variational Autoencoder) is a deep generative model for tabular data\n",
    "        syn_model = Plugins().get(\"tvae\", n_iter=100, random_state=42)  # Using TVAE instead of ARF\n",
    "        syn_model.fit(fold_loader)\n",
    "        synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "        \n",
    "        # Extract minority samples\n",
    "        minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "        if len(minority_synthetic_data) > 600:\n",
    "            minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "        synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "        synthetic_target = minority_synthetic_data['target']\n",
    "        \n",
    "        # Combine original and synthetic data for this fold\n",
    "        X_train_combined = pd.concat([X_train_fold, synthetic_minority_features])\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_combined)\n",
    "        y_train = np.concatenate((y_train_fold, synthetic_target.values), axis=0)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using TVAE\n",
    "syn_model = Plugins().get(\"tvae\", random_state=42)  # Using TVAE instead of ARF\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'best_MLP_model_with_tvae_CV.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_with_tvae_metrics_and_params_CV.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e217698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31T16:00:21.706878+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T16:00:21.707909+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T16:00:21.708278+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-31T16:00:21.708765+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n",
      "100%|██████████| 100/100 [00:26<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.7212\n",
      "F1 Score: 0.2921\n",
      "Precision: 0.2241\n",
      "Recall: 0.4194\n",
      "Accuracy: 0.8460\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using TVAE\n",
    "syn_model = Plugins().get(\"tvae\", n_iter=100, random_state=42)\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_tvae.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_tvae.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1492c",
   "metadata": {},
   "source": [
    "# MLP + Gaussian Copula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9652cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "from sdv.metadata import Metadata\n",
    "\n",
    "X_train_with_ID = X_train.copy().reset_index(drop=False)\n",
    "X_train_with_ID_and_target = X_train_with_ID.copy()\n",
    "X_train_with_ID_and_target['target'] = y_train\n",
    "\n",
    "metadata = Metadata.detect_from_dataframe(data=X_train_with_ID_and_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "575eec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.6188, Params: {'batch_size': 128, 'dropout_rate': 0.46592360311077285, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00010899374200443225, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.5775, Params: {'batch_size': 64, 'dropout_rate': 0.18700689584763242, 'epochs': 40.0, 'hidden_size': 160.0, 'learning_rate': 0.0004430396246892957, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.5695, Params: {'batch_size': 128, 'dropout_rate': 0.18602086514780344, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.0022771511751245544, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5407, Params: {'batch_size': 128, 'dropout_rate': 0.1413308279063807, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0010269434820131004, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.5081, Params: {'batch_size': 16, 'dropout_rate': 0.20670891684186052, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0014570973417703877, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.6041, Params: {'batch_size': 128, 'dropout_rate': 0.18905138432766463, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.00014176885716982903, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.6186, Params: {'batch_size': 128, 'dropout_rate': 0.46979181014961424, 'epochs': 20.0, 'hidden_size': 96.0, 'learning_rate': 0.00039414735176782935, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.5663, Params: {'batch_size': 64, 'dropout_rate': 0.3450858603000765, 'epochs': 40.0, 'hidden_size': 64.0, 'learning_rate': 0.00156285046834954, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5895, Params: {'batch_size': 128, 'dropout_rate': 0.1945203461460667, 'epochs': 30.0, 'hidden_size': 160.0, 'learning_rate': 0.0003862144696504806, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5464, Params: {'batch_size': 64, 'dropout_rate': 0.2820918051527706, 'epochs': 40.0, 'hidden_size': 128.0, 'learning_rate': 0.0057267232676637605, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5545, Params: {'batch_size': 64, 'dropout_rate': 0.4891038494698189, 'epochs': 10.0, 'hidden_size': 160.0, 'learning_rate': 0.00011907153420659085, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5903, Params: {'batch_size': 32, 'dropout_rate': 0.296611449299478, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.000141529565577446, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.6313, Params: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.6221, Params: {'batch_size': 16, 'dropout_rate': 0.48231211231356386, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00016276375705448647, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.5348, Params: {'batch_size': 64, 'dropout_rate': 0.1181289752128444, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0039212439128806734, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.6054, Params: {'batch_size': 16, 'dropout_rate': 0.31496231745733416, 'epochs': 20.0, 'hidden_size': 64.0, 'learning_rate': 0.0068362450129326275, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.5824, Params: {'batch_size': 128, 'dropout_rate': 0.18549297116964492, 'epochs': 40.0, 'hidden_size': 32.0, 'learning_rate': 0.00017710772048109056, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.5829, Params: {'batch_size': 16, 'dropout_rate': 0.1581728391010767, 'epochs': 10.0, 'hidden_size': 128.0, 'learning_rate': 0.006800285091797739, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.5900, Params: {'batch_size': 128, 'dropout_rate': 0.4468670780569276, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.002774776643552473, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.5837, Params: {'batch_size': 64, 'dropout_rate': 0.39098773803652587, 'epochs': 30.0, 'hidden_size': 192.0, 'learning_rate': 0.0003657969390121402, 'num_layers': 2.0}\n",
      "100%|██████████| 20/20 [07:16<00:00, 21.85s/trial, best loss: -0.6313270504330106]\n",
      "Hyperparameter optimization completed.\n",
      "Best parameters: {'batch_size': 64, 'dropout_rate': 0.49368924566674954, 'epochs': 10.0, 'hidden_size': 96.0, 'learning_rate': 0.004823648144379721, 'num_layers': 2.0}\n",
      "Best mean AUC: 0.6313\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get the original training data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index].copy().reset_index(drop=True)\n",
    "        y_train_fold = y_train_k_fold[train_index]\n",
    "        X_test = X_train_folds.iloc[test_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Generate synthetic data for this fold\n",
    "        train_fold_data = X_train_fold.copy()\n",
    "        train_fold_data['target'] = y_train_fold\n",
    "        train_fold_data['index'] = np.arange(1, len(train_fold_data) + 1)\n",
    "        \n",
    "        # Create loader for this fold's dataset\n",
    "        synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "        synthesizer.fit(train_fold_data)\n",
    "        synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "        minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "        if len(minority_synthetic_data) > 600:\n",
    "            minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "        synthetic_minority_features = minority_synthetic_data.drop(['target', 'index'], axis=1)\n",
    "        synthetic_target = minority_synthetic_data['target']\n",
    "        \n",
    "        # Combine original and synthetic data for this fold\n",
    "        X_train_combined = pd.concat([X_train_fold, synthetic_minority_features])\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_combined)\n",
    "        y_train = np.concatenate((y_train_fold, synthetic_target.values), axis=0)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "train_full['index'] = np.arange(1, len(train_full) + 1)\n",
    "\n",
    "# Create loader for full dataset\n",
    "synthesizer = GaussianCopulaSynthesizer(metadata)\n",
    "synthesizer.fit(train_full)\n",
    "synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "synthetic_minority_features = minority_synthetic_data.drop(['target', 'index'], axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'best_MLP_model_with_gaussian_copula_CV.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_with_gaussian_copula_metrics_and_params_CV.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f1dea29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.7118\n",
      "F1 Score: 0.0930\n",
      "Precision: 0.1667\n",
      "Recall: 0.0645\n",
      "Accuracy: 0.9046\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "train_full['index'] = np.arange(1, len(train_full) + 1)  # Add index for the synthesizer\n",
    "\n",
    "# Generate synthetic data using Gaussian Copula\n",
    "synthesizer = GaussianCopulaSynthesizer(metadata)  # Using predefined metadata\n",
    "synthesizer.fit(train_full)\n",
    "synthetic_data = synthesizer.sample(num_rows=10000)\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "\n",
    "# Drop both 'target' and 'index' columns before combining\n",
    "synthetic_minority_features = minority_synthetic_data.drop(['target', 'index'], axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_gaussian_copula.pkl'  # Updated filename\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_gaussian_copula.json', 'w') as f:  # Updated filename\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76904c2c",
   "metadata": {},
   "source": [
    "# MLP + ARF + EDGE CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "501c48c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>...</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>stent_type___5</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>anemia</th>\n",
       "      <th>atrial_fibrilation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96.915675</td>\n",
       "      <td>158.932853</td>\n",
       "      <td>22.532092</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.203800</td>\n",
       "      <td>28.790400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.254652</td>\n",
       "      <td>152.770464</td>\n",
       "      <td>27.473483</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.631838</td>\n",
       "      <td>32.941136</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.873062</td>\n",
       "      <td>149.671377</td>\n",
       "      <td>22.203660</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.587937</td>\n",
       "      <td>36.907801</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.667463</td>\n",
       "      <td>143.408284</td>\n",
       "      <td>26.260913</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.148615</td>\n",
       "      <td>33.811517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.948758</td>\n",
       "      <td>166.190727</td>\n",
       "      <td>27.239543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.549106</td>\n",
       "      <td>35.001648</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>87.795446</td>\n",
       "      <td>159.420133</td>\n",
       "      <td>26.406490</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.736894</td>\n",
       "      <td>36.332443</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>89.379282</td>\n",
       "      <td>144.584974</td>\n",
       "      <td>15.941906</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.394632</td>\n",
       "      <td>37.417018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>88.728409</td>\n",
       "      <td>145.131891</td>\n",
       "      <td>15.130884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.639743</td>\n",
       "      <td>36.390807</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>89.067582</td>\n",
       "      <td>146.095263</td>\n",
       "      <td>24.266571</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.607628</td>\n",
       "      <td>30.475761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>97.276788</td>\n",
       "      <td>153.779512</td>\n",
       "      <td>17.488966</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.322552</td>\n",
       "      <td>32.086462</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age      height         ef  cerebrovascular_disease  \\\n",
       "0    96.915675  158.932853  22.532092                        1   \n",
       "1    99.254652  152.770464  27.473483                        1   \n",
       "2    91.873062  149.671377  22.203660                        1   \n",
       "3    98.667463  143.408284  26.260913                        1   \n",
       "4    94.948758  166.190727  27.239543                        1   \n",
       "..         ...         ...        ...                      ...   \n",
       "145  87.795446  159.420133  26.406490                        1   \n",
       "146  89.379282  144.584974  15.941906                        1   \n",
       "147  88.728409  145.131891  15.130884                        1   \n",
       "148  89.067582  146.095263  24.266571                        1   \n",
       "149  97.276788  153.779512  17.488966                        1   \n",
       "\n",
       "     peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                            1                     1              1        1   \n",
       "1                            1                     1              1        1   \n",
       "2                            0                     0              1        1   \n",
       "3                            1                     1              1        1   \n",
       "4                            1                     1              1        1   \n",
       "..                         ...                   ...            ...      ...   \n",
       "145                          1                     1              1        1   \n",
       "146                          1                     1              1        1   \n",
       "147                          1                     0              1        1   \n",
       "148                          1                     1              1        0   \n",
       "149                          1                     1              1        1   \n",
       "\n",
       "     medina_side  cto_bifurc  ...  previous_pci  previous_stroke_tia  \\\n",
       "0              1           1  ...             1                    0   \n",
       "1              1           0  ...             1                    1   \n",
       "2              1           0  ...             0                    1   \n",
       "3              1           1  ...             1                    1   \n",
       "4              0           1  ...             1                    0   \n",
       "..           ...         ...  ...           ...                  ...   \n",
       "145            0           1  ...             1                    1   \n",
       "146            1           1  ...             0                    1   \n",
       "147            1           1  ...             1                    1   \n",
       "148            1           1  ...             0                    1   \n",
       "149            1           1  ...             0                    0   \n",
       "\n",
       "     stent_type___3  stent_type___4  stent_type___5  adhoc_pci  \\\n",
       "0                 0               1               1          1   \n",
       "1                 1               1               1          1   \n",
       "2                 1               1               1          1   \n",
       "3                 1               1               1          0   \n",
       "4                 1               1               1          1   \n",
       "..              ...             ...             ...        ...   \n",
       "145               0               1               1          1   \n",
       "146               0               1               1          1   \n",
       "147               1               1               1          1   \n",
       "148               1               1               1          0   \n",
       "149               1               1               0          1   \n",
       "\n",
       "     stent_diameter  stent_length  anemia  atrial_fibrilation  \n",
       "0          2.203800     28.790400       1                   1  \n",
       "1          2.631838     32.941136       1                   1  \n",
       "2          2.587937     36.907801       1                   1  \n",
       "3          2.148615     33.811517       1                   1  \n",
       "4          2.549106     35.001648       1                   0  \n",
       "..              ...           ...     ...                 ...  \n",
       "145        2.736894     36.332443       1                   1  \n",
       "146        2.394632     37.417018       1                   1  \n",
       "147        2.639743     36.390807       1                   1  \n",
       "148        2.607628     30.475761       1                   1  \n",
       "149        2.322552     32.086462       1                   1  \n",
       "\n",
       "[150 rows x 22 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_cases_features_names = [feature for feature in edge_cases.columns if feature in X_train.columns]\n",
    "edge_cases_features = pd.DataFrame(edge_cases, columns=edge_cases_features_names)\n",
    "edge_cases_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e6616901",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_folds = pd.concat([X_train, X_val, edge_cases_features])\n",
    "y_train_k_fold = np.concatenate((y_train, y_val, edge_cases_target), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e033d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train_folds, y_train_k_fold):\n",
    "        # Get the original training data for this fold\n",
    "        X_train_fold = X_train_folds.iloc[train_index].copy().reset_index(drop=True)\n",
    "        y_train_fold = y_train_k_fold[train_index]\n",
    "        X_test = X_train_folds.iloc[test_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Generate synthetic data for this fold\n",
    "        train_fold_data = X_train_fold.copy()\n",
    "        train_fold_data['target'] = y_train_fold\n",
    "        \n",
    "        # Create loader for this fold's dataset\n",
    "        fold_loader = GenericDataLoader(\n",
    "            train_fold_data,\n",
    "            target_column=\"target\"\n",
    "        )\n",
    "        \n",
    "        # Generate synthetic data for this fold using ARF\n",
    "        syn_model = Plugins().get(\"arf\", random_state=42)  # Using ARF instead of CTGAN\n",
    "        syn_model.fit(fold_loader)\n",
    "        synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "        \n",
    "        # Extract minority samples\n",
    "        minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "        if len(minority_synthetic_data) > 600:\n",
    "            minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "        synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "        synthetic_target = minority_synthetic_data['target']\n",
    "        \n",
    "        # Combine original and synthetic data for this fold\n",
    "        X_train_combined = pd.concat([X_train_fold, synthetic_minority_features])\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_combined)\n",
    "        y_train = np.concatenate((y_train_fold, synthetic_target.values), axis=0)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using ARF\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)  # Using ARF instead of CTGAN\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'MLP_arf_edge_cases_CV.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_arf_edge_cases_metrics_and_params_CV.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c41a38f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31T17:42:19.551811+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T17:42:19.552760+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T17:42:19.553234+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-31T17:42:19.553736+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7621848739495798\n",
      "Iteration number 1 reached accuracy of 0.44425770308123247.\n",
      "Test metrics:\n",
      "ROC AUC: 0.7641\n",
      "F1 Score: 0.2400\n",
      "Precision: 0.3158\n",
      "Recall: 0.1935\n",
      "Accuracy: 0.9071\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using ARF\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_combined)\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_final)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the model with combined data using the helper method\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'test_model_MLP_arf_edge_cases_CV.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Create test data loader for evaluation\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.FloatTensor(y_test))\n",
    "test_loader = DataLoader(test_dataset, batch_size=int(best_params['batch_size']))\n",
    "\n",
    "# Use the evaluate_model helper function\n",
    "test_predictions_prob, test_pred_class, _ = evaluate_model(best_model, test_loader, device)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions_prob)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('scores_test_MLP_arf_edge_cases_CV.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e68d89",
   "metadata": {},
   "source": [
    "# MLP + Edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4316f6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.8204, Params: {'batch_size': 16, 'dropout_rate': 0.4650195624188008, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.0002869735379360179, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.8267, Params: {'batch_size': 16, 'dropout_rate': 0.1195474458998624, 'epochs': 20.0, 'hidden_size': 160.0, 'learning_rate': 0.00019637635955910797, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8493, Params: {'batch_size': 128, 'dropout_rate': 0.47344291914264136, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.0006410139694441834, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.8494, Params: {'batch_size': 64, 'dropout_rate': 0.2321059523254693, 'epochs': 20.0, 'hidden_size': 224.0, 'learning_rate': 0.0010924547475591787, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Trial completed - AUC: 0.8556, Params: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8490, Params: {'batch_size': 128, 'dropout_rate': 0.4783056706793436, 'epochs': 50.0, 'hidden_size': 64.0, 'learning_rate': 0.0006876473282925838, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.7828, Params: {'batch_size': 32, 'dropout_rate': 0.22548085355497682, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.0008870500644536863, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.8095, Params: {'batch_size': 16, 'dropout_rate': 0.24371965037829493, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.0008475746755391144, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.8122, Params: {'batch_size': 32, 'dropout_rate': 0.45655986077336064, 'epochs': 20.0, 'hidden_size': 256.0, 'learning_rate': 0.0032014091176102983, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8012, Params: {'batch_size': 32, 'dropout_rate': 0.10106296460694351, 'epochs': 20.0, 'hidden_size': 192.0, 'learning_rate': 0.0009789865447589895, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.8070, Params: {'batch_size': 16, 'dropout_rate': 0.472677996490544, 'epochs': 30.0, 'hidden_size': 256.0, 'learning_rate': 0.0013190390390389857, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Trial completed - AUC: 0.8463, Params: {'batch_size': 128, 'dropout_rate': 0.18718259292058162, 'epochs': 30.0, 'hidden_size': 96.0, 'learning_rate': 0.0002573737108733572, 'num_layers': 3.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8173, Params: {'batch_size': 16, 'dropout_rate': 0.23358174487167635, 'epochs': 30.0, 'hidden_size': 64.0, 'learning_rate': 0.000977099064725083, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8553, Params: {'batch_size': 64, 'dropout_rate': 0.3821521924047234, 'epochs': 20.0, 'hidden_size': 32.0, 'learning_rate': 0.0008129596112481328, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8390, Params: {'batch_size': 128, 'dropout_rate': 0.31999187511382887, 'epochs': 10.0, 'hidden_size': 64.0, 'learning_rate': 0.00033622811874226867, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.7877, Params: {'batch_size': 128, 'dropout_rate': 0.37143589846087544, 'epochs': 50.0, 'hidden_size': 256.0, 'learning_rate': 0.002927562381012072, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8154, Params: {'batch_size': 128, 'dropout_rate': 0.3831667915364235, 'epochs': 20.0, 'hidden_size': 128.0, 'learning_rate': 0.00689119361576913, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.8175, Params: {'batch_size': 16, 'dropout_rate': 0.3349756919628448, 'epochs': 50.0, 'hidden_size': 192.0, 'learning_rate': 0.00015588544660113867, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Trial completed - AUC: 0.8011, Params: {'batch_size': 32, 'dropout_rate': 0.41233265184982915, 'epochs': 30.0, 'hidden_size': 224.0, 'learning_rate': 0.0014239364901727804, 'num_layers': 4.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Training model with parameters: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "Trial completed - AUC: 0.8388, Params: {'batch_size': 64, 'dropout_rate': 0.49177977054498023, 'epochs': 50.0, 'hidden_size': 224.0, 'learning_rate': 0.00038522652443777436, 'num_layers': 2.0}\n",
      "100%|██████████| 20/20 [06:09<00:00, 18.46s/trial, best loss: -0.8556465436955154]\n",
      "Hyperparameter optimization completed.\n",
      "Best parameters: {'batch_size': 32, 'dropout_rate': 0.48294830585363924, 'epochs': 10.0, 'hidden_size': 256.0, 'learning_rate': 0.0005141724501890821, 'num_layers': 1.0}\n",
      "Best mean AUC: 0.8556\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    # Convert parameters to proper format\n",
    "    hidden_size = int(params['hidden_size'])\n",
    "    num_layers = int(params['num_layers'])\n",
    "    dropout_rate = float(params['dropout_rate'])\n",
    "    learning_rate = float(params['learning_rate'])\n",
    "    batch_size = int(params['batch_size'])\n",
    "    epochs = int(params['epochs'])\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    roc_auc_scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X_train _folds, y_train_k_fold):\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train_folds.iloc[train_index])\n",
    "        X_test = scaler.transform(X_train_folds.iloc[test_index])\n",
    "        y_train = y_train_k_fold[train_index]\n",
    "        y_test = y_train_k_fold[test_index]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        X_test_tensor = torch.FloatTensor(X_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_dataset = TensorDataset(X_test_tensor, torch.zeros(X_test_tensor.shape[0]))  # Dummy labels for test set\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Initialize model with current parameters\n",
    "        print(f\"Training model with parameters: {params}\")\n",
    "        input_size = X_train.shape[1]\n",
    "        model = MLPClassifier(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "        \n",
    "        # Define loss function and optimizer\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Train the model\n",
    "        train_model(model, train_loader, optimizer, criterion, device, epochs)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        test_loader = DataLoader(TensorDataset(X_test_tensor, torch.zeros(X_test_tensor.shape[0])), batch_size=batch_size)\n",
    "        predictions_prob, predictions, _ = evaluate_model(model, test_loader, device)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        roc_auc = roc_auc_score(y_test, predictions_prob)\n",
    "        f1 = f1_score(y_test, predictions, zero_division=0)\n",
    "        precision = precision_score(y_test, predictions, zero_division=0)\n",
    "        recall = recall_score(y_test, predictions, zero_division=0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        \n",
    "        roc_auc_scores.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        accuracy_scores.append(accuracy)\n",
    "\n",
    "    mean_metrics = {\n",
    "        'roc_auc': np.mean(roc_auc_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'roc_auc_scores': roc_auc_scores,\n",
    "        'f1_scores': f1_scores,\n",
    "        'precision_scores': precision_scores,\n",
    "        'recall_scores': recall_scores,\n",
    "        'accuracy_scores': accuracy_scores\n",
    "    }\n",
    "    \n",
    "    print(f\"Trial completed - AUC: {mean_metrics['roc_auc']:.4f}, Params: {params}\")\n",
    "    \n",
    "    return {'loss': -mean_metrics['roc_auc'], 'status': STATUS_OK, 'params': params, 'mean_metrics': mean_metrics}\n",
    "\n",
    "# Define the search space for MLP\n",
    "space = {\n",
    "    'hidden_size': hp.quniform('hidden_size', 32, 256, 32),\n",
    "    'num_layers': hp.quniform('num_layers', 1, 4, 1),\n",
    "    'dropout_rate': hp.uniform('dropout_rate', 0.1, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.0001), np.log(0.01)),\n",
    "    'batch_size': hp.choice('batch_size', [16, 32, 64, 128]),\n",
    "    'epochs': hp.quniform('epochs', 10, 50, 10)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization with limited trials\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20,\n",
    "            trials=trials)\n",
    "\n",
    "# Extract best parameters\n",
    "best_trial = trials.best_trial['result']\n",
    "best_params = best_trial['params']\n",
    "best_metrics = best_trial['mean_metrics']\n",
    "\n",
    "print(\"Hyperparameter optimization completed.\")\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mean AUC: {best_metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_folds)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_k_fold)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'MLP_model_CV_edge_cases.pkl'\n",
    "with open(model_filename, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('MLP_metrics_and_params_CV_edge_cases.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "006c7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics:\n",
      "ROC AUC: 0.7800\n",
      "F1 Score: 0.0000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "Accuracy: 0.9242\n",
      "Best parameters, model, and evaluation metrics saved.\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best hyperparameters on full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_final = scaler.fit_transform(X_train_folds)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_final)\n",
    "y_train_tensor = torch.FloatTensor(y_train_k_fold)\n",
    "\n",
    "# Create data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=int(best_params['batch_size']), \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Initialize the best model\n",
    "input_size = X_train_final.shape[1]\n",
    "best_model = MLPClassifier(\n",
    "    input_size=input_size,\n",
    "    hidden_size=int(best_params['hidden_size']),\n",
    "    num_layers=int(best_params['num_layers']),\n",
    "    dropout_rate=float(best_params['dropout_rate'])\n",
    ").to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=float(best_params['learning_rate']))\n",
    "\n",
    "# Train the final model\n",
    "train_model(\n",
    "    best_model, \n",
    "    train_loader, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    device, \n",
    "    int(best_params['epochs'])\n",
    ")\n",
    "\n",
    "# Save the best model\n",
    "model_filename = 'pure_MLP.pkl'\n",
    "torch.save(best_model.state_dict(), model_filename)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "\n",
    "# Make predictions\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = best_model(X_test_tensor).squeeze().cpu().numpy()\n",
    "    test_pred_class = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_pred_class, zero_division=0)\n",
    "test_precision = precision_score(y_test, test_pred_class, zero_division=0)\n",
    "test_recall = recall_score(y_test, test_pred_class, zero_division=0)\n",
    "test_accuracy = accuracy_score(y_test, test_pred_class)\n",
    "\n",
    "test_metrics = {\n",
    "    'roc_auc': test_roc_auc,\n",
    "    'f1': test_f1,\n",
    "    'precision': test_precision,\n",
    "    'recall': test_recall,\n",
    "    'accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "print(f\"Test metrics:\")\n",
    "print(f\"ROC AUC: {test_roc_auc:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Save metrics and best parameters to files\n",
    "metrics_and_params = {\n",
    "    'test_evaluation_metrics': test_metrics,\n",
    "    'best_parameters': {\n",
    "        'hidden_size': int(best_params['hidden_size']),\n",
    "        'num_layers': int(best_params['num_layers']),\n",
    "        'dropout_rate': float(best_params['dropout_rate']),\n",
    "        'learning_rate': float(best_params['learning_rate']),\n",
    "        'batch_size': int(best_params['batch_size']),\n",
    "        'epochs': int(best_params['epochs'])\n",
    "    },\n",
    "    'evaluation_metrics': best_metrics\n",
    "}\n",
    "\n",
    "with open('test_scores_MLP_edge_cases.json', 'w') as f:\n",
    "    json.dump(metrics_and_params, f)\n",
    "\n",
    "print(\"Best parameters, model, and evaluation metrics saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d076c278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01dfde42",
   "metadata": {},
   "source": [
    "# Synthetic data correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d275c3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>def</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>stent_type___5</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>cto_bifurc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>87.795446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.406490</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.736894</td>\n",
       "      <td>36.332443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>89.379282</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.941906</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.394632</td>\n",
       "      <td>37.417018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>88.728409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.130884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.639743</td>\n",
       "      <td>36.390807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>89.067582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.266571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.607628</td>\n",
       "      <td>30.475761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>97.276788</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.488966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.322552</td>\n",
       "      <td>32.086462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1785 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  anemia         ef  cerebrovascular_disease  \\\n",
       "0    41.000000     0.0  49.000000                      0.0   \n",
       "1    56.000000     0.0  68.000000                      0.0   \n",
       "2    55.000000     0.0  70.000000                      0.0   \n",
       "3    79.000000     0.0  73.000000                      1.0   \n",
       "4    61.000000     0.0  62.000000                      0.0   \n",
       "..         ...     ...        ...                      ...   \n",
       "145  87.795446     1.0  26.406490                      1.0   \n",
       "146  89.379282     1.0  15.941906                      1.0   \n",
       "147  88.728409     1.0  15.130884                      1.0   \n",
       "148  89.067582     1.0  24.266571                      1.0   \n",
       "149  97.276788     1.0  17.488966                      1.0   \n",
       "\n",
       "     peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                          0.0                   0.0            0.0      0.0   \n",
       "1                          0.0                   0.0            1.0      0.0   \n",
       "2                          0.0                   0.0            1.0      0.0   \n",
       "3                          0.0                   0.0            0.0      1.0   \n",
       "4                          0.0                   0.0            0.0      0.0   \n",
       "..                         ...                   ...            ...      ...   \n",
       "145                        1.0                   1.0            1.0      1.0   \n",
       "146                        1.0                   1.0            1.0      1.0   \n",
       "147                        1.0                   0.0            1.0      1.0   \n",
       "148                        1.0                   1.0            1.0      0.0   \n",
       "149                        1.0                   1.0            1.0      1.0   \n",
       "\n",
       "     stent_type___3  medina_side  ...  def  history_of_cancer  stent_type___5  \\\n",
       "0               1.0          0.0  ...  0.0                0.0             0.0   \n",
       "1               0.0          1.0  ...  0.0                1.0             0.0   \n",
       "2               0.0          0.0  ...  0.0                0.0             0.0   \n",
       "3               0.0          0.0  ...  0.0                0.0             0.0   \n",
       "4               0.0          0.0  ...  0.0                1.0             0.0   \n",
       "..              ...          ...  ...  ...                ...             ...   \n",
       "145             0.0          0.0  ...  1.0                0.0             1.0   \n",
       "146             0.0          1.0  ...  0.0                1.0             1.0   \n",
       "147             1.0          1.0  ...  1.0                0.0             1.0   \n",
       "148             1.0          1.0  ...  0.0                0.0             1.0   \n",
       "149             1.0          1.0  ...  1.0                0.0             0.0   \n",
       "\n",
       "     previous_stroke_tia  stent_diameter  stent_length  adhoc_pci  \\\n",
       "0               0.477395        4.000000     11.000000        0.0   \n",
       "1               0.313995        2.750000     18.000000        1.0   \n",
       "2               0.478905        2.750000     33.000000        1.0   \n",
       "3               0.000000        3.500000     38.000000        0.0   \n",
       "4               0.448962        4.000000     28.000000        1.0   \n",
       "..                   ...             ...           ...        ...   \n",
       "145             1.000000        2.736894     36.332443        1.0   \n",
       "146             1.000000        2.394632     37.417018        1.0   \n",
       "147             1.000000        2.639743     36.390807        1.0   \n",
       "148             1.000000        2.607628     30.475761        0.0   \n",
       "149             0.000000        2.322552     32.086462        1.0   \n",
       "\n",
       "     previous_pci  stent_type___4  cto_bifurc  \n",
       "0             1.0             0.0         0.0  \n",
       "1             1.0             1.0         0.0  \n",
       "2             0.0             1.0         0.0  \n",
       "3             0.0             0.0         0.0  \n",
       "4             0.0             0.0         0.0  \n",
       "..            ...             ...         ...  \n",
       "145           1.0             1.0         1.0  \n",
       "146           0.0             1.0         1.0  \n",
       "147           1.0             1.0         1.0  \n",
       "148           0.0             1.0         1.0  \n",
       "149           0.0             1.0         1.0  \n",
       "\n",
       "[1785 rows x 22 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "16e1db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-31T20:48:22.856979+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T20:48:22.857404+0400][33486][CRITICAL] load failed: module 'synthcity.plugins.generic.plugin_great' has no attribute 'plugin'\n",
      "[2025-05-31T20:48:22.857734+0400][33486][CRITICAL] module plugin_great load failed\n",
      "[2025-05-31T20:48:22.858228+0400][33486][CRITICAL] module disabled: /Users/ivan.petrov/HSE/.venv/lib/python3.12/site-packages/synthcity/plugins/generic/plugin_goggle.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy is 0.7565826330532213\n",
      "Iteration number 1 reached accuracy of 0.44425770308123247.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anemia</th>\n",
       "      <th>ef</th>\n",
       "      <th>cerebrovascular_disease</th>\n",
       "      <th>peripheral_artery_disease</th>\n",
       "      <th>if_yes_what_type___1</th>\n",
       "      <th>single_vessel</th>\n",
       "      <th>calcium</th>\n",
       "      <th>stent_type___3</th>\n",
       "      <th>medina_side</th>\n",
       "      <th>...</th>\n",
       "      <th>history_of_cancer</th>\n",
       "      <th>stent_type___5</th>\n",
       "      <th>previous_stroke_tia</th>\n",
       "      <th>stent_diameter</th>\n",
       "      <th>stent_length</th>\n",
       "      <th>adhoc_pci</th>\n",
       "      <th>previous_pci</th>\n",
       "      <th>stent_type___4</th>\n",
       "      <th>cto_bifurc</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.477395</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313995</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448962</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>85.007005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.725871</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341170</td>\n",
       "      <td>3.087827</td>\n",
       "      <td>32.155276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>91.170605</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.076487</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906789</td>\n",
       "      <td>2.559256</td>\n",
       "      <td>29.900271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>96.329914</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.526546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.524870</td>\n",
       "      <td>42.144041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6769</th>\n",
       "      <td>97.511588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.620903</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.027034</td>\n",
       "      <td>2.349816</td>\n",
       "      <td>31.627604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7344</th>\n",
       "      <td>84.890817</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.209208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444889</td>\n",
       "      <td>2.613687</td>\n",
       "      <td>33.968499</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2385 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  anemia         ef  cerebrovascular_disease  \\\n",
       "0     41.000000     0.0  49.000000                      0.0   \n",
       "1     56.000000     0.0  68.000000                      0.0   \n",
       "2     55.000000     0.0  70.000000                      0.0   \n",
       "3     79.000000     0.0  73.000000                      1.0   \n",
       "4     61.000000     0.0  62.000000                      0.0   \n",
       "...         ...     ...        ...                      ...   \n",
       "4877  85.007005     0.0  27.725871                      1.0   \n",
       "493   91.170605     1.0  27.076487                      1.0   \n",
       "748   96.329914     1.0  23.526546                      1.0   \n",
       "6769  97.511588     0.0  22.620903                      1.0   \n",
       "7344  84.890817     0.0  25.209208                      1.0   \n",
       "\n",
       "      peripheral_artery_disease  if_yes_what_type___1  single_vessel  calcium  \\\n",
       "0                           0.0                   0.0            0.0      0.0   \n",
       "1                           0.0                   0.0            1.0      0.0   \n",
       "2                           0.0                   0.0            1.0      0.0   \n",
       "3                           0.0                   0.0            0.0      1.0   \n",
       "4                           0.0                   0.0            0.0      0.0   \n",
       "...                         ...                   ...            ...      ...   \n",
       "4877                        1.0                   1.0            1.0      1.0   \n",
       "493                         1.0                   1.0            1.0      1.0   \n",
       "748                         1.0                   1.0            1.0      1.0   \n",
       "6769                        1.0                   1.0            1.0      1.0   \n",
       "7344                        1.0                   1.0            1.0      1.0   \n",
       "\n",
       "      stent_type___3  medina_side  ...  history_of_cancer  stent_type___5  \\\n",
       "0                1.0          0.0  ...                0.0             0.0   \n",
       "1                0.0          1.0  ...                1.0             0.0   \n",
       "2                0.0          0.0  ...                0.0             0.0   \n",
       "3                0.0          0.0  ...                0.0             0.0   \n",
       "4                0.0          0.0  ...                1.0             0.0   \n",
       "...              ...          ...  ...                ...             ...   \n",
       "4877             0.0          1.0  ...                1.0             0.0   \n",
       "493              1.0          1.0  ...                0.0             1.0   \n",
       "748              1.0          1.0  ...                1.0             0.0   \n",
       "6769             1.0          1.0  ...                1.0             1.0   \n",
       "7344             0.0          0.0  ...                1.0             1.0   \n",
       "\n",
       "      previous_stroke_tia  stent_diameter  stent_length  adhoc_pci  \\\n",
       "0                0.477395        4.000000     11.000000        0.0   \n",
       "1                0.313995        2.750000     18.000000        1.0   \n",
       "2                0.478905        2.750000     33.000000        1.0   \n",
       "3                0.000000        3.500000     38.000000        0.0   \n",
       "4                0.448962        4.000000     28.000000        1.0   \n",
       "...                   ...             ...           ...        ...   \n",
       "4877             0.341170        3.087827     32.155276        0.0   \n",
       "493              0.906789        2.559256     29.900271        0.0   \n",
       "748              0.000000        2.524870     42.144041        1.0   \n",
       "6769             1.027034        2.349816     31.627604        1.0   \n",
       "7344             0.444889        2.613687     33.968499        1.0   \n",
       "\n",
       "      previous_pci  stent_type___4  cto_bifurc  target  \n",
       "0              1.0             0.0         0.0       0  \n",
       "1              1.0             1.0         0.0       0  \n",
       "2              0.0             1.0         0.0       0  \n",
       "3              0.0             0.0         0.0       0  \n",
       "4              0.0             0.0         0.0       0  \n",
       "...            ...             ...         ...     ...  \n",
       "4877           0.0             1.0         0.0       1  \n",
       "493            0.0             1.0         1.0       1  \n",
       "748            1.0             0.0         1.0       1  \n",
       "6769           0.0             0.0         1.0       1  \n",
       "7344           0.0             1.0         0.0       1  \n",
       "\n",
       "[2385 rows x 23 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate synthetic data for final model using full training set\n",
    "train_full = X_train_folds.copy().reset_index(drop=True)\n",
    "train_full['target'] = y_train_k_fold\n",
    "\n",
    "# Create loader for full dataset\n",
    "full_loader = GenericDataLoader(\n",
    "    train_full,\n",
    "    target_column=\"target\"\n",
    ")\n",
    "\n",
    "# Generate synthetic data for the full dataset using ARF\n",
    "syn_model = Plugins().get(\"arf\", random_state=42)  # Using ARF instead of CTGAN\n",
    "syn_model.fit(full_loader)\n",
    "synthetic_data = syn_model.generate(count=10000).dataframe()\n",
    "\n",
    "# Extract minority samples\n",
    "minority_synthetic_data = synthetic_data[synthetic_data['target'] == 1]\n",
    "if len(minority_synthetic_data) > 600:\n",
    "    minority_synthetic_data = minority_synthetic_data.sample(n=600)\n",
    "synthetic_minority_features = minority_synthetic_data.drop('target', axis=1)\n",
    "synthetic_target = minority_synthetic_data['target']\n",
    "\n",
    "# Combine original and synthetic data for final training\n",
    "X_train_combined = pd.concat([X_train_folds, synthetic_minority_features])\n",
    "y_train_final = np.concatenate((y_train_k_fold, synthetic_target.values), axis=0)\n",
    "X_train_combined['target'] = y_train_final\n",
    "X_train_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "092f0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'font.size': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 18,\n",
    "    'xtick.labelsize': 18,\n",
    "    'ytick.labelsize': 18\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2c850c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features count: 22\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABfIAAAVbCAYAAABqFFtnAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Qm8lPP////XtO+b0qaV9kIS0q4kEpFUSrJkiT4qLRIKLZaQXYhEpJSslbRooYho0SLtWpS073X+t+f7+7/mN+c0czpzzpxm5vS4327XbebMzHXNNddck8/n+X5dr7cvISEhwQAAAAAAAAAAQEzKFO0dAAAAAAAAAAAAoRHkAwAAAAAAAAAQwwjyAQAAAAAAAACIYQT5AAAAAAAAAADEMIJ8AAAAAAAAAABiGEE+AAAAAAAAAAAxjCAfAAAAAAAAAIAYRpAPAAAAAAAAAEAMI8gHAAAAAAAAACCGEeQDAAAAAAAAABDDCPIBAAAAAAAAABF34MABmzx5sg0aNMhuvPFGK1OmjPl8PrcMHDgwIu+xbds2e+ihh6xSpUqWM2dOK1SokNWvX9/eeecdS0hIOOX6f/31l91zzz1Wrlw5y5EjhxUpUsSuuuoqmzBhgsUSX0JKPg0AAAAAAAAAAGGYNWuWNW7cOOhzAwYMSHOY/8svv7jQ/d9//3V/58mTxw4dOmTHjh1zf+u5L774wrJlyxZ0/W+++cbatGnjBhwkX758tm/fPjtx4oT7+/bbb7eRI0e6gYdooyIfAAAAAAAAAJAuChYsaE2aNLHevXvbxx9/bMWKFYvIdnfv3m3XXnutC/ErV65sP//8s+3du9f2799vr776qmXNmtWmTp1q3bt3D7r+2rVr7eabb3Yhft26dW3lypVum1oef/xx95r33nvPnnvuOYsFVOQDAAAAAAAAACLu+PHjljlz5kSPlS1b1tavX5/mivzHHnvMtexRO51ly5a51jiBhg4dao888oh7/z/++MMqVqyY6Plbb73VPvzwQzewsHz5citQoECi59Vu56233nJV+uvWrXMDEtFERT4AAAAAAAAAIOKShviRNHr0aHfbrl27k0J86datm2u1o8GEMWPGJHpOVfteD/z77rvvpBBf+vXr52737NljkyZNsmgjyAcAAAAAAAAAxI2VK1fahg0b3P2rr7466GsU4mvSW/n2228TPTd37lw7ePBgsuvryoEqVaoEXT8aCPIBAAAAAAAAAHFj6dKl/vvVq1cP+TrvObXWScv6at0TbVmivQMAAAAAAAAAgNh2+PBhtwTKnj27W063zZs3+++XLFky5Ou859QeZ9++fa5KP3B99b1Xj/1TrR/4ftFCkA8AAAAAAAAAETb35rqWkXxX9Up74oknEj2W1glrU2vv3r3++7ly5Qr5usDntI4X5HvrJ7du4POB7xctBPkAAAAAAAAAgGRp8teePXsmeiwa1fhnKoJ8AAAAAAAAAECyotVGJ5i8efP67x84cMDy5csX9HV6Ltg63v3A55NbP3DdaGGyWwAAAAAAAABA3ChRooT//t9//x3ydd5zCvq9tjqB6//333928ODBU64f+H7RQpAPAAAAAAAAAIgb1atX999funRpyNd5z1WtWjVN61erVs2ijSAfAAAAAAAAACItky9jLTGkYsWKVrp0aXd/ypQpQV+zf/9+mzNnjrvfrFmzRM/Vq1fPcubMmez669evt+XLlwddPxoI8gEAAAAAAAAAccPn81mnTp3c/bFjx9q6detOes1rr71m+/bts8yZM1uHDh0SPZc7d25r3bq1u//GG2/Y7t27T1r/mWee8ffHb9WqlUUbQT4AAAAAAAAAIF2oD/2OHTv8y4kTJ/wTyQY+rtA90MCBA11gr2VdkKC+V69eVqxYMbedFi1a2C+//OIeP3LkiAvnH3vsMff33Xff7Sr4k3ryySddoL9lyxZr2bKl/fnnn/5Kfj335ptvur8fffRRK1iwoEWbLyEhISHaOwEAAAAAAAAAGcncdvUsI6k3dm6q1itbtqxrU3Mqt912m40aNSpRkP/EE0+4+2vXrnXbSUrh/VVXXWX//vuvv3r+0KFDdvToUX9LnC+++MKyZ88e9D2/+eYba9OmjRsMkPz587sBhePHj7u/b7/9dhs5cqQbTIg2KvIBAAAAAAAAINIU/makJQbVqlXLli1bZj169LAKFSq4AF9V9uqB//bbb9vkyZNDhvhyzTXX2OLFi61Lly5uoECDAKq+v/LKK+3TTz+1d999NyZCfKEiHwAAAAAAAAAibG77+paR1Pv4/yaORXRQkQ8AAAAAAAAAQAwjyAcAAAAAAAAAIIZlifYOAAAAAAAAAEBG4/NRQ43I4WwCAAAAAAAAACCGEeQDAAAAKeTz+axRo0Zx/x4ZWefOnd0xXLduXbpsf+vWrXbbbbdZqVKlLHPmzO69du3aZfF4XHRfj+k5AAAAxDaCfAAAAKSrX375xe68806rUKGC5c6d23LmzGnnnnuu3XrrrTZt2jQ70yikV3gaL7SvWrJnz27//vtv0Nf8999/7nv1XpsWAwcOdNuYNWuWxSKF3h988IE1aNDAHn30URswYIDlyJEjavvz5JNPuuOVNWtWN8iQnkaNGuX/joMtF154oZ0OsX6OAAAApAd65AMAACBdnDhxwnr16mUvvviiZcmSxa644gq77rrrXOC4Zs0a+/rrr+3DDz90QeRjjz0W7d2NGcuXL7dcuXJZLNH3d+TIERszZoz973//O+l5PX7o0CH3umPHjlk0DR061B5++GErWbJkxLetY6DBp6ZNm7rPHG0JCQn23nvvuVBbx/3999+3vn37pvv7NmnSxOrVq3fS48WKFUv39wYAIK7EUfEGYh9BPgAAANKFqpUV4qtK99NPP3VV+IEOHjxor776asgq7zNV5cqVLdbou/NC42BB/rvvvmuVKlVy91euXGnRVLx4cbekB1W8a4CqRIkSFgumT5/u2uPcfffdNnbsWPc9nI4gXwMZGiwBAADA6UNrHQAAAETc6tWr7dlnn7WzzjrLpkyZclKIL2rF0rt3b3viiScSPb5jxw7r3r27lStXzrVzOfvss+3mm2+2pUuXhuz7rQr/559/3qpWrerW8Xp+ly1b1i3qYf7AAw+4vuaqGleLEM/ixYutXbt2LvzNli2blSlTxrp165biAYZVq1ZZnz597KKLLnKfV21WKlas6ILOffv2JXqt9vX777/33/eWwB7loXrkp+a4rF271l5++WU3OKB19Nl0vBVGh+v222+33377zX799ddEj//++++2aNEi93wwu3fvtmeeecYaNmzoAnAdY9126tTJ/vrrr0Sv1ef2zofGjRv7j4++Q8+pvtOkveA1AHHNNde4xz755JNE76fnrr766qDPJaV90/ETVb4H++7279/vWu3oeOs8KFSokLVo0cLmzZuXbHsY7bvOH12JEc78CCNHjnS3CvLbtGnjzsU5c+ZYrPj8889d9X7BggXd8ahevboNGzbMjh8/nq7nSHLzTHjnTzj/jsg///xjPXr0sPPOO889V7hwYWvdunXQ39+ff/7pfg/eb1XnwQUXXOB+vzrnAAAAUoOKfAAAAEScgkmFdffcc48VLVo02dcq6PJs377d6tSp48I7BXEK2BVGq6JfrXimTp0atKWHgvf58+e70LRly5Yu5PYcPnzYtfVRqK7WPgp9vX364osvXBieKVMmu/76610o/Mcff7grBfReCxYscCFkciZOnOgCVYWK2meF5NoXBZMK7WfPnu3aCYlCXh2b9evXu/ueU/UWT+1x0UCJ9uHaa6+1q666yiZNmuQCZLWIGTx4sIVDE7zqKgtV5St09uiza9JXha56LliroMcff9wdnxtuuMHNk7BixQr76KOP3L5rYMALyL3gVPus9/MC1wIFCiTaZnLfaVIKaLVf559/vjsfL7vsMv/7DR8+3A006X3btm2b7OfXa/Q9vfTSSy6UbdWqVaLvTq2FtE8//fSTOz4Kbbdt2+YGCPT9fPzxxy5sT+q5556zmTNnuvOvWbNm7limxM6dO+2zzz5zoXOtWrXc8dd3oaV+/foWbf369bOnn37atTi68cYbLX/+/G6QQeekflfjx49P13MkNUL9O+L97jZt2uS+I333CvYnTJjgvltdGXHppZe6127evNkuueQSN6ij7ei80n2F+6+//robyND5CgAAEC7+FwQAAAAizqtAVrAZDrUFUWimEHDIkCH+x7/55hsXiqnKVa1bFLwHUlW9qsJLly4dtB2Kglftk64C8KjiXhPuqrJWz3lBoahNSfv27V24+MorryS7z9pGz549XRVxIPX+V1g/btw469Chg3tMIboqsBXk6356HxcFoDo2XqsZzUWgSYf1mbRvSfc5OdqGqtcVriqM1ACMAnX1ilfFe6h2NlWqVLEtW7a4quRACq/VomXQoEH29ttv+0NaVdIrpNX9UFXVob7TUBTyq4pe+3nLLbe4wZUlS5a4qya843Eq3r4pyFd4n/T70xUoCvH1XWsyXG/SX7Ui0uCBquabN29uefPmTbSePquC7Ro1alg4dNx1/HX+icJ7hdoKyHUVRr58+Sy9fPfdd27gIql7773X9cnXPAIK8TV4pLBbwbyoGr1r16725ptvusdV0Z5e50hqhPp3RIMk2j8N+ugzeTSwdfHFF1uXLl3cuqLPpatFNEj04IMPnjT4QogPAGcWn49mKIgcziYAAABEnIJWOeecc1K8jqrEVbWs9jQKyAIpgL3yyitdy55gbUpU5RssxA8MWZMGvqNHj7Y9e/a4yVEDQ3xRxbuqqhXon4oqjoMF4mr74oWeaZGW46LgPjBg16CFKr/37t2bql72d9xxhwsjVdkvutXfejwUVWInDWhF1dfVqlVL9fEJ9p0mRyG6gtUffvjBBfgaqFGwrGObJ08eSysNFOjKCwXYXogvNWvWdJXjCne94xZIAX+4Ib6o8l4DNx07dnR/6z11/8CBAyk6b9NCFehqb5N08X73uqJF3nrrLX+I7+2jd3x03NP7HAlXsH9HFOzrnNF3GBjii1poKcTXoFDSFjvBzs1gnxEAACClKAcAAABATFArDVX5KrxTr/Ck9LgqfdWnPWnrELWyCEW9uYMFpWqhIaqGTtqHW7Qv6kuvRQF4KN4ksGqZozBP/b4De9Cr1Ua0jotariTlDa4oWA6XWvSo3YgmVVXLEN3qbz2eHF2FoAplHWsdz2PHjvmfC+eqgFN9p6eiEFn7oisKRO2Pgh2jcGlASP3VVVkebPBK35EqyvUdeRX0KTl3Q1m4cKGbm0D95wPfT5Xjql5XyK8BgvSiwa/kJrvVb0sBvs6PYBRy67xOz3MkNYJ9F96/E2qTFOwqGu9z6FZzAKglj66cuf/++92AhwaQ1Pu/fPnyp+ETAACAjIwgHwAAABGn9hoKtv7++2+rVKlSisNQCdXr3Kss914XKLk+/AqaAyukPaokl9deey3Z/VJ/6+SCfLVOUQWy+uurX7v20+v7rypltT9Ji7Qcl2DtVbzWHkknHE0JVZyr6luBq6qUVSmtCUCTaxeiVi8K/VX1ropmtX/RgIS+E2++gHCF+k5PRd+L2gMpUNdgwF133WWRkF7n7qkmuVVwH0htgtTGR+HzsmXLXDV7NOi3pSA+6UTWSX9X6XmOpEaw78L7d0K9+rWc6vNo33X8Ffqr9ZVaa4kmQFa7rWDzJAAAAKQEQT4AAAAirm7duq7CVhWpKe2T74XOqnwNxmvbESycTi7UDfWctx21xVAlbWpowksNBGgi1R9//DFRxbz2N7kgM6XSclzSw5133mkvvPCCmyRYVx7o7+Qo0FRo/ssvv7igOVBqW8CkJsQXVXtrclm1KdIcCffdd5+bjDat0uvcDebgwYP+tjRq96IlVNiv7yka9Dn1uVRZnxKRPkf03oEV/YF0xYxa+YRaLynvO9M8Cl67rFPRvyeaiPro0aPuM02ePNnNW6DBihIlSrh/HwEAZ4hMqfvfLEAw9MgHAABAxGkSysyZM7se2du3b0/2tV7FuipWFeb9/PPPrs93UhoYEE00GgmXXnqpu1UAn1pqp6LWOpqQM2nbmzlz5gRdR8clnIr4031cTqVq1aru2OlqC1V/q51MctS2SK9JGtBq8lAdv7Qen5TSvACa6FZXD+iYaaJVVUuHav8SDoW9ap2iuQp0XNLzO1JArDBa29IgSrBF54sm3NX8CtGg80MDJX/++WeKXh/pc6RgwYJBvwdNkhtuS6m0/DuhK1j0G9GAnoJ8/Vvx1Vdfhb0dAAAAIcgHAABAxJ133nnWp08fV5GrViZr16496TXq+66KYa/vtPpgawJSraMe3IGmTJliU6dOdduNVDXr7bffbnnz5rX+/fu7NiRJKTT3+mOH4k2SqzYzgX3xN23a5PpkB+NNeLlx48YU7efpPi4pofD7s88+87d4OdUxUsAdWK2u717V8KpYTuvxSamuXbu6UFj98VUxrZ71aoek1kirVq1K8/ZVGa/Po+9dga1n8eLFrj2MqsBbtWqV5vfxjrl+O++8807Q5YYbbnDnyxdffGHRoGMqmgRZgX6wKxSWL1+ebudI7dq1XWj//fff+x/ToEbPnj1T1TdfYb6uggh29YZ+94Hvowr8YC2UvM+mQRYAAIDUoLUOAAAA0oUm3VQY9+KLL7o++WqxowBVVaoK9tVfXSGfXufR5KMKxfSYwnEFaArk1ENbFe+aVDZTpsjUohQpUsSFc+pZfcEFF7hJKVX9risEvBDw8ssvd2F5KOp9rsruCRMm2MUXX+wmH1Vgp6pb3Q82ia6Og6qqtZ4GORTs6f01SWYop/O4pLQqX0tKdOvWzS01a9a0m266ybU80eS8Crv1uTVpa9KJYdXi5JFHHnEDLArACxQokOK2JsF8+OGHbtEx1iSkXtW2HtP7qVJfFdc6N1NLA1fqoa5KeIXU+v7Veknhrz6zBg40cJQWCrtnz57t+rA3atQo2UEqndsK/XXMTzf9lh577DF76qmn3CCT/lZYr9+7PoOuVtG57F3NEelzRIH9t99+a9dcc40bBNNvRNvTa7z5CsKhY6n3bNeunZsf4qKLLnIT9m7YsMGdN7rqSP/Wib7/ESNGWIMGDezcc891V2v88ccfrl++BiD03QAAAKQGQT4AAADShYJlVQ0rJH3jjTdcAKlFFawK0zSppUIttaUJDNfVx1wB4Oeff+4CP6+SecCAAanuZR9KixYtbNGiRa5vugYWFPblzp3bzjnnHLdvmtj1VFRtrWBVYb76aJcuXdoFiX379nWBfVJdunRxIbx6fyugV2ipau7kgvzTfVwiScG5AnIdG4XZClN13HV1QbCJPzVAoIGJ559/3q2jgRWFwKkN8jVopH3QOZe0jY7CVlXQDx482IXCOg9SSwMyM2bMcN+pwnsNYClAbtiwodt2vXr1LK20/wq3db4k11tfgwi62kBhtqrWdf9008SuOr5qKaO5MtTSRnMTlCtXzl2F06FDh3Q7R5o1a+baJmkfFKwrQNd2hgwZkqrfivZZ/07o37NJkya591Z7H51T+oyBgyUaOFCoP2/ePPvpp5/cvunfE11d0Lt3b/fvAwDgDOKjGQoix5cQeN0nAAAAAAAAACDNfrjtSstILn9/WrR34YzGsBAAAAAAAAAAADGMIB8AAAAAAAAAgBhGj3wAAAAAAAAAiLDk5rQBwkVFPgAAAAAAAAAAMYwgHwAAAAAAAACAGEaQDwAAAAAAAABADKNHPgAAAAAAAABEmo8aakQOZxMAAAAAAAAAADGMIB8AAAAAAAAAgBhGkA8AAAAAAAAAQAyjRz4AAAAAAAAARFomX7T3ABkIFfkAAAAAAAAAAMQwgnwAAAAAAAAAAGIYQT4AAAAAAAAAADGMHvkAAAAAAAAAEGE+Hz3yETlU5AMAAAAAAAAAEMMI8gEAAAAAAAAAiGEE+QAAAAAAAAAAxDB65AMAAAAAAABApPmooUbkcDYBAAAAAAAAABDDCPIBAAAAAAAAAIhhBPkAAAAAAAAAAMQwgnwAUffff//ZyJEj7eabb7YaNWpYoUKFLEeOHFamTBm75ZZbbP78+cmuP3v2bGvZsqUVLlzYcubMaZUqVbL+/fvbvn37bNSoUebz+axs2bIh19++fbs9+uijVrNmTcufP7977/Lly9udd95py5YtS4dPDAAAAAAAAKScLyEhISGM1wNAxA0cONCeeOIJdz9z5syWL18+O3DggB0+fNg9piB++PDh9r///e+kdV955RV78MEHzfunTEH8wYMH7ciRI1alShW7++67rUePHm5QYN26dSet/91331mbNm1s165d7u+sWbNatmzZbP/+/e5v3X/77betU6dO6XoMAAAAAABAxrLg7paWkVz61pfR3oUzGhX5AKKuRIkSNmDAAFu4cKEL8Hfu3OnC+DVr1riQXnr27GmLFi1KtN4PP/xg3bt3dyH+lVdeaStXrnSBvEL48ePH27Zt2+zJJ58M+b5Lliyx6667zq3TpUsX++OPP9z7qpJ//fr11rVrVzcgoMp87RsAAAAAAAAQDVTkA4h5DzzwgL322msuUH/nnXf8jzdt2tSmT59uVatWtV9//dWyZ8+eaL2ZM2faFVdc4e4Hq8hv0qSJzZgxw/r162dDhgwJ+t4aSHj55Zft+uuvt0mTJqXL5wMAAAAAABkPFfmIJCryAcS8Fi1auNu5c+f6H1PVvkJ46d2790khvjRu3Njq168fdJsK9bV+lixZrFevXiHf22upoxY8x48fT/NnAQAAAAAAAMKVJew1ACAdqI3O66+/7qro//rrL9u7d6+dOHEi0Ws2bdrkv682O94FRQ0bNgy53UaNGtmcOXNOenzevHnuVu+hiv5QvPBe7Xr+/fdfO/vss1Px6QAAAAAAwBnHRw01IocgH0DUffbZZ9a+fXv/5LaiCW9z5MjhJrpVn/r//vvPPwGtbN++PVGP/VBKliwZ9PHNmzf7g3z10k8J9e8PRfseuP+iqwSCXSkAAAAAAAAAhINhIQBRpSr3zp07uxBc/exnzZrlAvPdu3e7gH3r1q1u4trkKOwPl1dpX7RoUVfZn5KlbNmyIbc3dOhQy58/f6JFjwEAAAAAAABpRUU+gKj65ptvbM+ePVawYEH78ssvLVeuXCe9RmF+UkWKFElUXR8qZP/777+DPl6sWDF3u2PHDlfpnzt37jR8CnMT5vbs2TPRY1TjAwAAAAAAIBKoyAcQVRs3bnS3lSpVChriexPNJlWzZk1/Jb6q+EMJ9VzdunX9lfmTJ0+2tFJor3ZAgQtBPgAAAAAAZ7BMvoy1IKoI8gFElVrQyKpVq+zQoUMnPf/bb7/ZRx99dNLjhQoVssaNG7v7zz//vOujn9Ts2bODTnQrFSpUcBPhSv/+/V0rn+Ts3LkzhZ8IAAAAAAAAiCyCfABR1axZM8uUKZMLyjt06OBvhaNgfty4ce75vHnzBl33iSeecFX5S5cuteuuu87+/PNP9/ixY8ds4sSJ1rp1a9eyJ5RXXnnF8uTJ4wYRLrvsMvv8888TDSZoXz744ANr0qSJ9e3bN+KfHQAAAAAAAEgJgnwAUaXK+N69e7v7Ct/POeccK1CggAvY27Zt625ffvnloOvWq1fPXnjhBXd/6tSpVrFiRRfcax2F+OqD//jjj7vnc+TIcdL61atXtylTprjXrVixwlq1auXWLVy4sGvzo33p1KmTzZgxI12PAQAAAAAAAJAcgnwAUff000/b6NGj7ZJLLrGcOXPa0aNH7bzzzrNHHnnEFi1aZCVKlAi5bvfu3V0f/GuuucaF+Kqo18S3jz76qM2fP98SEhLc6zQ4EKpXviryhw0bZg0aNHCv27Vrl2XOnNmqVKliHTt2tDFjxtjw4cPT7fMDAAAAAICMx+fLlKEWRJcvwUu5ACADUrse9di/4447bOTIkdHeHQAAAAAAcIb4qeuNlpFc8vrEaO/CGY2hFAAZlirt1a5HmjdvHu3dAQAAAAAAAFKFIB9AXFMP/FdffdU2bNhgJ06ccI/t37/fPvnkE2vcuLFrtVO5cmXX/x4AAAAAAACIR1mivQMAkBaLFy+2zz//3Lp162ZZs2a1vHnzuh73XqhfsmRJGz9+vHsOAAAAAADgtPH5or0HyEAI8gHEtR49erjJcH/44QfbsmWL7dy504X5FStWtGuvvdYeeOABK1SoULR3EwAAAAAAAEg1gnwAca1hw4ZuAQAAAAAAADIqeuQDAAAAAAAAABDDqMgHAAAAAAAAgEijRz4iiIp8AAAAAAAAAABiGEE+AAAAAAAAAAAxjCAfAAAAAAAAAIAYRo98AAAAAAAAAIgwXyZqqBE5nE0AAAAAAAAAAMQwgnwAAAAAAAAAAGIYQT4AAAAAAAAAADGMHvkAAAAAAAAAEGk+X7T3ABkIQT4ApKNlwx+3eFGt+5PR3gUAAAAAAAAEQWsdAAAAAAAAAABiGEE+AAAAAAAAAAAxjNY6AAAAAAAAABBhPh811IgcziYAAAAAAAAAAGIYQT4AAAAAAAAAADGMIB8AAAAAAAAAgBhGj3wAAAAAAAAAiDSfL9p7gAyEinwAAAAAAAAAAGIYQT4AAAAAAAAAADGMIB9AhteoUSPz+Xw2cODAaO8KAAAAAAAAEDZ65AMAAAAAAABApPmooUbkcDYByPBKly5tlSpVssKFC0d7VwAAAAAAAICwUZEPIMMbPXp0tHcBAAAAAAAASDUq8gEAAAAAAAAAiGEE+UAG8t9//9nIkSPt5ptvtho1alihQoUsR44cVqZMGbvlllts/vz5QdfTJLCaDFaTwsr06dOtRYsWVqRIEbd+lSpV7IknnrBDhw4l+/7bt2+3Rx991GrWrGn58+d365YvX97uvPNOW7ZsWdB1Zs2a5d5biyxevNjat29vJUqUsJw5c7r3HjZsmB07dsy/zrx586xVq1ZWvHhx9x7Vq1e31157zRISEsKe7Hbr1q32yiuv2PXXX+/eS/ut9z3vvPPsrrvuCrnfAAAAAAAAyfFl8mWoBdFFax0gA3nppZdc4C6ZM2e2fPnyufsbNmxwy9ixY2348OH2v//9L+Q2nnvuOevbt6+7r1D7yJEjtmLFCheCf//99zZt2jS37aS+++47a9Omje3atcv9nTVrVsuWLZutXbvWLR9++KG9/fbb1qlTp5DvPXnyZLvxxhvdgIHe+/Dhw+69e/fubb/88ot9/PHH9s4779i9995rJ06ccJ9Pr1HY/sADD9jGjRvt6aefDuuYPfzww/b++++7+1myZHHbPHDggP31119u0X6PGTPGWrduHdZ2AQAAAAAAgEihIh/IQFTFPmDAAFu4cKELo3fu3GkHDx60NWvW2IMPPuhe07NnT1u0aFHQ9X///XcXbGv5559/XIW/gvnHH3/cPT9z5kx/6B1oyZIldt1117nXdunSxf744w/3vvv27bP169db165d3YCAKvO1b6HoqgFVxmsdbWv37t3Wr18/95wGIRTSa1taVEmv1+gzdu7c2T8IsWrVqrCOmSrvtZ4+g/b533//dYMDS5cutQ4dOrj7t912m23evDms7QIAAAAAAACRQpAPZCB33323q5yvVauWq4YXtZQpV66cq8RXAH78+HHXhiYYBeOPPfaYDRkyxAoXLuweU4W6qvxVKS+qik+qe/fuLgRX6P7WW2+5FjVe1X7p0qXd++kqALXHGTRoUMj9r127ttu+1pG8efO6falfv777W9tXqP7yyy/b2Wef7R4rWLCgq9LXZ1SV/rhx48I6ZmoF1KtXL9eeRxX5kilTJqtWrZqrxleLof3799u7774b1nYBAAAAAACASCHIB84gCqVl7ty5QZ/Pnj27C7WDUaW818M+0Lp162zGjBkuBA+1rngtddSCR4MJwailj9crP9BVV13lv+9V6AfSoEGTJk2C7l96HzMAAAAAAAAgvdEjH8hg1Ebn9ddfd21w1ON97969rlI90KZNm4Kuqyr0PHnyhGzbI2plE0gTz4reo2rVqiH3ywvvVd2u9jVeRX2gSy65JOi6RYsWdbeavFeT5yb3GrUDCpdaCo0YMcKF9RqYUEugpBPnhjpmHrXg0ZJ0YAQAAAAAAJyhghQrAqlFkA9kIJ999pm1b98+UaCs1jg5cuRwle7qU6+gW2F6MGplE4rXdkbtcQJ5veMV5G/bti1F+6n+/eG8v/feKdm/o0ePWjheffVVN3+AN9ih46SJdr0QXi2D9uzZE/KYeYYOHeqfaNij+QraFAhrdwAAAAAAAICT0FoHyCBU5a5JXxXiX3HFFTZr1iwXmGvCWAXsmhx2/PjxEX9fr9JeFfGqYk/JUrZsWYsFy5cvd/39FeK3adPGfvrpJzt06JAb7NDx0vLCCy+41yat0E9KLX90rAOXYG2AAAAAAAAAgHBRkQ9kEN98842rHNfkr19++aXlypXrpNcomI60YsWKudsdO3a4qvXcuXNbvPj000/dQIQm5x07dqyb5Da1x0wV/LTSAQAAAAAAQHqgIh/IIDZu3OhuK1WqFDTE9yaajbS6deu6WwXikydPtng8ZhdccEHQED+9jhkAAAAAADgD+DJlrAVRxTcAZBDq6y6rVq1y7WGS+u233+yjjz6K+PtWqFDBGjVq5O7379/ftZRJTtLJcmPhmC1ZsiRo6xwNTKhFEQAAAAAAABBNBPlABtGsWTNXVa6gvEOHDvb333+7xzXB7bhx49zzyU0WmxavvPKK5cmTxw0iXHbZZfb5558nGkzQvnzwwQfWpEkT69u3r8WK5s2bu9tly5bZ/fff7x9kUIugESNG2E033WRnnXVWlPcSAAAAAAAAZzqCfCCDUGV879693f2JEyfaOeecYwUKFHABe9u2bd3tyy+/nC7vXb16dZsyZYrrl79ixQpr1aqVe7/ChQu7Nj/al06dOtmMGTMslmhgoV27du7+G2+84UJ7zTGgSv17773X9c4fOHBgtHcTAAAAAAAAZziCfCADefrpp2306NF2ySWXWM6cOe3o0aN23nnn2SOPPGKLFi2yEiVKpNt7q1e+KvKHDRtmDRo0cIMIu3btssyZM7tAvGPHjjZmzBgbPny4xRJvn84//3w3Wa16/deoUcOGDh1q8+bNcwMSAAAAAAAA4fL5fBlqQXT5EoI1hgYARMSy4Y9bvKjW/clo7wIAAAAAABnGr31vt4zkomfei/YunNGoyAcAAAAAAAAAIIYR5AMAAAAAAAAAEMOyRHsHAAAAAAAAACDDyUQNNSKHswkAAAAAAAAAgBhGkA8AAAAAAAAAQAwjyAcAAAAAAAAAIIbRIx8AAAAAAAAAIszn80V7F5CBUJEPAAAAAAAAAEAMI8gHAAAAAAAAACCGEeQDAAAAAAAAABDDCPIBAAAAAAAAINJ8mTLWkgZ79+61gQMHWo0aNSxPnjyWP39+q127tj3//PN25MiRsLe3bt06NwdBSpfbb7/9pG107tw5ReseO3bMYgGT3QIAAAAAAAAA0sX69eutUaNGLnyXXLly2eHDh23hwoVuGTNmjE2fPt0KFiyY4m1mzpzZihYtmuxrDh06ZLt373b3NWgQSo4cOdzAQqxPWkxFPgAAAAAAAAAg4lTN3rJlSxfiFy9e3KZNm2b79++3AwcO2NixYy1v3ry2aNEi69ixY1jbLVWqlG3dujXZ5dZbb3WvzZkzp91yyy0ht9W2bdtkt6NBg1hAkA8AAAAAAAAAiLj333/flixZ4u5PmDDBmjZt6u5nypTJBegjRoxwf3/zzTeuKj9SDh065Cr9pXXr1lagQAGLd7TWAYB0VK37k9HeBQAAAAAAEA0x0pIl2kG+NG7c2OrUqXPS8+3atbP+/fvb2rVrbfTo0dakSZOIvO/EiRPtv//+c/fvuusuywgI8gEgHT372fcWL/rc0NAGj59h8aJ/myuivQsAAAAAACAEtc+ZN2+eu3/11VeH7D/fvHlze+ONN+zbb7+N2HuPHDnS3VaoUMEaNmxoGQGtdQAAAAAAAAAAEbV8+XI7ceKEu1+9evWQr/OeUz/6nTt3pvl916xZYzNnznT377zzzlO+Xi19Klas6Ca9zZcvn9WoUcO6d+9uf/75p8USgnwAAAAAAAAAQLIOHz5se/bsSbTosVA2b97sv1+yZMmQrwt8LnCd1Hr33XctISHBsmTJYrfddtspX79p0yYX/ufKlctdRbB06VJ76aWX3ACDrhSIFQT5AAAAAAAAABBhPl+mDLUMHTrU8ufPn2jRY6Hs3bvXf18heSiBzwWukxrHjx+3UaNGufstWrSwYsWKhXztRRddZK+++qqtW7fODUjoagANTmhS3nPPPdeOHDliXbt2dX/HAnrkAwAAAAAAAACS1a9fP+vZs2eix7Jnz26xZMqUKfb333+naJLb//3vf0EHFW688UbXV7927dpuEt6HHnrIPaZ+/tFERT4AAAAAAAAAIFkK7dVDPnBJLsjPmzev/75a1oQS+FzgOqnxzjvv+Nv1hJpgNyXOOusse+SRR9z99evX26JFiyzaCPIBAAAAAAAAABFVokQJ/32vSj6YwOcC1wnXtm3b7KuvvnL3O3fubJkzZ7a0qFOnjv++euhHG0E+AAAAAAAAAERaJl/GWsJUpUoVy5Tp/+JnTSAbivec+tkXKlQo1Yd79OjRduzYMdcC54477rCMhiAfAAAAAAAAABBR6jdft25df+/6YBISEmzq1KnufrNmzdL0fiNHjnS3jRs3tvLly1tazZ8/33+/XLlyFm0E+QCQjDlz5rhZzosUKeIuydKobqtWraK9WwAAAAAAADHvtttuc7czZ860BQsWnPT8+PHj/W1rOnXqlOr3mTt3rq1cuTJFk9x6AwjJ2blzpw0ZMsTdL1WqlNWsWdOijSAfAJIZeb3iiivsm2++sX///ddd3lW0aFErWLBgtHcNAAAAAAAgLoL8GjVquOC8devWNn36dPf4iRMnXIjfpUsX97cmpm3SpEmidQcOHOgKKrWsW7cuRZPcKru58cYbT7lfH374oXvdhAkT7J9//vE/fvDgQZs0aZLrj+8NMDz33HP+FkHRlCXaOwAAsWr48OGut5ouA/viiy/S1KcNAAAAAACcYXzh95XPaLJkyeIyFbW7URjftGlT13JHQf6hQ4fca1TtPmbMmFS/x549e9yggHTs2NGyZ89+ynWOHz9un332mVskd+7cliNHDtu1a5d7TrSdF154wdq2bWuxgCAfAEJYsmSJu23Xrh0hPgAAAAAAQCqULVvWFi9ebMOGDbOJEyfa2rVrLWvWrFatWjVr3769devWzbJly5bq7Y8dO9YOHDiQ4rY6ooGFwYMH248//mjLly93nRh2795t+fLls/POO891aLjnnntioje+x5dwqoZAAHCG0j/WGi1+7733rHPnzqnaxrOffW/xos8NDW3w+BkWL/q3uSLauwAAAAAAQEi/DbzfMpILB74W7V04o0W/uQ8AnAYK5Lt37+5Ge/PkyeMu46pcubI9+OCDtmHDhkSvTdp/7fbbb/c/lpK+bAAAAAAAAEAk0VoHQIanPmt33nmnHT582N/jTJOUaDZzLaq4//TTT61Zs2bueU1oK9u3b3c923RZVc6cOf3by5w5c5Q+CQAAAAAAiBc+HzXUiBzOJgAZ2rRp06xTp05uopI+ffq4PmyagXz//v22YsUKa9Omje3du9fdepX5W7dudUupUqXc3y+99JL/scDHAQAAAAAAgNOBIB9AhqVq+vvvv9/dvvbaa/bMM8+4CVa8FjmVKlWycePG2XXXXedmONdM5AAAAAAAAECsIcgHkGHNnj3b/vzzTytcuHCys5arYl+mTp16GvcOAAAAAAAASBl65APIsObNm+dud+/ebSVKlAj5uiNHjrjb9evXn7Z9AwAAAAAAGZzPF+09QAZCkA8gw9q8ebO7PXr0qG3btu2Ur1fv/NTSRLreZLoeTaoLAAAAAAAApBWtdQBkWJrgVi699FJLSEhI0ZJaQ4cOtfz58yda9BgAAAAAAACQVgT5ADKsYsWKnbaWOf369XMtfAIXPQYAAAAAAACkFa11AGRYdevWdbdbt261hQsX2sUXX5xu76U2OrTSAQAAAAAAQHqgIh9AhtW4cWM777zz3P0ePXr4J7UNZefOnadpzwAAAAAAQEbn82XKUAuii28AQIaVJUsWe/PNN93t3LlzrUGDBjZ9+nQ3+a1nzZo17jW1a9e2119/Par7CwAAAAAAAARDax0AGVqTJk1s/Pjx1qlTJ1uwYIE1bdrUsmbNavny5bN9+/bZ4cOH/a9t1apVVPcVAAAAAAAACIYgH0CGp4B+9erVruJ+8uTJ9ueff9quXbssd+7cVrlyZVeN36JFC7vmmmuivasAAAAAAADASQjyAZwRzj77bBs4cKBbUmrdunXpuk8AAAAAACADy+SL9h4gA6FHPgAAAAAAAAAAMYwgHwAAAAAAAACAGEaQDwAAAAAAAABADKNHPgAAAAAAAABEmo8aakQOZxMAAAAAAAAAADGMIB8AAAAAAAAAgBhGkA8AAAAAAAAAQAyjRz4AAAAAAAAARJjP54v2LiADoSIfAAAAAAAAAIAYRpAPAAAAAAAAAEAMI8gHAAAAAAAAACCG0SMfAAAAAAAAACKNHvmIICryAQAAAAAAAACIYQT5AAAAAAAAAADEMFrrAEA66nNDQ4sn/dtcEe1dAAAAAAAAQBIE+QCQjla9+6LFi4p39LCVbz9n8aJSl942/Mu5Fi+6t6wX7V0AAAAAAJxOmWiGgsjhbAIAAAAAAAAAIIYR5AMAAAAAAAAAEMMI8gEAAAAAAAAAiGH0yAcAAAAAAACACPP5fNHeBWQgVOQDAAAAAAAAABDDCPIBAAAAAAAAAIhhBPkAAAAAAAAAAMQwgvwIGDVqlOt5VbZs2WjvCtJg4MCB7nts1KiRnSnnZ0b9zAAAAAAAAFHny5SxFkQV3wAAAAAAAAAAADGMIB84gxUuXNgqVapkpUuXjvauAAAAAAAAAAghS6gnAGR8DzzwgFsAAAAAAAAAxC6CfAAAAAAAAACIMM1LCMR9a52NGzdanz597MILL7T8+fNbzpw57dxzz7Xrr7/eRo8ebYcOHTppnXnz5lnHjh2tTJkyliNHDrfeJZdcYs8884zt27cv6Pt07tzZ/Wh0m5CQYO+8847Vq1fPzjrrLPe4JgINtG7dOuvevbtVq1bN8uTJY7ly5bLKlSvbgw8+aBs2bEjRZ5s2bZpdffXVVqRIEfe5tK1BgwYF/UzBJhydMGGCNWvWzM4++2zLlCmTez7QokWLrFOnTv7jULBgQbv88stt+PDhdvjw4ZO2r2Oq7d94443J7vdff/3lXqdlzpw5/scPHDhgH3/8sXtPfV/6XNmzZ7cSJUpYq1atbPLkyclud8WKFXb33XdbxYoV3fHUPpcqVcouu+wye+SRR9zzwZw4ccLGjRvn3qNkyZLuPfXetWrVsr59+9rSpUtDfteRnpg4Lccg6XvOnDnTrVO8eHHLnDlzsvubUvPnz3fbVKscnXNql9O/f/+Qv4uUTnY7depUd96cc845li1bNsuXL5+VL1/enZ/Dhg2znTt3Bl1v79699vTTT1udOnWsUKFC7ljpO2/Xrp39+OOPIfdH36n26YorrnD/Huiz6D1r1qxpjz76qO3YsSPkuseOHbO33nrLfRYdh6xZs7rfuY5F27ZtbeTIkSHXjcTvHgAAAAAAAMhQFfkffPCBC3a9YFsBYd68eV1gtmbNGvviiy/s/PPPd4GpF+j26NHDXn75Zf82FLbt37/ffv75Z7e89957LnRUuB2MQvw2bdq4kFzhuAYBdBtozJgxduedd/rDcIWPes3KlSvdovf49NNPXYgZyuuvv+5alej9ChQo4MLFP/74wx577DGbOHGiTZ8+3QXvoTz00EP2wgsvuHBV6yfdxxdffNG9RtsXfQ4dB4WjWrSPU6ZMcSGx59Zbb3XH9Ouvv3bBq4LVYD788EN3W65cOTfY4VGYfvvtt7v72i8Fq1myZLEtW7bY559/7hbtk4LdYIMaLVu29B9Thau5c+e2TZs2uWXBggXu+086WKHAtnXr1jZ79mz/YzoeOmd+/fVXt+g7mTRpkp0OaTkGgV566SV3Luv703enID+t3n33XevSpYv7nYi2q2B6yJAh7pzTby01nnzySRswYID/b4Xb2u+1a9e6Rd/txRdffNIgwG+//ea+c32/os+odfX3J5984o7l4MGDrV+/fie957XXXmvr16939zXgo/X+++8/t00tGhTRb0jhfKDjx4/bNddc4/bJ4/02dM6vWrXKva9+30lF4ncPAAAAAAAAZKiKfIXJt912mwtk69at6yq/Dx486IJbhW76W6Gkwl2PwkSF+KpQf+211+zff/91Fb9aT9XNqtZV4KbKYS/MTEqBpsJWBa0KBhXu7d6926666ir3vAJAVVsrENSVAgoqtX3tkyrGNQig99RtqArd7du3u6rem266yb1G77Nnzx574403XDioSvpgQaLnl19+cSG+qs23bdvm9lHv7wXIX331lfXs2dOFqaqy16DHrl27XNW1rmLQYMjixYvd++tzeBSqavDgyJEjLswMxQvyFfwHXvqjdXv16mVz585176X31H5t3rzZnnjiCRfOP//8826wIKn77rvPBaQKQZcsWeL2QcdFx1bV11o/aXW8Bj9UXa4QX8dNV1z8888/bj19B3///beNGDHCqlataqdLWo6BR9+pwn6d/zo/tA0dBw3ypJYGNO655x533itQX758uf+c0BUEW7dudYF8uBSm63OJzjkdc31eHX9tX7/Trl27unMukAY29JtSaK/f48KFC91n1O9An1+fVcG+rsQINgjTsGFDF9br/bWefuv6t+K7775zV99oP2655ZaT1tNn1W9Y4b+uuvH2U9vQ++r3r99FUpH43QMAAAAAAAAZqiJfAW23bt1cEK2Kb1XWBgb2uq/HA6vBVVk8dOhQ12Lj22+/tQsuuMD/nMJThZfff/+9C3UVaipIVQiclIJNDQbo/QOr+rUoBL3//vvdrUL3pBXMqv5VAK7wXNtX2K42NsHaryiIHDt2rL+SXvt97733un2966677LPPPnNXENSuXTvoPio0VUsSj4Js7yoDBY1Sv359d2WBV82t46bwXRXr1113nf3www/ufbzgUtu4+eabXfitwF/7k5Sq+VevXu3ua1uB9Lm1JKWq/8cff9xVTffu3dsdX72/R+G72vWIwtnAqwQUuKqNiZak3n//fddGSYMJCmBVaR1I7WxSW2WeWqk9BoEUSCvcVoW3R9+hWsikltrN6HeltkXffPONO99E55va2GgAonnz5mFvV1dK6Peg7WqAIpAq3ZP+TgP3R9+7wnZVugfSQJwGFbRPOs91FUbS36q++6R0fjdp0sT9e3Heeee537kGVALfX+e8KJQPHCzTOaT3veGGG9wSKFK/ewAAAAAAgKB8UetqjgzotJ5Nqp5XxavXIiYwxA9FAbCqZRVGBob4gVQV7AWCaq8TjMJDVS4Ho8rvP//80/XVVtgeikLC5N7DCzKTtsMRVdWrz7go6A9G66kaPxhV2qva2nuPYC1ZVHmvqmWvQjmQF84HBvZJ2x2JeporLA1HixYt/NsOvBJA34t3LFSpHU6rGFGAnzTEj1WhjkFSwdrJpJYqzr1zUYMIXogfSNXx+k7DpUEhUTW6qtNTQgMVH330kbsf6jwO/B39/vvvrlo+pTTopoEyUZAfbH91BUJKRfJ3DwAAAAAAAGSYinyvarZYsWKut3ZKqDJbVI2v9ULxJvX0+msnpQr4UAMH3nuo1Y6qvUNRW5jk3kM901UtH4wCbV09oPY1ajcSjAJ0VQ8H462j9/DCzGCuvPJK++mnn056D7UxUuW3KuS1D4E96fW51Ls8MLRMSoGr+v/re1C/cR2rpIG1rkhQ+xsFo6JgWZXUal+igRhdCaDAW62QQn0Xqi7XFQvewEQsSc0xCKTjcdFFF0Vsf1SZ7rWS0uSwoei55CaYDUYDQvoMGoC59NJL3XfXtGlTV6UeasZ1tYby5r1IaT95/ZaKFi2a6DG1kNLAks4DHXMd06S8/vseDfjoShZVzmuiaZ3H+p0k93uO1O8eAAAAAAAAyFBBvlctG2pC2mDUg1xUFZySyuBgoZ+ECsgD3+Po0aMpqhBWD+1gFHyqjU0oJUuWdLdqPRLuPnrrnOo9vKr/YO+hqnwF+EmDfLVkUT9+hett27Y9aT2FwApKVQEeWB2tdjIKdRVma44D0XcUGGKrX7lazaj6+qmnnnKL3kcDK2pZojYogZPvqie6vodwz5P0lpZj4DnrrLOCXq2RWoHfsXduJXdOhEMV7rqqQy1yli1b5m9JpbY6DRo0cK2adK6ohU/S35GktNI+8PeqQYmOHTsmuppEA1e6msYb+FHorsGCpP8WqM2O5lLQ1Sqa7FmL99k1AKFgv3HjxunyuwcAAAAAAAAyVGudUJW8yfEqntWqQ731T7XMmjUr6HaCtaJJ+h6qPE7Je2hJD8ntYyR47XVUle9VIwe21bn22mtdaJq0Qr59+/YuwL7wwgtd6K+JS9VyReGnBmfmz5/vf33SY1O6dGlXOa5g9X//+5/VqlXLBbZ6f/X811UIM2bMSNM5kt7SegxO1/cbaQrA1QpL8ypogt4KFSq4IP3LL79055KurNDks57AqxMUeqfkd6SrVDwjR450Ib6Ok+YdUNsbTZSsQSYdYy3evA/BjrHaC2l/1bZLrbY0MKbKfbXn0lUJmrDWGyRKj9+99lXnReCixwAAAAAAwBkqky9jLThzgnyvNU44LSpSs87p2K9gVJHtteEIxgs9k6u8D8VbR++RXDjotRwJ9h7ly5d3LXYCw3u1gfn6669DttVRJbqOi8JVtTxR2xL1vg90qr7kqkJXr/aXXnrJtfxRMKuJUBXy6/1V9e0dN1Xne1Xe4X4fqt4Wr71LMAqiwxWJY5AeAr/jwEA9qeSeO5XcuXO70F5huNoJ6fxS5bsmKw6s1JfA1lep+S15c0eoX/0TTzzhBnmSXsFwquOsFjndu3d3kz1rkEVzS3j97z/99FM3qW16/duiSbl1xULgoscAAAAAAACAuAryL7/8cn8YF6pPfFJe8Pzdd98lG9Cmhfce4exXqMrtOXPmBH1O1bzff/+9u5/S+QECeevoPbztBKPjJGpdE4wX1o8bN86F57rVwIBawQSbWHbjxo3utkiRIiHbt3jvmVIKwRXeqwJbFLguWbLEH8Z7E/aq8jsc3tUE3j4Hs2DBgrC2mV7HIBLUb98LujWRdCiBVzyklT6/rqR46KGH3N+a/yDYPBThfneBx1mV/qHmwQj3+6tRo4a9/fbb/t944P5G6ncfOJGxBooCl0hObgwAAAAAAIAz12kN8tWjWlXh0qNHj2Sr1z133HGHC3dViT5gwIBkX6vteZPehrtfqv5N6X6pojyUwYMH+ycgDfT+++/7g8pgfehP5fzzz7eqVau6+4MGDTppklVRyxcv6FQrmGDU21w99lUJr7DVq8xv165don7nHlUVe2F7sD7iqtB++eWXg77XqY6jJn/1BFZeq2++93m0pNQFF1zgbjVJarAwf/ny5TZx4kQLV1qOQXpSH3tvUtlhw4YFHejSAIM3yXQ4TtUSxvvuAr83Ve9rgEZUtb9hw4awfkfecdZ8CsFofgW1M4rU/kbydy/6XeXLly/Rktx8FgAAAAAAAEBMBvlqTfLqq6+6Puhz5861Jk2auFsv+FaQph73mvDyjz/+cI+de+659thjj7n7zz77rKsoX7p0qX+bqlD/7bff7Mknn3ShnO6HSwMFb775prvV/mgyz+nTpyfqp71mzRr3GlUdv/7660G3o4lPtb7CTK/FjcLVt956y+677z73tyZ49SrOw6VwVFT1r17h6gcu2k+1qvHCe135oB7hocLfli1buvtq++H1yvf65yelSUQV0OqKAg0CqL2KaCBh6tSprsd5qL72CpA1AKGe5QrRve9Z29Jz3jHRhKR6nUf7ovfV61q3bm3PPfecfyJZb5JSbVPzJgTS59IEtDoe2teVK1f6j8/nn3/uer7rs4QrLccgvSnc1u9qxYoV1qJFC/9n1u9CV1tof/Wdp+ZcUwshDfR457IXmGu7+k5E7xloyJAhrr2Nvq86deq49QPD9+3bt9uECRPshhtuOGmwqXnz5u5WFfT6zXjBuirmFbTr968Jg4PR+a5Bv8mTJyeakFjhuwa+9HtOur+R+t0DAAAAAAAEo7woIy04g4J8UTioftuqVFV4Vr9+fReAq7WLwlJVySqUDqyOVZCvRSeMgkG1y/DWUa9uteJQtb6qsFN7UmlQYfz48a7ti6ravdDXew8NKCh4VguOUO+h1isKmBV0lipVyvV7V1XuPffc4wJ9VYx77WRSQ5PRvvDCC+79J02a5K5uUDsZhdca/NDkmjo2+hzJTazqtdf55Zdf3G3lypVDDi6oSlrV3jJ79myrVKmSO0Z6TwWvah/y3nvvhXwvtczp2bOnu5pAx1HHU+1X1NZEz+n4fPTRR4n2V8Gqepzr3NBxUysX9YPXZ9V7q72LtumF1oH7Onz4cHd8NPmsPpe2r31V0Kue/BrwCVdaj0F6UsslBcz6zGqho8+s4F77pis/ihYt6iaODZcGXTRBsc4Vncv6vSlEV2W7tqvPXKVKFXc+BipevLi7CqBixYpuwEXra3+0rvZJ36MGoXT+Jr1yRe16tP8ahNBvRu+l71wDA/pe9Zh+A8Focl19B2oPpXW8HvV6X/3boUEYva/XLz+Sv3sAAAAAAAAgwwX5onBPFcSalFIBr4JbBXFlypRxgavCeoWEHgVoCmA1cWXXrl3dcwp+FSYqtFMFeu/evV2Vt9f3OjX03qtXr3aDAgq2FTyquleDDgrhFQIqYNZ7hXL//fe7Km0FvGrjoUXhpPZfk6aGqihOKVUmK1RUcK+A9cCBAy7wvOyyy9wggtrKKPg81WCKBh08oarxPffee6+bEFeV5zomCloVpmuiU7VB0eBBMKpi1qCGgtBatWq5cFSDDQpIL7zwQhfQq1JfgX1Seq2uzvjwww/9+7t//34XKGtbDz/8sKv+TkptebSvV1xxhQvxta8KlZ9++mk3t0BqKvLTcgxOh7vvvttdWaErEjR4pKp5/ZbUn/2nn37yzx0Q7jZVFa+q+erVq7vjru9O29L3pWD9119/TTTBrUe/T/1WR4wY4Vr/eN+7wnRdNdOmTRu3bZ0bgRT46zesfxfKli3rfuP6t0HH/OOPP3aV8aG88sor7ioCBfkVKlRw76V/U/RbuO6669xVAArsk06eG6nfPQAAAAAAAJCefAlKvAAA6WLVuy9avKh4Rw9b+fb/tU2KB5W69LbhX861eNG9Zb1o7wIAAAAA4DT646Xk5/uMN1UffCLau3BGi0pFPgAAAAAAAAAASJksKXwdAAAAAAAAACClfNRQI3I4mwAAAAAAAAAAiGFU5ANRNmzYMLeEo1evXm4BAAAAAAAAkPER5ANRtm/fPtu2bVvY6wAAAAAAAAA4MxDkA1E2cOBAtwAAAAAAACAD8fmivQfIQOiRDwAAAAAAAABADCPIBwAAAAAAAAAghhHkAwAAAAAAAAAQw+iRDwAAAAAAAAAR5stEDTUih7MJAAAAAAAAAIAYRpAPAAAAAAAAAEAMI8gHAAAAAAAAACCG0SMfAAAAAAAAACLN54v2HiADoSIfAAAAAAAAAIAY5ktISEiI9k4AAAAAAAAAQEay/PXBlpFU6do/2rtwRqO1DgCko5UjX7B4UenOnrZixLMWLyrf08de/foHixcPtLg87o4vAAAAAACIDQT5AAAAAAAAABBhPh9dzRE5nE0AAAAAAAAAAMQwgnwAAAAAAAAAAGIYQT4AAAAAAAAAADGMHvkAAAAAAAAAEGk+X7T3ABkIFfkAAAAAAAAAAMQwgnwAAAAAAAAAAGJYhgzyfT6fW2bNmhXR7Wp73rYzqjPhM55pRo0a5b7PsmXLnvTcwIED3XONGjWKyr4BAAAAAAAAODV65CPurVu3zoXVXjANAAAAAAAARJ0vQ9ZQI0oyZJBfqVIld5srV65o7wpOU5D/xBNPuPsE+eEpXLiw+72ULl062rsCAAAAAAAA4EwK8lesWBHtXQDiwgMPPOAWAAAAAAAAALGL6zsAAAAAAAAAAMhIQb4mxdTkmGphcuTIEXv66aft/PPPt9y5c1vBggXtyiuvtMmTJye7jaVLl9rdd99tFSpUcO1v8uTJ47bRv39/27FjR9B1kk7KOWHCBGvWrJmdffbZlilTpkQtVUJNdqsWLN5zuv/nn39a586d7ZxzzrHs2bO79iL33nuvbd68OUXHYvXq1XbHHXdYqVKl3PraTpcuXezvv/9Odj0dt9dff90aN27sWptky5bNihUrZtdff32yxy7wc/3zzz/Ws2dPq1ixojuGgZPTHjhwwD7++GPr1KmTXXjhhVakSBG3fyVKlLBWrVqd8vuJpK1bt9orr7ziPluVKlUsf/78ljNnTjvvvPPsrrvusmXLloVcV9+NPpduExIS7J133rF69erZWWed5R5XX3xN4KrjmPQYeYvWTWrv3r3uvK1Tp44VKlTIHRt9h+3atbMff/wx6L4kPXf++usvdw6XK1fOra/9+O+///zfxbhx45I9Lo899ph7Xfny5d1nS6v58+e771bnk46v2uXo97Rv375k1zvVZLdTp061G2+80Z3bOk/z5cvn9lm/vWHDhtnOnTuDrpeaY+z926B9uuKKK+zcc891n0XvWbNmTXv00UdD/vsgx44ds7feest9Fh2HrFmzunNFx6Jt27Y2cuTIkOvqO+3evbtVq1bN/Xuk77Fy5cr24IMP2oYNG5I9hgAAAAAAAMH4Mvky1II4ba2jMLpp06Y2Z84cy5Iliwu/du3aZd99951bBgwYELRf+bPPPmv9+vWzEydOuL8VmB09etSWLFnilvfee8++/vprF9yF8tBDD9kLL7zgAsgCBQq4ID9cCxYscKG7Akfte+bMmW3jxo02YsQIGz9+vE2bNs0uuuiikOvPnDnTrrvuOheU5s2b130eBfgKm7/55hv76aefrGTJkiett379emvRooU/wNZnUFC5bds2++KLL9yiwYQ33ngj2QEEBaJaJ0eOHC6wDKQQ+fbbb0+0fX1HW7Zssc8//9wtOoYKYtPbww8/bO+//767r33QvmigQUG4lg8//NDGjBljrVu3DrkNBd1t2rRxgzf6rjUY4H3nGqTYs2ePC9GlaNGiidbVawP99ttv1rJlS9u0aZP7W9+7zkH9/cknn7hjN3jwYHeOhvLDDz/YPffc4757resdfw1k3Xzzze7zKlDW/WCOHz/uznPRYEbgIExqvPvuu+5c9n5T+swKpocMGWITJ050Aw6p8eSTT7rfsUefVd/F2rVr3aLfyMUXX3zSIEBajvG1117rfiOic1vr6bvVNrVo8Gb69On+eTACj+k111zj9smj47B//3432LBq1Sr3vnfeeedJ76nzT48fPnzY/a1BB51fK1eudIu+q08//dQNXgAAAAAAAABx1VpHFeUKq998800XhitsU+XqTTfd5J7X5KMKpQOpIrZv374unFOQp2BZQZuC3YULF7oqXD3mBeTB/PLLLy7E13YUZCuk0za84DqlFMSqmlqBvvZf21D1sarytc0bbrjBPR6Kgmft7/Lly12QrPUVUirUV0V/sJBSr2nevLkL8RV+qrL+4MGDbgBEiz6XBhV0TF966aWQ792jRw83gKFAU9vU+ytw9ChQ7tWrl82dO9cdR21br9N+6XtR8Pz888+f9P2kB1XeP/fcc26QRp/133//dYGpKq87dOjg7t92223JXgWhMFqDDxp40Hmm72f37t121VVX2c8//+yeD7wCIHAJPI46t7SOAmVVmeuc0z7p+OlcUpW8QudHHnnEJk2alOy5o8ptvbeOq47xt99+656777773O2MGTNszZo1QdfXQI8GfTSwoSs60uLXX391+6MQX+eUzkd939onXZWhY6BAPlwK070JhHXlh/ZXn1W/CW1fA3hdu3Z153ugtB7jhg0burBe7++dL4cOHXKDg5dcconbj1tuueWk9fRZFeIr/Ndgmref2obeV+eI929TIK2jK1c0ENCnTx83QKF19Fk114YGkLQt3VKZDwAAAAAAgLgL8hWkKsxXiKjwTNQ6Q2F2gwYN3N8K6zwKwxQui6pb9ZzayYiCvVq1arkgXbcKARXGBaOAUsGi2naoGturoC1TpkxY+68QVSGewkFRVbQqbqdMmeJaiCi0U6AeilrWfPbZZ679hmgdVWBrgML7jGr1EUhBvcJBhZUKfnWrffeqhxXQjx492v09aNCgk9b3qFpYwaYGErzKdLXY8aiNjcLzunXrukETT/Hixe3xxx93ldry8ssvW3pTOxR979WrV3fH3Nt/BeGqxtfVCQpNVVUeir5zHTtdRaCKftGAhz5PuPuilkQKglXdr3PNq6ZXiyYF3rpiRIJdTeJRuxYdf1Wje7zjf+mll7pzQ5Xrb7/9dtD1Va0vGrDyfgOppc+k80TvrwEC73zU59JVG2PHjnWBdrg0wKXBAW1Xgz5qy+TRuaoWR6+99po7hpE8xrqaQQM7GlDz6LfVpEkTN3ClKy40eKFBqqRXSYhCeVXX6/zwftd6Xw3M6UqbQPp8999/v7vVZ3nmmWdciySvhZKq/lXFr+9JAxE6BwEAAAAAAIC4CvIV2gergldIqzBPVHmuSmxRqKdAUS1zVLEbjILe9u3bu/sK9YPucKZMrho/rdS+RgFfUurj7lXuKgQNRQMRwVr6KEQXVfWqB38gr0e3BiKStsPxqM+5wmr1AtfVB8Hceuutrmd5aik8F/UqVyVyNHn7kjSYDaQrDDRglBaq6v7oo4/c/eTOHwXB8vvvv7tK7mAeeOABf1AcjFeVr8pytY0KpIpyb46CtH4m/Z6830nv3r1dP/mk9FtTn/pw6YoP8a5WOd3HOBgdcw1+BTtfvP3VFQgpNXv2bPcbVT99tTg61f6G+jcJAAAAAAAgKLVTzkgL4rNHvjfpbTD169d3obwqhdVao0aNGjZv3jz3nFp/JFeFrABcvD7ZwVq1BAvgw6Vq9uSeUyC5ePFiF8QGC91VeR1MYOVy4ESgCnC9z6SKYV2FEIrXVkivD/Y+qrQ/FQWkumJClf/qD64rKJKG9mpppFY1CjLTkwJbzT2g8FW92/X5kk7w6vVTD6Z27dquKjstNCiioFlS2utcxz9pz/2UHH9Vo+sqBIXKX375pWsx49GVB/oe1NZJE0OnhSrTvb74pzqfk5tgNhhdqaLzQq1ydA5q4EtzYqhKPdTvPlLH+KuvvrIPPvjAtS7SeazzNKmk54v64+sqHbWLuvrqq134rtA/8PeYlPdvkn4byb1O84F4+woAAAAAAADEVZAfbCJXj1rtqP2IQji12RCvB7qCPi/sS06w8E4iEeKfav+95zQQoTA+WJibtDe4x2sfI4HV2IE94FVtnxKpPQYKbRVsBrZUUTWz2uwohFWQ7O2Dqq3TM8h/9dVX7cEHH/QHznp/tWbxWgp5/dOTq/qOxHceePxTWgWe2uOvY92xY0c3YbHa6HhBvo6Bd1WGJqdN6yS33m/rVOdzaq7eUIW7+s5rUEJX1nTr1s09ru9OrbPURqpt27aJBrnSeox1fHTc9L6BvyddkeEN5Ch0178fSc8XtfpRaxxdDaT2WFq8z64BCAX7jRs3TrSOt7/6naZkf71BRgAAAAAAACBuWuuEy6sGV/inauxTLarcDia5SvZYFlgNr6sSUnIMOnfuHPYx0OCD2hMpxFevdvVNV1CuFikKK1UlPn/+fP/rk1bGR5I+Z/fu3V1Aq8lCNTmyQlhdBeBNRuv1HU9uPyLxnQcefwWyKTn+uuoktfvjtdfRPAzeuayrI1TVrXA63MmZo0EBuCZ/1bwN6ltfoUIFF6TrKgO1d1KbLF1pEqljrEEOhfg6vprLQW1vNBmyBtO888VrexXsfFF7Ie3viy++6FpUacBFlftqcaSrEnQOBg6uefurKw5Ssq+n+q1oX/VbC1z0GAAAAAAAABC1ID8wwEtK4dW///6bqHrZa6cTK+0pktt/7zkFroUKFYrI+wW2E0rPY6BqfG1fYahalKjNSNKrB8LpI54WmvBXYanmHdB8A8Fa5JyufTldx9+jdlKXX355oip8b/JbzaOQ1kluk14ZkJLzOTVy587tQnuF4WrRpGBcle+66iawUj8Sx9ibk0L96p944gnXRivpPBSnOl/UIkeDR5qIWgNXao/l9b/X+airJJLub6TOh6FDh7orFgIXPQYAAAAAAM5QvkwZa0FUpfob+P7770NWqM6ZM8dVhsvFF1+cqK+4+mir73a0zZw585TPnX/++SEnpQ1X2bJl/e1PVNGcXjZu3OhuixQpErLdynfffZdu7x9sXy644IKgEwNHal8Ctx3qnAwcREjP4x+sKl998RWme+979913R2T7F110kf+zJ3c+z5gxwyJF51SfPn3soYce8l9xEKlj7J0vqvQPRnMrLFiwIOwBFQ2geP/+BO6v95gGBzSXR1r169fPXbEQuOgxAAAAAAAAIGpB/oYNG+z9998/6XFVIA8ZMsTdr1q1qgvSRG0t1HdbrS169uyZbJsKbSOwv3t6ePPNN4P2ql+5cqWr3PXaAEWS+qKLKrQXLVqU7GsDJ8oNh6qARdXIwfp+q6L65ZdfTtW2U7svS5YsCfp9T5482WbNmpXm98mXL5//fqjzRpXl6vcuqijX+Zsexz+QznnNFaFe7HpvnfuRmOTWo9+TN6nssGHDgs49oYGSH374Iextn6olTM6cOU8aREnrMfbOF02OHMxTTz3lWkRFan/VM19V/9KjRw//pLYp3d+kNO+DzsXAxZsLAgAAAAAAAIhKkK/QTRXHqnb1AkRV1Ko/u1cdPGjQoESh4/Dhw/0tNFq0aOGqa71JUHWrnurPP/+8VatWzbWFSU8KVRWo/vzzz+5vBc0KPa+66ioXCpYqVcruvffeiL6nqpg1sKHjpRBRE8F6LYi8EFrhtibmrF+/fqreQ5N+KlDV59GEpGqHImpxM3XqVNeTPK2TrKZU8+bN3a1asNx///3+IFQTlY4YMcL1O1fQnVYVK1b0V4K/8847IQeJNMCk1isawKlTp4598MEHiYLh7du324QJE+yGG25w53FaKcT15jmYPXt2xCa5TRpuq43SihUr3G9KA1GiK2LGjRvnzgH99sKlIF5tmXSMNPjj0W9D233uuefc33rPSB1j73zRvymaJNgL1lUxr6D92WefDXm+qCf+HXfc4X4/gYM5Ouf079D06dNP2l+1ztKAnm7nzp3rJvHV6wL76K9Zs8a9RlcbvP7662EfRwAAAAAAACCqQX7Xrl1d2xy1CVHlqXrJly5d2oV88uijj7qwLpAmzFSPaoWuCtwuu+wyy5UrlxUuXNj13FYFf69evVwomd5hs4Lkv/76yy655BLXQz5Pnjwu2Fe/bAWfEydOTFTpHQl6jylTprjPrbYb6i+uFjgFCxZ0AyO6veaaa1z4earq4FC0HVVne+FxpUqV/J9PQane97333rPToUmTJtauXTt3X9+7Qljvs2qQRL3zBw4cmOb30TmkPu6iti/6rGXKlHHtjHQ+eYoXL+4GaxT8q0peAyb6rrVfWkc95zW4MGnSJP8AU1rpc3rncnpMcqvfoAJmvYda6FSuXNl9Jn0eXVFStGhRN3FsuPT5da7qGGlQS8dYx0mV7dquziN9f95kxZE4xhro0v5rEOKee+5x76XzRQMDGgTUY9dee23Q/dXkujqv9fvxzjEtet/HHnvMDe7ofb1++YHn6Pjx491vRAOLmuBXA2Hev0nnnnuuG7BU653TNQAGAAAAAAAyBmUJGWlBnAb5CuNVvaoKXIXFqtRVcKZg7Ouvv3aVwqGCTVUNK2BV73RVLauCViGfQkmF2+pjHYmK6ORceumlLpxT0Kj9Vnio/t+qmFYrGK+3f6QplFT178cff2zXXXedCz4PHDjggnsFzy1btnShpVfBnRo6xvoOVH2v4+p9Nh1btS3x2h2dDmPGjHGfR/MN6LvWlQF6f00COm/ePLd/kfDaa6+5QQHvs6mtiwZlkrZPUvisCVA1kKO2NAps9+zZ44JetVlROxxVg3sDUmmlbV544YURneQ2KQ2m6Vjq3NGAmn6LGshQf/affvrJBdup2aaOg36H1atXd0G+jpO2patF9J3++uuvQT9Pao+xAn+1AdJktfot6EoDDX7oPNbvRZXxobzyyivuKgIF+RUqVHDvpXBfvzf9znQVgAL7YHM1qJp/9erVNmDAADewp3NS/ybpfNW/UQr/NXlu7969wz6OAAAAAAAAQCT4EpJrVh+EQjVNdKvQKxLV1KfTunXrXI9yWbt2rQsLgfSktjCqaNdgilobeT3tceZYOTLxVQuxrNKdPW3FiGctXlS+p4+9+nX4c0BEywMtLo+74wsAAAAASL1V775oGUnFO3pEexfOaKmuyAdwaqoiV4ivSvRITXILAAAAAAAA4MySJdo7AGRUat2kyZulZ8+e9BIDAAAAAAA4kwRp8QukFkE+EGFq2aQ+9WqrIzVr1jxpklUAAAAAAAAASCmCfJxS7dq1bePGjWGt8/PPP7ve8GciTbIrmgi2efPm9vTTT1vWrFlDvn7YsGFuCYcmi9YCAAAAAAAAIOMLO8ifNWuWxXOldJhz+8LMtm/fbtu2bQtrnePHj9uZKtxzbN++fWEfX60DAAAAAAAA4MxART5Oad26ddHehQxt4MCBbgEAAAAAAACAYAjyAQAAAAAAACDCfD5ftHcBGQhTJwMAAAAAAAAAEMMI8gEAAAAAAAAAiGEE+QAAAAAAAACAdLN37143R2SNGjUsT548lj9/fqtdu7Y9//zzduTIkVRtc+DAga590amW1atXJ7udX3/91Tp27GjnnHOOZc+e3YoXL2433HCDzZgxw2IJPfIBAAAAAAAAINJ81FDL+vXrrVGjRrZu3Tr3d65cuezw4cO2cOFCt4wZM8amT59uBQsWTNX2s2bNaoUKFQr5fJYsoSPwd955x+677z47duyY+1sDDNu2bbNJkya5ZcCAAW7AIBZwNgEAAAAAAAAAIk4BecuWLV2Ir0r3adOm2f79++3AgQM2duxYy5s3ry1atMhVxKfW5Zdfblu3bg25lC1bNuh6P/74o917771uH1u1amUbN260Xbt22fbt2+2ee+5xr3niiSds3LhxFgsI8gEAAAAAAAAAEff+++/bkiVL3P0JEyZY06ZN3f1MmTJZ27ZtbcSIEe7vb775xlXln059+vSx48ePu3Y/CuvVWkfOOusse/PNN+2qq65yf/ft29e9LtoI8gEAAAAAAAAA6RLkS+PGja1OnTonPd+uXTsrV66cuz969OjTtl9r1qyxuXPnuvu9evVy7XmS6tevn7vV1QSzZ8+2aCPIBwAAAAAAAIBI8/ky1hImtc+ZN2+eu3/11VeHOEQ+a968ubv/7bff2ukybdo0/33v/ZOqV6+ea/1zuvctFCa7BYB0VOnOnhZPKt/Tx+LJAy0ut3gSb8cXAAAAAIDUWr58uZ04ccLdr169esjXec+pn/3OnTuTnbg2mGXLlrltqMpeLXtKlixpDRo0sK5du1rNmjWDrrN06VJ3e/bZZ7slmMyZM1vlypXt559/du8RbQT5AJCOlr3wmMWLaj2firv9HTx+hsWL/m2usJVvP2fxolKX3rbizactXlS+9+Fo7wIAAAAAIMDmzZv99xWuhxL4nNYJN8jfsWOHGwAoUKCA7dmzx1atWuWWkSNH2iOPPGKDBg0KuW/J7Zf3vIL8wM8SLbTWAQAAAAAAAAAk6/Dhwy4oD1z0WCh79+7138+VK1fI1wU+F7jOqVSoUMGeffZZW7lypR06dMj+/fdf279/v02dOtVq1aplCQkJNnjwYHv++edD7lty+xX4fDj7lV4I8gEAAAAAAAAgwnyZMmWoZejQoZY/f/5Eix6Llg4dOljv3r2tYsWK/slqs2XLZs2aNXMT2dauXds9NnDgQNu9e7fFO4J8AAAAAAAAAECy+vXr5wLxwEWPheJNFOtNfBtK4HOB66RFjhw5bMiQIe7+vn37bPr06UH3Lbn9Cnw+UvuVFvTIBwAAAAAAAAAkK3v27G5JqRIlSvjv//3333b++ecHfZ2eC7ZOWtWpU8d/XxPhBtu3wPdObt8iuV+pRUU+AAAAAAAAACCiqlSpYpky/V/8vHTp0pCv854rVqxY2BPdplb16tXd7T///GPbt28P+prjx4/bihUr3P1q1apZtBHkAwAAAAAAAECk+TJlrCVMmii2bt267v6UKVOCvkYT0mpyWlFv+0iaP3++/365cuUSPXfllVf674fat3nz5vknuY30vqUGQT4AAAAAAAAAIOJuu+02dztz5kxbsGDBSc+PHz/e3/amU6dOKd5uQkJCss8fPnzY+vfv7+7nzp3bmjRpkuj58uXLW7169dz9559/3o4ePXrSNp5++ml3W6ZMGWvQoIFFG0F+CJ07dzafz+dug11W8cILL1jNmjXdiaDXaZk0aVJU9vVMs27dOv8x130AAAAAAAAAsRnk16hRwwXvrVu39k86e+LECRfid+nSxf199dVXnxS2Dxw4MGQGOHv2bGvatKl98MEHtmnTJv/jCuT1HvXr1/cPHDz++ONWoECBk/btmWeescyZM9vvv/9u7dq18/fD37lzp3Xt2tUmT57s/n722Wfd66KNyW5ToXv37vbqq6+6+9myZbOiRYv6Z0NGxqd/RESDPGXLlo3YdkeNGuX+UWrUqJFbcHrMmTPHfv31V7f88ssvrveZBusaNmxos2bNivbuAQAAAAAAxK0sWbLYF198YY0bN3a5l8J3tdxRkH/o0CH3GhVLjxkzJqztJiQkuMDeGxjImTOnK7jevXu3v7pe/fkffvhh69OnT9BtXH755fbmm2/afffdZxMnTnSLAn9tw6v4HzBggN18880WCwjyQyhevLhVqlTJ3QZSX6QRI0b4R2N69erlRoVw5njiiSfcrcL2SAf533//vX/bOD1i4dIoAAAAAACQ8ZAZ/h/lZ4sXL7Zhw4a5sHzt2rWWNWtWN4Fs+/btrVu3bq5YOhw1atRw2/vxxx9tyZIltmPHDtu1a5cbJKhataqryL/77rvd65Jz11132UUXXeTa6yiX08S3Z599ttWpU8ft1xVXXGGxgiA/hKFDh7olKVXreqM6Gq3hBwnEN43Y6h91/aNdq1Yt+/TTT/2TrAAAAAAAACDt8ubN64pjvQLZlHbF8DpjJHXWWWfZQw89ZJGgTCjcKwKigSA/TAcOHPDfz5MnT1T3BUDa6SqbwD5nc+fOjer+AAAAAAAAAEkx2W0KJ7tV2xP9HdjyxJtsIenj4dBEClr/mmuuSfZ1q1evdn2d9Npgfbt12cejjz7qekrlz5/f9evX7Mt33nmnLVu2LOR2NRlEjx493KUs6iOVPXt2K1GihKtM1uM///yzpUXLli3dPqsFUVJbtmzxH7+LL7446Ppqb6TnR44cGfI9tm3bZg8++KCVK1fOfW7NWaDjqqsnQpk/f7717dvXXWajmae1nnpgXXbZZW6ii3379oU8Jzzq7RV4DqS2zY53bnltdTQyGbhdb0KPKVOmuPvqLbZ58+Zkt6nPlXSyZp033vZk4cKFdtNNN7n2Ufr85513nvXu3dtdhpScI0eO2Ouvv+4+f+HChd2lT8WKFbPrr7/ePwlIPImFyUoAAAAAAACA5FCRH0b7DQXECjH/++8/95g3ya0UKlQoVdu999577ZNPPnGtPDZs2GClS5cO+rp33nnHTbJQsWLFkwYNvvvuO2vTpo0/gFWPKYWr6jel5cMPP7S3337bOnXqlGg9zcisMNb7PAo08+XLZ1u3bnUhuyb/1HMKmlNL2//qq69sxowZJz0X+NiiRYvc/gfOIK2ZoletWuXuh+pHpUGKO+64w/755x/XA0t0X8dUobJmsL7gggtOWk99rjxaT4s+q2az1jJ69GibOXOm64nl0QCJvnMNHEjBggUT9e8qUqSIpeXc0ozYatukAZWkV3vou7nqqqvcYIW+03fffdcN3ASjAQyvqly9wIL5/PPP3UQdOp/1nevc+uuvv1xvMc0YrtA/2MDE+vXrrUWLFv7BIQ0KaH0dE01cokXn9BtvvJGqYwEAAAAAAJBhZKIlNyKHivwUatu2rQu4NSGDR397S+Dj4VAoX6VKFTdTc6iqc4W7XpieNJjVZA7XXXedC8G7dOlif/zxhx08eNBVlCt07dq1qwtrVZmvCuxA6iOl8Fp9oDQxhN5HYbJmjFaArlBXlfppoSDfGzTQtgMpKBcFwfr8Sa808J5XxbwC7GBuvfVWq1ChgrtyYP/+/e5zT5s2zVWZ79mzx01KEepKAYX9GrDQeto3tU3S96irAHQcFUgHeumll9x37dFrA8+B1F694J1bmilbdPVC4Ha1lCpVyoXm99xzj3uNzhVv9uykNGgj1atX928zqdtuu809p8+pmbh1DHQ8NDih80Yh//HjxxOto9c0b97chfg6b/V96VzTuaflhRdecAMQmu1bxwoAAAAAAABAZBDkxwAvnFWVddLwVFTlrIpntb1RABuoe/fuLkzt16+fvfXWW25QwGsVour+1157zf73v//ZsWPHbNCgQYnW/eGHH9ztq6++6lrKeC1XVGWucFxBv1qtpIWq4XW1QrCg3qvI12cI/Dvp895gQDCqZFdw77XmUduZpk2b2ogRI9zfc+bMce2Dgh1ThdVqCRNYGX/DDTfY9OnT3bGeNGmSu0oilujqA30/arXz7bffnvT84cOH3dUEyVXje8ftm2++ceeLd9x0PMaNG+f+1qBE0sEpBfWq9m/YsKF7b93qOHlXK6gVk/feOtd0zgEAAAAAAABIO4L8GKBwXq1dFDgrXA1VYX3jjTe6nuQehbkKuxXCButB7/Fa6qgFT+BAgdfGRlXp6UV9/RX4Jg3qVfWtFjEaMPD2L2mQ71XkJxfka7BBAXxSV199tb/tja5aCEfJkiXdAIQq3r3Bjlih9j2tW7d29zVwk9Rnn31mO3bscMdEVyuEogGaYMdNgyBeFf/YsWMTPeddMdKzZ0/XvimYVq1auSsstA+//PJLmJ8OAAAAAAAAQDAE+TFAgbraqwSG9oGBtyrOg1VYz5s3z92q2r1q1aquujzYonYoXmuUf//917/+tdde6x9IUCCuyVbVXibSvP72gUG9d1/PnXvuue7qAbVsUX97UcivgYpTBfmXXnpp0Mc1uOH1rE/a0sc7Zh999JFrS6T3VqgdOLnsTz/95F4XrJo/2ryWP19++aW/X7/HO39UXR8430BSoeYcCHwusBWT5ivQuShq0xTqXFNLI2+iYO/1AAAAAAAAZyRfpoy1IKr4BmIsnFVFvkLTwEluFTqrb3vSSW43b97sbvW8At1Qi6qjPYFB/bPPPutCcgWvapui7auaWm1qBgwYkGg/0sIL4pcvX+7vMe9V23uhsfcaL+D3nlfIr/7woeTNmzfkcwrzRb3/A+kYqPK8Q4cOLgzfuHGjO4ZqAaSWM1q8inMNfsSaBg0auIEbfa733nvP//jq1av9x81r15TcVQenes4bVAk810TnU3Lnm46lpMegEAAAAAAAAHAmIsiPEZdccombdFatb7wWJrrvBbWayDYpr02Ogme1gUnJUrZsWf/6qthWcK4+8n369LG6deu68FstUZ588knX9ubjjz9O82fThLnax6RBvSrfvQA/adV+Svrjp9bgwYPd+6sK/8UXX3SV45rgV1creJPLepX+oSaUjZWBHw30ePvo3dckt3Xq1Ino+wW2ZNKATErOtc6dO9uZRPMTaILlwEWPAQAAAAAAAGlFkB+D4awmvVVVs1edH2ySW/EmalWFdFoqx+vVq2fPPPOMzZ0713bt2mWff/651ahRw02iq8lVk7ZvSQ3vagIF9KtWrXItaxQ4e+1vQlXkJ9cCJrW83u+PP/64m2hXrXW8iX493pUDsUrzCmhehb/++ssdM1Xnjxo1KkXV+JLc1Rbec2effbb/scBJgWmZE9zQoUPdpL+Bix4DAAAAAAAA0oogP4bccsstrrWNgtKpU6eGnOTWowp6r1p68uTJEdmHHDlyuL7xEydOdH+rUl0Bf1oFBvXBQnq1zznvvPNcMK05AbxWLknbCUWCWulIzZo1gz6v3vxqUxOKF/pHulpfEwOndLsKidu3b++f9Nbrl6+rDDp27HjK9b3vILnn1GLJoys5vJY7ei+crF+/frZ79+5Eix4DAAAAAABnpsD5GDPCgugiyI8huXPntltvvdXdHzRokKvIDzbJrUetb7ygu3///i44TE7gpK/Hjh3z9zIPRoFw0oA5LbzQXpPYeu2Cklbbe2H/Y4895m4rV67sJk+NNIXg8vvvvwd9/uGHH052fQ22iK5eiKRwt+tdwTFp0iQ330FKJrn1DBs2zA3SBAvxvUmUvQmYPV57J7V+WrRoUbLbDzbBcEanK2f0HQYuegwAAAAAAABIK4L8GOOFsz/88IOrtA82yW2gV155xfLkyePa1Vx22WWuLU5gQKs2KR988IE1adLE+vbt639crW00EKABA4WyCvY9ixcv9ld1a3ChYcOGaf5ceq9zzjnH3V+wYIFlzpz5pO16wb6eT6/++NK8eXN3q8+uKw+8z65BBl0VMW7cOCtYsGDI9dUSSMaMGRPRCV297Sad8DgUVczXqlXLjhw54j9mKWmrI1u2bLEWLVrYypUr3d86Bp9++qnddNNN7m/N16ArQQI99NBDruWSzi99N6+++qqbV8CjAQhdGaK2P/Xr17d4ocme1Z7KW7y+9mpXFPj4f//9F+1dBQAAAAAAwBmKID/GKMxVz3pPsEluk75+ypQprof5ihUrrFWrVi7YVyse9VBXeK5g1es9H2jNmjWu+l2hrVrqnHXWWa6C+IILLrBZs2ZZtmzZXN/1QoUKReSzBQbzek+vMj7Y88H+jhQF+Jp8d+/evda6dWt39YGq2MuXL+8m99VkuOeff/4pB1smTJjg1tMxVuuZwO8tNTQPgr4HtfVR3359p9quFg28BHPffff574czye3777/vJjnWVQ/6DDpn2rRp4yrp9d4K9TXxcSC9RueaBox09Ue3bt3cHAca9NB3qdtrrrnGDRxpcCFePPDAA+5zeIs3h4IG0wIfD9WKCQAAAAAAAEhvBPkxSIGqhJrkNlivfFXkq11KgwYNXDCr6mhVvVepUsVV16t6fPjw4f511O/8iy++sB49erhgVi1sVJms8LZq1ap2//3329KlS/0V2pEQGMwHm8RW4breW9R3Kz3640uZMmVs4cKFduedd1qJEiXcYwrQr732Wjc3wan6mut4KqxWcK/BElW3a16DUGF7OFctqLWN5ihQcKxqd21XS+AVE4H0/Xg9ylJajS/XX3+9C6o1kKHPrr785cqVc1X3v/32m7sfjI6X5kzQgIf2U+eNrkpQcK8Bh5YtW7rzbPbs2ak8CgAAAAAAABmEL1PGWhBVvoRIz9iJNFMY+tVXX7nJTD/66KNo7w5imK4KUJivqwo0QXBy/fF1lYU3mMLP/vRZ9sL/zfkQD6r1fCru9nfw+JOvNopV/dtcYSvffs7iRaUuvW3Fm09bvKh8b/LzmwAAAADA6bbm01GWkZS/qXO0d+GMxlBKjFG7G2+S28C2KUCoORJEgz4pmeQWAAAAAAAAQPwhyI8he/bsceH9iRMn7NJLL42rCUNx+r311lv2/fffW6ZMmaxnz57R3h0AAAAAAAAA6STxbJaIil69etn48eNt69atrte4+tQH9rMHPPPnz7d27dq5yWY1D4J07drVqlWrFu1dAwAAAAAAQKBM/zevIRAJBPkR8sknn9iDDz4Y1jpt27a1l156yXbs2GEbNmywPHnyWK1ateypp55yE9DGEn02fcZw6LPpM55JbrzxRjeJbDgmTpxol19+eYpee+jQITf5rSYyLl++vJsM+ZFHHrFYpQmYtYRDv4fChQun2+u9wTMtAAAAAAAAQDwgyI+QgwcP2rZt28JaR1XVMmrUKLfEMu1ruJ9Px+RMs3PnzrCPk67CSKlGjRqleqLatKybWvv27Qv7eEi464T7eu0XAAAAAAAAEC8I8iOkc+fObsmo4mGwIRbMmjUr2rsQUwYOHOgWAAAAAAAAAKlHkA8AAAAAAAAAEebzZYr2LiAD4WwCAAAAAAAAACCGEeQDAAAAAAAAABDDCPIBAAAAAAAAAIhhBPkAAAAAAAAAAMQwJrsFAAAAAAAAgEjz+aK9B8hAqMgHAAAAAAAAACCGEeQDAAAAAAAAABDDCPIBAAAAAAAAAIhhvoSEhIRo7wQAAAAAAAAAZCTrPv/IMpKy198S7V04ozHZLQCko+3LF1u8KFLlfNvy81yLF8Vr17OFq9ZbvLi4Yhn7Z9kiixdnV6tp237/2eJF0Qtq2+YfZ1o8KVGncbR3AQAAAAAQJ2itAwAAAAAAAABADCPIBwAAAAAAAAAghtFaBwAAAAAAAAAizeeL9h4gA6EiHwAAAAAAAACAGEaQDwAAAAAAAABADCPIBwAAAAAAAAAghtEjHwAAAAAAAAAiLRM98hE5VOQjwxo4cKD5fD5r1KiRxRrtk/ZN+4jYtW7dOvc9adF9AAAAAAAAIBoI8gEAAAAAAAAAiGEE+ciwChcubJUqVbLSpUtHe1cAAAAAAAAAINXokY8M64EHHnALAAAAAAAAcLr5fNRQI3I4mwAAAAAAAAAAiGEE+Ygrn3zyiV199dVWtGhRy5o1qxUoUMAqVKhg1113nb322mt26NChFE1227lzZ/ecbuXTTz91rytUqJDlypXLLrzwQnvppZfsxIkTIfclISHB3nvvPatTp47lzZvX8ufPb5deeqm99dZb7rmk7xGupUuX2t133+0+n/YpT548dv7551v//v1tx44dllafffaZ279s2bLZv//+m+xrGzRo4F575513nvScjtGYMWPsmmuucd+LtlekSBFr1qyZffzxx+5YBHPs2DF3rHTc1QZJ3+dZZ53l2iG1bdvWRo4cmeZzIND27dvt0UcftZo1a7rvKkeOHFa+fHn3mZYtW5aiYwYAAAAAAABEA611EDfuuOMOF5x7FGwfPXrUVq9e7ZYvv/zSWrRoYWXLlg1ru2q/owA4U6ZMli9fPjt48KD9/vvv1r17d/v111/t/fffP2md48ePW4cOHVyoLAq5FSgvXLjQfvrpJ5s1a5YLtFPr2WeftX79+vkHEhTk67MuWbLELToOX3/9tQulU0vHSgMXO3futLFjx9r9998f9HXr1q2zuXPnuvudOnVK9JzWveGGG2z27Nn+xxSSa6Bh2rRpbtG2x48fn+h46Pgp+Nfzgevt37/fbXPVqlU2bty4kwYOUnsOfPfdd9amTRvbtWuX+1sDANqftWvXuuXDDz+0t99++6TPBwAAAAAAAMQCKvIRFxQkK8BV2P7MM8+4CvK9e/e64Feh8dSpU+22224LOzz/4osvXID7wgsv2H///ecWbe+uu+5yz48ePdpmzJhx0nrPPfecP8Tv2bOnq/ZWAK31hwwZ4sJrbTs1VInet29fF94PHjzYtmzZ4j7ngQMH3EDBFVdc4R5TBfq+ffsstXSsVPkuH3zwQcjXKeRWVb3CcVXmB4bxN954owvxdQWDQnTtp8Jy7ZcGQM4++2x3HPR5AqlSXyG+quLfeecd911qPQ2ibNu2zSZOnGg33XRTRM4BDXzoWGn7Xbp0sT/++MO9j/Zx/fr11rVrVzty5IgbNNDxBQAAAAAAiAifL2MtiCqCfMSFH374wd02bdrU+vTp4yrJPWrHojYuo0aNshIlSoS1XQXvI0aMsB49erhqfG97Cvdr1arlD50DKTgeOnSou6/w9/nnn3friLahSvrHH3/cbTtcCqZ79erlb/fzyCOPWLFixdzfmTNndvukwFq3mzZtciF4WngV6AsWLHBV8MF4IX/Hjh3dlQeejz76yL7//nurXLmyuwLh2muvdYMPkjt3brftb775xq3z+uuv2z///HPS96nX6Biqsl70WoX/qvJXFX8kzgFdWaHgXt+LWvlUqVLFHUspXbq0uxrjf//7n2v1M2jQoDQdTwAAAAAAACA9EOQjLqhtjajyXZXgkVKqVClXxR2Mqrhl8eLFiR7/9ttvbc+ePe6++tUH89BDD/lD7XBMmDDBVY6rZc5VV10V9DVZsmSx9u3bu/sK9dPisssuc/3lQ1Xlq02QF/DfeuutiZ7zetjfd999ri1OMBpwqFatmqt4nzlz5knf59atW9P1HFBbIF1RoWPmDZAkN6ChFjyRPL8AAAAAAACASCDIR1xo0qSJa8OyaNEiq1+/vguR1ds8rWrXrp2oyjyQV9mtljmB1Dffq+YuV65c0HU1+a1X0R+OefPmudvly5e7SvxQy5NPPulep9YwaeUF9F4LnUBeuK9JfCtWrOh/XGH3/Pnz/ZMKJ7evK1euPGlf1R9fx11tdzRxra562Lx5c8TPAe94aq6BqlWrhtzH5s2b+6+2ONXEvwAAAAAAAMDpxmS3iAvnnnuuayNz77332o8//ugWKVKkiDVu3NhuueUWV0EfKpQPRYF7KKriFk2mGkgV4XKqNj4lS5a0cHlh9qFDh9xyKuqbH4kgf8CAAf5JbRWSe59bvf5DTXJ7+PBhdz+lLYQC97VevXquz/2jjz5qU6ZMcYucc845rnWO3k/fa1rPAe94KshX7/1w9xMAAAAAACDVfNRQI3I4mxA3OnTo4Kq633zzTTdJq9riKFQfN26ctWrVyho2bOhveXM6hDtokBJeWxd9PlXHn2pR+J5WmsTWC+81ua9H4bomkQ2cFDfpfsrkyZNTtK+q3A/Uu3dvV1H/4osvuu9PvfHV91997jWhb5s2bU4aRAn3HPD2s2jRoinaR29S39TQwIbeO3DxBjsAAAAAAACAtCDIR1zRBKf33HOPqxTfsGGDrV692h5++GEXqs+ZM+eksDg9qAJcTtUK5u+//w57297EtpFomZOa9jqaYNa7EsBrq6M2ON5kvh797V2xkJZ91VUNmoz2s88+cxXzmo/grrvu8k/2+8Ybb6TpHPCOpwYk1DYnPWkCZM0VELh4kyIDAAAAAAAAaUGQj7imdisKS9VWRaZNm5bu73nRRRf5A+xQFfH79u2zX375Jext161b191q3S1bttjpoup39Z/fvXu3ffnll/7bYG11JGvWrHbJJZe4+97rIqFGjRr29ttv+49DSr7P5M4BbzuqzNeVA+mpX79+7rgFLnoMAAAAAAAASCuCfMSFU7UoyZkzp7vNlCn9T+lmzZpZvnz53P0hQ4YEfY3axaSm17oC9QIFCriWMj179jxp8tlA6vu+a9cuiwRVj19//fX+9jpeZb6q31u0aBF0nbvvvtvdfvPNN25JTtIJg1PzfaZmnQoVKlijRo3c/f79+7twPZz9DEf27NndeRG46DEAAAAAAHBmUveAjLQgugjyERceeOABu/nmm23ChAn2zz//JKp8V790r7d7qNA5knLnzm19+/Z191U93qdPH38AvHfvXjeJq9q7FCxYMOxtK8QfPny4u6/WMfo8CxYscKG96Hb58uX2/PPPW7Vq1eyrr76KeHsd9cZ/9dVX3X31oVeP/GA6duzoJqbVYMMNN9xggwYNStRuSK1sZs6caffff7+VL18+0brqZ3/HHXe4KvnAwQgdR21n+vTpJ32fqT0HXnnlFcuTJ4+tWrXKLrvsMvv8888TTSSsFkhqI9SkSRP/9woAAAAAAADEkv9rcg3EOFWoq0pciyiYVY/2wBC4Xr16rur6dFB4v2jRItfH/bnnnnPBuqraNcGp2rgoFNdIpcJltawJx2233WYHDx60Bx980AXdWlTZrc+s7QdOABvJ0dCrrrrKTQqrXvW///57yLY6nsyZM7tQXRPQakDhsccec4sq0VUVr+p374oCr5++R5/vvffec4t4VzgETlR70003+fvlp+UcqF69uhuc0PZWrFjhBhG07xo00VUT2hdP0gEHAAAAAAAAIBZQkY+4oID45ZdfdpXflStXdgGuKrHPPvtsu/LKK+3dd9+1WbNmuWr500HvP27cOHvnnXdcr3i1dTl27JhdfPHF7jEF+F7ArMA4XPfee6+tXLnSevXqZRdccIEL8rU9hdd6j27durle8O3bt4/oZwrcntrSqII9OQrg1SNfrXVUvV+6dGnXAkcBecmSJV0bIvWv12dJWiWvKxc0ka7eR4G/AnVNfnvddde5AQIF9oFtctJyDqhXviryhw0bZg0aNHDfiY6nAv0qVaq4qwvGjBnjvxoCAAAAAAAAiCW+hOSacANIFf2sFGpv2rTJhfpe2xqcebYvX2zxokiV823Lz3MtXhSvXc8Wrlpv8eLiimXsn2WLLF6cXa2mbfv9Z4sXRS+obZt/nGnxpESdxtHeBQAAAADpaMO3kywjKd2sVbR34YxGRT6QDtRzXSG+qsbVRx4AAAAAAAAAUosgH0gltaFRj/wdO3b4H1N/+aefftq6dOni7zFfvHjxKO4lAAAAAAAAgHjHZLdAKmkS2rFjx7r7uXLlsqxZs7oJXj3169e3F198MYp7CAAAAAAAACAjIMgHUkkTryrMX7Rokf3zzz9u4tUiRYrYhRdeaO3atXN98RXunw7FihULe52tW7emy74AAAAAAADAzOfzRXsXkIEQ5AOppLY5WmKBWvoAAAAAAAAAyJgI8oEMICEhIdq7AAAAAAAAACCdMNktAAAAAAAAAAAxjIp8AAAAAAAAAIg0euQjgqjIBwAAAAAAAAAghhHkAwAAAAAAAAAQwwjyAQAAAAAAAACIYfTIBwAAAAAAAIBI81FDjcjhbAIAAAAAAAAAIIYR5AMAAAAAAAAAEMMI8gEAAAAAAAAAiGG+hISEhGjvBAAAAAAAAABkJBunf2UZSakm10Z7F85oTHYLAOnoz9GvWryo0OkBW/PpKIsX5W/qbGO+/9XiRYeGF9m6r8ZavCh7bbu429/VH42weHLeLffYfxvXWbwoWKpstHcBAAAAiCu+TL5o7wIyEFrrAAAAAAAAAAAQwwjyAQAAAAAAAACIYQT5AAAAAAAAAADEMHrkAwAAAAAAAECk+aihRuRwNgEAAAAAAAAAEMMI8gEAAAAAAAAAiGEE+QAAAAAAAAAAxDB65AMAAAAAAABApPl80d4DZCBU5ANIsc6dO5vP53O3kVK2bFm3zVGjRkVsmwAAAAAAAEBGQpAPAAAAAAAAAEAMo7UOgKg699xzLUeOHJY/f/5o7woAAAAAAAAQkwjyAUTV9OnTo70LAAAAAAAAEefz0QwFkcPZBAAAAAAAAABADCPIBzKAjRs3Wp8+fezCCy90LWpy5szpWtZcf/31Nnr0aDt06JD/tWvXrrVnnnnGmjdvbhUrVrTcuXNbnjx5rGrVqta9e3fbsGHDaduX5Ca7XbdunXtci+6HktL1169fb126dLHSpUu7Vj7ap0cffdT279/vX2fp0qXWsWNHK1WqlHtNhQoVbNCgQXb06NE0HRMAAAAAAAAgLWitA8S5Dz74wO6++25/QJ4tWzbLmzevC+TXrFljX3zxhZ1//vkuWJfbb7/dvv/++0Sv/e+//2z58uVuUSD+1VdfWb169dJ9X06XX3/91e68807btWuX5cuXz44dO+b2Z/DgwTZ79mzX3ufbb7+1m2++2Q4cOOAGII4cOWKrV6+2xx57zAX8Y8eOPa37DAAAAAAAAHioyAfi2Ndff2233XabC87r1q1rc+bMsYMHD9qOHTtcpbn+VhW6AnWPQvTXXnvNVq1a5X/t4cOHbcGCBa5Kf/fu3da2bVv3XHrvy+miEL9WrVq2bNky9/n27t1rL7/8smXOnNnt15NPPmkdOnSwli1buup9Bf579uyx/v37u/U/+eQT++677077fgMAAAAAgDjm82WsBVFFRT4Qp1RV3q1bN0tISHDV86oqDwzJdV+PJ62sHz58+EnbypIli11yySWuEv+iiy6yxYsX24QJE1ybmfTcl9OlZMmSbqAhe/bs7m+1+9H+/vzzz+4qArXPufLKK+3jjz92rXhE7Yb0uCr2FfarIr9p06ZR2X8AAAAAAACc2ajIB+LUzJkzXb97efHFFyNS6a4KdVXly9y5c6O6L5HUo0cPf4gf6KqrrvLff/jhh/0hfrDXaHADAAAAAAAAiAYq8oE49cMPP7jbYsWK2cUXXxzWuqowHzlypM2fP982bdqUaMJXjx4/HftyOuhqg2CKFi3qv1+7du1kX6N5BAAAAAAAAIBoIMgH4tTWrVvdbZkyZcJar2/fvvbss88mqsIvWLCgv4p+3759LtgPFu5Hel9OF024G4xaCqX0NUePHk32PTTPgJZAwa4CAAAAAAAAZwZfJvrKI3JorQPEqWBtYE5l2rRp/hC/a9eutmTJEhc+79y504XxWtSGRtTvPj33JaMZOnSo5c+fP9GixwAAAAAAAIC0oiIfiFNqYyPr169P8TqasNXr+/7aa68lW12f3vtyKoHV8ocOHQr5ut27d1ss6Nevn/Xs2fOkivwNn7wdtX0CAAAAAABAxkBFPhCnLr/8cn/wvnDhwhSts3HjRndbs2bNoM+rCn/GjBmnZV9ORe1+ku53UqtWrbJdu3ZZLFBony9fvkQLrXUAAAAAAAAQCQT5QJxq3LixlS9f3t1XO5wjR46cch21e5Hff/896PNvvvmmrVmz5rTsy6nkzp3bzj33XHd/woQJQV8zePDgNL8PAAAAAABAuvBlylgLoopvAIhTmqT21Vdfdf3p586da02aNHG3J06ccM8rTJ81a5Z17NjR/vjjD/dY8+bN3e3kyZPtqaee8k9oq6r2IUOGWLdu3eyss846LfuSEu3bt3e37777rr3++ut28OBBf4X+XXfdZZ988onlypUr7P0FAAAAAAAA4glBPhDHrr76ahs1apRr4aLgvH79+i7YLly4sKtoV6X8mDFj/BXynTp1cq+Rxx9/3PLmzWuFChVy4X3//v1d0H/fffedln1Jib59+1rVqlXt6NGjdv/991uePHlcy53SpUvb6NGj3fsVKVIkVfsLAAAAAAAAxAuCfCDOKZxfsWKFde/e3YXemiRWletlypSxVq1a2QcffGBVqlRxr82aNat9++23NmDAAKtYsaL7W33xL7nkEnvjjTfsiy++cNX1p2NfUkLBvQYFNIlsuXLl3Pa0z61bt7Yff/zR2rVrl+p9BQAAAAAAAOKFL0EpHgAgXfw5+lWLFxU6PWBrPh1l8aL8TZ1tzPe/Wrzo0PAiW/fVWIsXZa9tF3f7u/qjERZPzrvlHvtv4zqLFwVLlY32LgAAAABxZfOPMy0jKVGncbR34YxGRT4AAAAAAAAAADGMIB8AAAAAAAAAgBhGkA8AAAAAAAAAQAzLEu0dAAAAAAAAAICMxuejhhqRw9kEAAAAAAAAAEAMI8gHAAAAAAAAACCGEeQDAAAAAAAAABDDCPIBAAAAAAAAINIy+TLWkgZ79+61gQMHWo0aNSxPnjyWP39+q127tj3//PN25MiRVG3z77//ttdff93atGlj5513nuXMmdMt5cqVs/bt29uMGTOSXV/74/P5TrmsXr3aYgGT3QIAAAAAAAAA0sX69eutUaNGtm7dOvd3rly57PDhw7Zw4UK3jBkzxqZPn24FCxZM8TY3btxoZcqUsYSEBP9j2q7+1vtoGTt2rN1xxx321ltvWebMmUNuK2vWrFaoUKGQz2fJEhsROhX5AAAAAAAAAICIO3bsmLVs2dIF68WLF7dp06bZ/v377cCBAy5oz5s3ry1atMg6duwY1naPHz/uQvsmTZrY+++/76rztd19+/bZsmXL7Prrr3eve/fdd13lfXIuv/xy27p1a8ilbNmyFgsI8gEAAAAAAAAAEaeQfcmSJe7+hAkTrGnTpu5+pkyZrG3btjZixAj39zfffOOq8lOqYMGC9ssvv9h3331nnTp1shIlSvi3W7VqVfvss8+sefPm7rHhw4fboUOHLN4R5AMAAAAAAABApPkyZawllUG+NG7c2OrUqXPS8+3atXM97WX06NEp3m7+/PntoosuCn3ofT7XVkdUpb98+XKLdwT5AAAAAAAAAICIUvucefPmuftXX311yMDdq5z/9ttvI/r+OXLkSNSKJ94R5AMAAAAAAAAAIkpV8CdOnHD3q1evHvJ13nPqR79z586Ivf+sWbPcbbZs2axixYohX6ee+toHTZabJ08eq1SpknXp0sX17o8lsTHlLgBkUBU6PWDxpPxNnS2edGgY+jK6WFT22nYWT+Jtf8+75R6LNwVLxcakSQAAAABwKocPH3ZLoOzZs7slmM2bN/vvlyxZMuR2A5/TOoUKFUrzvq5du9befPNNd1+9+PPlyxfytTt27HADCAUKFLA9e/bYqlWr3DJy5Eh75JFHbNCgQRYLCPIBIB1t+Wm2xYvilzSwLT/PtXhRvHY9m7dsjcWLutXK29ZffrR4UaxWHdv263yLF0Uvuiyujq93jHdt+dviRYHiJW3HymUWLwpXqhbtXQAAAMAZTm1jMpKhQ4faE088keixAQMG2MCBA4O+fu/evf77qnYPJfC5wHVS6+DBg9amTRvX2qdw4cL29NNPB31dhQoV7Nlnn7Xrr7/e9enPmjWrHTlyxFXyK8DXZLqDBw92E+s+9NBDFm0E+QAAAAAAAACAZPXr18969uyZ6LFQ1fjRcuzYMbvllltcCK9gfsyYMVaiRImgr+3QocNJj6kNT7NmzaxBgwZu+fnnn91AxV133eUm2I0meuQDAAAAAAAAAJKl0F4tagKX5IL8vHnz+u+rOj6UwOcC1wnX8ePHXTg/adIky5Ili3300UculE/tRLlDhgxx9/ft22fTp0+3aCPIBwAAAAAAAABEVGAl/N9/h24rGvhcqOr5lIT4HTt2tHHjxlnmzJntww8/tJtuusnSok6dOv77a9ZEv7UvQT4AAAAAAAAAIKKqVKlimTL9X/y8dOnSkK/znitWrFiqJro9/v9X4o8dO9Yf4muC24yGIB8AAAAAAAAAIs2XKWMtYdIktnXr1nX3p0yZEvQ1CQkJNnXqVHc/NW1wjh8/7nrif/LJJ/4Qv127dhYJ8+fP99/XZLjRRpAPAAAAAAAAAIi42267zd3OnDnTFixYcNLz48eP97et6dSpU6oq8ceNG+d64mti25SG+BpASM7hw4etf//+7n7u3LmtSZMmFm0E+QAAAAAAAACAdAnya9So4YLz1q1b+yeNPXHihAvxu3Tp4v6++uqrTwrLBw4caD6fzy3r1q0L2hNflfjexLbhtNOZPXu2NW3a1D744APbtGmT//GjR4+6faxfv75/4OHxxx+3AgUKWLRlifYOAAAAAAAAAAAyHoXsX3zxhTVu3NiF8QrP1XJHQf6hQ4fca2rWrOmq6cMxb9481xNfFPR369bNLaG89NJLiYJ+DSwosPcGFnLmzOkq73fv3u3CfFF//4cfftj69OljsYAgHzFj0qRJ9ttvv9mFF15orVq1sjNpH7VNbVuje927d4/YdpE8/UdCo6u//vqrG33dvn27G9E9++yzrVatWm5kV6PFAAAAAAAA4VLADLOyZcva4sWLbdiwYTZx4kRbu3atZc2a1apVq2bt27d3AXy2bNnC2uaJEyf89xW8b9u2LdnXHzx4MNHfukpA+/Pjjz/akiVLbMeOHbZr1y43yFC1alVXkX/33Xe718UKX8KpGgIBp0nnzp3t/fffd5fcjBo1ys6kfdS2br/9ditTpsxJlwoh/eTJk8f279/v/zt//vzuH/YjR474H9NEK/qPjEZlU2PLT7MtXhS/pIFt+XmuxYvitevZvGX/10cvHtStVt62/vKjxYtiterYtl//38Q+sa7oRZfF1fH1jvGuLX9bvChQvKTtWLnM4kXhStWivQsAAAA4w8XT/6dK6f/vQvTQIx/AGeuuu+5yAzN//vmnu5xLI6+6/euvv/yXY3377bf20EMPRXtXAQAAAAAAcAajtQ6AM9bw4cODXvZWvnx5e/nll91lVR9//LGNHj3aXnnlFXfZFwAAAAAAAHC6UZGPdKWZozXrdNGiRV0Iqh7wFSpUsOuuu85ee+01V/08a9YsF56qMlp0681I7S16TVJLly51vaq0PfWvUpuU888/3/r37+8C2GC82a4bNWrk/taEFi1atLAiRYpYjhw5rEqVKvbEE0/4J9vwpHYfU0Lrqq2OrF+//qTtap/Vt/2cc85xfz/77LPJbm/kyJHudXnz5rW9e/cm6kemx9XGR4/369fPKlWq5CbzKFy4sOv5783GfarJRNQ7Xm2AdMzUjuaSSy6xZ555xvbt22cZyWWX/d8lY2q3s3PnzmjvDgAAAAAAiCeZfBlrQVQR5CPd3HHHHdauXTubMmWK/fPPPy701eQTq1evti+//NIeeOAB27p1q5vMQkG/nhfd6u/AJemEFwqzL7jgAnv77bfd9hRQa9uanGLIkCEu0F+0aFGy+/fcc8/ZlVdeaZMnT7Zjx465vugrVqxwwfk111zjwnNPavYxpbRuvnz5/LNhJ92uBigyZ87s2sDIO++842bWDkXHRDRZiML8pP777z+rXbu2Pf30064fv/b733//tc8//9wuv/xye/fdd0NOIvLggw9avXr13CSxGzZscIMz6jH/888/u1m8L774YjcYkVHMmTPH3eo70AS4AAAAAAAAQDQQ5CNdzJ0719577z0XTKtSW0GxqsAV+qpafurUqW7CWIXICo8V6Ldt29atq1v9HbjoNYEV53379nVV+IMHD7YtW7a47R44cMAWLlxoV1xxhXtMVf+hKsR///13Fzxr0SCDwm31R3/88cfd8zNnzvRX30u4+xgOrfvSSy+5+6VKlTppu7169XLPdenSxQX66uceqvpfAxleVf0999wT9DW64kCfedy4ce647d692/744w9r2LChC+u13q+//nrSegMGDHDtZhRo62oK7ztVtbqOV82aNW3lypV24403Jpo5PN7oeOg80kDUp59+6h7r2bMnM80DAAAAAAAgagjykS5++OEHd9u0aVPr06ePFSpUyP/cWWedZc2aNXMtXkqUKBHWdhUce8G2QtZHHnnEihUr5v5WyF2rVi03SKDbTZs2uer1YBTaP/bYY656X21lRFXxCrkVRIt6o8eSkiVLWsuWLd39t956K+hrvMcvuugidwxCBdXjx4+3Nm3aWJYs/zdNhloK6coEtSnS1Qk6NoFUuT906FDXhkeTv3bt2tX/naoqX62Kvv/+e9f+R4MAX3zxhcWTsWPH+lsZqf2TrljQQFT27NndYI83wAMAAAAAAABEA0E+0oXCUNm+fXuiFjVpNWHCBBfCq/r7qquuCvoahdNqKyMK9YNRQOsNCCR1/fXXu9vFixdbrLnvvvvc7WeffXbSPACqjP/www+TrcaXunXrWpMmTU56XCF979693X21Q1Lg79Ggi77H5s2bu5ZGwaiNj/rsJ3fcY5U+u9fKSANColsNQj300EP+xwAAAAAAAFLMlyljLYiq/yvHBSJMQbH6yKtPff369e3OO+90LW/KlSuXpu1qolVZvny5vxI/GIXaEqpfe7Vq1Vzf82C8qwRicXJT9fQ/99xz7a+//rLRo0e7li8eXaGgQQ59rltuuSXkNvQ9nOo5tcZRZX3jxo0THXdV4yd33L1WRvHWJ1+DN94Ajq5I0PmlKxCeeuopd5WDBk7q1KkT7d0EAAAAAADAGYqhFKQLhc1qa6NQ+ccff3QTtZYvX971V1d/eU2smtyEraFs3rzZ3R46dMi2bdsWctmzZ497nfrmBxNsEliP125GgW6sUeuXu+++O9Gktknb6ijEDzVI4bXoSclz6qOf9Lirp35yx13PJ3fc44G+/xo1athHH31k3bp1c59L56w3OAQAAAAAAACcbgT5SDcdOnRwldlvvvmmC0I1kata7WiSVbVg0eSqXuCeUl6bHm1PAwGnWtTbPaPRJKxqDbRixQqbPXu2e0z3NcGweEF/JHnHXZMMp+S4h5qMN9706NHD3W7cuNHNIZCcw4cPu/M5cNFjAAAAAAAAQFoR5CNdaUJU9WvXZKIbNmyw1atXu8lDVVk+Z84cGzhwYFjb89q6xFvrlkjS5LytW7dOVJXv3WqC21CT3Hr+/vvvFD2nqyfO9OMeeIWCzt3kqBVP/vz5Ey16DAAAAAAAnJmUf2WkBdFFkI/T3nJH4abXw33atGn+5zJl+r/TMbmWO5qoVX755RfbsmWLnW4p2cfTsV1v0lv1xd+6davrl5/SavyZM2ee8jntjyYUTnrcv/vuO9fW6EyxZs2aFLVjkn79+rkJggMXPQYAAAAAAACkFUE+0sWpWorkzJkzUYAt+fLlc7easDWUNm3aWIECBezo0aNuotfkgm9N2JrctlIjJft4OrZbr149q169ugvV1WZox44dp5zk1qMWPMFa32hbzz//vLt/1VVXueMc2M5HveP1PgMGDEh2+0eOHPFPehvLUjIHQmBFvVpBJUftjvQ9Bi56DAAAAAAAAEgrgnykiwceeMBuvvlmmzBhQqJJUxXwqme+V0HeokUL/3MKpkUtd9TzPRiFy8OHD3f31a5H6y9YsMCF9qLb5cuXu0C6WrVq9tVXX0X0c6VkH9OyXfVV1xwCKaGWReL1yT/VJLcetXxRax5V83thtj6LjqVuM2fObE8++eRJV1I89thj7v6zzz5rnTp1sqVLl/qf13Z+++03t955553n7se6p59+2jp27Oh63wcOoOiz6Jy68cYb/eepjm3VqlWjuLcAAAAAAAA4k2WJ9g4gY1LF/Pjx490iCphV0R0YmKqqvH///v6/FS4/8sgjbkLcKlWquF7wuXPn9of2l112mbt/22232cGDB+3BBx90IawWVT7rPRSE6709ke7fldJ9DJfC7yZNmtj06dNdhf1dd93l5heQ7t27uyUphemab2D//v1hTXKrivoRI0a4qxt03HLkyOHawHjH64033rCLL774pPUU5CvkHjRokH3wwQdu0ZUVuXLlct+rNyGut51Yp88yZswYt4jOHx0PHYvAan19HyNHjozingIAAAAAgLjko4YakcPZhHSh0Pfll1+2G264wSpXruxCfFXjawLVK6+80t59913X3sULwaVgwYKuurxdu3ZuklEFqppcVUvSvuz33nuvrVy50nr16mUXXHCBC2AVJiuMVQjdrVs313+/ffv2Ef1c4exjuFQh36NHD6tYsaIbjPC2G6rdjlq3NGvWLMWT3AZ+hp9++skNApQuXdq1QdKgQcuWLW3evHnWpUuXoOspnFfF/eLFi61r165uIEPV+zoG2ubll19uvXv3th9++MHfUz+WqV3QK6+84gZndI5my5bNHWudkzVq1HADI7ryQgM0GuwAAAAAAAAAosWXEOlZOwGcFgrgNZjw77//ugr7U1Xkly1b1g0MvPfee9a5c+fTtp9nui0//V/ro3hQ/JIGtuXnuRYviteuZ/OW/b8JiWNd3WrlbesvP1q8KFarjm37db7Fi6IXXRZXx9c7xru2/G3xokDxkrZj5TKLF4UrVYv2LgAAAOAM98+SXy0jObvGRdHehTMaFflAnPr4449diK/K/JRMcgsAAAAAAAAgPtEjH4hDf/31l3/yWbUZSskktwAAAAAAADiNMsX+HIKIHwT5QBzRBMFr1661rVu32okTJ+ycc86xfv36RXu3AAAAAAAAAKQjgnwgQj755BN78MEHw1qnbdu29tJLL6X49Zs2bbLNmzfbWWedZQ0aNLBnn33WChQoYLFo48aNVrt27bDWyZs3r+3duzfFr9++fbsb0ChatGiK1ylVqpT9/PPPYe0XAAAAAAAAEE0E+UCEHDx40LZt2xbWOrt37w7r9evWrQtzryKzbmocP3487OORI0eOsNeRcNbRewAAAAAAAADxhCAfiJDOnTu7Bf+nbNmylpCQEO3dAAAAAAAAiAqfL1O0dwEZCGcTAAAAAAAAAAAxjCAfAAAAAAAAAIAYRpAPAAAAAAAAAEAMo0c+AAAAAAAAAESazxftPUAGQkU+AAAAAAAAAAAxjCAfAAAAAAAAAIAYRpAPAAAAAAAAAEAMo0c+AAAAAAAAAESYjx75iCAq8gEAAAAAAAAAiGG+hISEhGjvBAAAAAAAAABkJDtWLLGMpHDlGtHehTMarXUAIB1t/mGGxYsSl19hm+d9Z/GiRN2mNm3RSosXV9asZNt+W2DxouiFl9rWX360eFGsVh37e840iycl619pu7ZutnhRoFiJuDuHd23eaPGiQIlS0d4FAAAAADGMIB8AAAAAAAAAIs1HV3NEDmcTAAAAAAAAAAAxjCAfAAAAAAAAAIAYRpAPAAAAAAAAAEAMo0c+AAAAAAAAAERaJl+09wAZCBX5AAAAAAAAAADEMIJ8AAAAAAAAAABiGEE+AAAAAAAAAAAxjCAfiBFly5Y1n89no0aNOuk5Pa5l1qxZdqbRZ/Y+fzTWBwAAAAAAAKKNyW4BAAAAAAAAIMJ8PmqoETkE+UAcqFSpkrvNlSuXnWn0mb3PDwAAAAAAAJyJCPKBOLBixQo7U11yySVn9OcHAAAAAAAAuL4DAAAAAAAAAIAYRpCPDKNRo0ZuQtOBAwfasWPH7MUXX7SaNWtanjx57Oyzz7ZWrVrZ77//7n/9gQMHbNCgQVa9enXLnTu3nXXWWda2bVv766+/Qr7HkSNH7PXXX7fGjRtb4cKFLVu2bFasWDG7/vrrbfLkycnu38GDB937Va1a1XLmzOn26ZprrrHp06ef8rOFmux23bp1/ud0f9u2bfbggw9auXLlLEeOHFa0aFFr165dshXt8+fPt759+1r9+vWtTJkybr0CBQrYZZddZs8884zt27fPImnBggXWoUMH/z7q2Ot9GzZsaE899ZRt2vT/sXcfUFJU69rHX3LOOQfJSUlKECUHQUQBAROIiuEYEVREEVSMwBGPHBMqYCKrGBAQQRQQBUGCgKCSc85x5lvPPl/1bYbuYXqmZ6Z7+P/uqtU13VXVu6paPffZu969JeTJanV+OqbuhY5Zvnx5e+CBB9z1SIjDhw/bSy+9ZA0bNrT8+fNblixZrFSpUu7aLVy4MMnnDAAAAAAALkLKMtLSglRFaR2kOadPn7a2bdu6gFxBe6ZMmWz37t32xRdfuPfmzJnjQuRWrVrZ0qVLXfCrkHjfvn02ceJEFxz/+uuvVrp06XOOu3HjRmvfvr2tWrXK/a19cufO7cLiadOmueWee+6xN99887w26dgtW7Z03ycZM2Z07VT4/+2339qoUaOSfN5qV+/evW3Xrl2+WvpanzBhgvueefPm2aWXXnrefgqvPdpPy/79+13grmXcuHHumqnjIanGjh1rt99+u8XGxrq/FZjrWmzatMktaqMC9F69eiX4mLp+6qQ5efKk+1sdN9u3b7c33njDpkyZYkOHDo13/2XLltm1117r60DIkCGDuwb6W9dOvwkdY8CAAUk6dwAAAAAAACCxGJGPNEcj5hXOTpo0yY0m12jrX375xY3S1t8asX7XXXe5sHrGjBl29OhR9/53331nhQoVcuH3k08+ec4xtY06BxSWa+S/wn6NsD9w4IBbRowY4QLkt956y0aOHHlem+68804X4iu41jZqk75fo+gVQqtN6mxIiltvvdUqVqzoOiG8c5o1a5YVK1bMDh065EaoB6IQW4G1wm/tp04HPa0wdepUN8nsH3/84TookkrHVBsU4t9yyy22fv16O3HihB08eNC1dfHixda/f/+QOgwUtuspCoX4tWrVch0PurY6D3VeKJTv27dv0P11zm3atHHHueGGG1wbdF91vdRB8/TTT7tj6Pfw+eefJ/kaAAAAAAAAAInBiHykOQrWf/zxR7vyyit979WvX9/effdda9GihS1YsMCVtlm+fLlVqFDBt40+U3mVO+64w4XYGjGv0fyioF7lW1T+ZebMmb73JU+ePPbII49Y2bJlXRis8jn/+te/3EhzUSfCZ5995utk0Kh5j0rKqMNBnQM//fRTks5bZXQU3OvcRN+vpwDefvtt69ixo7smCqxLlix5zn56kiAuHeP66693E81ecsklLsTWiPm4TymEYuXKlS5kVymdDz74wHd9RO/VrVvXLaF44YUXXOiuskg6d68TIH369K7jRWF+nTp1gu7/1FNPuY6bm266yT7++ONzPtOxnn32WcuXL5/rDFDJJnW6AAAAAAAAACmNEflIcxTg+4f4HoXwGhEvXbp0OSfE92h0tmhU9rp163zvv/fee+5Vga5/iO9PIa9K7ezZs8eWLFnie3/8+PHuVSVjVFYmLo341sjvpHr00Ud9Ib6/du3auRJDsmLFipCOWaJECVeOR6Po1QGSFKq7780zsHfvXksqtUlPEoieGAg0kl/zH+heB6KnAT755BO3rjkCgrntttvcq+ZXSGjNfQAAAAAAAEuXPm0tSFWMyEeao1HkgSgw1wS1W7dudSP0g41q96j0jWh71ccXjdbXcYLxJobV9ldccYVbV7kW/8l4A7nqqqvcCHVN0ptY3vfFpeOqZJDOQ2Vz4oqJiXGdDVpUkkglfhRyxxV3EtpQaWR/lSpV3JMNauu9997rOk5q1qwZ7zUN5p9//vGdT/PmzYNup88+/fTT895XZ4t3nq1bt07Qd+q++v9GAAAAAAAAgJRAkI80J1euXEE/88q5BNvGv9yLSuvItm3bfO9ptH1C68F7VLrFG90ejCbcVXmYpIz4Tsh5e+fk384OHTq4yWw9Gr2fP39+35MHCsu1n+rOJ4XCenUWqGSPQvgnnnjCLZpYtlGjRq4sUc+ePX0T9V6Id10vdG3jlhLy+N/XhF53//sal+r0exPuerwnQAAAAAAAAICk4JkI4ALOnj3rW1+9erUr6XKhpVevXhYNhg4d6kJ8leT597//7Uaca5S6St/s2LHDLd5If51XUqlMj0bkT5kyxfr06eNK36iMkSYavu+++9yI/VDL/4TjvqoNCbmveqoimBdffNHNl+C/6D0AAAAAAAAgqQjygQsoWrSob90rsRMKr3a7StsEo5Hc4agbHyqvfv+gQYPs4YcfdpPZxi3/ozA/nDTiX6PvNQmvQnuV8nnrrbfcUwCbN292o/ITwr8mfnzXNthnSb2vcQ0YMMAOHjx4zqL3AAAAAADAxUkZS1pakLoI8oELKFu2rK90y5dffhny/vXq1XOvP/zwQ9BR7fPmzUtSffzEUnAutWvXDvj5hg0bbP369cnaBpUUuvvuu+3ll192fy9dujRBnRrlypVz4b/4lwaK6/vvvw/4vuZJ8CYBTsx9jUtldDTZsf9CaR0AAAAAAACEA0E+kAB33XWXe33vvfdc0ByfuBPKduvWzb1u2rTJxo4dG3Cy2eeff95Sg8q/yO+//x7wc9WwD5e49ePjUnkfT/r0F/5Xk3qCb7zxRreuEf2B5i/4448/bPLkyQH3z5Ejh910001uXZ0Iuj/xCTRRMAAAAAAAAJASCPKBBHj00UetZs2arn58s2bN7I033jhn1PiBAwds+vTpdtttt1mTJk3O2Vc15jt27OjW7733Xnv33Xd9obbCYwX9CxcuTPAkr+HUtm1b96qOhKlTp/qeCtBktAq5J06caPny5QtbGZ/GjRu7kjp///33ObXqZ8yY4es0aNiwYYK/U6VrNMmvQvxWrVrZ4sWL3ft68mHmzJnWrl27eK/rCy+8YMWLF3f763s//PBDO3z4sO9zlf1RPX9N0NujR48knD0AAAAAAACQeAT5QALkzJnTvv32W2vQoIGrff7AAw9YoUKFXOCsUe16veaaa1wQfOrUqfP2f//9991Er+oI0CSvCp+1T5kyZVxQ/Nprr7njpTQF+EWKFHHhdefOnd2o+Lx581r58uXt008/dZPh1qpVKyzfpXB9wYIFds8999gll1xiWbNmtYIFC7ryNupQ2LJliwvVda0SSjX91U6VsFm2bJkrl6OSNhpt36ZNGzt9+rSNGDEi6P7FihVzE+1WqlTJtm3b5jpidP4q96N7rjr8Xbp0sc8//9w9OQEAAAAAAJBgqjiQlhakKu4AkEAKmX/66ScXHGuEvULgY8eOueBedfSvvfZaF8ir3n1cCoYVYg8ZMsSqVKniSsdkzJjRBdizZs2y++67L1XOSR0JGsV+xx13uPMTBewdOnRwo+TDOVmrrtm4cePs9ttvd50a6gBRp4g6NS6//HJ77rnnbNWqVe76hKJ9+/b222+/Wffu3V3wrvuhzon777/flUFSLf34VK1a1ZYvX+6eFGjdurXrXDh06JDreKhQoYJ17drV3nnnHfd0AgAAAAAAAJAa0sUGm30TAJBk2xYEnmw3EhVv1Ny2zf/OokXxxi1t1tK1Fi1a1a5sO5ctsmhR5LIrbMeShRYtitZtaFt/nGXRpESTVnZgxzaLFnmLFo+63/CBbf+b1D0a5C1eKrWbAAAAgDDbt/H/SgunBfnLlE/tJlzUGJEPAAAAAAAAAEAEy5jaDQAAAAAAAACAtCZdunSp3QSkIYzIBwAAAAAAAAAggjEiH0BIhg0b5pZQ9OvXzy0AAAAAAAAAQkeQDyAkR44csZ07d4a8DwAAAAAAAIDEIcgHEJLBgwe7BQAAAAAAAPGgRj7CiBr5AAAAAAAAAABEMIJ8AAAAAAAAAAAiGEE+AAAAAAAAAAARjBr5AAAAAAAAABBu6RhDjfDh1wQAAAAAAAAAQAQjyAcAAAAAAAAAIIIR5AMAAAAAAAAAEMGokQ8AAAAAAAAAYZYufbrUbgLSkHSxsbGxqd0IAAAAAAAAAEhLDmzbbGlJ3uKlUrsJFzVG5ANAMlo7ephFi8p39rN1Y1+3aFGx54M2YtqPFi36dmxi6z9526JFhZvutr8nj7FoUb5LL/vz/X9bNKnU+xHb+dvPFi2K1GlgG6dPsWhRpl1n2/3H7xYtClW71HYsWWjRomjdhqndBAAAAOCiQo18AAAAAAAAAAAiGCPyAQAAAAAAACDc0jGGGuHDrwkAAAAAAAAAgAhGkA8AAAAAAAAAQAQjyAcAAAAAAAAAIIJRIx8AAAAAAAAAwi1dutRuAdIQRuQDAAAAAAAAABDBCPIBAAAAAAAAAIhgBPmIWnPnzrV06dK5Jdy84+o7wuWDDz6whg0bWu7cuX3Hf+2119xnvXr1cn/rNa6mTZu6zwYPHmzJacyYMe57ypYtG9JnKSG1vx8AAAAAAABITdTIR4pRKK5FYWygwDotGz58uPXr18+tZ8yY0QoXLuyC6Rw5ctjFbMOGDS6kl+TuqAAAAAAAAEhJ6dIxhhrhQ5CPFKMQf8iQIXb11VeHJcjPnj27Va5c2aLBq6++6l4ffPBBGzZsmGXKlOmcz4sVK+bORa+pJU+ePK4NJUqUSNEgX7+JCwX5qdE2AAAAAAAAIFIQ5CNqXX755bZmzRqLdLt377adO3e69bvuuuu8EF9efPFFt6Sm66+/3i2RKJLbBgAAAAAAACQ3nu8AktmxY8d86zlz5kzVtgAAAAAAAACIPgT5CNn+/fvtvffesxtvvNFq1qxp+fPnt6xZs1qZMmXspptusp9//vm88imqB++VUPnhhx98k716i1cnPe7krqdPn3b15evVq2d58+Y9ZwLa+Ca7jYmJsdmzZ7tSNg0aNLCSJUta5syZrUCBAq60z1tvveWOnZy89vlP0FquXDlfm/3fj2+yW3+nTp2yl156yWrVquXq6+fLl89atWpl06dPD7qPvse7xkeOHLFBgwa5+5YrVy73vu5PUiaU1XWcNm2a9enTx90nlQfStdY8AG3atLFPP/3UYmNjA7arWbNmvr/j/ib8r0VC2vbXX3/ZvffeaxUrVrRs2bK5SYXr1Kljzz77rB06dCjgPnF/Q+vXr7fevXtbqVKlLEuWLO53o6cotm7dGtI1AQAAAAAAAMKJ0joI2ciRI32hfIYMGVxgKps2bXLL+PHj7bXXXnMhurdNkSJFXIh89OhRV1pG4b8/Ba9xnThxwoX6CxYscBPEesFzQqgdLVu2PGckvGrq79u3z+bNm+eWTz75xGbMmBHwu8NBYbbO++zZs7Znzx73XsGCBd31kEKFCoV0PIX4Oqcff/zRXQ+d04EDB+y7775zyzPPPBNvnfm9e/da3bp17c8//3Rt0/UIh/nz59t1113n+1u/B3XsqKTQzJkz3fLZZ5+530X69P/Xd6jzV8CujiHRtYpbFz+hJk6caLfddpudPHnS/a3fiq7X0qVL3TJ69Gh3r6tWrRr0GHPmzLGOHTu636n2V2eQAnzt+80339gvv/xCjX4AAAAAAJBwCcyxgIRgRD5CVrx4cRcaL1682JWNUTh+/Phx+/vvv+2hhx5y2/Tt29cFqKLRzTt27LB+/fq5vxs1auT+9l+6det23veMGjXKli9fbh988IELfPU9Coc1Gv1CFHTffPPNbqS4AuzDhw+70FuvOp7OQYH4wIEDLbl45/nrr7/63tO6d87+7yfEf//7Xxcm62kCnYcCcHVYdOnSxX2uzhWdbzAK+XUdFaorrNb+mzdvdiPnk0IdAnfffbfNmjXLDh486BZ9j667On0U7E+aNMneeOONc/bT+U+dOtX3d9zfhPZNiN9++81uueUWF+I3btzY/Wb0/fpt6nroCQGd57XXXuvOO5jOnTtb8+bNbfXq1W5/dTpNmDDBhfrbtm2zAQMGJOEqAQAAAAAAAIlHkI+QqYSKQmGN7tbIbtFIeZWN0Uj8++67z41CVxCfFApdNWpeJVa8UfMqjRN3NH8gKony0UcfufDWf3uNYtfxvvjiC/f3O++840b+RwMF5ArzFZprxLvXSaKw+aqrrnJ/P/nkk0H3V2eLRpZ36tTJN+GurlNSR+Zr0mF1LuhpAe/pDNF111MZKsMkr7/+uiUHdcaovE+FChXc6H+VDRKN/tf9//rrr13HjkrvqJ3BXHbZZa6To0qVKu5v/bZVPmro0KHu78mTJ9uZM2eS5RwAAAAAAACA+BDkI+zat2/vXn/66ackHad69eouiE0OquWukegadb1s2TKLBgrtb7/99vPeV2D91FNPufVVq1bZihUrAu7ftm1bq127tqXW70FBukbah5OeslDJHOnfv3/ATgmd8w033ODWVa8/GHWC+Jf+8Xhlg9QRsm7dujC2HgAAAAAAAEgYgnwkisroqFSORuVrElrVffcmDb3mmmvcNlu2bEnSd6hMSlKoRrpGYLdu3dqV0tHkpf6Tqe7atSss7Uwp3iTAgTRp0sSNOheVPEqO6xkflfp59dVX3UTC6iDRaHbvOvuH6+G+1iqr402k6z8nQlyaEFhUdifYJMdXXHFFwPf12/GovBMAAAAAAEBCpEufLk0tSF1MdouQqfxIjx49fBOL+k9wquBWAbrqr2u0e1IkpXa7QnoFu/6j09U+/8lmVW9fE5omtZ0pJb6JVnVuKju0c+dOXwdFXEmthR+MJs9t0aLFOSG9wnt18Hgj3NUuCfe19j/X+K6PSgiJSuMojI87sa6oFn4gXgeJBOsEEP3z4P/PhKjzCAAAAAAAAEgqRuQjJJrAVDXmFVhqYtC5c+e6SUVVv11hrUqnaGLTcPAC98R45JFHXIivcPv999+37du3u9IoCu+9yVS9kdbeiO60LinXMz4q96MQv2zZsu7e6zeiwF4hu67z1q1bfdum5Wv94osvWp48ec5Z9B4AAAAAAACQVIzIR0g0WeqhQ4csX7589uWXXwasSR7uOuih0qjpqVOnuvU33njDunfvft42mox3z549Fk38A/G41LGiAD05R94HsnnzZluwYIGv/nyDBg1S9Pfgf67qTLjkkksCbuc9LaDR9QmZLDkxBgwYYH379j1vRP6GD/+TLN8HAAAAAACAiwdBPkIObqVy5coBQ3z57rvvAr7vlVlJ7lHZGnV/4sQJtx5scldNxOttEy1++OEHd+0C1cn/8ccfXdkYbyLflP49xHetg/0exH9y2WDnFp86deq4Y6hE0uzZs4MG+V4bLr30UsuUKZMlB4X2lNIBAAAAAAA+6SiGgvDh14SQqFyIVxc9UBC+bNky++STTwLuqzr6cuDAgWRto77HC4R///338z5X4D1w4ECLNps2bbKxY8ee975C7BdeeMGtV6tWzWrWrJniv4dg11qT4D7//PNB9/d+E4n9XagOf5s2bdy6JttVmae41K4pU6a4dc3tAAAAAAAAAEQbgnyEpHXr1m4EtCYMvfnmm33lXjTB7cSJE93nwSYNrVGjhntdtWqVrxxLcsiZM6c1btzYravUyffff+/Cblm5cqVdc801tnjxYsuRI4dFE4Xm9957r7377ru+ThSNiFc4PWfOHPd3fKF5cqhataqVLl3arffu3duWLFni+2zhwoXWtGlTN/FxMJUqVbLMmTO79dGjRyfqaQ2ds0bZr1+/3oX63gTHuucqBaX7rc4bjda/++67E3GWAAAAAAAAQOoiyEdIKlasaP3793frqkNfsmRJNypa4Xm3bt3c6+uvvx5wX4W6Ksmj+vQK2lWrXBOkapk8eXJY2/naa6+5oF4dDS1atHBlgDT6W6PVFXorDC9YsKBFk/vuu8+VzenTp487F10/hejqQJGnnnrKrr/++hRtkzp1Ro0a5WrPq4NG7dN119KoUSNbu3atTZgwIej+ui+33nqrW3/sscfc76dMmTLuN9GvX78El9f58MMPXYeASibVqlXLdXqoDe3bt7dt27ZZqVKl3JwOOj4AAAAAAAAQbQjyEbKXXnrJxo0bZ5dffrlly5bNTS5boUIFe/LJJ23p0qVWvHjxgPsp7FUd8zvvvNPKlStnR48etY0bN7rlyJEjYW1j3bp17ZdffrEbb7zRBfYana0nBfS3ngbwwuNooqBa109ldNQhogluFViro+Lrr7+25557LlXa1aFDB5s3b54LzdWpo9Hvuua33367G6Gv9sVHHQGDBw/2lQRSCSH9JkKZjFidSOpI0Ih7jbzXtdHv7bLLLrMhQ4a4JzH09AAAAAAAAECKUenntLQgVaWLTe6ZRwHgIrZ29DCLFpXv7GfrxgZ+oiYSVez5oI2Y9qNFi74dm9j6T962aFHhprvt78ljUrsZCVa+Sy/78/1/WzSp1PsR2/nbzxYtitRpYBun/2/OkWhQpl1n2/3H+fO3RKpC1S61HUsWWrQoWrdhajcBAAAg4h3at9fSktz5C6R2Ey5qjMgHAAAAAAAAACCCEeQDAAAAAAAAABDBMqZ2AwAAAAAAAAAgrUmXjjHUCB+CfCABHnroIZswYUJI+4wcOdJNwgoAAAAAAAAASUGQDyTAwYMHbefOnSHtc/z48WRrDwAAAAAAAICLB0E+kABjxoxxCwAAAAAAAACkNAo1AQAAAAAAAEC4pU+XtpYkOHz4sA0ePNhq1qxpOXPmtDx58lj9+vVt+PDhdurUqSQde+fOnfboo49a5cqVLVu2bJY/f35r0qSJjR492mJjYy+4/19//WV33323lStXzrJmzWqFChWyNm3a2JQpUyySMCIfAAAAAAAAAJAsNm7caE2bNrUNGza4v7Nnz24nT560xYsXu+Xjjz+22bNnW758+UI+9pIlS1zovnfvXve3OgnUafDTTz+5ZfLkyTZt2jTLnDlzwP2/+eYb69q1qx07dsz9nTt3btu3b5/NnDnTLbfffru99957li5d0joywoER+QAAAAAAAACAsDtz5oxde+21LsQvVqyYzZo1y44ePeqC8/Hjx1uuXLls6dKldssttyRqTssOHTq4EL9KlSr266+/uhBfx3/jjTcsU6ZMNmPGDHv44YcD7v/PP//YjTfe6NrSuHFjW7t2rTumlkGDBrltPvjgA3v11VctEhDkAwAAAAAAAADCbuzYsbZixQq3rlI1LVu2dOvp06e3bt262dtvv+0bGa9R+aEYNmyY7dixw5XT0f716tVz72v0/b/+9S8bMmSI+/udd96xP//887z9FdYr9C9atKh99dVXVqlSJd+ofu3bp08f9/fQoUNt//79ltoI8gEAAAAAAAAg3NKlT1tLIoN8adasmTVs2PC8z7t37+5q08u4ceNCOva4/7+9/zH8PfDAAy6UP3v2rCvf408BvlcD/95777W8efOet/+AAQPc66FDh+zzzz+31EaQDwAAAAAAAAAIK5WsmT9/vltv165dwG1Ue75t27ZuXTXpE2rt2rW2adOmeI+tEF+T3gY6turnHz9+PN79y5Yta1WrVg25bcmFIB8AAAAAAAAAEFarV6+2mJgYt16jRo2g23mfqUyOJppNiJUrV563f3zH/uOPP5K0/6pVqyy1ZUztBgAAAAAAAAAAItvJkyfd4i9LlixuCWTbtm2+9RIlSgQ9rv9n2id//vwXbMu2EI+t8jhHjhxxo/T998+XL5+rsX+h/f2/L7UQ5ANAMqp8Zz+LJhV7PmjRpG/H/z0iFy0q3HS3RZPyXXpZNKnU+xGLNkXqNLBoUqZdZ4smhapdatGkaN3za4YCAAAgesWmS2dpyYsvvuibQNbzzDPP2ODBgwNuf/jwYd969uzZgx7X/zP/feJzOJHH9oJ8b//49vX/PKHtSk4E+QCQjCbP/92iRZfGl9qspWstWrSqXdl2LP5frb1oULReY5u3cr1Fi6tqVLD5q/62aNG4enmbs3ydRZNmtSrarn0HLFoUzp/XFvwRPb+JRtXK2/qtOy1aVChRJOraG22/BwAAACSNJn/t27fvOe8FG42P8CPIBwAAAAAAAADEK74yOoHkypXrnIlvg/H/zH+fUI6dO3fukI7trcfXLv/PE9qu5MRktwAAAAAAAACAsCpevLhvfevWrUG38//Mf59wHjt37ty+sjr+++/fv9+OHz9+wf0T2q7kRJAPAAAAAAAAAGF2NiZtLaGqWrWqpU//v/h55cqVQbfzPitatGiCJrqVGjVqmCchx65WrVqS9q9evbqlNoJ8AAAAAAAAAEBYaaLYxo0bu/Vvv/024DaxsbE2Y8YMt966desEH7tSpUpWunTpeI999OhR+/HHHwMe+8orr7Rs2bLFu//GjRtt9erVIbctuRDkAwAAAAAAAADCrmfPnu51zpw5tmjRovM+nzRpkv39999u/bbbbkvwcdOlS+fbfvz48bZhw4bzthk1apQdOXLEMmTIYDfffPM5n+XIkcM6d+7s1t988007ePDgefu//PLLvvr4nTp1stRGkA8AAAAAAAAASJYgv2bNmm7kvYLz2bNnu/djYmJciH/XXXe5v9u1a2ctWrQ4Z9/Bgwe7wF7LhgBBfb9+/Vw5Hk1I2759e1uyZIl7/9SpUy6cf/rpp93fffr0cSP443r22WddoL99+3a79tprbd26db6R/Prsrbfecn8/9dRTli9fPkttGVO7AQAAAAAAAACQ1sRarF3sMmbMaNOmTbNmzZq5ML5ly5au5I6C/BMnTrhtateubR9//HHIx86TJ4999dVX1qZNG/vjjz+sXr16bvS8jnv69GlfSZx///vfAfcvV66cTZw40bp27epK8Cjs1zE1iv/s2bNum9tvv9369+9vkYAR+QAAAAAAAACAZFG2bFlbvny5DRo0yE0yqxH2mTJlsrp169qwYcPs559/TvSI97p169qqVavskUcesYoVK7oAX6PsVQP/3XfftenTp1uWLFmC7n/NNde4tunJALVTnQBqS6tWrWzy5Mn2/vvvu/ZGAoJ84CLXtGlT9y8kPa6UksaMGeO+V/+SDLdevXq5Y+sVAAAAAAAAqUsj5YcMGWIrVqxwI94PHTpkixcvtkcffdQyZ84ccB9lVSrJo6VsPPlRkSJFbMSIEfbnn3/a8ePHbf/+/W6E/Z133mnp0184/r7kkkvsnXfesX/++ccF+bt377aZM2f6auhHCkrrAECATgY97qVODi0AAAAAAABAaiLIB5AqVHOscuXKVqJECYvEIP+HH35w6wT5AAAAAAAgMWIpkY8wIsgHkCquv/56twAAAAAAAACIHzXyAQAAAAAAAACIYAT5AHw0eYhm9L7iiissd+7cbiKShg0b2kcffRTvfitXrrQ+ffq42cGzZ89uOXPmtFq1atnAgQNtz549iZ7sdt68eXbttddawYIFLVu2bK4Uj46pSVFCmSxXs4yrRE7+/Pld+y677DIbOXKkxcTEBGyTV1ZHk7Dob/9FtfMBAAAAAACAlERpHQDO2bNnXambL774wjJmzOgC78OHD9vPP//slnXr1rlgO65XXnnFBgwY4AvFtd/p06fdLORaPvjgA/v666+tdu3aIbXnP//5jz300EOuc8Grqa8Q/YUXXrDPPvvMdRwkxP3332+jRo1ys5Src0Kzl//+++/28MMP22+//WZjx471bavOAs10vm/fPncOOXLkcJ0S/jJkyBDSeQAAAAAAgItTDEXyEUaMyAfgKOyeO3euG5V+6NAhO3jwoG3evNmNiJfnn3/ehfn+3nvvPXv88cddeD906FDbvn27HT161I4dO2aLFy+25s2bu/c6duzoRtEn1IIFC1zQrhC/VatWtnbtWjtw4IA79qRJk2znzp327LPPXvA406ZNc08YjBgxwvbv3+8WPSFw5513us/HjRtn33//vW/7bt262Y4dO6xRo0bu7379+rm//ZdSpUol+DwAAAAAAACAcCDIB+Ao5NZI9549e7qR6VKyZEkXnBcvXtyNuJ84caJve43WV9Dtla558sknrWjRor5R63Xr1rUZM2a41y1bttjo0aMT3JZBgwa576tWrZp9+eWXVqlSJfe+nhTo0qWL+z61NyHn9Pbbb9sjjzziRuNLgQIFXLivdsmnn34a0nUCAAAAAAAAUhpBPgCncePG1qxZs/Pez5Ili7Vp08atL1++3Pf+lClT3Ch5lczxPo9LwXuPHj3cukL9hFBZG2+UfP/+/d33x6V2NmnS5ILH0uh5dUwEoqcE4p4TAAAAAAAAEImokQ/A0QS3wWhEvheye+bPn+9eV69e7RuJH4hq0svGjRsT1I6lS5f66uJfffXVQbfT5LU//vhjvMeqX7++m6A2oecEAAAAAAAARCKCfABOrly5gn6mkfWiCWA927Ztc68nTpxwy4Wobn5C7N69+7ywPZASJUqE/ZyS4uTJk27xF+hpAgAAAAAAcHHwBioC4UBpHQCJcvbsWd8EsfoP04WWDRs2hPwdwUbTR6IXX3zR8uTJc86i9wAAAAAAAICkIsgHkCheOZ2ElsxJqEKFCp036j+QrVu3WiQZMGCAHTx48JxF7wEAAAAAAABJRZAPINGT48qSJUts+/btYTuuJs/1RuLPnTs36HbxfZZU6dOnD/kROJXRyZ079zkLpXUAAAAAAAAQDgT5ABKla9euljdvXldjvm/fvvGG3jExMXbgwIEEHTd//vzWrFkztz58+HA7derUedvMmzfvghPdJoVCeElomwEAAAAAAOKKiY1NUwtSF0E+gERRiP/aa6+59fHjx1v79u1t0aJFLrQXva5evdqF8dWrV7evvvoqwcceMmSIG5W/cuVK69ixo61bt869f+bMGZs6dap17tzZ8uXLl0xnZlajRg33+s0330RcCR8AAAAAAABcfAjyASRaz5497c0337TMmTPb9OnTrUGDBpY9e3YrWLCgZc2a1apVq2b9+vWzNWvWhDRx7ZVXXmkjRoxw6zNmzLBKlSq54D5nzpwuxFd9/kGDBrnP9T3JcV467vr166106dLu+8qWLeuWLVu2hP37AAAAAAAAgPgQ5ANIknvuucfWrl3rAvtLL73U1YVXSRqF7vXq1bMHHnjAZs2aZT169AjpuA8//LCrg3/NNde4EP/EiRMuSH/qqafs559/9pXy0ZMB4VaxYkWbM2eOexpAk+/u3bvXTeqrRU8FAAAAAAAAACkpXWwoszkCQIS4+eab7ZNPPrHevXvbe++9Z5Fq8vzfLVp0aXypzVq61qJFq9qVbcfi+RYtitZrbPNWrrdocVWNCjZ/1d8WLRpXL29zlv+vDFe0aFarou3aFz1zcRTOn9cW/BE9v4lG1crb+q07LVpUKFEk6tobbb8HAACAlLZ9z35LS4oVTL4yx7gwRuQDiDp//vmnq5Uvbdu2Te3mAAAAAAAAAMmKIB9ARFIN/DfeeMM2bdrkm0D36NGjNmHCBGvWrJkrtVOlShXr1KlTajcVAAAAAAAASFYZk/fwAJA4y5cvty+++MLV2M+UKZPlypXL1d73Qv0SJUrYpEmT3GcAAAAAAABAWkaQDyAiPfLII1a8eHFbsGCBbd++3fbt2+fC/EqVKlmHDh3s/vvvt/z586d2MwEAAAAAAAJialKEE0E+gIh09dVXuwUAAAAAAAC42FEjHwAAAAAAAACACEaQDwAAAAAAAABABKO0DgAAAAAAAACEWQw18hFGjMgHAAAAAAAAACCCEeQDAAAAAAAAABDBCPIBAAAAAAAAAIhg1MgHAAAAAAAAgDCjRD7CiRH5AAAAAAAAAABEMIJ8AAAAAAAAAAAiWLrYWB7yAAAAAAAAAIBw2rxzr6UlpYoUSO0mXNSokQ8AyWjFK49btKj52Mu2/IVHLVrUenK49R873aLFqz3b2R+vD7FoUe3BZ+yPkc9YtKj20BBbNvhfFk0uGzzKts3/zqJF8cYtbd24NyxaVLztftu24HuLFsUbNbctc762aFGyWXtb8+aLFi2q3DvAZi1da9GiVe3Kqd0EAAAQBoyfRjhRWgcAAAAAAAAAgAhGkA8AAAAAAAAAQAQjyAcAAAAAAAAAIIJRIx8AAAAAAAAAwiyGGvkII0bkAwAAAAAAAAAQwQjyAQAAAAAAAACIYAT5AAAAAAAAAABEMGrkAwAAAAAAAECYUSEf4cSIfABRr1evXpYuXTr3Gm7Tpk2z5s2bW758+Sx9+vTuex5++OGwfw8AAAAAAAAQDCPyASCIKVOmWJcuXdx6hgwZrGDBgi7Mz507d2o3DQAAAAAAABcRgnwACOLVV191r507d7Zx48ZZ9uzZU7tJAAAAAAAAuAgR5ANAECtWrHCvKtlDiA8AAAAAAEIRE0uVfIQPNfIBIIhjx46515w5c6Z2UwAAAAAAAHARI8gHEBU+/vhja9y4seXKlcvy5MljV1xxhb3zzjsWm4De7ZUrV1qfPn2sYsWKbmS9gvlatWrZwIEDbc+ePedsu2HDBjehrRZPs2bNfO/5vw8AAAAAAACkBErrAIhoCurvuOMO++CDD9zfCtLz5s1rixcvtl9++cXmzJljWbJkCbr/K6+8YgMGDLCYmBj3t4L806dPu7I5WnTcr7/+2mrXru2b1LZIkSJufefOne41X758ljlz5hQ4WwAAAAAAAOB8jMgHENH+85//+EL8+++/33bt2mX79u1zy+DBg23ChAn2xRdfBNz3vffes8cff9yF90OHDrXt27fb0aNHXckcdQQ0b97cvdexY0c7cuSI26dUqVK2Y8cOt3imTp3qe8//fQAAAAAAgPgGJ6alBamLIB9AxDpx4oQNGTLErd96660u1C9YsKD7W+V1nnnmGRfUHzhw4Lx9Dx8+bP369XPrkydPtieffNKKFi3qG3Vft25dmzFjhnvdsmWLjR49OkXPDQAAAAAAAEgognwAEWvmzJlu5L0MGjQo4DZPPPGEZc2a9bz3p0yZ4gJ+lcxp06ZNwH0zZsxoPXr0cOsK9QEAAAAAAIBIRI18ABFL5W+8cjcVKlQIuI1G5mtU/fz588953/t79erVvpH4gRw/fty9bty4MYwtBwAAAAAAAMKHIB9AxFI9fClRokS825UsWfK897Zt2+Yrz6PlQlQ3PylOnjzpFn/xTcILAAAAAADSNsrKI5worQMgTTp79qx77datW4ImbNmwYUOSvu/FF190Twf4L3oPAAAAAAAASCqCfAARq3Dhwu5169at8W4X6HOvnE5KlcwZMGCAHTx48JxF7wEAAAAAAABJRZAPIGLVq1fPvW7evNn++uuvgNscOnTIlixZct77jRs3dq/6bPv27cnc0v+V0cmdO/c5C6V1AAAAAAAAEA4E+QAiVqtWrSxfvnxu/bnnngu4zSuvvOKbsNZf165dLW/evHb69Gnr27evK58TTExMjB04cCCMLQcAAAAAAADChyAfQMTKli2bPf3002597Nix9vDDD9vevXt9I/EV7r/wwgsusI9L77322mtuffz48da+fXtbtGiRC+1Fr6tXr7bhw4db9erV7auvvkrRcwMAAAAAAGlbTGxsmlqQujKm8vcDQLweeughW7p0qX344Yc2cuRI+89//uMmklWQrwltu3fv7krYKOiPq2fPnm60vo4xffp0t2jbnDlzuv01Wt+TLl26FD4zAAAAAAAAIGEYkQ8goqVPn97GjRvnlgYNGrhR+mfOnLE6derYW2+9ZZ988km8+99zzz22du1a69evn1166aUuyFcZHYX5qsH/wAMP2KxZs6xHjx4pdk4AAAAAAABAKBiRDyAq3HrrrW4JZMyYMW4JpmzZsvbqq6+G/J3x1dUHAAAAAAAAUgpBPgAAAAAAAACEGQMEEU6U1gEAAAAAAAAAIIIR5AMAAAAAAAAAEMEI8gEAAAAAAAAAiGDUyAcAAAAAAACAMKNEPsKJEfkAAAAAAAAAAEQwgnwAAAAAAAAAACIYQT4AAAAAAAAAABGMGvkAAAAAAAAAEGYxFMlHGDEiHwAAAAAAAACACEaQDwAAAAAAAABABCPIBwAAAAAAAAAgglEjHwAAAAAAAADCLJYa+QgjRuQDAAAAAAAAABDB0sXSNQQAAAAAAAAAYbXyn62WltQoVyK1m3BRo7QOACSjjV9PtGhRpv2NUdfeKQuWW7To3KiWbZ71hUWLUq2ui7r2bvhqvEWTsh262551f1i0KFixmm1bOMeiRfGGzWzP2lUWLQpWrm67V0fPv9MKVa1lW+ZOt2hRsmk7W/bXZosWl11Syv6a+J5Fi0tuvCO1mwAAAJDmEeQDAAAAAAAAQJjFUAcFYUSNfAAAAAAAAAAAIhhBPgAAAAAAAAAAEYwgHwAAAAAAAACACEaNfAAAAAAAAAAIs1ijSD7ChxH5AAAAAAAAAABEMIJ8AAAAAAAAAAAiGEE+AAAAAAAAAAARjCA/DWratKmlS5fOBg8enKL7IryOHTtmTz/9tFWtWtWyZcvm7ouWZcuWpXbTAAAAAAAAcAGxsbFpakHqYrJbJKsxY8bYhg0bXAeBFiRct27d7KuvvnLrCvKLFCni1jNlypTKLQMAAAAAAACQkgjycY7SpUtb5cqVrWDBgmEL8n/44Qe3TpCfcGvWrPGF+BMmTLAbb7wxtZsEAAAAAAAAIJUQ5OMc48aNS+0mwMxWrFjhXgsUKECIDwAAAAAAAFzkCPKBCK2PLzlz5kztpgAAAAAAACARYigrjzBists0ThNRvPvuu3bFFVdY7ty5LVeuXNawYUP76KOPQp7s9syZM/bOO++4bVR6R7XaNWJcpXhUz/299947p6SOjuOV1RkyZIhvslZvUe18f2fPnrX333/fmjdv7o6fJUsWK1GihHXt2tXmzp0b9Bz923z69GkbPny41atXz/Lmzeve177du3d369dcc02812v9+vWWPn16335JdeLECXvttdesUaNGli9fPsuaNauVKVPGbrvttoCT1uoc9N29evVyf2/cuPGca+a9nxRHjx61ESNG2NVXX+2uc+bMma1kyZLub127nTt3nrP9/v373b3VkwE1a9a0/Pnz+87jpptusp9//jnod3nn45VVmj17trVv394KFSrkjqGJfPXb0HWKz969e+3ZZ591v2Pv+8uWLWutW7e2N9980w4ePBhwv5UrV1qfPn2sYsWKlj17dtcxUqtWLRs4cKDt2bMnQW2eMmWK+57ChQu73wYTQQMAAAAAACClMSI/DVMwfv3119sXX3xhGTNmdEHm4cOHXfCqZd26dS5ETeixFILPmjXL916ePHlcKLxv3z77888/beLEiXbHHXecMzmrPlO4niNHjvNGl2fIkMG3riC2U6dOvvBcn6nTYfv27TZ58mS39OvXz1599dWgbVQYrPB1wYIF7ny1vwJZueeee1yt+RkzZtimTZvcXACBjB492nV+VKpUKck1/bdu3Wpt27Z1YbKo40P3QN//4Ycf2scff+xC/gceeMC3j66Rrtvx48ft0KFDLjhW6O1/zZPit99+c9d58+bN7m8dXx0eCrXV3nnz5rlr//DDD/v2GTlypO93os/UISQ6Dy3jx4935/Hggw/G+926d48//rjvPE6dOuXmAlAwrg4f/bb8fxOemTNnuo4YdSiI7q3237Ztm+vo0H7FihVz5+XvlVdesQEDBlhMTIz7W9dev0WVLdLywQcf2Ndff221a9cO2uZHH33UdXrod6TrpOsFAAAAAAAApDRSqTRs1KhRLhjX6HiFwgrLFeBee+217vPnn3/ehfkJ8emnn7rAVCOhFXarQ+DAgQMucNYI7qlTp1qXLl1822uE/o4dO9xIdFEIr7/9l1KlSvm2VweA2qrR4a+//rprr4JbhbW9e/d22wwbNszeeuuteM93+fLlLqDV/upE2L17txuBrVBeo78V6vo/OeBPIa+ulWgUd1Ko46Nz584uxFforCcgjhw54q7ZX3/9ZR06dHBteeihh2z69Om+/bzrpPBcdI38r5n3fmLo3rdp08a96rgK4HUfNdpd93HVqlUuVPfvOJDixYvbM888Y4sXL3Ylf3Rdtf3ff//t2i99+/a1pUuXBv3u33//3Z544gm37Nq1y91bXYtBgwa5z+fMmWNjx449bz8d87rrrnPbV69e3b755hvXBnU8qA1qk8J2ddr40z1Wp4HC+6FDh7oOIXU6aV/to6c+9F7Hjh3dfQlkyZIlLsTXcfQb13nrGLfffnuirj8AAAAAAACQWAT5aZjCz88++8x69uzpRsiLSqhMmjTJhbMKkjWKPiE0yl1UEkahuze6XiOVVXJEI/913MRYtGiRK18i//nPf9wIdQWwUrRoURfKKhSXp59+OmgZFgWyn3zyiSs/452vSv+oFIvcfffd7lXlexS0xzVt2jQX2Kqkj65ZUugJAp2X6BrffPPNrpNCypcv7+6LysRo9P9jjz1mKeHJJ590Abiuyfz5811ni3eddR+rVavmAnu11Z86NRTw161b13cO2r5cuXJuJP59993nrqc6UoJRaK9798ILL7hyPqKR/Rrpf8MNN/g6i+LSKH/db5XGUZvbtWvnnmwQjd5Xm9TB06JFC98+6pxQh4h3H3Te+h3576MnM/S6ZcsW1zEV7PekDoqXXnrJ17mh34ZKCgEAAAAAAFyIcp+0tCB1EeSnYY0bN7ZmzZqd977CSI3MFo1gTwiVFRGNCg83lbzxOhnuvPPOgNs899xz7lVBtH95H38ase09bRCIwnkF1wpvNbI7Ls0lIAqWvbA5qeek+QhUXz0ulYdRaC4ata9SL8lJI8m9NmlUvP/TEEmlmvfy008/Bd1GvzkvXI9LI+4D/Rb1tIh3THUAJLSskDqF1HGgkjne7zzQ9e/Ro4dbV6gfiMroeKWAAAAAAAAAgNREkJ+GacR3MBqRLyoXkhCqj69R2Bq1rlHRGj2tsjfhoFInok6HYDXIVRZHE9/6bx+o4+JCnREahe4f2nu8WuvhKKvj38aWLVsG3Ubn69WED3ZO4aLjq3SQxNfZEYzK6CiI1yh2XUe125uA15tAWB0kwaiTJe4cCRf6LXpPgei79JtLKI3cl9WrV7uR+MEWTZ7r3ftAKlSo4J42AQAAAAAAAFIbk92mYXHrhscdkSxeuHshV155pb388sv21FNP2bfffusWbxS9wmqV3Ak0+j8hVDNdvKA+GH2XJmT1to8rIaGrJr1VDX2NyNexvO9UeRWVGqpcuXKSJ7lN6DlpvgGN/Fc5n2DnFC7+T1KEWhpGZYA0ev3kyZO+91QWR+1XkK9Ja1XGSaP+k/JbPHPmTMA26xppsuSE8jqYVJInWBkmf6qbH0ioIb6uj/818p5EAAAAAAAAAJKKEflIsP79+9s///xj//73v61Tp04u6NQobE0Qq8lDu3btmuCOgeTgjW6Pz+WXX2516tRxNd29SW+1rnBf7rrrLkuLFLgnhibC1ZwDCqh1jzUhsYJvTZysDgiF7YmdGyG52uzNf6CnLxJS323Dhg2J/j35e/HFF135H/9F7wEAAAAAgItTate0p0Z+2kKQj5CoDMrDDz/sRmkryFVdc6+uvSYWffPNN0M+pjfyOb7SLP6fJ7XciUble5PeahS+Nzo/HJPchnJOGi2uoNx/++TiTfYaXymZQHRtDh06ZPny5bMvv/zSrr76at9Ewp7kmDfBv82aFyG+0f7B9gvlPMNhwIABroPDf9F7AAAAAAAAQFIR5CNJatas6erNe/Xp405E69W8j6/Xrl69eu51zpw5LlgPZM2aNS5sl/r16yepzTfddJMrDaOgVxOdhnOS27jnNHv27KDbaHS7V04mqeeUkPZkzpzZrSuQT6jNmze7V5Uc0kTBgXz33XeWHBo1auQbYT99+vQE7+f9FpcsWWLbt2+3lKKOIP2u/BdK6wAAAAAAACAcCPKRIHFrf8fljdKOO1mtwkw5cOBA0H27d+/uXhXUq1Z9IIMGDXKvCtrjm0A2IVRv/dZbb3Xrzz//vBt1Hq5JbuOe08KFC23mzJnnfa4A35tstUaNGm5JTgrhvTa99NJLvoD+QlQeRv7888+A9eaXLVtmn3zyiSUHTTZ71VVXufUnn3zSPRmQECrxpAl5Veapb9++8XYiqeMovt8mAAAAAAAAEAkI8pEgqonfu3dvNzLaP/jct2+fC8O9keft27c/Zz8voPbK1wSrW9+5c2e3/sADD9gbb7zhm4BUZVtUt96rw/7cc8+5SVaTyiuvs2DBAjfiO1yT3Hp0PldccYVbv/HGG13Y7c0foHkG9LlCfnnllVcsJQwdOtR1hKicj0atT5w40Y4fP+4+U9i9cuVKNw/Chx9+6NundevWrnNG9/nmm2/23UNNcKv99Xl8E9km1ciRI939XrdunWuzJln2rqPu26+//urupf9TAQrxX3vtNbc+fvx495tctGiR72kPva5evdqGDx9u1atXt6+++irZ2g8AAAAAAC5eMbGxaWpB6iLIR4Io8NWEsNdcc42rl+5N5lmgQAF7+umnXRDcpUsXX718j2rOK4hdv369lS5d2tUvL1u2rFv868dr4lnVX1dArDBfx86fP7+rye+N0u/Xr58vgE8qdTBceeWVvr/DPcmtJkqdMmWKC4pVK10heM6cOd21K1++vE2bNs0F5Aqq27VrZymhZMmSrpRQiRIl3Ih8TQarEF7hvkbsq0zSsGHDfHX7pWLFii7cl6lTp7pjKCjXuWh/vb7++uvJ1ubLLrvMvvjiC/d7UEeDrpWeqFCb9RSIOoHefvttO3LkyHm/O83XoHJC6nxq0KCBO0ftp99jtWrV3O9JJZsSO6kuAAAAAAAAkFII8pEg//nPf+zll192Qb7CXQX3CvcVtHfs2NGF1ho1H7e0jrZV7XttU6hQIRcSqza9Fq8+vCio1ah+BfoaGa+AWeGsgn+NXtcxXn311bCek0qwSDgnufWnwHzx4sU2YsQIFyQreNaTBqVKlXKlfVTD/cEHH7SUVKdOHTcaXeV11CZd58OHD7t7o+uutmoOAX/adty4cS401zloRLzK3qjczdKlS91vIDlp1L9G5A8cONBq167t2qDJb3V927Rp44L85s2bn7efOn3Wrl3rAvtLL73U3Wc9TaLOB80ZoA4jzenQo0ePZG0/AAAAAAAAkFTpYuMrIA2kYddee60rq6IgN7nqvAMbv55o0aJM+xujrr1TFiy3aNG5US3bPOsLixalWl0Xde3d8NV4iyZlO3S3Pev+sGhRsGI127ZwjkWL4g2b2Z61qyxaFKxc3Xavjp5/pxWqWsu2zE34ZPSprWTTdrbsr4TNERQJLruklP018T2LFpfceEdqNwEAgIj0y9oNlpZcXrlsajfhosaIfFyU/v77b98kt/fee29qNwcAAAAAAAAAgsoY/CMgbTp06JAL7zXpqSakbdKkSWo3CQAAAAAAAGkMdVAQTgT5uGioVrrq+O/YscNNqpsxY0Z77bXXUrtZAAAAAAAAABAvgnxcNPbs2WObNm1yk53WrVvXnnvuOTfhazCbN2+2+vXrh/Qdmsj2119/teQybNgwt4TagaEFAAAAAAAAQHQiyMdFY8yYMW5JqLNnz9rOnTtD+o6sWbNacjpy5EjIbdI+AAAAAAAAQFpx+PBhGz58uE2ZMsX++ecfy5Ahg1WqVMm6d+9uDzzwgGXOnDlRx926dat98cUXNmfOHFu6dKn7W4oWLeoGBN91113WvHnzoPsPHjzYhgwZcsHvWbdunVWoUCGkthHkA0GULVvWYiOsmJn+ZaAFAAAAAAAAkS0mwnKltGLjxo3WtGlT27Bhg/s7e/bsdvLkSVu8eLFbPv74Y5s9e7bly5cvpOOqOkeZMmXOyQN1bP2t79Iyfvx46927t73zzjuu8yCYTJkyWf78+YN+rpLfoUof8h4AAAAAAAAAAKSwM2fO2LXXXutC9WLFitmsWbPs6NGjduzYMRey58qVy42kv+WWW0I+tqpzKLRv0aKFjR071o3G17FV7WLVqlV23XXXue3ef//9Cw60bdSokZunM9iiAcShIsgHAAAAAAAAAES8sWPH2ooVK9y6yuq0bNnSradPn966detmb7/9tvv7m2++caPyQ6ER/EuWLLHvvvvObrvtNitevLjv2NWqVbPPPvvM2rZt69577bXX7MSJE5aSCPIBAAAAAAAAAFER5EuzZs2sYcOGFpdq5JcrV86tjxs3zkKRJ08eq1OnTtDP06VL58rqiEbpr1692lISQT4AAAAAAAAAhJnKtKSlJbUdO3bM5s+f79bbtWsXNGz3Rs3PnDkz7G3ImjXrOaV4UhJBPgAAAAAAAAAgoq1evdpiYmLceo0aNYJu532mWvT79u0Laxvmzp3rXjNnzmyVKlUKup1q6qsdmiw3Z86cVrlyZbvrrrtc/f7EIsgHAAAAAAAAAES0bdu2+dZLlCgRdDv/z/z3Sap//vnH3nrrLbeuevy5c+cOuu2ePXtcx0O2bNns5MmT9ueff9ro0aOtbt269tRTTyXq+wnyAQAAAAAAAADxUiB96NChcxa9l1IOHz7sW9dI92D8P/PfJymOHz9uXbt2deV9ChYsaC+99FLA7SpWrGivvPKKrV271k2Gu3fvXjt69KjNmDHDhfgqUTR06FAbPnx4yG0gyAcAAAAAAACAMFNZ+bS0vPjii25CWP9F78VnzJgxrm59Ypdvv/3WUtuZM2fspptusiVLllimTJns448/tuLFiwfc9uabb7b+/fu7sjva1ivD07p1a/vpp5+sfv367r3BgwfbwYMHQ2pHuthImKkAAAAAAAAAANKQ+av+trSkXoUS543Az5Ili1viC/Jvv/32RH/n9OnTfZPXfvnll9axY0e3/vvvv1utWrUC7vPFF19Yp06d3PqKFSvirad/IZrQViH+xIkTLWPGjPbpp59aly5dEn287777zlq1auXWp0yZYjfccEOC982Y6G8FAFzQ6lHPW7So+q+nbOWrT1i0qNH/JRs66XuLFgO7Nrc1bwV+9C4SVbnnCVv77qsWLSrf1d9WDR9o0aT6o0Nt28I5Fi2KN2xmf018z6LFJTfeYTt//9WiRZFL69vWH2dZtCjRpJX9OWakRYtKvR6yOcvXWbRoVqui/f7sgxYtLh30um36dqpFi9JtE/7/MAMAgISH9oH06NHDOnTokOjv1Kh/T3G/UfBbt24NGuTrs0D7JCbEv+WWW1yInyFDBvvoo4+SFOJLw4YNfet//x1aRw9BPgAAAAAAAAAgIsL/YKpWrWrp06e3mJgYW7lypbVr1y7gdvpMihYtavnz5090iK8yORMmTPCF+JrgNjVRIx8AAAAAAAAAwiwmNjZNLakte/bs1rhxY7cerHa+qshrYllRXfqklNPxD/G7d+9u4fDzzz/71suVKxfSvgT5AAAAAAAAAICI17NnT/c6Z84cW7Ro0XmfT5o0yVey5rbbbkv0SHyvJr4mtk1oiH+hqWg1v8DAgf8rCZsjRw5r0aJFSG0jyAcAAAAAAAAAREWQX7NmTRead+7c2WbPnu3eV7kdhfh33XWX+1tldwIF5YMHD7Z06dK5ZcOGDQFr4mskvkL8Tz75JKRyOvPmzbOWLVvahx9+aFu2bPG9f/r0adfOJk2a+DofBg0aZHnz5g3p3KmRDwAAAAAAAACIeBkzZrRp06ZZs2bNXBCv4FwldxTknzhxwm1Tu3ZtN5I+VPPnz7fx48e7dQX9DzzwgFuCGTly5DlBvzoXFNh7nQvZsmVzI+8PHjzownxRjf8nnnjCHnvssdDPPeQ9AAAAAAAAAADxirXUryufFpUtW9aWL19uw4YNs6lTp9o///xjmTJlsurVq1uPHj1c+J45c+aQj6vOAI+C9507d8a7/fHjx8/5W08KqE0LFy60FStW2J49e+zAgQOuo6FatWpuRH6fPn3cdolBkA8AAAAAAAAAiBq5cuWyIUOGuCUUKq2jJZCmTZtesM59fAoUKGCPPvqoJRdq5AMAAAAAAAAAEMEYkY+I8fnnn9uyZcvssssus06dOtnF1EYdU8fWJBcPP/xw2I6L+Kmn9Ycffoh3mxIlSpwzQQkAAAAAAACQ0gjyETEUZI8dO9bNPh3JQX5ytFFBvh4FKlOmDEF+KtDEIzlz5gz4WeHChVO8PQAAAAAAIPoloUoLcB6CfAAXvX79+gWtjwYAAAAAAACkNmrkAwAAAAAAAAAQwQjykawmTJhg7dq1syJFilimTJlcDfiKFStax44dbdSoUXbixAmbO3eupUuXzpWsEb3qb/9F28S1cuVK69Onjzte9uzZXWmUWrVq2cCBA23Pnj0B26NR1zqeaqPL7NmzrX379laoUCHLmjWrVa1a1ZW4Ubv8JbaNCaF9b7/9dre+cePG846rNp89e9ZKlizp/n7llVfiPd57773nttPs3YcPH/a9X7ZsWff+mDFj3PsDBgywypUrW7Zs2axgwYKuVNCiRYsu2N758+fbLbfc4soA6ZrlyZPHLr/8cnv55ZftyJEjiboGAAAAAAAAAIKjtA6STe/eve2DDz7w/a2g/fTp07Z+/Xq3fPnlly5Ez5w5swv6Dx486AJ0Lxz2p238KcxWEB0TE+P+VpCvY69YscIt+t6vv/7aateuHbR9r776qj3++ONuXd936tQpW7NmjQvONQHqrFmzLEOGDL7vD7WNCaXjHj9+3A4dOmTp06d3nQr+dN3UjjvvvNN1MowePdr69+/vQvlA3n33Xffao0cPF+bHtX//fqtfv76tXbvWtVnnsnfvXvviiy/cPdH+undx6Vo/8sgj9vrrr5/TtqNHj9qvv/7qFl33GTNmuJAfAAAAAADgYhZDkXyEESPykSx++uknF+oqmNZIbQXFGgWu0Fej5RX2asJYBcmNGjWyHTt2WLdu3dy+etXf/ou28R9xrgBe4f3QoUNt+/bt7rjHjh2zxYsXW/Pmzd17GvUfbIT477//bk888YRbdu3a5cLtAwcO2KBBg9znc+bM8Y2+l1DbGArtO3LkSLdeqlSp846r+u1y1113uUB/3bp1QUf/qxPDG1V/9913B9xGnQE654kTJ7rrps6JP/74w66++moX1mu/33777bz9nnnmGRfia/JXPU3h3VN1Quh6qdNEnQM33HCDr4MlWnz88cfuiYUsWbK4p0bq1avnnuzYtm1bajcNAAAAAAAAIMhH8liwYIF7bdmypT322GOWP39+32cFChSw1q1buxIvxYsXD+m4Co69YHvy5Mn25JNPWtGiRd3fCrnr1q3rOgn0umXLFjd6PRCF9k8//bS98MILrqyM5M6d24XcCqLl008/tUhSokQJu/baa936O++8E3Ab7/06deq4axCIgvtJkyZZ165dLWPG/z2Uo5JC06dPd2WKzpw5466Nvw0bNtiLL77oyvDMnDnT7rvvPt89VckklSrSUwwq/6NOgGnTplk00RMiCu1z5MjhnoxYsmSJ+23ounz22Wep3TwAAAAAAABc5AjykSw0qll2797t6ruHy5QpU1wIr9Hfbdq0CbiNwmmVlRGF+oFo5LXXIRDXdddd516XL19ukebee+91rwqX484DoJHxH330Ubyj8aVx48bWokWL895XSK+SPfLtt9+6wN+jThfdx7Zt29qll14a8Lgq46M6+/Fd90ijDgg9ObJ161Y7efKk7du3zz2doff05IFCfT198fPPP6d2UwEAAAAAAHARo0Y+koWCYtVeX7p0qTVp0sTuuOMOV/KmXLlySTquJlqV1atX+0biB6JQ25s8NpDq1au7+u6BeE8JKNSNNK1atbJLLrnE/vrrLxs3bpz17dvX95meUFAnh87rpptuCnoM3YcLfabSOBpZ36xZs3Ouu0bjx3fdvVJGwa57pNF8CHFp7oNevXq5361K7Oia6qmSefPmpUobAQAAAABAdIqlRj7CiBH5SBYKm1XWRqHywoUL3USt5cuXd6OcNcJZE6sm5l9mXs1yTTi7c+fOoItGUovq5gcSaBJYj1duRiVmIo0muO3Tp885k9rGLaujED9YJ4VXoichn6mOftzrrpr68V13fR7fdY+23/C//vUv35wPmhMAAAAAAAAASA0E+Ug2N998sxuZ/dZbb7nwXhO5qtSOJllVCRZNruoF7gnllenR8dQRcKFFtd3Tmt69e7vSQGvWrPGNEte6wmbxgv5w8q67JhlOyHUPNhlvtGnYsKF71Tn9888/8W6r0jz6Pfsveg8AAAAAAABIKoJ8JCtNiKp67ePHj7dNmza5SUWfeOIJN7L8xx9/DFjaJD5eWZdoKd2SHDQ5b+fOnc8Zle+9aoLbYJPcelQPPiGf6ekJD9f9wjQZsMry+C96DwAAAAAAAEgqgnykeLkShZteDfdZs2b5Pkuf/n8/x/hK7miiVlmyZIlt377dUlpC2pgSx/UmvVVd/B07drh6+QkdjT9nzpwLfqb2aELhuNf9u+++c2WNLhbeJLfqeCpbtmy82w4YMMBNEOy/6D0AAAAAAHBxiolNWwtSF0E+ksWFSopky5btnABbcufO7V41uWgwXbt2tbx589rp06fdRK/xBd+asDW+YyVGQtqYEse98sorrUaNGi5UV5mhPXv2XHCSW49K8AQqfaNjDR8+3K23adPGXWf/cj6aO0Df88wzz8R7/FOnTvkmvY1kF+o0USmdUaNGufVGjRq5JyHio3JHuo/+i94DAAAAAAAAkoogH8ni/vvvtxtvvNGmTJlyzqSpCnhVM98bQd6+fXvfZwqmRSV3VPM9EIXLr732mltXuR7tv2jRIhfai15Xr17tAunq1avbV199FdbzSkgbk3Jc1VXXHAIJoZJF4tXJv9Aktx6VfFFpHo3m9yb01bnoWuo1Q4YM9uyzz573JMXTTz/t1l955RW77bbbbOXKlb7PdZxly5a5/SpUqODWI91LL71kPXv2tOnTp5/TgaJ7oN+nwvv9+/dbpkyZ7OWXX07VtgIAAAAAAODiRpCPZKER85MmTbIuXbpYkSJFLFeuXJYvXz73qrIwGrWtUeUDBw707aNwuVChQi48rVq1qltXORMtXokTUfj65ptvWubMmV0I26BBA8uePbsbMZ01a1arVq2a9evXz4XSKokSTgltY6gUfrdo0cKta4S9RnN7x/U6LuJSmJ4jRw7f3wmd5FYj6tVuPd2g4F+dIzqX77//3l0vXdt69eqdt5+CfC3a5sMPP7SaNWuec91VikfH3rx5c9ive3I9NaLA/pprrnG/TV3zAgUKuHX9xlSySJ0e6jDySgsBAAAAAAAAqSFjqnwr0jwFvpp0VTXXNUJeoahG42sC1UsvvdR69OjhgmiN/vYoQNXo8iFDhrgR7xrJr1IuErcu+z333GNt27Z1pU9UZ19lUDSqWmGsRo83bNjQOnbsaM2bNw/reYXSxlBphLxGtH/99dduYmBvYtlg5XZ0rq1bt7bPPvssQZPc+p/DL7/84uYq0BMTCt41KbHCatV017ULROG82qcnLRT2695qX9WC1zErVarkjnH99dcHPUYkUUeGyussXLjQTcK8d+9eNxpf56KODV1bdY6oIwoAAAAAACBU4Z5jERc3gnwkC4XpDzzwgFtCUaVKFfv0008TtK1Gq7/66qshHX/w4MFuiU/Tpk3j/RdtKG0MhUbGjxgxwi0JHVHuldVJ6Gh8/04ABflaElMGyKsdH81UekkdMgAAAAAAAECko7QOEKXUmaBR5ArlEzLJLQAAAAAAAIDoRJAPRKG//vrLN/msygwlZJJbAAAAAAAAANGJ0jpAFNEEwZoPQHMOxMTEWMmSJV1dewAAAAAAAEQWauQjnAjygTCZMGGCPfTQQyHt061bNxs5cmSCt9+yZYtt27bNChQoYFdddZW98sorrrZ+JNJEuPXr1w9pn1y5ctnhw4cTvP3u3btdh0YoE9KWKlXKfv3115DaBQAAAAAAAKQmgnwgTI4fP247d+4MaZ+DBw+GtP2GDRtCbFV49k2Ms2fPhnw9smbNGvI+Eso++g4AAAAAAAAgmhDkA2HSq1cvt+B/ypYtyyNkAAAAAAAAQBgw2S0AAAAAAAAAABGMEfkAAAAAAAAAEGYxFCpAGDEiHwAAAAAAAACACEaQDwAAAAAAAABABCPIBwAAAAAAAAAgglEjHwAAAAAAAADCLDaWIvkIH0bkAwAAAAAAAAAQwQjyAQAAAAAAAACIYAT5AAAAAAAAAABEsHSxFGsCAAAAAAAAgLD6+tc/LC1pX79aajfhosZktwCQjA7t2WXRInfBwnZgxzaLFnmLFre1m3dYtKhcqqgd2rfXokXu/AXs8P79Fi1y5csXVe312sxvIpl/E4cOWbTIlTu3bdu9z6JF8UL57eCunRYt8hQuYhu277ZoUbZYoaj73xCHDx6waJErT147sH2rRYu8xUqkdhMAAEAEoLQOAAAAAAAAAAARjCAfAAAAAAAAAIAIRmkdAAAAAAAAAAgzJiZFODEiHwAAAAAAAACACEaQDwAAAAAAAABABCPIBwAAAAAAAAAgglEjHwAAAAAAAADCLDaWKvkIH0bkAwAAAAAAAAAQwQjykWyaNm1q6dKls8GDB6d2UxCiDRs2uHunRevRjt8iAAAAAAAAohmldYAI4gXNvXr1srJly6Z2cyLe559/bsuWLbPLLrvMOnXqlNrNAQAAAAAAAJIFQT6STenSpa1y5cpWsGDB1G5K1BgyZIhvBDlBfsKC/LFjx1rPnj3jDfL5LQIAAAAAgJQWQ418hBFBPpLNuHHjUrsJgMNvEQAAAAAAANGMGvkAAAAAAAAAAEQwgvwImoTz1KlT9tJLL1mtWrUsR44cli9fPmvVqpVNnz494L4qvaJ9x4wZY0eOHLFBgwZZzZo1LVeuXAEnKZ0/f77dcsstVqZMGcuaNavlyZPHLr/8cnv55Zfd/v5Onz7typDoOK+//nq85/D++++77XLnzm3Hjh0LeG7BTJ061Tp06GBFihSxzJkzu1f9/dlnnyXomgWjz7SNtg1kwoQJ1q5dO/d9mTJlsrx581rFihWtY8eONmrUKDtx4oQl1f79+909qVOnjrs2Or+iRYu6+3vPPffY7NmzfduqJr7a62nWrJlvslkt/mV25s6d63tfli5dajfffLOVLFnSnUvcc96xY4f179/fqlev7n5XWrT+2GOP2c6dOxN1bsePH3elbNQG/U5+/vnncz4/fPiw+y03bNjQ8ufPb1myZLFSpUpZ9+7dbeHChZZU3jVQWR3Rq//10qJtEvKb0fX5z3/+Y9ddd51VrVrV/XORLVs2q1Chgt155522atWqJLcXAAAAAAAASApK60QIhfgtW7a0H3/80TJmzGg5c+a0AwcO2HfffeeWZ555JmhwvXfvXqtbt679+eefLizOnj37OZ/HxMTYI488ck4gr+MfPXrUfv31V7d88MEHNmPGDBfyiwJhha4KtT/88EN78MEHg7Zdn0vnzp3P++74zve2225zgbqkT5/eBah79uyxr7/+2i09evRwAa3aEk69e/d25+t/LdRxsX79erd8+eWX1r59+yTVqN+yZYs1btzYNm3adN75KTxfsWKFrVmzxlq0aOE+12fqVPCCdXXi6F56ChUqFPB7pkyZ4q6T2q/OAv12/P3www8ucNdvSRTiyx9//OGW0aNH27Rp0+zKK69M8Lnt27fPrr32WluwYIGrPa/fTZUqVXyfa/JZfa5rIBkyZHC/C/2t+z1x4kQbOnSoDRgwwBLL6/Q5ePCg63TxOqbibpMQTzzxhK9DQNfP65D666+/3PLRRx/Zxx9/7H7fAAAAAAAACUWJfIQTI/IjxH//+1/75Zdf7K233nKjmTWaWyFwly5dfJOgKnANRAH/oUOH3Ch2jazXvps3b7bChQu7z9UJoBBffyuYV/Cv79Co6jlz5ljt2rVt7dq1dsMNN7jQ36OgXRYvXuxC50DURoXF/tsnxJNPPulCXY2Sfvrpp12bFBAr6NZn8umnn7rPwumnn35yIb6CdT2J4F0LdWrouxVKa+LUhIbAweie6NqoM0AdMeq40PmdPHnSPSnx5ptvWoMGDXzbjxw50o0M939SQX97izpbAtFIfj21sXr1ahdq656+++677jP9BrwQv1q1au7c9fvQMm/ePDf5q34rGom+devWBJ2XjqnQXyG+nv7Q6Hr/EH/79u3Wpk0bF9rr96Tfjtqk36c6KXQ/FezrHmui2sRq1KiRuy7dunVzf+vV/3pp0TYJoZH3r776qutcUVv1m9B9WrlypXvSQev6TWzbti3R7QUAAAAAAACSgiA/QiiEVZh/9913u9HFolIkCruvuuoq97cXcMel8PGbb75xoa03el1lVjQKWqHxiy++6EqFzJw50+677z5X6kS8MiwK4rX9b7/9dk5ngcruKOyNb7JQjVSOjY11I7ODlbGJS6GxgmtvNPSzzz7rStt4I9E1Wrtv377u7xEjRrhwOFwUQIueflBpGe9aSIECBax169auVFHx4sXD8j0vvPCCG3Wv8Fr0qqceVFpHpWeSSgG97pl/mK4SQd53K8TXNVUZHz0h4GnSpInrYNDoc3Uw6DdyIQq2FY6r00C/ST09Evc6PfXUU7Zr1y676aab3NMCelLE+02qI0n3+pVXXnF/x1caKSWpzf369bMaNWr4nmhQR4/KD2k0vp7OUEePSkgBAAAAAAAAqYEgP0IotL/99tvPe1+BooJGUa1ujRqOq23btm5UfSAKpc+ePeu2ufTSSwNuo5r66gQQjUj3d+utt54T2Acrq6ORy/413uOjgPfMmTOuw0JBfiA6Z9VVV8mYyZMnW7h4HQa7d+921yW5eN8Tzk6IQFT73usk8Kd7pRI2ok4D1eaPS503+kzGjx8f7/cotFf47420V6dQ3FI2KnHzySefuPXHH3886LG8Jzd+//33RNfoT0kK8kVPNAAAAAAAAACpgSA/QniTcQaiANUbKaxSJXH5j7SOSxPcioJXhbnBFq9m/MaNG88L8tUu/xI6niVLlrjR2aGW1fHOoX79+m5EeCAaRV6vXr2g55xYGh2vDgRNEKvr+t5779k///xj4aYJe0UdFX369LFvv/3WlZcJt2D3Xuekkfbe0wfBqCyPqJxMsOugkk16UkGj+++9916bNGmS62SJS78Hb5JgbR/st6aR7p64v7fUok4FPa2iiYj1m1QHmjdprt4Xr+Y/AAAAAABAQmigZVpakLqY7DZClChRIuhnCp5V9kWjl1W2JC6vFn4gXl1vlQbRciGa5NOfSuZcffXVNnfuXDf63r98jjcaX4G8f2mXC/HOIb5z9kaM+28fDpdccomb4FUj0VXfXYs3mWyzZs1cSZiOHTsm+OmC+EbKKxzWqHjVrNeiYyrE1tMRd955p69sUVIEu/f+1yy+6+xdY2+fcuXKnbeNV+ZII9NV/ikY/xryCR1pH/f3lhreeOMNe+ihh3zzQ+g+6WkDr7PCq/F/oX9+VEtfi79AHR4AAAAAAABAqBiRnwYEKq3i8crHqNRJQnrWFNjH5Y22V4kbhZqi0jiajNa//E60UBkgjQTXxMKaJFVljVRqR6G7Sgyp4yKpo+dVF17zGyxbtswGDRpkzZs3d3MWqM78sGHDXKA/fPjwZL334XLLLbe4V83DoGsWjH+pIv1OEvJ7S+i8CslFT5Q8/PDDLsTv2rWrm3BaTxVoEmBv0lzN0yAX6nnWPAPqAPBfEjL3AAAAAAAAAHAhBPkRQhPABqNRvip9cqHR94F4tdGTUsKkS5cubrJchdtffPGFr1SPRnArsO7Ro0dIx/PO4UKlSrzP456zV2bIK+MSbPLg+GiSW00srNrwKhu0fv16VwZHo7FVDz5cE7FqXoIhQ4a4yWZVmkYTzGqiWIXe3qj95OB/zeK7zv6fBfttPffcc/b000+7IFtlZkaNGhVwO/86/JFSMudC1Dmle1G1alX3W9DTJZkzZz5nG4X5CTFgwAD3u/Nf9B4AAAAAAACQVAT5EUL154ON+FWwrBHw4tWND7WGugLk+ILv+PhPhuuV0/Fe27VrZwULFgzpeP6174MF7gq9/Wvpx62fL5s3bw76HYsWLQq55I5GT6u0jsyaNcvCTR0QqtH/9ddfu5Irut+6L/68kj5JrTumEjnqrBB1IgTjfb9KNwUqq+N59tlnXeeG2nX//ffbyJEjz9vGPwT/8ssvLSWoln1Srpf3G1KHi3esuOLeo2B0T1Vf33+htA4AAAAAABevmNjYNLUgdRHkRwiNCh87dux576vkxwsvvODWq1WrZjVr1gzpuL1793YB8p49e+yZZ56Jd9tTp07ZkSNHAn7mldfRSPx169b5RuaHMsmtp3Pnzq5N6lh4+eWXA26jc9aTCBrxr+39KXSVGTNmBKxb/v333/tq38cVt4Z5XHryQIKFugkV3/co3PVK4sT9Hm/yX3VkJIU6BFQ2SN5+++2Ao8pV016fSUKeqtDv5/nnn3frKkfjlZzx5MiRw9cRovuq33R8vMl4kyKp10vlb2TFihUBOwOmT58esNwUAAAAAAAAkJII8iOEAsV7773XTYrqjZzXaGEFrHPmzHF/eyFqqCPNVRZFXnnlFRe8q067RyP9VcddI64rVKjg1gNp1aqVK52i7RXWqga6RsZ36NAh5DZp8lVNLiovvfSSC4i9IFavau+rr77qm2i1WLFi5+x/4403ugBc5YZ0fbzyMGqTOkOuv/5632j0uDSaXPtPmTLlnAlh1YGh+u/jxo3zTeyaFGXKlHFlVX7++edzQn2V8FGNfk3yqnNo06bNOfvVqFHDvX788cdJngj2ySeftLx587rAvGXLlrZgwQLfZ/Pnz3fv6XrrWqmsUEIMHDjQ3TN59NFH3W8qbgdM8eLFXcdRw4YN3ZMbhw8f9n2uuQh07XWPQi3JFIh3vfTUypo1a0LeXxMPy6pVq+xf//qXr3NBHUTq5FBZKT2tAAAAAAAAAKQmgvwIodrjKjnTp08fN8pY4Wrp0qXdBKzy1FNPufAzMRSMa9EobQWrGtWviVdVEidr1qxWu3ZtF6ar48Ar7RKXRpB7o629kjcKxBNbOkSBr/bXKGh1Iigs1Tnr1euwUNCr+uxxVapUyV0Pr4SLJqtVYK3r1qtXLzexrK5nIKdPn7ZJkya5gLZIkSKubJA6JPSqjhQ9lXDllVe6wDopdu7c6QJvhdm61jo3jfavWLGi+35dZ012q6cs/N1zzz3uVWG3zqlkyZJWtmxZ16ZQad/PP//cdRIpqFaZpZw5c7pFx9NEr/oObaPOlYTSxMmasNdb954YEXW6qBSN7pFG/KvjSN+h+6rvVR1+XXt9p542SSo9rVGoUCE3Oa3q3Gtd10uLOlEuRKWOunfv7tbffPNN1079HnTNdC90zHDNlwAAAAAAAAAkFkF+hFBtcdUyVyhauXJlN4pbYaJXUz1QoJ1QCo0Vli9fvtwF3AonFcyrPr1Cy0aNGrmJVzVi26upH0jcMjqJKavjf74TJkxwk42qzr4CVI3c1qv+njp1qn3yySeutE4gmkBWnRINGjRwJV00Yelll13mRtVrX690TVzq0Hj99dddp0iVKlVciR+NxlfArKcO3n//fVdKRcdMCpUg0oj8Jk2auI4GPS0geurh9ttvt19//dWVp4nrlltuceeloF0dANu3b3cTx15oYuBgrr76ahfYa/S87rvCc3WeaL1fv37uM7UxVDrea6+95tbV6aHfl0fH1m9NI9pbt27tOow0UbK+V+fftWtXe+edd3ydVEmh3++8efNcGK/OCP2mdb20JHROCD39oHOpVauW65jSb0mdXZozQU8uqAMCAAAAAAAgVMpC0tKC1JUulruQqpo2beomutWIeEb+AmnPoT3/V8Ip0uUuWNgO7Nhm0SJv0eK2dvP58z9EqsqlitqhfXstWuTOX8AO799v0SJXvnxR1V6vzfwmkvk3ceiQRYtcuXPbtt1Jnz8mpRQvlN8O7tpp0SJP4SK2YftuixZlixWKuv8Ncfhg0uZ4Skm58uS1A9u3WrTIWyzhT88CACLL5Pm/W1rSpfH/5q1E6mBEPgAAAAAAAAAAEYwgHwAAAAAAAACACJYxtRsAAAAAAAAAAGlNDAXNEUYE+UAQmzdvtvr164e0jya21US2SLiHHnrITXwcipEjR1q3bt2SrU0AAAAAAABAJCHIT2Vz585N7SYgiLNnz9rOnaFN4pY1a9Zka09adfDgwZCv8/Hjx5OtPQAAAAAAAECkIcgHgihbtqzFxvIMVHIbM2aMWwAAAAAAAAAERpAPAAAAAAAAAGHGAFGEU/qwHg0AAAAAAAAAAIQVQT4AAAAAAAAAABGMIB8AAAAAAAAAgAhGkA8AAAAAAAAAQARjslsAAAAAAAAACDMmu0U4MSIfAAAAAAAAAIAIRpAPAAAAAAAAAEAESxfLMx4AAAAAAAAAEFbj5y21tKT7VbVTuwkXNWrkA0AyGvv9YosWPZvXs0+i6H9k3HRVbdvw1XiLFmU7dLcJPy6zaNGtyWU2ZcFyixadG9Wyj+YusWhyS9O6tvKfrRYtapQrYbOWrrVo0ap2ZVuzabtFiyqli9kvazdYtLi8cln7/OeVFi06NahhOxbPt2hRtF5j++/0hRYt7mvX0OYsX2fRolmtilH13wz99+LwoUMWLXLlzp3aTQCAiBGT2g1AmkJpHQAAAAAAAAAAIhhBPgAAAAAAAAAAEYwgHwAAAAAAAACACEaNfAAAAAAAAAAIs9jY2NRuAtIQRuQDAAAAAAAAABDBCPIBAAAAAAAAAIhgBPkAAAAAAAAAAEQwauQDAAAAAAAAQJhRIx/hxIh8IELNnTvX0qVL55a4xowZ494vW7ZsqrQNAAAAAAAAQMphRFBVo8IAAQAASURBVD5Szeeff27Lli2zyy67zDp16mSRKBraeLF1bmhRB0avXr1SuzkAAAAAAABAimBEPlI1JB8yZIh7jVSR2sY8efJY5cqV7ZJLLrGLiUJ83Q89kQAAAAAAAABcLBiRD0Sh66+/3i0AAAAAAACITDGUyEcYMSIfAAAAAAAAAIAIRpCPsJowYYK1a9fOihQpYpkyZbK8efNaxYoVrWPHjjZq1Cg7ceKEbxLXsWPHun306k3q6i3aJq6VK1danz593PGyZ89uOXPmtFq1atnAgQNtz549AdszePBgd7ymTZu6v2fPnm3t27e3QoUKWdasWa1q1aquVIva5S+xbQzVmjVr7Oabb7aiRYu69pQvX94eeOAB27lzZ7z7xTfZ7enTp23atGnuWtWrV8+KFStmmTNntsKFC1ubNm3s008/DTpretwJdpcvX249evSw4sWLW7Zs2dz1GjZsmJ05c8a3z/z58938AfoenUONGjXcvb7QzOyh3M8NGza4NuleyQ8//HDe/QhUbkf7Pfzww1a9enV3fH1PlSpV7KGHHrJNmzYl6NrOmTPHd34ZMmSgNj8AAAAAAABSHKV1EDa9e/e2Dz74wPe3glOFyuvXr3fLl19+6UJ0hcoK+g8ePOgCdIW/qvnuT9v4e+WVV2zAgAEWExPj/lYgq2OvWLHCLfrer7/+2mrXrh20fa+++qo9/vjjbl3fd+rUKRekK+xXMDxr1iwX1HrfH2obQ/Xtt9+6gPjkyZO+67V9+3Z74403bMqUKTZ06NBEHVfB+nXXXef7O3fu3K79u3fvtpkzZ7rls88+s/Hjx1v69MH78qZPn2433HCDO3+du9qp69W/f39bsmSJ6xAYPXq03XPPPe6+6Hu0zapVq+z++++3zZs320svvRTw2KHeT90X3Y8jR47Y0aNHXSdR/vz5zzmmOhr8ffzxx3bHHXf4rm+WLFnc+a5du9Yt+o7Jkydb69atg16DkSNH2iOPPOI6JXQNvN8HAAAAAAAAkJIYkY+w+Omnn1wwqqD05Zdftr1799rhw4dd6KrR1TNmzLCePXu68LtRo0a2Y8cO69atm9tXr/rbf9E2nvfee88F8Ap7FW4r7NZxjx07ZosXL7bmzZu79zTqX0FvIL///rs98cQTbtm1a5ft37/fDhw4YIMGDfKNuvZG30uobQzVli1b3DEVMmsU+qJFi3zXSwG6AuO+ffsm6ti6TnfffbfrmFBHhJZDhw65e6JgWoH7pEmTXIdBfG666SbXIbBx40Z3rXQche+iTgCF9Pfdd59bdD20zb59+3wj1tVx8ueff5533MTcz1KlSrnv6Nev3zn3x3/x7pXo3G+77TY7e/asPfbYY/bPP//Y8ePH3feoM6Jr167ueus12Mh8PRXx6KOPut+tttH56RhPP/10ou4LAAAAAAC4uGhgYFpakLoI8hEWCxYscK8tW7Z0wan/aOkCBQq4Uc8qWaISLaFQ2OqFtxo9/eSTT7oyNKKwu27duq6TQK8KxzVCPBCFsApgX3jhBStYsKB7T4G2SrVo1LlohHlKUTsUruvaKHS+/PLL3fvqCGnbtq0L8xU6J4aO9dZbb7l7oXP06J48+OCDLkiX119/Pd7j1K9f312T0qVLu79z5crl2t2kSRP3t0J9hdw6jsr2SL58+dw9KFeunBttP3HixGS5n/HR9/7rX/9yryrxo44llcnxSvBUrlzZtUsdBboHI0aMCHgcPYmgjgx1UKkjwWvjJZdcEnKbAAAAAAAAgKQgyEdYqBa+qHyLRkGHi0rMKIRXiRXVdw8kY8aMro67KAQORGVVvAA5Lq8MjerBpwT1YGouAVFZGi8E96c68126dEmW71d5I/nrr7/cSPZgNGreq5Xvz/8+eCP0/SnsbtGiRcBrGq77GZ958+bZunXrXIfNnXfeGXQ7jdi/0HcEOj8AAAAAAAAgpVEjH2Gh4FZ12JcuXepGbKs2uUqkaGR2Uqjeu6xevdo3cjsQlTwRlYEJxJvsNBDvKQGVhUkJKvPifZeuUTD6LLFPCWjku0blf/XVV+7aKTxXDfq4NOo92HX1nhKIS7XqvRH+mpw3vm1Uwig57md8vO9QKaD4ngDRHAnxfYdq7tepUyfk7wcAAAAAAADCjSAfYaFyI97EpwsXLnSLFCpUyJo1a+bqrauUSaAR3vHZtm2br8yJlgtRnfVAVBYmGI0AlzNnzlhKUI1+T4kSJYJuV7JkyUQdX3Xp1bGikN6jevR6asKb3Fb13yW+8j3Brpl3vRJyTeN2HoTrfsbH+w59t3ee8fE6DeJS2aP4JgMGAAAAAACITwx15RFGpFQIm5tvvtmNbtZIcE08qrriKrWjeuSdOnWyq6++2tUkD4VXpkfHS8ikGxs2bLCL3e233+5CfNWF16S2muRWgb06EFRKZ+vWrb5tU3qikpS4n953XHHFFUmarEUlgkKhiYv1+/Zf9B4AAAAAAACQVAT5CCuVW7n77rtt/PjxtmnTJlu/fr098cQTbiT+jz/+aIMHDw7peF75lcSUWIlU/jXx/UP1uOL7LJjNmzf7Jh5WWR7V2fefeFjiq4uf3FLifqbWb+bFF1+0PHnynLPoPQAAAAAAACCpCPKR7CV3FGaqtI7MmjXL95lXtiS+UeGNGzd2r0uWLLHt27dbSktIG0OleQO8cH3OnDlBt/v+++8TFeR7NKFsIN99952llqTez1B+M+qwWLx4saUUTYyruvz+C5PlAgAAAAAAIBwI8hEWFyohoolDxb/meO7cud2rJmINpmvXrq62u+qd9+3bN94ANyYmJt5jJUZC2hgqPZ1w4403unWVIdqzZ8952/zxxx82efLkkI+tUeCe33//PeAkuM8//7yllqTez4TcD83JUKFCBbf+yCOP+Ca1DSZckxxnyZLFtc9/0XsAAAAAAODipNgjLS1IXQT5CIv777/fhdNTpkw5ZzLXI0eOuLB63Lhx7u/27dv7PqtRo4Z7VcmdNWvWBDyuQt/XXnvNratcj/ZftGiRC3lFr6tXr7bhw4db9erV7auvvgrreSWkjYmhkdqaLFYhfqtWrXwjxxVsz5w509q1a+cmqA1V1apVrXTp0m69d+/ebuS7RxMQN23a1Pbv32+pJan307sfq1at8pUQCjTRrn5zev3pp5/sqquustmzZ58z8e7ff//ttqlfv77997//TcYzBgAAAAAAAJKOIB9hoZBUE6uqJnuRIkVcSJ0vXz73eu+997pR0VdeeaUNHDjQt0/nzp2tUKFCLlhWAK11TdCq5eeff/Zt17NnT3vzzTctc+bMNn36dGvQoIELuQsWLGhZs2a1atWqWb9+/VzQrtHu4ZTQNoZKYbtq2GvE9rJly1ygrBHcOXLksDZt2rjrOWLEiJCPqyceRo0a5UJshd316tVzx9TSqFEjW7t2rU2YMMFSU1LupzoiKleu7Ca0VQkdlSjy7of/EwwtWrRwv0f9/tRR0LJlS3cNvO9QySf9LtWBEu7fDAAAAAAAABBuBPkIi6efftpef/11u/76661KlSouSNZofE3sqhHn77//vs2dO9eFqR4F/fPmzbPu3btbiRIlXE1xTVCq5cSJE+cc/5577nEhtALeSy+91AXgKq+SM2dOF1Y/8MADrv5+jx49wnpeobQxVBqN/ttvv7lj6zqps0OdIHq6YenSpa6WfmJ06NDBtVnH1wj4M2fOuAD79ttvdyP0FXKntsTeT/2uNLr+zjvvdNfn6NGjvvuh35u/Tp06ucmWn3nmGbv88svdsfUd+i59p47x2WefWf/+/VP47AEAAAAAAIDQpIsN5yyeAIBzjP0+5SbcTaqezevZJ/OWWrS46aratuGr8RYtynbobhN+XGbRoluTy2zKguUWLTo3qmUfzf2/cmLR4JamdW3lP1stWtQoV8JmLV1r0aJV7cq2ZlPoE6unliqli9kvazdYtLi8cln7/OeVFi06NahhOxbPt2hRtF5j++/0hRYt7mvX0OYsX2fRolmtilH13wz99+LwoUMWLXL9/3mtAABm7836xdKSO1pdntpNuKgxIh8AAAAAAAAAgAhGkA8AAAAAAAAAQAQjyAcAAAAAAAAAIIIR5AOJNGHCBCtatGhIy0MPPZTazQYAAAAAAEAKiImNTVNLJDl8+LANHjzYatasaTlz5rQ8efJY/fr1bfjw4Xbq1KlEH1fHTJcu3QWX9evXx3uc3377zW655RYrWbKkZcmSxYoVK2bXX3+9ff/994luW8ZE7wlc5I4fP247d+4MaZ+DBw8mW3sAAAAAAACAtG7jxo3WtGlT27Bhg/s7e/bsdvLkSVu8eLFbPv74Y5s9e7bly5cv0d+RKVMmy58/f9DPM2YMHquPHj3a7r33Xjtz5oz7W50MyhA///xztzzzzDOuwyBUjMgHEqlXr14WGxsb0jJmzJjUbjYAAAAAAAAQlc6cOWPXXnutC/E1yn3WrFl29OhRO3bsmI0fP95y5cplS5cudaPhk6JRo0a2Y8eOoEvZsmUD7rdw4UK75557XDs7depkmzdvtgMHDtju3bvt7rvvdtsMGTLEJk6cGHKbCPIBAAAAAAAAABFv7NixtmLFCrc+ZcoUa9mypVtPnz69devWzd5++2339zfffONG5ae0xx57zM6ePetK/iisV2kdKVCggL311lvWpk0b9/fjjz/utgsFQT4AAAAAAAAAhJnKyqelJVKCfGnWrJk1bNjQ4urevbuVK1fOrY8bN85S0t9//20//fSTW+/Xr58rzxPXgAED3KueKJg3b15IxyfIBwAAAAAAAABEtGPHjtn8+fPdert27QJuo4lo27Zt69ZnzpyZou1TmR+P14a4rrzySlf+JzHtI8gHAAAAAAAAAES01atXW0xMjFuvUaNG0O28z1TLft++fYn6rlWrVrnjaCLdnDlzWuXKle2uu+5y9feDWblypXstXLiwWwLJkCGDValSxfcdoSDIBwAAAAAAAADE6+TJk3bo0KFzFr2XUrZt2+ZbL1GiRNDt/D/z3ycUe/bscR0H2bJlc+f4559/2ujRo61u3br21FNPxdu++Nrm/3mobSPIBwAAAAAAAIAwi4mNTVPLiy++aHny5Dln0Xsp5fDhw751jZQPxv8z/30SomLFivbKK6/Y2rVr7cSJE7Z37147evSozZgxw4X4sbGxNnToUBs+fHjQ9sXXNv/PQ20bQT4AAAAAAAAAIF6aqPXgwYPnLN7krcGMGTPG1a1P7PLtt99aSrr55putf//+VqlSJd9ktZkzZ7bWrVu7iWzr16/v3hs8eLA7/5REkA8AAAAAAAAAiFeWLFksd+7c5yx6L6Xk+v+TxHoT3wbj/5n/PkmVNWtWe+GFF9z6kSNHbPbs2QHbF1/b/D8PtW0ZQ2wvAAAAAAAAAAAX1KNHD+vQoUOi91f5Hk/x4sV961u3brVatWoF3EefBdonHBo2bOhb//vvv8/5zPsu/++Pr32hto0gHwCSUc/m9Sya3HRVbYsmZTt0t2jSrcllFk06Nwr8P4oi1S1N61q0qVEu/kmQIk2r2pUtmlQpXcyiyeWVy1o06dSghkWTovUaWzS5r93//T+J0aBZrYoWTaLtvxm5cudO7SYAAJAoGrEfrlH7VatWtfTp01tMTIytXLnS2rVrF3A7fSZFixa1/PnzW0qpUeN///t4165dtnv3bitUqNB525w9e9bWrFnj1qtXrx7S8QnyASAZbfkhZWu5JUXJq9va9p9/sGhRrMHV9u2S//3HLxq0rVvFti343qJF8UbNo+73EE3/vHn/zO3fssmiRb6SpW3HkoUWLYrWbWgHdmyzaJG3aHHb+/c6ixYFyleMun9HbNi+26JF2WKFbPOsLyxalGp1ne1a8ZtFi8I169jm2V9ZtCjVooMd3LXTokWewkVs+uLVFi3a1aua2k0AkIZpgliET/bs2a1x48b2448/utr5qmUflyaj1cS0orr24fbzzz/71suVK3fOZ61atfKtq3233nrrefvPnz/fN8ltqO2jRj4AAAAAAAAAIOL17NnTvc6ZM8cWLVp03ueTJk3ylby57bbbQjq2OgHic/LkSRs4cKBbz5Ejh7Vo0eKcz8uXL29XXnmlWx8+fLidPn36vGO89NJL7rVMmTJ21VVXhdQ+gnwAAAAAAAAAQFQE+TVr1nShe+fOnX0TzqrcjkL8u+66y/2tsjtxg3YZPHiwpUuXzi0bNmw457N58+ZZy5Yt7cMPP7QtW7b43lcgr+9p0qSJr/Ng0KBBljdv3vOO//LLL1uGDBns999/t+7du/vq4e/bt8/uu+8+mz59uvv7lVdecduFgtI6AAAAAAAAAICIlzFjRps2bZo1a9bMBfEK3lVyR0H+iRMn3Da1a9e2jz/+OORjq3NAgb3XOZAtWzY38v7gwYO+0fWq0f/EE0/YY489FvAYjRo1srfeesvuvfdemzp1qlsU+OsY3oj/Z555xm688cbQzz3kPQAAAAAAAAAASSrVgsQpW7asLV++3IYNG+aC8n/++ccyZcrkJo/t0aOHPfDAA5Y5c+aQj6uR/jrmwoULbcWKFbZnzx47cOCA6yioVq2aG5Hfp08ft1187rzzTqtTp44rr/PDDz+4iW8LFy5sDRs2dG1r3rx5os6bIB8AAAAAAAAAEDVy5cplQ4YMcUsoVFpHSyAFChSwRx99NCztU5CfmKcC4kONfAAAAAAAAAAAIhhBPgAAAAAAAAAAEYwgH7iIzZ071zdT98XIm6m8adOmqd0UAAAAAACQxqhEflpakLqokY+L3ueff27Lli2zyy67zDp16mSRKBraGEk0a/mYMWPcerC6ZwAAAAAAAEC0YEQ+LnoKyTUxhl4jVTS0MdKC/MRMeAIAAAAAAABEIoJ8AAAAAAAAAAAiGKV1AAAAAAAAACDMYigsjzBiRD7SpAkTJli7du2sSJEililTJsubN69VrFjROnbsaKNGjbITJ074JnodO3as20ev3sSv3qJt4lq5cqX16dPHHS979uyWM2dOq1Wrlg0cOND27NmToElVZ8+ebe3bt7dChQpZ1qxZrWrVqq4MjNrlL7FtDKdTp07Zf//7X2vWrJkVLFjQMmfObEWLFrXrrrvOpk+fHnQ///YdPnzYnnrqKatSpYply5bNChQoYB06dLBFixbF+926no888oiVL1/eXadixYpZ165d7bfffjvvOzxly5Z1bY3bDm/p1atX0O9L6H0BAAAAAAAAUhIj8pHm9O7d2z744APf3wraT58+bevXr3fLl19+6cJaBdIK+g8ePOiCWgW3efLkOedY2sbfK6+8YgMGDLCYmBj3t4J8HXvFihVu0fd+/fXXVrt27aDte/XVV+3xxx936/o+BeVr1qxxYf8PP/xgs2bNsgwZMvi+P9Q2htPGjRvdtVq1apX7W0F47ty5befOnTZt2jS33HPPPfbmm28GPcb27dutTp067tqr/enTp7d9+/a566Rz1f1o3br1efv9+eefLpDftm2b+ztLlix27Ngxmzx5svtevQaiEP7QoUO2f/9+97eun7+41y8x9wUAAAAAAABISYzIR5ry008/uTBdYfHLL79se/fudaPBjx496kZ3z5gxw3r27OnC70aNGtmOHTusW7dubl+96m//Rdt43nvvPRf0KrwfOnSoC6h1XIXLixcvtubNm7v3NOr/yJEjAdv3+++/2xNPPOGWXbt2ubD5wIEDNmjQIPf5nDlzfKPvJdQ2hpPOrW3bti7E15MEGvV+/Phx114tI0aMcJ0kb731lo0cOTLocf71r3+56/3999+7Y+ra/PLLL1a5cmUXluvpBq9jxKPOkS5durgQX08BTJ061e2rDo3Vq1fblVde6e5jIL/++qvb3hP3egVqa6j3BQAAAAAAAEhJBPlIUxYsWOBeW7ZsaY899pjlz5/f95nKuWjk95gxY6x48eIhHVedAf369XPrGgn+5JNPuvIyolHadevWdZ0Eet2yZYuNHj064HEUDj/99NP2wgsvuIBaNMJd5VtuuOEG9/enn35qkUBBvUakX3311TZz5kz3qlHx3oh1lbwZN26c+/v555+3M2fOBDxOxowZXRCu0fXqYNGo/vr169ukSZN8o/4XLlx4XmkkPeGgbRXKX3/99b7R8CrPo9H8cUfaJ0U03RcAAAAAABAdYtPY/yF1EeQjTVEtfNm9e7edPXs2bMedMmWKC3tVMqdNmzZBA+sePXq4dYX6gSgI9zoE4lLNeVm+fLlFAj2BIH379nXzDATSqVMnF3jraYclS5YE3EYj7gsXLnze+zVr1rRy5coFPGcv5L/qqqusSZMm5+2rEj39+/e3cImm+wIAAAAAAICLDzXykaa0aNHChbxLly51AfAdd9zhSt54gXFizZ8/372qrIs3Ej8QlZ7xRpkHUr16dVeOJhDvKQHVj09tW7du9Z2DrmF8teG9MkLa/oorrjjv80Dv+Z/zP//8c945e5PZ6imAYLyJg8MhWu4LAAAAAAAALk4E+UhTLrnkElfWRhOwqlyLV7JFE6CqtMtNN93katirZEsovAlXNeGslgtR3fxAcuXKFXQfjeiXYCVqUpJ3vqLR9gmRlHNWTXx/eqJC4iuBVKJECQuXaLkvAAAAAAAAuDhRWgdpzs033+xGh2sSVk0OW6pUKRcMT5w40ZWC0SjvQ4cOhXRMr0yPjhcbG3vBZcOGDRbN/MsS6SmEhJxzr169wt6OUDtcUtPJkyfd78p/0XsAAAAAAODiFBubthakLoJ8pEma5Pbuu++28ePH26ZNm2z9+vX2xBNPuGD4xx9/tMGDB4d0PK+cTrCSOWmNf/mg1DhnPUER98mAQOV/IsmLL77oJgH2X/QeAAAAAAAAkFQE+bhoSu4oVFVpHZk1a5bvs/Tp//ePgUaVB9O4cWP3qgldt2/fbiktIW0Mp7Jly/pK13z55ZeW0urUqeNe586dG3Sb+D7zrldKXrMBAwbYwYMHz1n0HgAAAAAAAJBUBPlIUy5UyiRbtmznBb25c+d2rwcOHAi6X9euXS1v3ryulnvfvn3jDYdjYmLiPVZiJKSN4XbXXXe51/fee89NHhyfcE8E26VLF/c6b94830TDce/zsGHDLni9UvKaZcmSxX2v/6L3AAAAAAAAgKQiyEeacv/999uNN95oU6ZMsV27dvneP3LkiKuZP27cOPd3+/btfZ/VqFHDvarkzpo1awIeVyH+a6+95tZVrkf7L1q0yIX2olfVkh8+fLhVr17dvvrqq7CeV0LaGG6PPvqo1axZ003uq4mC33jjDdu7d+85Afn06dPttttusyZNmoT1uzUXga6jOkxuuOEG++KLL3x1+9euXWsdOnSwHTt2BN2/UqVKljlzZreuyY9TalQ+AAAAAACAJyY2Nk0tSF0E+UhTNGJ+0qRJbkR3kSJFLFeuXJYvXz73eu+999qpU6fsyiuvtIEDB/r26dy5s6vJvn//fqtatapbV2kZLT///LNvu549e9qbb77pAmIF2A0aNLDs2bNbwYIFLWvWrFatWjXr16+fC9rDPUlrQtsYTjlz5rRvv/3WnafKxDzwwAPue3U9Vf9dr9dcc419+OGH7rqGk67x5MmTXa1+dchokuIcOXK4DpUqVaq4Dg2vU0Z0/f3pvtx6661u/bHHHnPnUqZMGXe9dI8AAAAAAACAaEKQjzTl6aefttdff92uv/56F/hmzJjRjcYvXLiwtWrVyt5//31XW12hsEeBtEq4dO/e3dWFV2itCV61aDS6v3vuuceNCFcYfOmll7rSKRqZrqC4Xr16LuxW/f0ePXqE9bxCaWM4FS9e3H766Sf79NNPrWPHjlasWDE7duyYC+4Vil977bXuSQW1Ldx0/5YvX24PPvig+y6Nqldgrycu1HnhzVsgCvjjGjVqlJvUWE8ViCY91vXas2dP2NsKAAAAAAAAJKd0sdScABCF1GHSunVrF+4fOnTIMmXKZJFoyw/fWrQoeXVb2/7zDxYtijW42r5dkjKlpsKhbd0qtm3B9xYtijdqHnW/h2j65837Z27/lk0WLfKVLG07liy0aFG0bkM7sGObRYu8RYvb3r/XWbQoUL5i1P07YsP23RYtyhYrZJtnfWHRolSr62zXit8sWhSuWcc2zw5vKczkVKpFBzu4a6dFizyFi9j0xastWrSrVzW1mwAgDRsx7UdLS/p2DG9pZYQmY4jbA0CqU//jyy+/7NabN28esSE+AAAAAAC4eDF+GuFEaR0AEWnOnDn28MMP2+LFi+348eO+/wAuWbLElfSZPXu2m4tANfABAAAAAACAtIwR+QAikuYBGDlypFu8eQIU6HtzAijEHzZsmF199dWp3FIAAAAAAAAgeRHkA1FuwoQJ9tBDD4W0T7du3XwBeaRq0KCBPffcc27k/d9//227d/+vrm358uWtSZMmdv/997sJhgEAAAAAAIC0jiAfiHIapb5z586QR7tHuqJFi9pTTz3lFgAAAAAAgGgTQ418hBFBPhDlevXq5RYAAAAAAAAAaROT3QIAAAAAAAAAEMEI8gEAAAAAAAAAiGCU1gEAAAAAAACAMKNEPsKJEfkAAAAAAAAAAEQwgnwAAAAAAAAAACIYQT4AAAAAAAAAABGMGvkAAAAAAAAAEGaxFMlHGDEiHwAAAAAAAACACEaQDwAAAAAAAABABEsXyzMeAAAAAAAAABBWL0+da2nJ4zc0Te0mXNSokQ8AyWjn779atChyaX3bteI3ixaFa9ax+av+tmjRuHp527t+jUWLAhWq2J51f1i0KFixWlT98+b9M3dw5w6LFnmKFLU9a1dZtChYubod2rfXokXu/AWi7vew9+91Fi0KlK9om3bssWhRumhB27lskUWLIpddYfu3bLJoka9k6aj6b4b778WunRYt8hQuYuu3Rk97K5QoYvv+WW/RIn+5CqndBAAhiGH8NMKI0joAAAAAAAAAAEQwgnwAAAAAAAAAACIYQT4AAAAAAAAAABGMIB8AAAAAAAAAgAjGZLcAAAAAAAAAEGbMdYtwYkQ+AAAAAAAAAAARjCAfAAAAAAAAAIAIRpAPRIkxY8ZYunTprGzZsud91qtXL/eZXhFegwcPdte2adOmqd0UAAAAAAAAXKSokQ8AAAAAAAAAYRZLkXyEESPyASAeBQsWtMqVK1vp0qVTuykAAAAAAAC4SDEiHwDicf/997sFAAAAAAAASC2MyAcAAAAAAAAAIIIR5ANhtH//fnvvvffsxhtvtJo1a1r+/Pkta9asVqZMGbvpppvs559/jnd/fd6pUydXziVbtmyupMvAgQPtyJEjIbVj8uTJbnJWfX/27Nntsssus5EjR1pMTEy8+82dO9e6du1qJUqUsCxZsrh2tGjRwj744AM7e/ZsvPsePXrURowYYVdffbXbL3PmzFayZEn39/Dhw23nzp0hnUOgtmnSWS2yePFi69KlixUrVsxd4woVKlj//v3twIED8R7n1KlTNnr0aGvbtq0VKVLEnaeO0bBhQ3v22Wftn3/+OWd7JrsFAAAAAACJERMbm6YWpC5K6wBhpLB8yJAhbj1DhgyWO3dut75p0ya3jB8/3l577TV78MEHz9v3/ffft7vuussXtufJk8c2bNhgL7zwgk2dOtX69OmToDaoDMyoUaMsffr07vuPHz9uv//+uz388MP222+/2dixYwPu17dvX/v3v//t1hVc6/sVin///fdu+eijj+zzzz+3XLlynbevjqsOiM2bN7u/9d158+a1PXv22NatW23evHnueqgN4fDFF1+4zhKF8jpHTR7z119/2bBhw2zSpEku9C9btux5+ymk79ixo61cudJ3nmrnoUOHXCeKln379rl7BAAAAAAAAEQKRuQDYVS8eHF75pln3GjxY8eOuVBYQfrff/9tDz30kC8wX7p06XlB+N133+1CfI38Xr16tQvRNRL/008/tR07drjR4hcybdo0e/fdd93IeD0doEVh+p133uk+HzdunAvl43rjjTd8Ib46DLZt2+b2PXjwoHs/Y8aMbj91NMSl8L5NmzbutVSpUq6z4vDhw7Z371537qtWrXKj2gsVKmTh0rNnT2vUqJH98ccfro16GmDChAmWL18+27hxowv54z5BoLBe7VSIr+3eeecdd466R9pfHQF6ckBPTwAAAAAAAACRhBH5QBgFGjWvUd/lypVzo7zPnDnjRstrUXkXz1NPPeU+q1Spkn3zzTeurI5kypTJunfv7oJnlYK5EAXTKoPTq1cv33sFChRw4b46D5YsWeI6Bpo3b+77XGG7Oh+kR48e9vbbb/s+y5EjhxtFr9H0eopAYbnK19StW9e3zZNPPuk6C/Q98+fPd2G+/7lXq1bNd/xwUUkc/+ukjgaF9yol1KpVK/v111/dUwwqE+R59dVXbd26da6UzuzZs6127drnHLN8+fKukwUAAAAAAACINIzIB1JQ+/bt3etPP/3ke08j72fMmOHWFZJ74bQ/jSRXDfcLUYiu0eqBqKSMLF++/Jz3Z82a5Uali0bOB3Lfffe5OvLyySef+N73RsLLE088cU6In5yCXaeWLVu6kfqiJwPili4SPZ0QN8QHAAAAAAAIt9g0tiB1EeQDYaYyOv369XOj1lV/XaPZvUlar7nmGrfNli1bzimr49XF9x8pH1d8n3nq16/vmww2UNkf8UJ7j8oAiUJ4PREQiM7B+35ve2/99OnTbv3aa6+1lJKQ6+TfTpXbUbmglG4nAAAAAAAAEA6U1gHC6LPPPnPlaU6ePOl7T5OxZs2a1QXsmpxV5W80kt2za9cu33qJEiWCHrtkyZIX/P5AE9F6VH5GvOA97vfH993+3+/fXtXu96Rkbfn42up9FgntBAAAAAAAAMKBEflAmGhyV9WmV4ivUeFz5851E95qMtadO3e6MHnSpEmWlgQb/X8xtlP3XRPq+i/+HToAAAAAAABAYhHkA2GiyVcV3mpi2i+//NKuvvrq8+q4+48M9xQuXNi3vnXr1qDHj++zpPC+37/cTyDe5/7tLVq06Dnla1JKQq5TSrfzxRdftDx58pyz6D0AAAAAAHBxiomNTVMLUhdBPhAmmzdvdq+VK1e27NmzB9zmu+++O++9OnXqWPr0//tHcc6cOUGP//3331tyqFevni+o//PPPwNuc/bsWV/bVIfff9/MmTO7dXVepJT4rpP3mXdeUrp0aV/JneRq54ABA9zTF/6L3gMAAAAAAACSiiAfCBONwBaF4SdOnDjv82XLltknn3xy3vuaELd169ZufdiwYQH3VQfAggULkqXdrVq1sgIFCrj1wYMHB9zm7bff9k0WqzkAPOqw6N69u1t/6aWXfJ0ZyS3YdVKIP3/+fLferVu3cz6744473Ovo0aNt6dKlYW9TlixZ3HwI/oveAwAAAAAAAJKKIB8IE4XxGlm/b98+u/nmm30lXjTB7cSJE93nwSajfe655yxDhgy2Zs0aa9++va1du9a9f+bMGbfvjTfe6AL/5KDyP16A/+mnn9o999zjavqLavy//vrr9vDDD/vC8bp1656z/9ChQ61gwYJujoDGjRu79h4/ftx9FhsbaytXrrT+/fvbhx9+GLY2b9++/bzrNHnyZOvSpYvvKYcbbrjhnH369etnFStWdHXrW7RoYe+++64rheT566+/7Nlnn3WdBAAAAAAAAEAkIcgHwkQhsQJrmTp1qpUsWdKF7zlz5nQBuF4VigeiMjD//e9/3aSsKqFTpUqVc/YtUqSIDRo0KNnafv/999sjjzziG31frFgxy58/v3vK4KGHHrLTp09bs2bNXPgdl85zxowZrnSNRuSrveqwULivEfs1a9Z04biC/nAZO3as/fjjj+dcp65du7pOFJXRUaifMWPGc/ZRm7799lurVq2a7d+/3/r06ePmM9DTCDly5LAKFSrYM888c8G5AgAAAAAAABJCAxzT0oLURZAPhJHKy4wbN84uv/xyN9JdAbgC4ieffNKVcylevHjQfRUsqyzMtdde60J0jRwvU6aMq7P+yy+/uNA5OY0YMcJ1InTu3Nl1HBw5csSF3wrw33//fZs1a1bQJwo0An716tXu/Bs0aOC2O3z4sBUqVMiaNm3qjn3TTTeFra3XXXedKzWktmbNmtX9x6RcuXL26KOPuhJGWg+kfPny7j6o00Tt0jVVO9UZ0LBhQ/dkhNehAQAAAAAAAESKdLF0pwCIAnPnznWdChJN/9ra+fuvFi2KXFrfdq34zaJF4Zp1bP6qvy1aNK5e3vauX2PRokCFKrZn3R8WLQpWrBZV/7x5/8wd3LnDokWeIkVtz9pVFi0KVq5uh/aF72mw5JY7f4Go+z3s/XudRYsC5Svaph17LFqULlrQdi5bZNGiyGVX2P4tmyxa5CtZOqr+m+H+e7Hrf6Uvo0GewkVs/dboaW+FEkVs3z/rLVrkL1chtZsAIATPjJ9lacmQ7q1SuwkXNUbkAwAAAAAAAAAQwc4tIg0AAAAAAAAASLIoKiiAKMCIfAAAAAAAAAAAIhgj8gGkGE1Qe8MNN4S0T6NGjWzq1KnJ1iYAAAAAAAAg0hHkA0gxp06dsp07Q5v4at++fe61adOmUTXJLQAAAAAAABAuBPkAUgxhPAAAAAAAuFjEkIEgjKiRDwAAAAAAAABABCPIBwAAAAAAAAAgghHkAwAAAAAAAAAQwaiRDwAAAAAAAABhxjyBCCdG5AMAAAAAAAAAEMEI8gEAAAAAAAAAiGAE+QAAAAAAAAAARDBq5AMAAAAAAABAmFEiH+HEiHwAAAAAAAAAACJYulimTwYAAAAAAACAsHryoxmWlrxwS5vUbsJFjdI6AJCMdq1aatGicPXatmPJQosWRes2tMV/brRoUa9SGdu5bJFFiyKXXWG7Vvxm0aJwzTq2a/liiyaFa9Wzff+st2iRv1wF2795g0WLfKXK2oFtmy1a5C1eyvb+tdaiRYFLKtvev9dZtChQvqLt3n/QokWhfHlsx+L5Fi2K1mtse9b9YdGiYMVqtvP3Xy1aFLm0ftT9fqPtf6Pt2/i3RYv8ZcrbX9t2WbS4pHjh1G4CAKQZBPkAAAAAAAAAEGYxFEJBGFEjHwAAAAAAAACACEaQDwAAAAAAAABABCPIBwAAAAAAAAAgglEjHwAAAAAAAADCLJYa+QgjRuQDAAAAAAAAABDBCPIBAAAAAAAAAIhgBPlAlGjatKmlS5fOBg8enNpNuWiMGTPGXfOyZcumdlMAAAAAAABwESPIBwAAAAAAAAAggjHZLRAlSpcubZUrV7aCBQumdlMuGnny5HHXvESJEqndFAAAAAAAEGVimOsWYUSQD0SJcePGpXYTLjrXX3+9WwAAAAAAAIDURGkdAAAAAAAAAAAiGEE+0uyEsKdOnbKXXnrJatWqZTly5LB8+fJZq1atbPr06QH31YSm2lcTnB45csQGDRpkNWvWtFy5crn3N2zYcM728+fPt1tuucXKlCljWbNmdWVYLr/8cnv55Zfd/v5Onz7tSuLoOK+//nq85/D++++77XLnzm3Hjh0LeG7BTJ061Tp06GBFihSxzJkzu1f9/dlnnyXomgWjz7SNtg1kwoQJ1q5dO/d9mTJlsrx581rFihWtY8eONmrUKDtx4oQlha69vt+7D+vWrbNevXpZyZIlLUuWLK7s0D333GPbtm2L9zgxMTE2ceJE69SpkyuXo30LFSpkdevWtccff9xWrlx5zvZMdgsAAAAAAIBIQGkdpEkK8Vu2bGk//vijZcyY0XLmzGkHDhyw7777zi3PPPNM0OB67969Ltj9888/XRiePXv288LgRx555JxAXsc/evSo/frrr2754IMPbMaMGS7kF4Xb3bt3d6H2hx9+aA8++GDQtutz6dy583nfHd/53nbbbS5Ql/Tp07uOhT179tjXX3/tlh49etjYsWNdW8Kpd+/e7nz9r4U6LtavX++WL7/80tq3bx+2MHzRokV211132eHDh913ZciQwTZv3mxvv/22TZo0yWbNmmV16tQ5bz9dC13TefPm+d5Th4M6GX777Te3rF271j7//POwtBMAAAAAAFzcYo0i+QgfRuQjTfrvf/9rv/zyi7311lsu8N2/f79t2rTJunTp4j4fMmSITZs2LeC+CvgPHTrkRrFrZL32VVBcuHBh97k6ARTi628F8wr+9R3Hjx+3OXPmWO3atV0gfMMNN7jQ36OgXRYvXmxr1qwJ+N1q4w8//HDO9gnx5JNPuhBfo8effvpp16Z9+/a58Fqfyaeffuo+C6effvrJhfjqONCTCN61UKeGvludGT179nQdIuFy9913W7ly5Vyg732Xvkej8nXOqmmv9/2dOXPGjcJXiK9R+Grrrl273L3Vtlu3bnUdAdWqVQtbOwEAAAAAAIBwIchHmnTw4EEX5iv0VdkbKVWqlAu7r7rqKve3F3DHpUD+m2++ccGvN3pdJVw0Ol5lXV588UXLli2bzZw50+677z7Lnz+/20bbqvSMgnhtrxHe/p0FKrtTuXLleCeu/fjjjy02NtaF0sHK2MSlEHrkyJFu/YknnrBnn33WjTQXlRMaOnSo9e3b1/09YsQI2759u4XLggUL3Kuefnjsscd810IKFChgrVu3duVpihcvHrbv1BMWGnWv6ynqvND3fPvtt67DQJ0h6sDxpycRVApJ26r8kNqqkjoeta9Pnz72wgsvhK2dAAAAAAAAQLgQ5CNNUmh/++23n/e+Ro4/9dRTbn3VqlW2YsWK87Zp27atG1UfiELps2fPum0uvfTSgNuopr46AUQjxf3deuut5wT2wcrq3HzzzS50TogpU6a4EefqsFCQH4jOWSPRVfJm8uTJFi5eh8Hu3bvddUkJqoXvPR3hr+r/Y+9N4KYa////y55SspM2RUSLsiUlKhSyhYpQqZAKkYRUthZlyb6lIiTJXqSFFi3WRBKKQn1sESlL838839//md/c06w1M+ec+349PY57OnPmvq85c+Y61/W63u/Xu2bNaMbFs88+u0ndATj55JNtE0IIIYQQQgghhBAiTEjIF8USr4BrIho3bmxR3Z7NTTzHHHNM0t9LVDcQjb/33nsn3TzP+G+++WYTIZ92xVroeLz//vtu8eLFWdvqeO/hiCOOsAK5iSAy//DDD0/6njeXZs2a2QLChx9+aOf18ccfd8uWLXP5pGnTpmmfW7hwoS1aAIsc1C2AVq1a5bVtQgghhBBCCCGEEB4EcRanTfiLhHxRLNl3332TPofwjO0L4JMeT6Job4/vv//efuLLvnr16qQbz8O6deuKvB7LnCZNmhSJvvfw/o0gf9BBB2X8Xr33kOo9A3Y/scfngurVq7vHHnvMis6+++67rnPnzq5atWp2Dtu0aeNeeumlnHf0qd6n9xziPX75gG+/J+p7xYeFEEIIIYQQQgghhAgTEvKFiGObbbZJ+pxnH9OnT5+MVipnzJixye/wou2xuMGP3xOeKUYba78TFrABIvMAX3rEe2yNsNp57rnnzGKIhQuKB/tFphZFW8qGDRvsfcZu7BNCCCGEEEIIIYQQYkuRkC+KJRSATQbiKlHa6aLvE4FtTiLLnGzAx51iuQi9RKx7Vj1EylMwt127dln9Pu89rFy5MuVx3vPx79mzGVq/fn3K4sGpoMgthYXxpsc26MsvvzS/fkT0mTNnugEDBrhCfLbec7wnr/AuP72ixVvyuaWDIsg777xzkY19QgghhBBCCCGEEEJsKRLyRbEE//lkli4Iy0TAg+cbnymef/5bb72VUvhORWwxXM9Ox/vZsmVLt/vuu2f1+2K975MJ7mvWrCnipR/vnw8rVqxI+jfmzZuXteUOIvZ5551n/54yZYrLFdOnT0/7XJ06daLiPaL+kUceaY9feeUVly/69u1r5z92Y58QQgghhBBCCCFKJhsjxWsT/iIhXxRLiAofPXr0Jvs3btzobr/9dnt88MEHu9q1a2f1ezt16mTC8E8//eT69++f8ti///7b/fHHHwmf8+x1iMRfunRpNDI/myK3Hq1bt7Y2sbAwZMiQhMfwnslEQNzm+Fjq1q1rP994442ot38s06ZNM//7RKSzjiHzALbeOnddDRY+nP94lixZYnZFgMVPLBdffLH9fP31123LBzvssIMVG47d2CeEEEIIIYQQQgghxJYiIV8US7A1ueyyy9yjjz4ajZwn4hzbGi9q+9Zbb8369xJp3q9fP3s8dOhQE94XLVoUfZ5I/48++sjdfPPNbv/997fHiTjhhBPMpofjiVrHK5/I+FNPPTXrNlHg9YorrrDHgwcPtgUGIvCBn7T3jjvusH/36tXL7bPPPkVef+6555rQjt0Q58ez4KFNLIaceeaZUZuaeLp3726vnzBhQpEiuixgILiPGTPG/n3KKae4XEHhWs7fggUL7N9kXpAhcdJJJ9nCAh79l156aZHXUHegUaNGdiwLGZyP2MUAihjfddddVvtACCGEEEIIIYQQQoigISFfFEu6detmljNdu3a1yGiE6MqVK1sBVrjxxhtNoN4cEMbZ8H/HEoeo/tKlS5slTqlSpVy9evVMTGfhIFmhVQrqerYznuUNgvjmRnATcc/rEapZRNhtt93sPfPTW7BApL/llls2eW2NGjXsfHjWMwjh5cuXt/PWoUMH17RpUzufyUT18ePHm+//XnvtZbZBLEjwk4UUshIQ0G+44QaXKx5++GH31VdfmV0Of2ennXYyYR//e9r9wgsvWNtjIWNh4sSJrnHjxrawc+2111qtAK+tLIawyEFUvxBCCCGEEEIIIYQQQUNCviiWbL/99m7q1KkmcB944IEWqU2UfrNmzdxrr72WUNDOFMR5xPKFCxeawF2zZk0T5vFERxhu2LCh6927t5szZ07UUz8R8TY6m2OrE/t+x40bZ9Yy+Owj4K9du9Z+8m/E7aeffjrqGx/PwIEDbVGiQYMGrkyZMu6///5zhx56qEXV81reXyJY0BgxYoQtihx00EEmmBONj0iOuD5y5Eg3Y8YM+5254qijjrLFD84XnylZDQjxXbp0cZ988knSugcstNCWp556ys7JHnvsYVZCLMIcdthhVpzXs10SQgghhBBCCCGE2FIIuCxOm/CXbX3++0LkDcRtio1mWnB0+fLlWf3+WrVqufvvv38zW/d/3vTZdIKI0OnANibeAz9T2rdvb1siBgwYYFsiq6EePXrYVkjIIkhUAyEdWAidf/75tmUCGQlsQgghhBBCCCGEEEL4iSLyhRBCCCGEEEIIIYQQQogAIyFfCCGEEEIIIYQQQgghhAgwEvKFEEIIIYQQQgghhBAix2yMRIrVFiTWrl1rNtC1a9d2O+20k9VRPOKII9zw4cPd33//vVm/E9ttamNmunXs2HGT34FFcyavpeZjtsgjXwhREFasWGEdajZUqlTJLViwIG9tEkIIIYQQQgghhBDh4ptvvnHHHXdctN5l6dKl3YYNG9x7771n29ixY93UqVPdLrvsktXv3Wabbdxee+2V8pj169e73377zR6n0rlKlSpliwvJQMzPFgn5oliRSUFY4Q///fefW716dVavodODqlWrqjq6EEIIIYQQQgghRAnn33//da1atTIRf5999nFjxoxxzZs3dxs3bnTjx493Xbp0cR9++KFr3769e+2117IOKF21alXKY3r06OHuu+8+t+OOO7rzzjsv6XFt2rRxo0aNcrlE1jpCiILgifHZbN7KqhBCCCGEEEIIIYQQo0ePdp988ok9njBhgon4sPXWW5t4/vDDD9u/X3/9dYvKzyVE4xPtD61bt3bly5d3hURCvhBCCCGEEEIIIYQQQuSYbAMag74FAYR8OP74493RRx+9yfNt27Z1++23nz0mWj+XvPDCC+7XX3+1x507d3aFRkK+EEIIIYQQQgghhBBCiECzbt06N3v2bHvcsmXLpN7zLVq0sMdvvvlmTv/+448/bj8POOAA16RJE1doJOQLIYQQQgghhBBCCCGECDSLFy82L3yoVatW0uO85/C7/+WXX3Lyt7/++ms3ffp0e3zxxRenPR5bnxo1alj9x3LlyrnatWu7K6+80i1dunSz2yAhXwghhBBCCCGEEEIIIURKNmzY4H7//fciG/sKxffffx99vO+++yY9Lva52NdsCSNHjjR7oW233dZddNFFaY9fuXKlif+lS5e2TIJFixa5e+65xxYZHnzwwc1qg4R8IYQQQgghhBBCCCGEyDHYyhenbdCgQW7nnXcusrGvUKxduzb6GIE8GbHPxb5mc/nvv//cqFGj7PEpp5zi9t5776TH1q9f3913331u+fLltshBRgALHhTmrV69uvv7779dt27d7N/ZIiFfCCGEEEIIIYQQQgghREr69u3rfvvttyIb+1KBAI5v/eZukydPdn4zefJk991332VU5LZnz57u8ssvd1WqVHHbbLNNdGHhrLPOcvPmzYsW4r366quzLiAsIV8IIYQQQgghhBBCCCFESnbYYQfze4/d2FcoypYtG32MXU0yYp+Lfc3m8thjj0Ute5IV2c2E3XbbzV1//fX2+JtvvnEffvhhVq/fdrP/shBCCCGEEEIIIYQQQgiRhHbt2rlTTz11s1+PfY9HhQoVoo+JkK9Tp07C13jR8/Gv2RxWr17tXn31VXvcoUOHaJT95nL00UdHH+OhjxVPpkjIF0IIIYQQQgghhBBCiByzMUvrlOIIEfu5itqvWbOm23rrrd3GjRuteGyy6HieA7zsd9111y36m2PGjHH//vuv2fx06tTJ+clWkWzNeIQQQgghhBBCCCGEEEKkpNsjL7nixANdT/e7Ce7YY491M2fOdE2bNnVTp07d5Hmk7v3339+i3S+88EI3evToLfp7Bx10kFuyZEnSv5ctjz/+eNRn/7333nOHHXZYxq9VRL4QQuSRb9980YWFyiee4b557TkXFqqccq57ce7/rbKHgTMa1HIrp7/mwkLF409x305+wYWFyi3Oct+8Pt6FiSonn+N++vwTFxZ2P6i2+372Wy4sVDimuft97VoXFsqVLev+98kHLizsWbu+W/m2/4XHMqVikxZu0bL/l2IddGrtt6/7+oUtm3QWkmpnXeT+t/A9Fxb2rHN46MY8a3//3YWFsuXKuWkff+HCQtO6NdyPixe6sLBHzTrupyWfurCw+4GHuJ+/WuLCwm7VD/S7CUKINFx00UUm5E+fPt2Kxx511FFFnh8/fryJ+ICQvyXMmjXLRPxMitx6iwhE7ifjl19+cbfffrs9rlSpkqtXr15W7VGxWyGEEEIIIYQQQgghhBChEPJr165tonnr1q2jUfLY7SDid+nSxf6N7U6zZs02ef2AAQNMbGdbvnx5RkVusec566yz0rbtqaeesuMmTJjg/ve//0X3//XXX+7FF180f3xvkeGOO+4wm6BsUES+EEIIIYQQQgghhBBC5Bg5mueebbfd1r388svu+OOPNyG+efPmrnTp0ibkr1+/3o4h0n3s2LFb9Hd+//13WxiA9u3bZ+Tz/99//7mJEyfaBmXKlHGlSpVya9asseeA33PnnXe6Nm3aZN0mCflCCCGEEEIIIYQQQgghQkHVqlXdwoUL3bBhw9wLL7zgli1b5rbbbjt3yCGHuHbt2rkePXq47bfffov+xrPPPuvWrVuXsa0OsLhw2223uXfffdctXrzY/fzzz+63335z5cqVM99+fPYvueQSt99++21WmyTkCyGEEEIIIYQQQgghhAgNZcuWdQMHDrQtG7DWYUtH165dbcuGKlWquOuvv97lC3nkCyGEEEIIIYQQQgghhBABRhH5QgghhBBCCCGEEEIIkWNkkS9yiSLyhRBCCCGEEEIIIYQQQogAIyFfCCGEEEIIIYQQQgghhAgwEvJFYHjxxRet2AQ/S1obP/roI/u9d999d05/r8ief/75x9WpU8dttdVWtnXo0MHvJgkhhBBCCCGEEEKIEo6EfBEYEMepNB10IT8fbUTI5/dKyPef2267zX3yySd+N0MIIYQQQgghhBBCiCgqdiuEEP8/CPi33367q1atmvvzzz/d6tWr/W6SEEIIIYQQQgghQspGVbsVOUQR+UII4Zz777//XKdOncxa56GHHnKlSpXyu0lCCCGEEEIIIYQQQhgS8kVeGTdunGvZsqXba6+93HbbbefKly/vDjjgAHfaaae5+++/361fv97NmDHDvMhHjx5tr+Gn50/ubRwTz6JFi1zXrl3t95UuXdrttNNO5m1+ww03uJ9++ilhe/Ch5/cdd9xx9u+pU6e6U045xe2xxx4m3NasWdMsbmhXLJvbxkzgtR07drTH33zzzSa/lzYjMlesWNH+PXTo0JS/7/HHH7fjypYt69auXRvdX7VqVds/atQo29+3b1934IEHuh133NHtvvvu7owzznDz5s1L297Zs2e79u3buypVqtg523nnnd2RRx7phgwZ4v744w8XVoYPH+7ee+89d+GFF7oTTjjB7+YIIYQQQgghhBBCCBFFQr7IG0Q3t23b1k2ePNn973//M9GXaOcvv/zSvfLKK6579+5u1apVbvvttzeh34uA5if/jt04JhbE7Lp167pHH33Ufh8CNb/bs0ZB0P/www9Ttu+OO+4wwXbSpEnu33//dX///bf7/PPPTTg/+eSTTTz32Jw2ZgqvLVeunD3eeuutN/m9LFBss802rnPnznbMY4895iIpUrM4J9CuXTsT8+P59ddf3RFHHOEGDx7sli9fbu3++eef3UsvveQaNmzoRo4cmfD3bty40V1xxRWuUaNGbuzYse7bb7+1xRksaBYsWOCuu+46d/jhh9tiRNj44osvXP/+/W1B58477/S7OUIIIYQQQgghhBBCFEFCvsgLs2bNck888YQJ00RqIxQTBY7oS7T8G2+84S666CITkRGPEfTbtGljr+Un/47dOCY24rxPnz4WhU9h0h9++MF+77p16yyiumnTpraPqP9kEeIff/yxCc9sLDIgbq9Zs8bddNNN9vz06dOj0feQbRuzgdfec8899rhSpUqb/N5rrrnGnuvSpYsJ+kuXLk0a/c9ChhdVf8kllyQ8howD3vNzzz1n5+23335zn332mWvSpImJ9bzugw8+2OR1CN0jRoxwe+65p2VTeJ/pX3/9ZeerXr16bsmSJe6ss86y3xMWWBS5+OKLLQvjrrvucrvttpvfTRJCCCGEEEIIIUQxIFLM/hP+IiFf5IU5c+bYz+bNm7trr73W7brrrtHnEEpPPPFEs3ipUKFCVr8X4dgTtp9//nl3/fXXu7333tv+jch92GGH2SIBP1euXGnR64lAtO/Xr59F72MrA0TFI3IjRMMzzzzjgsS+++7rWrVqZY8feeSRhMd4++vXr2/nIBEI9+PHj3fnnHOO23bb/6t3jaUQmQnYFJGdwLmJhcj9QYMGmQ3Pm2++6bp16xb9TInKx6ro7bffNvsfFgFefvllFxbuu+8+W3g66aST3Pnnn+93c4QQQgghhBBCCCGE2AQJ+SIv4IUPP/74YxGLmi1lwoQJJsIT/Y3wmgjEaWxlAFE/ETvssEN0QSCe008/3X4uXLjQBY3LLrvMfk6cOHGTOgBExj/11FMpo/HhmGOOcc2aNdtkPyJ979697TF2SAj+Hiy68Dm2aNHCLI0SgY0PPvupznvQYIGCWgFkdzz44IN+N0cIIYQQQgghhBBCiIT8XziuEDkGoRgfeXzqGzdubNYlWN7st99+W/R7KbQKixcvjkbiJwJRG5L5tR9yyCHmPZ8IL0vgl19+cUEDT//q1au7r776yo0ZM8b16tUr+hwZCixy8L7OO++8pL+DzyHdc1jjEFl//PHHFznvROOnOu+elVFYfPKxK8JeaNiwYVt8bQohhBBCCCGEEEIIkS8k5Iu8gNiMrc2ll17q3n33XduAYqKIwwjNeNhTpDYbvv/+e/uJnzlbOvDNT0SiIrAent0MFjNBg/PVtWtXqxFAUdtYId+z1eHcJluk8Cx6MnkOH/34847ozba55z1IcH2+9dZbZkN05ZVX+t0cIYQQQgghhBBCFDM2ylZe5BBZ64i8gd84kdkPPfSQFYelkCtWOxRZxYKF4qq///57Vr/Ts+nh91GkNN2GdUpxo1OnTmYN9Pnnn7t33nnH9vEYn3dA6M813nlnASGT856sGG9QwDYIayWKMd99992WwUE2QezG+/AWdLx9qYr4btiwwa7n2I19QgghhBBCCCGEEEJsKRLyRV6hICp+7c8++6z79ttv3Zdffumuu+46iyyfOXOmGzBgQFa/z7N1CYt1Sz6gOG/r1q3tMVH5sT8pcJusyK3Hd999l9Fze+65Z7E977/++quJ+Qjzxx57rGVoxG9crzB27NjovlR1EygGvPPOOxfZ2CeEEEIIIYQQQgghxJYiIV8U3HIHcdPzcJ8yZUr0OaKjwYuETlaoFd5//333ww8/uEKTSRsL8Xu9orf44q9atcr88jONxp8+fXra52gPBYXjzztWNJlYGpVEKJrL4kDsxj4hhBBCCCGEEEIIIbYUCfkiL6SzFNlxxx2LCNhQrlw5+0nB1mScc845rnz58u6ff/4xf/hUwjfR1ql+1+aQSRsL8XsbNWrkatWqZaI6NkM//fRT2iK3HljwJLK+4XcNHz7cHp900kl2nmPtfKgdwN/p379/yt//999/R4veBpWqVaumtQeqUqWKHXvRRRdF9x166KFJfyd2R3yOsRv7hBBCCCGEEEIIUTLJxJ44TJvwFwn5Ii90797dnXvuuW7ChAlFiqYi8OKZ70WQn3LKKdHnEKYByx083xOBuIynOWDXw+vnzZsX9S7n5+LFi02QPuSQQ9yrr76a0/eVSRu35Pfiq04NgUzAsgg8n/x0RW49sHzBmodofq+gL++Fc8nPbbbZxt18882bZFL069fPHg8dOtRdeOGFbtGiRdHn+T0fffSRvW7//fe3x0IIIYQQQgghhBBCiNwgIV/kBSLmx48f784++2y31157mb/4LrvsYj+xhSFqm6jyG264IfoaxOU99tjD/Mtr1qxpj4mcZps7d270OCKkH3zwQbf99tu7SZMmuQYNGrjSpUubd3ypUqXcwQcfbIVMEaXx4s8lmbYxWxC/mzVrZo+JsCea2/u93sJFPIjpZcqUif470yK3RNTTbrIbEP5ZHOG9TJs2zc4X5/bwww/f5HUI+Wwc8+STT7ratWsXOe9Y8fC7V6xYkfPzLoQQQgghhBBCCCFESUZCvsgLCL4jRoxwZ555pjvooIPMloVofAqonnDCCW7kyJFm7xIrRCP0E13etm1bt++++5rHOMVV2eJ92S+99FK3ZMkSE+zr1q1rFibY0iBMI0L36NHD/PfbtWuX0/eVTRuzhQj5q666ytWoUcMWQrzfm8xuB7H/xBNPzLjIbex7mD9/vhUdrly5stkgUZS4VatWbvbs2a5Lly4JX4c4T8Q9BV+7detm4j/R+5wDfmfDhg1d79693Zw5c6Ke+kIIIYQQQgghhBBCiC1n2xz8DiE2ASsWxHS2bED0f+aZZzI6lmj1O+64I6vfP2DAANtScdxxx6X0/cqmjdlAZPydd95pWyYgwHu2OplG48cuAlB0mG1zbIDuv/9+V9xZvny5300QQgghhBBCCCFEiJGvvMglisgXIqSwmPDzzz+bKJ9JkVshhBBCCCGEEEIIIUQ4kZAvRAj56quvosVnsRnKpMitEEIIIYQQQgghhBAinMhaR4gQQYHgZcuWuVWrVrmNGze6ihUrur59+/rdLCGEEEIIIYQQQgghRB6RkC9Ejhg3bpy74oorsnpNmzZt3D333JPx8StXrnTff/+922233dyxxx7rhg4dat76QWTFihXuiCOOyOo1ZcuWdWvXrs34+B9//NEWNPbaa6+MX1OpUiW3YMGCrNolhBBCCCGEEEIIkS0bZZEvcoiEfCFyxF9//eVWr16d1Wt+++23ghVgLXTx1v/++y/r81GqVKmsXwPZvIa/IYQQQgghhBBCCCFEmJCQL0SO6NChg23i/6hataqqswshhBBCCCGEEEIIkQNU7FYIIYQQQgghhBBCCCGECDCKyBdCCCGEEEIIIYQQQogcI6cCkUsUkS+EEEIIIYQQQgghhBBCBBgJ+UIIIYQQQgghhBBCCCFEgJGQL4QQQgghhBBCCCGEEEIEGHnkCyGEEEIIIYQQQgghRI6RR77IJYrIF0IIIYQQQgghhBBCCCECjIR8IYQQQgghhBBCCCGEECLASMgXQgghhBBCCCGEEEIIIQLMVhGZNQkhhBBCCCGEEEIIIUROOf/u51xxYuyV5/rdhBKNit0KIUQe+eqZR1xYqN6uq/ti5F0uLNTodJW759VZLixccWoj99W4R11YqN6mi1v65P0uLBxwweVuyWPDXJg4sPM17vt3p7uwUOHo4903kya4sFClZWu3+uMFLizsVfcIt/qDuS4s7FW/gfv6+VEuLFQ7u4Obv2S5CwtHHljVfXpnPxcWDul1i/t28gsuLFRucZb7/KHBLiwcdOl1bu1va1xYKLtzeffE1PD0vx2bHRG66/fnr5e6sLBbtQPcDwvCM2bf54hG7ts3X3RhovKJZ/jdBCFEgZC1jhBCCCGEEEIIIYQQQggRYCTkCyGEEEIIIYQQQgghhBABRtY6QgghhBBCCCGEEEIIkWNUmlTkEkXkCyGEEEIIIYQQQgghhBABRkK+EEIIIYQQQgghhBBCCBFgJOQLIYQQQgghhBBCCCGEEAFGHvlCCCGEEEIIIYQQQgiRYzbKI1/kEEXkCyGSMmDAALfVVlu54447Lm+vf+KJJ9zRRx/typUrZ8ey3X333VvQaiGEEEIIIYQQQgghiheKyBciICB6Q4cOHVzVqlVdSWD48OHummuuscfbbrut23PPPU3IL1OmjN9NE0IIIYQQQgghhBAiMEjIFyIgDBw40H4SvV5chPzdd9/dHXjgga5y5coJn7/jjjvsZ8+ePd2wYcPcdtttV+AWCiGEEEIIIYQQQggRfCTkCyHyRvfu3W1LxI8//uhWr15tj7t06SIRXwghhBBCCCGEEMUKOeSLXCKPfCGEL6xbty76eKeddvK1LUIIIYQQQgghhBBCBBkJ+ULkkRUrVrhrr73WHXrooW7nnXd2O+64o6tevbo7/fTT3ZgxY9z69evNEx9feI/jjz8+WvSVLZHNzm+//eZuvvlmV79+fSsSy+894IAD3GWXXea+/vrrvL2f5557zjVp0sTtuuuu5mN/2GGHufvuu8/9999/GRe7nTFjxibva7/99kv4fnnMvlGjRiVtk3f++BlP7Ov/+OMPd9NNN7natWu7smXL2v7ly5cXOX7evHmuY8eObv/993elS5e2c3vwwQe7Tp06uTfeeCPr8yWEEEIIIYQQQgghRC6QtY4QeeLJJ590Xbt2NbEett9+exOQv/32WxPbX375ZVenTh0T+Pfaa6+ozcwuu+xix3rsscceRX7vp59+6lq0aOFWrlxp/y5VqpTZ0nz55Ze2PfHEE27s2LGudevWOX0/ffr0cUOHDjUBvHz58va+PvjgA9teffVV99JLL7kddtgh7e/hvfF+Ef9/+umnqJf+Nttsk/D95oKff/7ZFh2++OIL+/uI9LHQll69erkRI0ZE97FQQQHezz//3C1evNi98MILbs2aNTlvmxBCCCGEEEIIIYQQ6VBEvhB54LXXXnMXXXSRid3HHHOMmzlzpvvrr79MuP7zzz/t3/jCIyrfc889btWqVdHXIhjzb29bsGBB9Lm1a9e6Vq1amYi/77772t/h9/3+++/uo48+cg0aNHAbNmxw559/vvv4449z9n743Yj4+N2z4PDLL7+4X3/91d1yyy0m7BOt3rdv34x+V8OGDTd5XzxO9H5zBZkBnKOJEydaZD5tJ1tizz33tOevv/76qIhP9P2SJUvsOO99vvjii7Z4IoQQQgghhBBCCCGEHygiX4gc8++//7oePXq4SCTiGjVq5KZOnVokwp7H7GfLlgceeMAtW7bMIvAnT57satWqFX2ubt267s0337QofyxjbrjhBouUzwVY+VxwwQXu3nvvje7DdubGG2+0hYNbb73VnrvmmmtchQoVXNBgEeWdd95x9erVi+6rWLGi/SRKf9iwYfYYG6QhQ4YUeS0ZE1ghsQkhhBBCCCGEEEJkCtqQELlCEflC5Jjp06eb2A533XVXERF/Sxk3bpz9PPvss4uI+B5Y9yBGw6RJk0yAzxX4yyeid+/e5tHPAsaECRNcECGaPlbEj2X06NFu48aNbrfddnMDBw4seNuEEEIIIYQQQgghhEiHhHwhcsycOXPs59577+0OP/zwnP3ev//+2y1cuNAeN2/ePOlxJ5xwgv1EnMa/PhdUqlTJCsAmgsh8/Ofhvffec0EEe6N0nxfnjXoDQgghhBBCCCGEEEIEDQn5QuQYz+++SpUqOf29+LVTlBXwx0+GZxkD//vf/3Lyt1P9vdjnc/X3co3nhV/Iz0sIIYQQQgghhBBCiFwhj3whcgzFX0Ww2GabbfL+eVErgC2WHXbYISe/WwghhBBCCCGEEOFjozzyRQ5RRL4QOQZLHfjmm29y+nt33XXXqCC9cuXKpMfFPpcqEj0bvvvuu4yez9Xf89h22/9ba1y/fn3SY7a0DkCuPq9BgwZZYdzYjX1CCCGEEEIIIYQQQmwpEvKFyDENGzaMWrZk4xnvRYYnq2hO0dw6derY46lTpyb9PW+99Zb93HrrrV39+vVdLlixYoX76quvEj63du1a9/7779vjXNYEgF122SX69xNBHYAt9eX3Pq8pU6akXDBIR9++fW1RIXZjnxBCCCGEEEIIIYQQW4qEfCFyzPHHH++qVatmj6+66iorUpsJFI2FNWvWJD2mbdu29vP55593ixYt2uT5P/74ww0dOtQen3zyyRYVnituueWWhPuHDx/u/vrrL4ueb926tcsldevWtZ8TJ05MuMAxevTolNkJmdChQwfLdPj5559d//79N/v3YKPDZxi7yVpHCCGEEEIIIYQQQuQCCflC5BhE4fvuu88i7GfNmuWaNWtmP4keB4T9GTNmuPbt27vPPvss+rpatWrZz7Fjx7p169Yl/N2XXXaZ22+//dw///zjWrZs6SZNmhT9vZ988ok76aST3LJly0xAvvXWW3P2nlgQQDS/4oor3E8//RSNxL/99tvdzTffbP++/PLLXYUKFVwuadeunf1cvHix69q1q4nt8Pvvv7u77rrLXXrppWY5tCXsv//+rnfv3vaYRZDOnTu7pUuXRp/nb40bN86deeaZW/R3hBBCCCGEEEIIUbIgJrE4bcJfJOQLkQcQ2UeNGmWCOiJ+48aNXenSpd3uu+/uypQpY1H7CPax0fqI0jBhwgRXvnx5V7FiRVe1alXXqFGj6DFly5Z1L7/8stt3330tEp2oe34fQju2O3PmzLG/+dRTT0Wj2XPBoYce6q699lo3YsQI88FHPMf25oYbbrBI+ebNm7vBgwe7XMMiyAUXXGCPH3vsMTt//F22Xr16uUsuucS1atVqi/8Oix4sRMDjjz/uatSoYeea98lnQSbE9OnTt/jvCCGEEEIIIYQQQgixOUjIFyJPXHjhhe7zzz93V155pTv44IPNegYLmipVqrgzzjjDPfnkk65mzZrR44nQZx/CPaL/Dz/8YAVY461jiNz/9NNP3YABA0xg5/du2LDBVa9e3RYDeO7ss8/O+fsZMmSIe/bZZ619iPd49vP377nnHjd58mRXqlQplw9YEOFv8Ld23HFHy0A45phj3HPPPWcLC7nMomDR5fzzz3eVK1e2rAfeJ5/dxRdfbAssQgghhBBCCCGEEEL4wba+/FUhSghE1GMBkymI+WzpIAIfP/ct8XTPBBYL2DzatGlj2+a+Pv7cJCvsGwtFe3v27GlbMqGfLRHLly932cACAZsQQgghhBBCCCGEEEFCQr4QQgghhBBCCCGEEELkmEwCGIXIFFnrCCGEEEIIIYQQQgghhBABRkK+EEIIIYQQQgghhBBCCBFgZK0jRDFn2LBhtmXDNddcY5sQQgghhBBCCCGEEMJ/JOQLUcz5448/3OrVq7N+jRBCCCGEEEIIIYTYfDbKI1/kEAn5QhRzBgwYYJsQQgghhBBCCCGEECKcyCNfCCGEEEIIIYQQQgghhAgwEvKFEEIIIYQQQgghhBBCiAAjax0hhBBCCCGEEEIIIYTIMRF55Iscooh8IYQQQgghhBBCCCGEECLASMgXQgghhBBCCCGEEEIIIQKMhHwhhBBCCCGEEEIIIYQQIsDII18IIYQQQgghhBBCCCFyzEZZ5Iscooh8IYQQQgghhBBCCCGEECLASMgXQgghhBBCCCGEEEIIIQLMVpFIREkeQggREjZs2OAGDRrk+vbt63bYYQcXdNTe/KL25pewtTeMbVZ784vam1/U3vyi9uYXtTe/qL35JWztDWObw9beINNq0JOuOPFK3wv8bkKJRkK+EEKEiN9//93tvPPO7rfffnPlypVzQUftzS9qb34JW3vD2Ga1N7+ovflF7c0vam9+UXvzi9qbX8LW3jC2OWztDTKn3j7GFSdevf5Cv5tQopG1jhBCCCGEEEIIIYQQQggRYCTkCyGEEEIIIYQQQgghhBABRkK+EEIIIYQQQgghhBBCCBFgtvW7AUIIITKHQkP9+/cPTcEhtTe/qL35JWztDWOb1d78ovbmF7U3v6i9+UXtzS9qb34JW3vD2OawtTfIqDSpyCUqdiuEEEIIIYQQQgghhBA55pTbRrvixGs3XOR3E0o0stYRQgghhBBCCCGEEEIIIQKMhHwhhBBCCCGEEEIIIYQQIsDII18IIYQQQgghhBBCCCFyzEYZmoscooh8IYQQQgghhBBCCCGEECLASMgXQgghhBBCCCGEEEIIIQKMhHwhhBDFnrPOOst17ty5yL5vv/3Wfffdd761SQghhNhSevXq5QYMGOB3M4TIGZ06dbJt2bJlfjdFCCGECBxbRSIRuTUJIUQIoLv++eef3bp161zlypX9bk6o2Hrrrd3ee+/tvv/++yL79tlnH4n5Qggh0sLi7zbbbOP23XffjI7nfvPvv//m/X5dXO5vN998s/3s2LGjq1Spkt/NET6y7bbb2vbXX3+5rbbayu/mCJHTudwnn3xij+vUqeN3c0QBaXHrKFecmHxjB7+bUKJRsVshhAg4H3zwgbv11lvdW2+95f7880+b1CAOePz666/uuuuus/133XWX23HHHX1tbxBB1Pjvv/822R+2teyVK1e6O++8073xxhvum2++cevXr9/kWnjwwQftWujdu7dNhEX4xcNcoQXA9NBP/PLLL26PPfbY5LkNGza4SZMmuS+//NKVLVvWNWnSxB100EEuqPz444/WT7D4e+yxx7qgsnHjRrd06VI77//880/KY/18H1WrVs1KHD/mmGPcihUrivTR+YD+nnMY9vvbwIEDbaGkb9++Loxw//UiyLlWdt11V7+bFFr23HNPG99IxBfFDe7Hhx56qM1L8n1vyJQ333zTtW3b1rVo0cI9/fTTaTOcZ8yY4SZMmOCOP/74grVRCFEUzfCFECLAPPnkk2YJk0rc2GWXXdxXX33lpk+f7o477jgbjPnJqlWr3MiRI92sWbNMeGbxIZmgwCSNtucbJtRkM/z2229u5513dmFkypQp7txzz3W///579HzGT3K5Fl588UX3/vvvu0MOOcSddtppzm+0+LBl7Lfffjn5PfELgH4xbdo09+yzz7qFCxfaZ5+qbytU/wBEfl599dVuzJgx9ninnXayf/fr18/aMW/ePNemTRsTZmM5//zz3WOPPea23357FxRefvlls1r5+OOP7d+JFn/btWtnj8eNG+dbn/jDDz+YaPv888/bOQ/DNZytOF4IMZ3Pj0UQ+tZSpUq5sLL77rvbQtp2223nwsT8+fPdtddea2Oe2HszCzlDhgxxDRo08LuJoePII490r7zyii2aZZoB4zd89qNHj3bPPPOM3d/4TqbqrwrVnzVt2tR+VqlSxT3xxBNF9mUD7Z06dWrO21dSCdJCK+MA5kfeuCAVjIOYZzCOk5AvhH9otiyEEAHls88+c126dDGhq2fPnu7CCy+0aAkE6XguuugiE8iIFvVTyJ84caK1JZ14n0yIzhdHHHGEmzx5smvVqpWdH0Q6QDxCuMsGPodCg3h49tlnu7Vr15o4Txu4NtasWbPJsfjKvvfee+61117zXcgP6+JDOjjv9erVs4iqfAvNuZrs+T1pRLDgumXCmGl7ChmNeeaZZ9r16rWL7xoRwn///be76qqr3BlnnOFWr169yevGjh1r4iM/g8DgwYPdDTfckPL88p0jcwvBHxH94osvdoUGG5ijjjrKfmZ6bfp9DWcLwnohFiaJ7nz77bft3svm3d+4dmfOnJnVefMz46Fu3bo2jmGMs9tuu7mgQCbTXnvt5RYsWLDJc9y7GFMwTos9zzzm3BNcQZ93+umnu6AQxGCLeK644goT8vv3728LpUGHbK1TTjnFAmqC1k8RPQ2x2WPevmwo5P24WrVq9nP//fe3aPHYfdlQqOuXcXemxC7exL6Otj7++OPOD+bOnWt/n/4qHSeffLId++677xakbUKIxEjIF0KIgEIUMxPxyy+/3N199922j7TzRDRr1sx+Iob6ufBw3nnnRSc0bN26dbNoweHDh9vkEXsgJhBE3hExWqZMmYK0DeshRDomrrNnz47uR2DGjzdTGLz6IeRz/hAWEcWJggGui0ScdNJJ9jOR6FBIwrr4kAkIt2QXFGJiW1yK/RGZ6l27jRs3tusUcSwIGRgvvPCCiQV8nkSkEUGLCIfITT9MGxHxe/ToYaI+EaJff/21u/322y1rivfF97Fhw4a+vg8m44j4tHfo0KHuggsusMWx//3vf5sc2759e/fSSy9Zv+iHkE//T7QtFkW33XabCZ0VKlRIeo8LGyxQYG2ERUi+ufLKK+2+yvXKFpt5kYkwE5SMh0suucTGCHznuCaCAmJ3ovNCRkmHDh1snFa+fHnrA44++ujod/H++++3z4AxxpIlSxLadRWaoAZbxEOkL1aRZEUxTmMMV79+fRfk+xuLUJ71iNefBeH+xmIIMO6O3xdUli9fbj9jM4y8fdlQqOt31KhRWf8tL4PDe+ynkE8fRx/G/TgdHMOxYaq/EhSCtsgnwo2K3QohRECpXr26DVwRDCtWrGj78OdFlEnk944ozqSB9Eg/QKRlEIpA5EW5JyrCR9bAOeecYwITwnqh0uiZWN9zzz1WZAqPSs4topF3boMsrNasWdN98cUX7vPPP3cHHHBA2muBaFsmQIgIfoG4NGLEiCKLD8nazDnleieylJoQQYeIUUQZJl6Jzr/YlBo1alhkHEKzV9QyKCC8IGoj1HuLpt4CExN0+lWu46eeeirpa7t27WoWUX7CIsRzzz1ndkAI5am+cz/99JOJzPQniIyFhmKm3BeIVmbBL4i88847RSJXOadEu19zzTVJX8O0isXK119/3WopsDCJeJpv8CseNmxY9P4WK8ZmQyKv/ULCufUEXOxqYsVHv0g0joEbb7zRFvNYkCRAID5imPsa9josAt5yyy3u+uuvd35CsMVhhx2WdbAFwn+h8c4lbaK93riGTI1ki31+ZQ/AwQcfbP3oTTfdFHiRPAx4AjfXJtlwsfuypRDXL30E1x/31HT2ZvTL1D7i+Pi6RX4FbvA953vFolkmlCtXzhY3udeIzDnplv+ztiouvNEv80A4kXsk5AshREBh0oLIHTuwSiXeIiwi4hMd5gcIQkSpLlq0yITnVBPghx9+2F122WUWxYQvuh8ka1sQYZDNoP+PP/4IxbUQ1sWHTJGQnz18vthP0J+VLl3aBQm8g4lIQwSiSKUHGU7YcvE543nM4mMif2wi+OvUqeM++ugj5yeIAkTJIRx6Amiq75wXfUfWTKHhu84UhMjgIEStJgJrJTYv0tKLmswEjuU9Iori911ownR/8/B8u8nO4rrgPWCtgTiWSrzNt293snNJ38DCM77jyTL1CGogap8sJOyP/CTowRax0K5s8fN+7N3fWMTzrK1EyYH7P3MfAlIeeuihaJZ0IhjHI4QHafzozd9YjKLPTQUL1ARmMG4qLhmjhUJCvsglwRw5CyGEcDvssIN57GYiHhCxxAQC72O/QEBCkPFEfKDdXjRVLFg+dO/e3SK1/RLywwST2kwH/ETJIJYyUfATIo6Y3HoifjqY/BYym2Rzir15pCrQ6gf0ESwuEB0VH+EVFFj4YAIbNBEfELopVhsr4oN37SIixvZrsRDhSr/H9R6E94E4n2kUM/cYP0R8QJylnwqqiA9cD02aNIn+GyEWUdOzT0nWV9P31qpVyyJB04kiwiX17eaeh7CUKmPEL+sXT9Di71NfIxk8R2bP4sWLXRDOL+2lwHQqWrZsaRH6BFuQoeTHGM0ryhoW6He5XiXil0xY0Lv11lvdoEGD3Iknnmh9PxZhWNAEqc9KRqNGjUzIx5LvkUceSXksAVi8BxYnhRD+EdzRsxBClHBILf74448tqvnAAw9Meewbb7xhk4hEEaOFAiEsPnLLE2cRl2MFG8Q8Jj5+pUEHwUIgG4h8QQhALEwn1GIHgdCcqYBeUhcfPFEjzImJ3uQROwQiWOM9rsluwFuY/dhVsLDiFxTRfOaZZyzyPVs7q3yDUE//FY93PSKMJ4sQ5bWk//tlaRafuYMwz/cundc8iyos/vrl2928eXOzSli6dKnvfVUyvOKxHlwDu+66qxW0DDpESoat3kDYLEn++uuvtL7Snp90EPqHMAVb+GHnsyWQncE4/JdffrE+IuhgLYn1IWNLCgungkUdrh3qw2CJJjaF7xVWVK1bt45a8pHZwriLYthBh0U77sdk7Hi2WvFjIjJ86aM5hn6D1wgh/ENCvhBCBJSTTz7ZrBqIiErlvYxw44l1fhYKpbAXwjwCuSd6EdFIuikLEkSuxgqMiEjpvCQLAcIikTNMwqhHQBZEvBjK+ef8MqH1I4IU0Qshn5RdPHmTgYCPBzltJarOT4K++IDIxbVK0VWsBbIB4cPz/fcLiqx27tw5ZXYAGTp8JxEeKXrp54SSPurFF190ffr0cWPHjnVBAjGb65RzuTk2ElwPiPl+w4LvvHnzzAaoXr16KY/ls+D6py6FH+AXTmFWrgeKDYcBooT9XAzLtv8NG2ET8rGtouBtOuhXgpCJFLZgizDRq1cvN3nyZBNuqYcQdBg/UDMKkT4dZPpxLPfJdNkc+eTTTz+1+i/UIyCAId14gyAoxssHHXRQwdpYu3ZtuwdTrwQx/Pzzz7dz/cADDwS6T8b+jRpB9957r0XcP/bYY+6EE06Itpm50ZQpUyzzE2ILe4vM2RjeuCERQLI3oBNCCFGwYqGIQ6Q5MnhF+I6PBkMAYQCGDzliJAUX/QLPRCaDtMWDQm9EPDOojS8SB+kyDfINA1MG3kxSEJ2ZsMRHaCOGInrRZgoY+gGRUEzCmXQRDZMsOhvBn0kEE3CK2PkJbQEWH1Lh1+KDN7nDCxiBLpuNyY7fRQvxO+bc9ezZ0zylk9mpENnINU10mJ9gNUJhU75DfM5kRJBFEAS8DIEVK1Zs8hxZBKmuYUQwotuxivEbFnL5rEnvT7d46S3+EkHoB1jOvPzyy2ZXg2DAYlNQrodk8F2i6HGY4J5G5C2FTfkO4uEcf/0+/fTTdp2L5PAdp0h37IYoTh9MQdZkcH4JtqBIq98QbEHmW2w2IsEW9BkEW8TiBVv4WWcnTOCJjgA6ePBgE/KDXgTUGw94hWRTgRjNNfLaa685P0EQp7B8vAVeIihAzbGJCtTnGwKZKNRNIFbDhg3tXNP3EpQV5AxQFqEIVmJc8NNPP1mwCtc0G4/Zx3tj7MB7EUL4i4rdCiFEgMEy4/TTT7cocaKlmICxMUhlUIWFAt04UVVElPsZIYG4SYouoj3RSUBkaP369a2NpHPXrVvXffLJJxZZAwwGiQLxA0Q7BtdMshHAKFaHOMrkNd4SBiEPYZznKdTrB0Qxe6Isoi0CASLCUUcdZdEyiAk8x3VCpKuf2RlAmxDLuV6JRrr44os3KbzJ4gOLFDNnzjQbEzyHM/X33lIoQMjE8NJLL3X3339/qIrdEok/cuRIi4ryFhWSFTWliCFCNVFsZMf4CW2jeCjRdJn4xMZbBeUL+q377rvPUsspBJkNRGGSPXX22We75557zvktNtLP8pkjviAmIJJzXXAPwU7hlVdesYn5jz/+aAup9NF+FLPcHNuXQl0PxQWEJMYPLNx40734Pov9WPLhQ8/C9pbUDimuIF4l6q+8+kWpit16/QO+2Tz2E0Rbvv+MwbgfAOMaxjdt2rQpspjDvYVMRMZsH374oW9tDmLGZKrvCN85xmbUH+F7lcp2qRCFmlMt6jD2zbRGCnMMgloSLXYXisMPP9yuRWx+0mVRkimz77772msoSO8njNHIQGNxh8xkBHP85YNU7DYW7O4YC82ZM8fmFbST882iBOPm+MVgkTkn3Byu2h/pmHKTit36iax1hBAiwBDVPHfuXIvOj/XljY0AwzKDgaKf/vhApCLCLBMtjzp16phYj1hLFDGbR7t27XwT8YHodiYxtNuzSWHymgjsV2DBggXOLxDmiPqljQjeHlwfsVGuTMqDIMaQkkt6LosPZIowkfF8gpkQxC8+jBkzpmAiPrDAxN/0U6TYXOgLmFxhS5LJhB07ED8n4MAkFkGLRRsIUhwJi2EsjNB/ZSvkezZB9MN+g9iCUEd/RSRirIVRrI0Z557rgkwjP0R8rw1hhWwSRE8WQfDETmVvxffUD3sSFhuJwkfQQjzifksUebxwR/tYZEUEJUMiCPcO+gruHZ54S/Zh7DnkPkJ0MG3nfRWivkeqhUcWyJLhjS2CYENB1DifMQsKnpDPQjZZnyxCIvDHBlvwnvH79gsWlhifkUUQuxCVKGPy/ffftzFwIQIY4osyJ4JxMG1KhZ9FT+m3sinMy/2DxV8/wf6ONmdihUhgA8f6Pe4B5jlclwRgsHAThLFConMLzDGwuExnXSSE8B9F5AshREhgQjt79myLtiSKg8Es1jWIt0EHux2ixBlUYxfUokUL3wUDIlfx0KRtnjd7sqhmQAxlMkMEmJ9w28ZTPtG1cPzxxweuwCGT8fjFh1j8WnyYNWuWCTR4ASNuZTOpxgKE9+RFYxYarkUEWAQOj1TXLtkDiF9+2iRgD3bbbbfZ9XneeeeZ2ExmUboIyiZNmrigwrnGSoEIUcTQoBTxZYEMuyrE5tiFVcCii/OPd3C2tSFyCZY6m4Of1wN9L8ImC4Dev9PhV9QlVnB8xoi3COJElSfrI7gHIuxSsBNrNj8pblkE9A/U0ECQji0y6werV682WwzGOyyse5CNRLBF/HXBIolf9UyCnDFJVlnY60LQ95PVy3g2VdYA8BmwYEIRX/oPv2D8TUF3z6c9HbSXRcH4e6CfsEDJoinjsSBF5HN/YEPQZ5Ff5IfmA0e64sRb/f1b6BUS8oUQQpRQmBAwkMaOIixiaFgJ2+JD0ClfvrxNTolU9RYgkl27iEheWryfk3AWbJYtW2Z+3ckyX0Ru4bMnKjT2O4dYG4TCm2GEa5fsOCDKHYER0SPdYhRZSYWGyGqstKif4RU+TtZH0D8jkiHoIe75BQIdWXyJsgji20xGHYIYNULk11z8gi34nvF9i82YTHb9cl/B7oPC3WRVifRQp+bNN990jz76aNqsC8RnsioZq/llBQQslNM3cA2kqzlBX0J0OVsmBakLCQEYXkBQUArgYm1JcEimiyRi85CQL3KJrHWEEEKUSIg+yTQahohbBt8MdkX2IDYTSRvk6OowUa1aNStOSEZJuoLRRONynfttvYWvLQs2pJeXFChEzsTYD2sVwKcZGyuRG8i+oS/jGvarVkqmfP3115Z9gbiZDt4T9zbP+swv8I5GdIvNIrjjjjsS+nhjG4SQ/+6777qw4nf/EAv1bMjiCAp8/lyXFI5Nx3777Wd9HYK+yAyKnHOOqaOCjzwLaIlgnIGFH5+F34W+WYTGGmrUqFHu6quvTttXs0DJgmDQoK/NdC5RqD6CAsJ44zNWVGCNEOFga78bIIQQQvgBkTBErHrekKkgmhwfZM+CJ0gw8CY1HjuCM8880z3++ON+N6lEQ2E+okjzCV7zTFLTRaIigGGlwCTc7+LHRMaRBYPgUlIgujWVf7bYtC/Dh5ktKJYDsbBw5tmlBB2KjJMpkIllGH0JmWl8P/2E+g60d+jQoSbip4IFTCJIgyCCby7qH5LDuAwLuUzHXGSdYXnnF0S19+rVK+PjEdCxY/MLsoRY3Mcrv0GDBlbwHZsq+jg2HpPtQm0Hosex3vKzvUCGDn0VNn0sQiSDGhA33XST9SXUlgozheojKIRNtvHrr7+e978lRC5Zt26dmzRpktV1OOuss2xuz3efbcCAATm1pmMBkbEH9yasuyhaTcZSJgY3jFUuueQSW3gmA5IsfyxGJ0yYsNltkrWOEEIEOOo2G7gxYLnB4Jy0aAZm+Yqs8IRKipPiTRq7L1sYcPuVuk2RYKKN8BJOlrqNgI+X+vz5883P1I/2UogT/9ezzz7bjRs3rshzREl5AwFu6QxezjnnnGg6ehDh/D744IM2WUSwOfXUU32fJOaKVPZMuQL7CwQOskTwOmZwif+y93ex3GFgi086PtK0icm5n0Id1y/XMQWv02URFBcKcS0Uh0kYHtde8ViynwARGnsY/PyxdQiCHZBn5xAG+4EaNWrYxJEIdxbRUl2P3NsQ8/y2JsHah8+fayKdZVhxsLtT/5D6WuC8cC2kO19cM9zb/LSGYhyDdRk2ZpmAmMNihZ+fPRkMCEnUL0q24MeYkrEGwjlR235CWygUO3PmTDvfZOUwdvTsaagjxmIgYjQLmYzbMylMHGQK1UewCFa/fn1b0GXsmCxDQ2wZTQcUr0CraQP8n7fNmDHDbL8SwZw9F2I+FpX0ld7Yj4Vj7E298SrPkS1EFmQi6JOYl3v3MzJy+K7RT0HHjh0tCC/bAugS8oUQIqDERqTRuSfrruOf824ECHvjx4/PS4E12sbfQZBDmIvdly1+TWQY9JNOzo30gQceMCE5ftCMqEEROCYO3HiZ8LB4UWjatm1rn+ULL7xgkfexAxjPxxa/eaIEPA/T+GMLTXFbfAjaxOutt96yz5fBJKIn1zEbBWQRM/j7nFsGnEzCiazzE0QLhELS41999VWLpi3u5PNayNUiLd89bzJSaFhkatWqlQnOqe5v1FdAoEGc9hNEJOp8EKHK9yrIsPjBxJBFaharU12PCGJEsV5zzTVuyJAhvtatYRwRa6WTytefxZ0gFKAPYv8Q9mALCt0uXrzYxObKlSunPF/Tpk1zzZs3d0cddZRvVkvZCvmI4kRb+72Iw3eNDBisaOLbvu+++9q4mH4hKP0dQhrjnjlz5qRcfGjUqJGbOHFiWi/9oFOo8SQF3Bk3InoypiQYjDkFi8CpxhoUoRaZIyE/98yYMcMi8VmI8jbm7atWrcqJkE+wAFoBv4+fTz75pNmREUBAjRH+FgF/l112mWkJ8XAPq127ti2W8Z1ibsxYFiEf60DvvszYi0ytbJCQL4QQAWX06NFuzZo11skzUSWFCyGBwbXnOc0NDJGZFC8mWwh5FLdDxGUwVqlSJfO4JFI/l9AOBtFMsGhn7L5smT59uvOLsWPHWooxt0ImvNywuSEzIUTo58bNcwilFILzy56EwQP+laT2xS4kkM6NXyiCuefZTHoh1wKTHSYyfhHGxYewRVl+8sknllmS7DvEd5KsE7/98T0hn6gWhAGK1mFDgKhPFGUqPBEnjOTzWkhnPZIp9Nl+iEkISIh1iFn0r0zETjjhBLs2YOXKlbZYxYIfCw1EXXK9+ykocQ9gERJLK2wngsynn35qGQ2I45xDhM7465H7Cd9DsiGwvGJhxc/vWxizCILcP4Q52CJMGZObI+TTj/FZJKr/4Oc9mjEv7eK9MH8IInz+jHtZfFiwYIFdA0BwAJ7yjDEuuOCCYuH1XqjxZGzf4AXXBDkIIKxIyM89/yWo68BCKXP4XAj5WHkxr2auyriKbKpYBg0aZJnRtIF7bXzACX3RU089ZX0qi9Pxegx2O4888ogFC2Kjtcsuu2TcNhW7FUKIgEIkM4NSBlhEHCHKJfNv51hWeYlGYgKEjQZiKWLI/fffbxYbuSRRumoYU1jxz0QwuPzyyy3a3mPu3LnRx0SDYv3gic9+QKQMQkt8NgBCF4PpWFGJ98JklgUdP/noo4+iYn185A8kWnxgchZ2Ib+QEOXBIggDViKFEREY1DJg5Lxz7QaF2MEvC2aZWClpopicZIs3RP8gzhL9w32BfssTx1n85V6CII3ASz0Hv+wSEMMR8StUqGAZGomKsnKNsBBNxDgi0z333JPze1k2cD7pXxEXmWwxQQsqLN4hgFIjg7TvevXqRYvZYldEn8HCmieCcW79XjRjjIOQj0DnZREkY+DAgdY/sPgjNgVx2wu2iN8XBohyZHwwfPhwV7169YT3Cy9jct68eSaCeJkHQYbvIJ7KWCwEzb6Ea8XvPiATEMy4HtgY7xClz3VNQFNxEO/9gM89LH2DELFsk+fvvDdnJTgtXsSHHj162FiLCHuCAxmbeDAO97LPidhPFFTZt29fE/KxSn3xxRfNZidTFJEvhBAB5cYbb7SVXqKaiVZMBZHMiAyIod7qM3YmFIdiMSBWmBabwq2QBZFEYijee35PDvDdI4KLwmQeRC2SnYGVCo9jYbBARgabX7DowGQ11uPWmzAgKOKH7UWKk3FCCjTvB3EvzMj3OLcR5J6HZBgp9LXA30KwJcIdT85kmRhEDVEwmXYhhuE1XmgOO+wwW+zDVxShPhW8F7yQeW+Iz4WAbKdkvPTSS5YtR8RquqwSxBE/C5Dzt7HG8ER8r03e9I97BYsqQbBICGMWwZage0V4MyYRa2KtijKNYo6FsTrRnkIkQ31E8eL4/sUrIn/6QP8j8hORq4h8xhdkxMNzzz1nFrCJYDxNbQmyBGPt3bA1xaYKyBpjvJgIiokTrc9iAWObTFFEvhBCBBQmJgi4FK1NB1HMTGq50Xg3LbyHEc+IzhepYQLWpEkT24LIzjvvbCI+orhX9PHtt9+2nw0bNkz4GryD/YTogngbDBYcyBJh8SFWZCS6lYi6H3/80YeWikJApLjIL2S2IG4xoUhlp8SkgQggJhi33XabCbmFhgwo7lnpRHxo2bKl9WexWVP5huygRLVpYveRJcCWCO84v4V8olbbtGljwniihWomptxfgkAYswhEyc2YjK9NlWlsJON6snm4zv2GNhMIRH0isjgRjYHzjg80wtKZZ56ZMyu3XENf5gW4KCJfCJFLFi1aFH2MFWQyeI5xt2djtzmvR8gnmCEbJOQLIURAQSDAky2TATSDV45louuB4Eu0XZA8OMXmwU2ejAEWajp06BBN9/MWIGJB+EBE97swZBgXH8ICRZYQbBEEEORiIb2TxbwpU6ZY30EkM/6N9A9+gse5yC+vvfaafYdOPPHEtMdyDNcERWT9EPIRY7l+M4F+jmO57gsFEerFxWqABVUim9mCDsXeyM4iiyDW+54MwyBmEYQJxhB8j4gazAQiCMnqw5LHL7BOIioyaBmTjMM8u0uuSxYSEJI9G4VEcD8mYIGxmd/3Y2+OQc0PfOYhdiGCuQTPI/KTPUVmcFDu4dhVsHjD4gOZnZ79HpkZ2BWx+IDvdFAK9Aohwsn3MTVPvPqEifCeY+7NHMzre7zXE6yWqs/3Xp9pjRUPCflCCBFQSC9HCMUzFo/QVBCtRKo/EwkPBuWI+LH7CgFtQXBmgI1lihc9lwiEEq/QqUgOFkmI4ESm4QeLiDt58mSLaGUiFouX1nfAAQc4Pwnj4kNYwGMXX0aEOWpjxEKE86xZs6KTcr6HFMTGU724CJMiMUwCMhXHPeEj3parUODbz72NCCYyBFJBVBP9QyFrPhCRL/whTFkEYQLhGasOrO0ygc8Aqzu/65QEMWMSUTtW2CYzhEzDILUxFYy5aCtiPWMFgitYjPAEJa4Rxgx8/4jUZ8Hkww8/9P17hx0bGQJeu2NhrkHGDguA9913ny1CkNUjhMgPGzZssC0W5qVsxYG1MYGQXkBaImKf4zWekO+9PtVrY5/PNvBSQr4QQgQUoqbwBu7evbv5CG+33XYJj2OShajHZOfoo4+O7sfChIEtE7dCQeTvHXfcYb7WmaQZS1jMXNjAaonitlhieJYNWGnER2QTOZVILC80YVx8CAv4Lnp2E7HQTyDaE/nHc0SAsHjCvieffFIRrMUcIpWxRkDMIIoyFRzDpAHxyQ+aNWtmi74UAON6TpaNQ0QwRSzp0/BMF9n5+WeD3zZAYc0iCBPZlsbzq5Qe9y3uX8k8ieNBtCUS0q973PLly12YwFKNqHsCfch2oT9OBGI+nwHHYns1ZMgQ5xcsOnMPIMCJBWuvmHv84gNjZdpLNgeBDBRUF7m/hwTpfhEWguopv7mQ/Rtb3BXS+dITJJFNQdd4sLDxfOdLOhLyhRAioPTu3duE/DfffNPVr1/fUs5JcWZQygCKKLUZM2a44cOHR33YOCZW1EtlY5JrHnjgATd48GB7TGV3JgaIRER9ii2D1HFEcIrgzJkzxwQ7iusQnRgL1hNMdrhO8JX2kzAuPoQFvBQhXqx9+umn7Tz26dPHJupA34EQynN+CvkIM5uDFh8yB1GDPqJLly5mrYRFSSIQQjiGa8UPb2nv/saEjuwRCpxy7+Ke4YkyLESTrcXC8NKlS20BELsVkbmffzaL5UHw8xfBAguTZAEk+YYsPoJQMhXyr776asse0P0iMyZOnGjfdyxqkon4QCQ+xxB8QYaMn0I+xYW5d5EJgZjnFaGMF6RvvPFGE/qI2r/lllvcgw8+6Et7i8s9JNF9RPcLAX379rXi87EUl2h8KFu2rPPAJhZrtETwXKLXeI9jn0/1+tjXZoLUFSGECCiIsfjAXnXVVVYAxbMniccbUN15552ucePG0f1EZlIEl/ToQsBgmXbQzkcffTSwxbHCCueT4m9sySBKicWfIBDGxYewQFFgUjHxXYyFaDTo3LlzdB9F9RDyP/74Y+cn9AvZZuBwfJiFmdWrVxc06+imm26yyFQ+65o1a1q0O0JMfMQiwgzXEFHw/fr1c35QrVo1N3r0aLs+Eeq7du2a9P6GmMixvEZk5+f/0ksvme0enzULf1gaedcCWRl//fWX9SOnnXaa8xsyRLg+mcxy3aZi2rRpFoHNQlRYvbAL3T9kA770P/30U/R68YOwZA8ANoLZwPeRMRG2mX54/LNQynjxrLPOSnssVjaIc5laMuULxrZ8X5hfJBLxPQ488EA7hjow1I0JM4XqI9LVhMGKCYslrhsCBKi9JMTm2OiQrb0l108h7b0qxGTz0P8lE/K9vpHnY8cj3uuxGWaslcwn33t9ttlDEvKFECLAYJnD5BuBhglu/ETFi6gktS1eII1Pd8s32CQACwoS8UUYFx/CFCkZPyAktR9xFq9eMmJia20gGBDJ5ie0K91EEcHRa/Puu+/uisP1X0hxCQGDSEuK/SHCkf3CFg9tQixlkS2VIJJviPLE9/6GG26wzLP4c8X5I7KS9xAEr+NsFxI8se6QQw6x93HGGWfkRbRL5uePvRbfK6LmyNKJn4QinBNhO2jQIFtQHTt2rPMT/j5WbERXpxPyyeIi04uN7K8wku/+gUUctli4HlLZaNAe+mHs2OivY4NDggw1NLKpD5KP+gObI7jSRxART0ZSo0aNXKFg8Q5hKZOxOn0W7fS7QC+iNm3IxGKNYwh2YEwUZgo1hsikJgzt4DgCBBBTCTQTIlvC5KFfq1at6GOcDwiQSYTnihBf7yn+9UcccUTK1zNWzIqIEEKIUPDLL79Epk6dGnn22Wdt4zH7gsI+++wT2WWXXfxuhhC+su2220a23nrrvP6Nvfbay/7Gr7/+Gt33+OOPR7baaqtIu3btNjm+bNmykV133TUSdL744ovIhRdeGNlxxx0j48aNi4SdvffeO+/XQiJWrlwZueyyyyK77babXROxG/t47ttvv40EiTVr1kSmTZsWvb/xmH1BIvY88rnGn9tkz/FvtkMOOSTy2WefFaStjzzyiP3Nm2++Oe2xHMOxjz76aMRPTjzxRGvHBx98kPbY+fPn27lt2bJlJKzku38YMGBA2ms11bbnnntGlixZEvED/j5jykyYM2eOHV+9evWIX2zO+Y3dttlmm8jdd99dsPa2bt3arotMPl+OoY3nnHNOxE8qVqwYKVeuXMbHM+6pVKlSJMz4NYZIxZ133mltmjBhgt9NESIhVapUYfUr0r9//8iWsHHjxkjlypXtd3Xq1CnhMX/88Udkp512smNuuummTZ5jPsNzycZiy5cvt+fZRo4cmVX7tuJ/2Un/QgghxKYQbfjqq69aUdPiEE0bVLCpwVeaFFcis1N5Wsq/svDg64ut1X///Ze3v4FFEQVChw4datGrFJcmcnLu3Llmm4L/uQcRadSqIJIEi64wgDXQU089Ze/n0EMPdWGlENdCOpYtW2ZtgD333LNItobIDux9iFbGq5lUab5zROLGWhdRt4ZoZopIkknHdxNLAiyPKNxbqVIlsz4iUj+fNGjQwKxzyMRJ57tKZD7tJfuP75xfcG1is0akcLroZs4r0blYv3z11VcujOS7fyAa/8UXXyxy/XLO4ovNx0cAk7lBJGHr1q3zfp3Gto3Ng+8REfapajx52QPc1ziH3Dcefvhh5xeMfynOzP2WGiCJ+oZhw4ZZZDk1Y3hvCxYssKwYrKI49/Pnz7e6NvmGPokMADbsZ5JFyJKpw3iDPu3dd98tSNtS2fM9+eSTdo7SFXPn/R155JH2eTzxxBMurARhDJHofkFGB/c/z85RiCBRtWpVK3idrvBuJmA/SVYoGT7ca/jdsTAPI+ORzKXPPvvM1ahRo8jz2Ecyn+G7TH2zeGsgrE+xJmacRpvjLVNTkpXsL4QQQiRh1qxZFo185ZVX+t2UYgnRyocffng0utPbYiM+4/cFhdmzZ0eGDBkS6dGjh0U1dOzYMeGWLOIhTBQigoqIZT5jvm8tWrSIHHbYYfZvotVio/SBqCmeIwIvLKxYscLafO6550bCTBCj6cTmQ3TVwQcfHNl9990j06dPT3rc22+/Hdljjz0idevWjaxbty4a1brvvvva9XDrrbfmva0777yzZV9kChk7vMZPSpUqZectU/gcSpcuHQkrhe4fsolyLzRe9sDmbgcddFDk+++/9639ZJFw/TZv3jyyfv36pMdt2LDBjiFKc+HChdH9p5xyir2PQo6BXnrppUj58uXt3BEJumzZssjff/9tG4/ZR39Hpu3LL78c8ZulS5dalH29evUiP/30U9Ljfv75ZzuG/ozXhJmgjiG4Jrh2hAgCv/zyS+THH3+MbmTiIHP37t27yP61a9du8lqi9r2IePq9eMgM5XvI8/SH7733XrQvf+CBByLbb7+9PUemayK+/vrrSJkyZeyYxo0b21zeG08OHDjQ+n2eY46cLYrIF0KIgEP03v33318kCjsZRLH9+++/zi8ee+wx87jt2LGju+666zZZuRabx88//2yRyUR1Ee3VpEkT99xzz1l0HVFzZEHMmzfPImXIhjjllFPsdX5HIlHEEp/mDz74IGGB5kT7ghR5FOQIKnyOY31N8bAlA4NCUrFQ7Pr55593I0aMsO9mWCBCmIhMru2wEsRoOrH53HjjjeYnjz97uiKRROCfffbZFpXvRYSNGzfOvp9EiuY78p2o6nXr1tn1x3cpFUTtk61BxBle435BEUUK2NLudLUEGOdQS4M2kx0RRgrdP7z99tvWpx599NFb9Hu4/smayGUhctpGxHpsjSeKBpJxlkn2ANHvfhSN9SDLYcKECRZxGR+RmaiQMBly1DJ5+umnbR/ZM/gnU/yWcVO+ydW5KuSc49tvv7V+85JLLrEC6KmKuf/zzz+WnXHUUUclrdkTBoI4huB+wTyDvpf+WoigROCngwyd+HoQjM+8moJksCbSLeifTzrpJJuLA9HzZFjSzwCFtV9++eWkmU3UgTvnnHNsbANE5fPd8b7XaCbM37KtsyIhXwghAsx9993nevXqZZ19Jt11EIRQ0oQprkdbEBBSpfVzTFjT4gsJqX233XabTUqmTp1qA2gmsXvvvbf7/vvv7RgWeLB8uOOOO9yll17qHnjgAV/bHNbFhzBNvGbPnm1WS9gfUDAvvhgnafHdu3e3wSaCYlhsVRggI+IwWUcwCitBnIT7gXddUtiWorax+7LB7/sFhYGZLNLXpisSyWfONcx3jnRrYBKH8MiW7+LTWGZghdGjR4+0RQmvuuoqd88995jAS5/iF9gBYTUyadIkmxinAmuxli1bmtUHNhphJKz9A+3Gsi2fAm78+CboVKhQwe5VmS4qYZ/AWCj2/TGuo49LFayTKzIpcpsJhZxzhHHxoTj2EV27drWgLQrQI3AKUdyFfMASDX0DC7UVK1ZY8BSLyPxOAqvS9amMXXn9lClTzEIQbYTvEAuTzIk3h20361VCCCHyDiLnFVdcEfVQQ+jEqxJxHEEUIfStt96yiB6EASJuGfT5BQNNIrSeffZZ+zcLD4i53gp2IrJdfS6p4GHKubr99tttspcIohMZJCDeci0QqUQEgF8gHiHixy4+cN0SiYA/bPziA5NavxcfwsYxxxxjWzKIvnzkkUdc2GAxBw9sL9JOJBc1EJe92gebI3QUQtRYvny5/WTiE78vG/y+XxARSj+ViQjGZ8GxsZNL+kAW3Vi8zDdEq7LId++997rffvvNFoPjF0+YtN5yyy3mTc65ZZzhJ4xv8L/GX5xFhWRBAESycQxt5jWi8OQ7DpBr088I+2xBwOd6TJRtGA/3Nhar2WKhv9iwYYMrBGH0Ns/VNacY1k3xxuTJ4FpFvJw4caJlnXCNE0UsRBBYvhnjyVghPxMffQLS7rzzTts2B7Ktcj0fU0S+EEIElPPPP98988wz7sorr4zeOBJFKX300UeW8oWYj4VJusJ2+WL48OE2uQaKINEmbnzbbpt6zZjVbJEaxG9EbwbT3vnkWmBR56efftokaoDosKZNm9rKv18QKYktFItNLCqkirIjIpTFBxaB/Fx8KK4RVEEAETSTiSL2BCNHjrQsArKRWOQJK/m8FjwxGSHfi/jenCjLQkRUekUs6ccoih67L1v8vF/sscceFkn/xRdf2KQsFV9++aVZbMT20Uy5WMxgHxFZ+caz3/KERQrtxtpQ8H3z2sUifHykWqHh3B5wwAFWwJSf2Bi1aNHCBE4g4plo/euvv94+AxZFsCHBkieMhPVeEdZ25xP6A8QkhM7TTjst5bFYMNAPkq3jZRhx/2Ohr0qVKraIITYlk4jbTOE8h4FCfdcYO2SyUO7JhkG4XwhR0lFEvhBCBBRS3BlYeVH5HvHrr9iXEHWH3yaiFxHOfuD5u2GrQ4V3kTsQNUnFjl0UYdKXKLKTxRMEs4ULFzo/YYLK9cCiTixkDMRDPQWEfKIVwi7k+w0TvgcffNAWcZicnXrqqe7iiy/2u1lZ2frQxx1yyCHmSS5SR1TGZugENcoykfgexgVcrF/wOsWuCjEO66dEkOGApQ39X6wfOTVu6MsLlTnHghjjA8YEiOQspsUvqHFfIVo/fpzhByxwELyAyIlQT40BorKxXgMWRDybQRZEyPAKq4gvMgM7Kmw8sFJCyGUxJ9Zei2wTL2Mxvj5MIUG8x56qS5cudr02bNgw4XHYXWFNQntjBX8vq2pzLMf8hO8o2QhkXeabsIjvYYSaAamEfOYe3Cvq1q1r3zMChYQQ/qKIfCGECChEoTGw8oqjeIMpIu7jfTgRB/DjJYpt0aJFPrT2/wQlRFomVti8iNyBtzQRnLHeqV4EGBGJsZM/rgWuHa6V+NTtQl8PXAd46XpwjdK+ROnjiDgIY2QUhJlCRFAh0CEYMImmgGaionvgpfmzOOJZXvlFptHiXNdMFPv06RP6fkSRq8WLd955J5pddPDBB7trr73WHXvssZYBxfeMTCMKdpKd5t2H+be3mEnRegR+LGyof1Mo6G+pTYCXPNcjUNz28MMPdyeccEIRy6Mg8OGHH7qePXsm9evnnCOaIiqFmbD2D4VqN9mmp59+ui2AeXJFfAaRt+hLAVkWr/0SGLGQrFOnjo3TuNdxjVIXKL5voA/BWodzSLCFtxDl1akgCIaMk7AQxmuYYuN8XmGozxXG8yuEKAyKyBdCiIDiFb6KBRH/999/t4l5bHV0BFCOz2XqabYQrUG0VNjFtyDipVszoa1YsaLtO+KII0zIf+qpp6yQqQfprkHwF2cCG28fQbYAbf766683WXzguk5nwyT+D69g6HnnnVdkP0LB888/b4/xzmdBh0i58ePHmziOKOIX6ewCvIivZDUgRPEC2xesUTL1G0U0R3wh88svEOeo/YHoRgRthw4dEh7nLaDx3mIzkhBk+A62adOmgK12NlZo1aqVbWGAAnAzZ840eyJ8/qkHxPnElo1I53S2RiL88F2nLhRjiMMOO8zuX2SWxGchcl2QcYatI1kyfgn5CPJkRLG4ziIe9+K33367yDHeYgQLD9ynY7NJ6BeOO+44y/oR+QVLMW9BsyRC9ivztCBkagohtgAi8oUQQgSP2rVrR7bbbrvIP//8E9132GGHRbbeeuvIzJkzixz73XffRbbaaqtImTJlIn7Rtm1ba9vKlSt9a0NxpX///nZun3zyyei+V1991T5zrpFu3bpFHnnkkcjll18e2X777e3YXr16+drmpk2bWjtWrFgR3demTRvbN3DgwCLH0nbeS7Vq1SJhZ++997b3mE8OPPBA+xs//vhjkf0dO3a089i1a9fovltuucX2nXHGGXltk/DnWsiWX375JbJmzRq/m2HX5D777JPx8VWrVg3MuZw9e3akWbNm1h7eR+zGPp6bNWuW380UASeI/UNQ2n3DDTfY96l58+aR//77L+XfXbx4sR175JFHRvyG8fpTTz0VOf300yOVKlWKlCpVyjYes48x3N9//x0pLoTxGg5Tm/PRVr4rFSpU2OT+etRRR+X07wgh8kv2VbGEEEIUhJo1a1o65SeffBLdR8QOUT1EJnm2KdjZkIYOtWvX9q29eOMT+UfkpMgtWKPgYRnrQ0q0GnUR8GN+6KGH3KWXXmre6ES3UwAzNkrfD7xIVCLTPC644AK7fkkfv/zyy92jjz5qftNsRNZ5hTBFavCK5rvmeUd7UFiY8+j1B8B5Bmw1RGEhg6qQvr7YN4wZM8ZNnjx5k+eIIMdKhWsGGyu+n/iQh4UgOYESFc53je8hP/F1Z4vdR0aMEEHqH8LEK6+8YveyoUOHprVlO/DAAy0rNQhWKWSWnX/++e7FF1+0ehRkqbLxmH3t27dPWltDiEL1EWTtxkI2d3z9FCFEsJFHvhBCBBQsBPDBHjBgQFSUxZ4Cb17Ee2womMAgxlDIDhBxmET4BQISdh9HHXWUCfp4UcpqJ39wC6cQHD7ppAtT5LZFixbu6quvtsd+gnBIoVUWn5544onofq4P/NpjbaN4HyxcYaPgd7u3FCbpTJLy6Wm6/fbbW70B73sPWBBgp4R9UbylERYmLPz5WTOhJFJof1sWyPr37282E4MHD47uR0hicS/Waxqw6cIGoly5cq7QIM5hlcLiQyZwvdNnJCrwLUQYCav/dSHajYBJkAI1oryxQqq/u8cee1h9JsbGonCE8RoOU5vz0VbG2IwF+W5RTHxz7sdCCP+RGa0QQgSU1q1bm/CC17jHfvvt555++mnXsWNHE/Hefffd6CAM8cZPEd8bEHoe3p6PdyqYoDFZE5sH54/FHraggQ9sIl/0sWPHWsHIIC4+5AIinvPtv8p54vvPRMzzlPf8eIkWTkQhC1qyoOi10/Pl9/Zly4UXXpjTthVniASHeA/20aNH23cNT2YEfmonXHfdde67776zAqxkUwUVxDkWK7nWKSYpijcsNHG9kuFAMVD6uVRjBI0hiicshhPdHl8nKtk188cffyhoRIgMx+bz5s2zOWPnzp1tkRxYLGCckE2ML5nCQgh/UES+EEKEECa3r7/+elQIPfHEE93+++/va5vSpT8ngklaGKJihAhStBcLIe+8845l7XgFN08++WT3xhtvuLvuuquItQ5CKNk7NWrUcJ9//rkrVF/Ad5uMoc8++6zIvmwIu0hX6Mi/qlWr2j0BUQux3oP7A7ZcWHB5i35cKy1btrTsKW9BOJ8MHDjQLOHiC8JmA9lp/fr1y0PrRBDYsGGDWcZRNDTT6WmYxxBhigwudLu5X2GVQ3bZnnvumfLvzp8/34rEHnrooe6DDz5wfkN/6i1CYXWYCr8tEEviNRymNuejrWTIUug2Piu2pI3PhAg7isgXQogQgscxXptBgsm3KAw//vijeVoSpXrsscf63RxRYNq1a2cR+PjfE1m1atUqs7XCN//cc88tcqwn0h5wwAEFax9RWkzyYrOJvH0if+DPjk1OrIhPZCuWVZz7s88+O7r/hBNOsMWVJUuWFKx9seIs7clUrMVKivoaZBEUimrVqtlPFsi97DJvXzbwPoPg3R0GhgwZ4qZNm2aPzzrrLMvmoQ8hMluULLDk43uD6NinT5+0i4R8z+jT/M6I6tq1q43NMiXsQr4IH15G97Bhw9zq1auj+7ON7VUssBD+opGREEKInNCkSRO/m1Dsefnlly0q9eOPP04YEfPrr7+ayAtY1wTJqkaLD7mDaKrnn3/ehINHHnkkGk2FRzo+p7GMHz/enivk93P58uUZ7RO5hai9+CJ2FEvnO0chdDIzPBDx+ffvv/9ekLaROYI4B1yvTZs2tQXpCRMmJH0NbWRhgujc2MWJQuBdr7GWVJtzDWvxKnO82imIm9R6EMGExeJ89xtXXHGFGzlypLv99tvdYYcd5po3b77JMYiQvXr1cpMmTbJFbK+wux+QFUBNIM+jHxtMLUKJoIKVJRuL/3/++addr9SZ4DoWQoQD3V2EEEKIEIC39Q033JAyCgZhDsELwR+hF8HXb8K8+BBUqEdBBD4+0kRbU8wWa51jjjmmyHGIClgTsHCCjYoo3pCGz2IZtSmYmHsWOslqJ2DBg5heCKpUqWJbbIYGhZmDugDsFeiO7Y9ii3aL3MN1y/0BgUkEd3H9nnvucYXw8UbEJwvnpJNOcvXq1TObODjvvPOs3e+//37UuoY2+enXfcstt9j9lqLizz33nKtVq5ZvbREim5pObN64MvYeLYQINvLIF0IIkRe4vfz88882SVRBpC1j7ty5JtIS3TV06FCzmWCim8g7kwjXc845x6LmiHAM2uJDIk/jM8880wR/osuDsPhQUvxXRfG6Fih2znee/oFoVvrfI4880n377bfWL5xxxhlFRNPq1asHxldaCLzQ+a5w3ZYE/LpXhGlxnTow11xzTVTEj7flYhH77rvv9r0oOmIo542IZjIISgphHO+Eqc2FaitWjVjYHX300Xn9O0KI3JF9ZUIhhBAiBYhC+Nsy+SPiMt5XmMnOJZdc4i699FL3119/+dbOMOFFwPXt29dSzlNF0XoRrh9++KHze/EBEZ/FBwqwksLL9ZAI6j0wMZ8yZUrB2ykKA9GKFADMpOAux3BsukKBoij0DfDkk0+awFWpUiWLXCU6H9uHWLzvWv369X1pqxDxHHHEESbY4t8s8re4zsL5Rx99ZPdcb0uU2UcfQWafn7CwTwFvsmE6d+5smWcU777ooots4Z8FSb9FfCBgpXTp0iVKxAfFgxYPmDdIxBciXMhaRwghRM5AQGKylUqAY5JIETOK4+KZ3LZt24K2MYzMnj3bfnbv3j2jyLAyZcq477//3gVp8SEVQVl8CCMskPBd8iwSglo8j8hOfNK7dOniHnrooZTH3nbbbe7pp592Tz31VDQyVKSH6Hsi8Xv27OnWrl1r+7B6IEo/3qt5zJgx9vP44493QYCow5UrV5pfbypxSPU1ii/4nWMZxsIvViUif4vr8Zl9iRbXX3rpJRPz/c6S22mnnUy4ZwsqWJKQ+VTSmDhxYrQuQFjQ4oMQojggIV8IIURO+Oyzz0ykQ8RHSCJKqkWLFgnT5JmQTZs2zYqUSchPDxPtsmXLRr0s00HhN0/I84swLj6ECawQ+vTp4x544IEiE+lYIZ/sFzJiyHwhyr1q1ao+tfb/LJ8gk+hJhKOxY8daNKiE/Oygb8VWa9GiRRaVj30ORWNj4Xrp2rWr9dennHKK85P77rvPjRgxwhZ30xFvAeIXLJg99thjVn+ABTS+X7HtJ6r8tddes/bq+s2cZs2auSFDhtjiLzYPeOUT5SxygxbX80fr1q3doEGD3DvvvBOKxUbGlCzwUuA0XR/FvZhxPLUJ4segYYzifu+990Jhq5MvKDTvLT55dV+8fdnA/W3q1Kk5b58QIjMk5AshhMgJd955pwlEl19+uXmWesWTkk3YgWJlIj2I3AjzTD6SndPYApZr1qyxCZqfhHHxIUxQBwGvYyCqcsmSJZuInGS/MPl+8MEHrQDftdde61NrnQnLRIISNZ4Orx7EJ598UpC2FTewxcCmJBmIpKkWVOjL6Ufynd3BIu748eMzjpAMQiQlliSnn366ZQ947UHQiKVcuXLu1ltvte8kdmKbI5KURLzzxH0DD3eEUfo2/p0MiUmZo8X1/EFRXrLOGP/OmDHD7bbbbi7IkO3Wu3dv+56lg1oKw4cPt8cE6fgF84tVq1bZ/Wvvvfcu8hz3K94LGSQsXGMld/3119u9MJ6KFSu6kgzXp5etF78vG+Lve0KIwiIhXwghRE7A3oOBHVHC6ahQoYINsPE+Fek58MAD3bx588w3vF69eimPffHFF93GjRutiKWfhHHxISwQSYftASLh66+/bteEVxQtkeCPkM/3008hH0GIuhnxFi+J2G677ezYH374wYWZIAjPm8Mdd9xh11I+hXyuYRaX+JwpaNmyZUvrMxBoEMkRbBBlsFmib0Ak89sGiKhUMhi4LvHCJpL15ptv3mQBkvsgWSUIZSy2ScjPjHgxaf369WkX+8MsJhW6fwjj4vqXX35p/QRjHzLMUtk2+rmoQ20o7KAQ8ll8IuPpqKOOSrkIBX5F73tBAIwP0sGi77Bhw2zM4aeQTxZUjx49LOsMC7lY6JdnzZoV/U5xvcycOTM6Lwkr+egj+vfvbz9j+wFvnxAiPEjIF0IIkTOhDiEm02gXUuaxIBDpOe2008zflghFJrXJQAAjMoyJC6nefhLGxYewiDOkQ/MZI7imO7dEwHMs1ld+QhRdpqIQ55DFHQT9MFPSU/hTMWrUKLsuEb8ojh4LEZUs9iLY0I9h83HGGWeYqLv//vv71ma82xHxySjDVod28h1MdF0jLCHkv/vuu760NYyUNDGp0P1D2BbXiajm+8XYIJP7qp+CLfWeYv8+C5BBtgrDCoyFmtio7GTUqlXLlSpVKiP7s3xCnwtkGcYvSiDa0x/zHEFC1IBhH3W7glAMOUh9RKJ+tqT1vUIUByTkCyGEyAlMCoigY8KVbkK1YcMGmyRi/SHSQyr8/fffbz7jTEpiI6uJUFu+fLl75ZVXzF/4xx9/NBHd78JwYVx8yAWId4gg+cTzLc7kfLFgRtRzomj9QrLffvvZog7CZjpf3Tlz5lgf4adoGysSxHqhx0Z8UpgV2wGu3UTvqaSn8GdyDVNUMxZEu/hCl/joY7dE//boo486v6CP5bOmUGh83YF46INZiPJb/AoTYRSTwtQ/hGlxndovgwcPjt47WDwjAy2TjK6wLOL7mbHFeAALsGwWgVavXu38ZPHixfaTbKhYnn766Wg2sLeAUr9+fdetWzd7zm8hP0x9hBAiRESEEEKIHFCvXr3I1ltvHfn888+j+/bee2/bF89LL70U2WqrrSLHHXdcgVsZXj788MPInnvuaeeNc5po47l99923yGfgF2vXro1UrFjR2nXBBRdEPvnkk+j18Pfff0e++OKLyPDhw6Pv6aCDDrL9QeC///6LzJ8/PzJ+/PjI6NGjI0Fj++23j+yyyy5F9iX7rsHOO+8c2XHHHSN+0rt3b/ucjz322Mg///yT9Diea9y4sb2XXr16Rfzi22+/jRx++OFFvlvx55frtXLlyrZ/7ty5keJCqmspl9cw12X8vp122inh8WXKlIlUrVo14ie0rVSpUpGNGzdmdK523333yHbbbVfAFopCEcb+YdCgQdbOc845J+X1u2LFChtHsP/RRx/1oaWRSK1atezvd+rUye7HIrfQN2277baRv/76K+2xHMOxu+66a8RPypcvn/D+wBiSa+Xrr7+O7vvjjz/sWuf69osw9hFCiPCQOpxECCGEyJCTTz7ZIoy8QrfJILXbi8AmaltkBpFxRO507NjRsh8417Eb0Z8dOnSwVFwi7/yGSFoiWPHhpLBa3bp1o1HhpGmT0k30OhkE2GgQARgEK5V7773X/OYbNGjg2rRpY+c7Fnx6STWn/X5FqJHJgi0VGTDpwArk999/t2hGP8Fbl88dH9vmzZtHI7LjfYaJvOQYrvErrrjCl7YSJXfiiSealcu+++5rvsdEJMbD9YoXOt+/iRMn+tLWsEIxyPjMrfLly7t169ZZtlYi8M33EyKUiQjOxMLDs4dKdN2IcBPW/oHMPtrrZfZRgDw2s2/p0qVW6JqIZ6wSa9So4VtmH974QHvSZb+I7MHHn/7s1VdfTXss4zjsXTKx4cn39y7+WiAblTFkpUqVLHPDg+8j95NffvnFh5aGt4/w7rNkADP2xSKOjcfs8/seLISIwe+VBCGEEMWDH3/80SJmiCy58cYbI7/++muRaK9169ZFJkyYYJHXRKZUqFDBomZE9qxfvz4ye/Zsixh/9tlnIzNmzIj8+eefkSDyww8/WFQdEeF87rHbDjvsEOnYsaMdEwS6desWjZwiWnibbbZJGG1LhgH77733Xl/a2bJlS/v7r7/+etrI4FtvvdXeT7t27SJ+M2bMmCIZJPQBRx99tG08jo1ae/LJJ31r55AhQ6wdhx12WLSPSnZ+P/roIzu2UaNGkeJCISLyvUhFMnc8mjRpYvteeOGFIse+//77do79jgg94IADrH2rV69Oe67mzZtnbSZTTRQvwtw/hCWzb5999tkk60zkDrIh+ZyrVKkS+e6775Iet3LlymjE+NChQyN+stdee1k7mFt4PP7440nHN2XLlvXtnhHGPoLsgKuvvtoy42L7gti+gufIlNywYYOvbRVC/F8UnxBCCJETpkyZEildunR0wEc6Lo+ZlGEx4A0MGWDPmTPH7+aKAhL0xYdJkybZtVmuXLnIiy++mHLi5R17+umn+9DSSOSpp56KThI9ITRRW2kniyXsnzx5ciQIvPrqq5H99ttvk0Udb6tevbq120+OPPJIO2dvv/12dF+ya+Hff/+1fg5xrLhQCCG/a9eu9jemTZsW3YdQxDVQrVo1s7ZCWFiwYEHUZqNVq1YRP+nSpYu1Y/DgwWnP1cknn2z7r7322gK3MvwgbHGua9asaWOFZIIzG4uthSbs/UMYFte5t/LZEiASNoJuzQeMvSpVqmTX7B577BG58847ze4QgZbNsz7kOa4LjvU78MYLYBg2bFj0PDds2ND2PfLII0WO/d///mftPvjgg31pa9j6CM6ld345b8zjsDhs27atbTxmnyfqn3TSSUUs5oQQhUdCvhBCiJyycOHCSNOmTZMKdccff3xk0aJFfjdTiE2EAyYod999d9qJ15o1a6KCox8wgcJrnjYccsghlhlA5BltffPNN21Si+iJEMIxp512WiRIMHFl0W/gwIGRyy67zDIhbr755shbb70VCD9ksjFYeKSdmXqhs3BZXCiEkO/VSeHzj6+rER8tzL85v357CHPf4jvFYh/Xb6JztWrVqsh5551nbcZP/5tvvvGxxeGDvix20T/dlu/rtDj3D0FeXJ81a5aJm1deeWUkTIwYMSLq2e5tsfzyyy92zz7wwAOtr/ATMp08oT5VdgbHkMnhN1yjtIfrokWLFhbI4AVfxEbpA9m/PNe6dWtf2hq2PuK+++6LXgf9+vWL/P7775scw/25f//+0WuD1wgh/ENCvhBCiLywfPnyyNixYyN33HGHRTCOGjUqsnTpUr+bFUqYpBDZ88EHH2zy3Pfff2+TFSYzWBu1b9++iPWDyAxvkhU7gUlXQJYIJb9AEMCKJN0k/IQTTihiXyLSgwDL9ymWVNcC10H88WGmEEI+RY0RDolcjYVIUKIsY8Va7B/I5AgCnmUC5wchiahmHmPtQLu9DBiOefjhh/1ubqhgocbru7p37x7NfNptt90iU6dOtfEE0eKcY8TFZ555xq6hQhPW/gG7p2y55ZZbIn5BoV3EzUsuuSSybNmySNAJizVffGFjxoyc50TZGRdddJHZ6wQFvv+xbaT/ffrppzc57txzz/VVbA5bH8G9jLbddtttaY/lGM59/fr1C9I2IURiJOQLIYQQAYdUYk/ciBfDPNuJ2AhF9vntYRm2xQcmsvGevKkmXhzLZM1PiF7Hdx5Bn7Z41wCRYMccc4yl9Qchwj1sIBzHe/EmuxaI0vYyI4oLhRDyMxGYsF/79NNPA5fC/9hjj1m/FR8Z7j2mbwiqpUaQ8TIZrrrqqug+/o01XyKf9/333z9h5Gi+CWv/wOIHC2WZcvvtt/veDxAE4n2/iFrGli3Z5leGXNis+RJBJgbjtXHjxkWee+65yDvvvGN1rYII2RrYsJF5+NVXX23yPGNfrLk6dOgQ+frrr31pY9j6iDJlylimQyZBHxzDsbxGCOEfEvKFEEKIgHPiiSfaBIA0+ERe6UTzUGCYSBmv4LDf0V5hW3xAJCCCDl/udBOvn3/+2fZjAxIUEOzxEyZdn3MsNp/zzz/fPt+HHnoo7bVw4YUXJrzOw0wQhPygg5hBlhmC0SmnnGJWDwhHRBFjvSU2X/wim8+D+wPXYzwIjjyHDUShCWv/wPlC8M7E0oVMSr+siwBLEhZ2MrVY8rOtYbPmE/knbH0E1oxkPmVzvN/F54Uo6WzrhBBCCBFovvzyS/tZu3btIvufe+45t9VWW7mBAwe6a665xvbtv//+rm3btu7555933bt3d37x5ptv2s927doV2T9u3Dj36aefuh133NH16tXLft5xxx3us88+c4888ohvbebcvv32227evHmuUaNGKY995plnCIRwhx9+uAsKW2+9tdt9991dEOjUqVNOfg/X9uOPP+4KTbdu3dzTTz/tBgwY4I455hhXq1atTY75+++/Xf/+/d2TTz5p5/6yyy5zxQWubZGanXbayV100UW2idywevVqt8MOO7gqVapE9/HdWr9+/SbHnnnmmW677bZzL7zwgrv55psL2s6w9g+nnXaae/nll12LFi3cO++848qWLZvwuLvvvttde+211v/y2A/4u9xnoXHjxu6kk05ye+21l9t222BKF4wbMr337bzzzq5cuXJu1apVBWiZ8IOw9RG0b/bs2e7nn392u+22W8pjOWbNmjX2vRRC+IjfKwlCCCGKD1ggPPHEExZBTvQJdiXJ/LvZiIAW6SFdO5F/phd9j1WNB1HtXhq6nxBtFu85DxReZT8Rf/HRlVjE+MX9999vbWjWrFnUjiZRBNVHH30UPe+02w86d+4cmTlzZiSoxFuNZLt5r/UzwrJnz57WBtLHsYHaaaedrD19+/a1SFGvoCHHUACuOEE2zYABA/xuhihhJIoK9fpaCrPGw3N8L/0gjP3DX3/9Fa0/cfzxxxfJPost1ur1vXfeeWfEL2rWrGltuOGGGyJhIIzWfB7YH15zzTWR4447LnLwwQfbxuPevXsntEYUxa+P8MbgV1xxRdpjOYZjsWASQvjHVvzPz4UEIYQQxYMNGza4U045xU2fPj3jiE4ivv7777+8ty3sEKW4/fbbu7Vr10b3LVmyxNWsWdPVqFHDff7550WOJzKbY/lM/IKoM/jtt9+K7N9ll13c77//7lauXOn22WefaGQSkfm77rqr+/HHH31p7z///OPq1avnFi9e7I477jh31VVXWXQd0Uec3+XLl7tXXnnFIsT/+usvd/TRR7tZs2bZNVxoiN7i71atWtVdcMEFrn379paJERQ6dOiQs/PyxBNPOD+gD7vpppvc4MGDo31U7HvieaJD+/XrZ5tITrVq1XLyezj/X331lfMb2kA21MKFC90vv/xifUeqNk+dOrWg7QsrderUsb523bp10chrsp4+/PBDy5aKzZT6/vvvXcWKFV3p0qXdH3/8UfC2hrV/+PXXXy1CmPFD69at7Tr2ePDBB93ll19uj4cMGeJ69+7tWzv5XBkXMH4oU6aMCzp77LGHnVvGBmSKAOOb//3vf5uMcekzOL5ChQpuxYoVPrXYuT///NN16dLFsiQhftzuXc9keJIt6ffn0LRp06xf42f/G7Y+4rrrrrPs2AsvvNDaE3/fXrZsmbvlllvc6NGjLWNn0KBBvrVVCOGchHwhhBA5gfR20kjhrLPOcqeffrpNVNKlQjdp0qRALQwvlSpVMuHiu+++c3vvvbftu//++12PHj1MNB05cmSR45lwsTGJ9IswLj588803ZjtAO5MJ0QybsOF54403op9FoTn22GMtDZq2eO086qijzObj3HPPtcUSkbtrYtSoUXa++Q4yIedzRwxjoSdXInWuYaFszpw59hPBJtVwH7Eh3wtPuSAIC7/YmN16661u48aNGS1YB6HNYaFNmzZmCffee+/ZoipgGXfnnXe65s2bmy1MqVKlTOA977zzzFaHfu/dd9/1rc1h7B8Qjxs2bGjtxQLk3nvvdQ8//LA95pq+7bbbXN++fX1t47777muiOKJ3GEBkZrEpdsEpmZDvjd0YI0+cONGX9tJ/nXjiidHAG9rKe2BxDLhv8BzXCH0Yz2GX6EfgQrb3Ea+N3vjI7/43aH1EqgURFk0JtPHmHXwPgbmHt+hEkM6hhx6qRWohfEZCvhBCiJxw8MEHmwCKKITvo8gdLIy89NJL7uqrr3ZDhw61iEUEDHzlx4wZ484///zosQy4GYAjNn/88ce+tTmMiw/AuR0+fLi1jwlYLExqiGDjc/A7Oo224a361FNPuS+++ML2MbFi8YTMGCL1+RlUT2GRH3766Sd36aWXuhdffDGt0FwooYMIvlzhpyf92LFj7XsFLFLj253JYrXuh5lBthP9KwEB3uISUaCMLRDvWaA88MADrb/zBN74+5/IjEWLFpnHNaId94nXX3/dxF0WqoIQHUxtHbIFvv3226iYGGQeeOABq+/jCd6IzomEfMZkZPxx3qkBwMK7HyAsIyKTPcB4h0WceKGc6+Ghhx6y7MR///3XsuOI1vYLrs1UkL1BrQIW9vB5x3N+m222Uf9bjBfWhSjJSMgXQgiRE7BGwWKAIkgUAhS5g+jvli1b2sCZaHYi1xHJ99xzTxM6OPceCLtMtohY5LFfhHHxIR7OcWwEVWwRxiCxYMECO6ekyCPkAtcKVkWkxSM+HnnkkX43U+QZIu/5jmEPxYJO3bp13fz58+0xnz/FFb3C2VwbXvFsIi9Feohinjt3rhUNRWTkvIrcwdjhnnvuMeG2c+fO0f1ELXfs2DEaKeqJUVi/yN5h85k5c6YtRpEFhxyAgJ9OLC0U2FY1aNDAihqzgBZ0wmTNB2S40O/fddddrmfPnimPHTFihLvyyittkeKtt95yQWfatGk2/uQ9kuEjipLL77gWSYTwDwn5QgghcgKiMoInExeRH+siNqKkPCsaIrqaNWtW5LiTTz7ZTZ482T366KPu4osv9qm14Vx8CDtEzfHZI+q/+uqrbv369VGhgM8AkUFkD9fuBx98EM0W4RpGtClXrpwLEiyY4XN70EEHWco7EaEInixC8d3zMjn69OljAgcWGjwWmcHnzWIJFgNE4ovCQQQ+UeOce6wdsAUJSl2QIPYPRLJnAvZEvXr1ssVe/K8TUblyZecH3MsYE7A4iSc3i5F+Z8IVB2s+wKOfCHa22LFYIlh44DvH9ewFCgQdssBYSMEyKnZR0C+C2EcIIcKNhHwhhBA5gfRsJicMVIn2FPmZnJM6XL58eZvUegVlPbAfoEgdYv8ll1zi60QxjIsPxQmiV8ePH+/uu+8+y3IISho00Z8TJkywaMR0/u1+e7B+9NFHFqXKteldwx4I5Ig2XN+en7ffEOVJBD7iHP7LEC/keyCQkcGBDUT891Ekhv6W80lRSyGC3D9gKZIL6INZIA5D+/1qaxit+ag1QRsyDbzBqoZ7NcEBYYB2IpLXr1/fsqj8Ish9RD6gngnFx/Ndd0cIISFfCCFEjkBwI0ru+uuvTxrZJUoeYVt8YFiEEPrss89a0cXYCKrDDz/crGpI98+Vz2g+4JySxk9kPhNI0v6DIORTfJWClojKsYV6vaFobBSj34Xq8APGax5hKNVQGX90fISJ/vMbPMRZwEFMotg0cJ0iwvz4449FjiUrpnr16mYTg5++SA+RwQgznGPv/IqSSdD7h1zen+IFyKC2Pwj3uLBY81HUFqs1L0syFYyByO7iPWCDGBa4H3LtknXgB0HvI/JBsgLPQojcIyFfCCFEzhg2bJjr27evRWMQdVS6dGm/myREVosOFJ/Dcx7ih0ie0HzYYYdZtHuQJuYwe/ZsE+9pG5NXr/177bWXFQ8kWsovsMSoU6eOtYufRKJhBUM9Dfx3ERXwtv36668tc4MJsF+F6ohqxw8dEeCAAw4wL278gb2ii4gZtJXzif8xohOLFH7XIcAigSjLWPsD+mCuA+wREgkdvCY+Wj/XVKtWzX5ihUIGQOy+bOD799VXXzm/IGOIxUa+Y+3bt/etHcUVBCAWULH9oL9KBb7pRBOTWUJ/UUjC0D/ER4NvCX7c595+++3Nel2TJk1y3pbiyDnnnGMBC/RnFOpNBUVjsag5++yzrTZIGPDqLjG+iK2tUSjC0EfkAwn5QhQQhHwhhBBiSzn++ONt22WXXSJbb711ZMcdd4wcfvjh0f2JtqZNm/rdbCGMNWvWRKpWrWrX7lZbbRU55phjIv369Ys89NBDtvG4UaNG9hzbfvvtZ6/xm6VLl0ZuuummSLVq1aztXvv5/rVt2zby2muvRf7991+/mxm58sorrV0nn3xyZOPGjbaPf++zzz5FjnvggQci2267beS0007zqaWRyBlnnGFto4/666+/kh63fv1668M4ltf4TZUqVSI77bRTkX2VK1e2a2LFihVF9nNNbLfddpHtt98+7+3yvjM1a9bcZF82G+/Db04//XS7x7399tt+N6XYMXz4cPuMb7755rTH9u7d24695557IoUmrP2DEB7Tp0+P9qnt27e3cUQ87Dv//POjx82YMSMSBtatW2fjB9rdsGFDX9pQUvuIvffeOxD3aSFKAorIF0IIkROKQyp0ECBqx4uCIzU3dl82+O0vHjYopkdGCfUd8A5P5hs+ffp0i2bDJ/uaa64xW6BCw98mcvXJJ58026JYK5rGjRtb4ULaGKRCaocccohFntFeLIpS+bfffvvt5itLujmewoWGiGCKa3722WfuwAMPTHks7+nggw9OaF9TaI499ljLyvjhhx+idgl45VP4+O6773Y9evSIHjtx4kTXunVrixAkWyLfhQcBW60zzjijyL5sueiii1whwLc4EdyvqDuxZs0ad8wxx5jdTtmyZVP+LvkFZ8Zxxx3nZs6c6T799FMr2JyKRYsWWWbP8ccfX/D7XFj7ByFiocgx9wUv05AIdi9inPo1bN7YgmMZH/lJsj451hefexm1ujzvf8ZIZO0UmpLaRygiX4jCISFfCCFEThg4cOBmvc4P64wwLIggZDAJiN0X1EWS4rD4QPozti6I+KSQp+L55583Cx7sQb788kvnR6E6fO+9IRxtR7xnC5rdjwdiJxNtit161zM/WTiJtYIB7HeY1CKSIkwXGuxo8EDPtKgpFjXUJaAYoJ/06dPHxBbsDxDp4emnnzYbGN4Tfe2hhx5qxY9vvfVWt3btWisu/cgjj/ja7iDCtRlbsyGeRHUdkiFRIzMQEhHgqPGQCVzTLFgtX748720rDv1DMgue2DowQb1/BImwFxKOhUXJAQMGmOicCO7DPH/55Ze7oPfJsX0zx954443Wdj8oTn1ENkjIF6JwSMgXQgghArgggu+vN3kK+iJJGBcf4sErHJhIpWs7bcR7FRJ5j+cbTwCncOyFF15ognfQ4XwxufVEI0/cR9hni5+gIyCAF1lXSLiOEbiyuRYQwIis8xOyHY4++ugiBWwZ5pNdMmPGjE2KCZMNQUHnChUq+FKPwhMPWZgKYnR4JqJRJpDFI9KD8EUWUaZRqUS9/vHHHwXvg8PaP3iQsTNo0CDL6orvX+l3iWBmURBRLihw3yBCnHOeSrogKykshYSDkpHKAvuUKVPsXhC7qEPm3AknnBCY/jldn0zRWATxunXrWqAFAQ5+EfY+YnORkC9E4di2gH9LCCGEEJshvgc9a8FrX2zRwaC3OR4mgAhCmUzSichjcuuJ/4WGInWnnHKK22677VxYIGXfE289Klas6L744gu3ePFiSy33ICIX65Ltt9/eh5Y6d+aZZ1ohXsTws846K+WxHMNChBcB7ycs6FBcLxaEj9dee80i8Mk2wXoAixuKDbPPDxEfqlatat81rgm/2pAKFj5EYUHE53uPsJhOPOQYjvXDPiys/QOQ4YS9FRHYiQRxsqPuvfdey+Sh7RTs9DtifMSIERkVuS5UhHtxW5jju9aqVSvbgkyY+uQw9xFCiHCgiHwhhBBClHiw08E3HFG5Ro0aKY9FfCbiitdgYxLm6CmiXwshfrRs2dK9+eabdu6qV69u+zp06GAetmSeINZ4IDDjK463LJ9HoSHKl2hERC1slIgETMQ777xjk3SiF+fPnx/N0hDpQYBlIcqPjAsRbI/8TOzNxo8fbxlJZKAU2n4rrP0DkbI1a9Y0uw++f5deeqlFXLOgCkS8v/XWW+7hhx+2RRKyvsiw8+ptFJq2bdva55yNVBG/kCmEH4S1j9hSFJEvROGQkC+EECKn4L98//33u1mzZkVToYPsESoEkFbeqFEj24hgxuYhEfiYnnzyySY4vfvuu65+/fourBRy0kVR4L59+7oHHnjABCSgj8AKgX7gpJNOcvXq1bP+Y9KkSdGsDj8KhY4ZM8YiVrG0+v33362oKTUfvEKA3333nUVl0n6i22knGR2JwPpIbAqFSpcuXWqCR648p0W4ufPOO62AeOXKld2cOXOSZmrw/SNSnPHF4MGDXe/evQvazrD2D9jl3HHHHbYIjZWK1954KD7evHlzt2TJEju3nONCg+0PFj+cv8cff9wWgsuUKWN2YHzuq1atsvdw22232aIDiz8UPg47V111lV1TvGcRXsLaR2wpEvKFKBwS8oUQQuQ0DbpXr142iMvk9hIUj1Ah4OWXX3YXXXSRiQXXXnutCQPxEy+KieIxPHr06MCnogdp0kVByo4dO5pYj2AXLy55/YHXbyDwE8Hvh71ObFE92pPMlzfVc6CFyuSwQIMIh61A2L9HIjdgqYXITF+LVzsLf6eeemq0ACue06+88ooJy0S6EklOxg4CbyEJa/9Qq1YtO19EASMspoIsh8aNG5vl2aJFi1yhwfoLof6ee+5x3bt3j5537s0sNHiwENikSRMrOv/++++7/fff34WZQguh2NU888wzbuHChSY8//PPPymv10wsjgrB6tWrLdI93tf/iCOOMIuavfbay9f2hbWP2FIk5AtROCTkCyGEyFmhRc9PtVu3bubhTeQy6dnYjxBBRdo23qukdWOlwaCPSZj4f1SrVi0nvydIk64wkKuo4DBNvIIy6aJfIAIz1r+dKDSK1/nl356rQqfLli1zfoDY9cknn6QVZ/yK+CNTi2wWhDgyMIjQF+KDDz6w7z9CfSrxi3osLPQdeuihBW9jWPsHbDsQGIkQzgSKkcPatWtdoUGI5RrAeqt8+fK2j7Yj1jKWjIXMOBYmLr74Yvfoo4+6MFOoezLfoU6dOlnkuPfvMATe8Pf79etnwQDefc1ru/edxLLt6quvdjfffLNv2V5h7SOKy5hSiJKAhHwhhBA54fzzz7fIniuvvDIacZsoguqjjz4yGw3EfCbt3mRR/B/piq3GRi2neq6Qk67isPiQSZHbTAjCZDdTNOkqfiDe9+jRw6yfgrzwhICEUDdgwAArXIp4ixiHUJdKfAmTzYDYPLBOIRqfAID4RSgydPBOJ5sjmTWMyJ2Qz3iCxbZCg7UdxeSxzYndx+efaGGB97bHHnuESvT0855MIA1jdTjssMPcaaedZlZW6RbPyVj0e57Boj/XJdcDPvSxNR6I0KdwLPc1rJmowSMKB/M96i5pTClE/pGQL4QQImcRKETUfv3119FUeCaNRFZhRRILE3Qm4zfeeKNFzYj/B5YtiaBAHeeKiS0F/vDb9CYwWBFMmzbNfIXx2cS2gii2Qk26wrj4EM/bb7+ds98VliyTQgr51Bb4/PPPTYjBPiMVHMfxFGYkuk5kBp7WRx11lAldfKc414hb6cQZP8SvTK0HwprtInJjtYMwRwQ2nz0iEcIdAq/YfGsdbHMaNGiQ8lgvyt0vax1E5b/++svGPami9GOFfO5jvCbMFOqejMUddjqdO3e24sZhABs2CsMCFp7MH+Kvg99++80W+bBApM+YOHGiLVKIwjB8+HBb+MPzXwiRXyTkCyGEyAlMrhk4M/n2QEAiqit2MgZE2THxOuCAA3yZJIYNbCjw/sQXlKyHE088MalFSZs2bWwyiNVRobyDw7j4IAor5BMZ16FDB9elSxf30EMPpTz2ggsuMAuup556yrVr18758X0rtO92LuBcUfQREYxzTIHIoBaS3VzrgbBH3Ir8Q0YgYlK+CmWHtX+gcC1CG4L+1KlTbZEvEdwTmjVr5j777DOzKBk6dGjB28p4h4xNhFnGinDcccdZphHe6GeeeWb0WI5jgYdxBCJ/mCnUPZnrl0woFkaSFVkNGtRSef31193111/vbrnllpTHYr+DoI/FJ3U1Ck1Y+wgPggH4XsXWH8AKTxnUQgQIhHwhhBBiS9l1110ju+22W5F95cuXj2y99daR9evXb3I8z+20004FbGF4ueGGG+w8jhs3Lu2xHLPVVltFbrzxxoif/PHHH5GaNWvadfHGG28kPW7KlCl2zCGHHGKvEYVj7733tuuqEJx++un2t2bPnp322OnTp9s1fNZZZ0X8oFy5cpFLL7008sEHH0TCxF577WXneOrUqX43RYhi26+FtX9YtWpVZJdddrFzw1iNMQJ97RdffGHbtGnTbKyx++67W//LsbzGD7p27WrtpE0eQ4cOtXZVq1YtMn/+/Mjff/8dWbBgQaRWrVp2bKtWrSJhp1D3ZMZcbGG7v2277baRNWvWpD2WY7bZZht7jR+EtY9YuHChfY84z1yHsRv7GMdxjBDCfxSRL4QQIidQrBBLDCLyPSsHoqQ+/PBDsy1p1KhR9Fg884nMLl26tC/+q2EDK5JvvvnGzlW6CFsiuYhgI+KVNHq/IO150KBBlkFw7rnnpjzWs1q64YYb0kZa5QsKv11yySVmTVJSKGRE/v7772/WW0SqpbN6IWOHaDau4S+++ML5afuCfzDXBdHu9FdhyIqin8hVzQchwka++7Ww9g/AWIxodrLkUhUTJjsOK5Njjz3W+cHLL7/szjjjDHfppZe6Bx54wPbRr2G3RjZfbNtpLxZs77zzTujv34W6J5PdgMUSWZNexkPQwROfiHCyCDJht912s2sGz/xCE8Y+4oUXXnDt27e385XKCpPPYezYsUWyYoQQhUejfCGEEDmBCRaTD4otxk4WGBBir0IaL+B93bNnT3tcu3Zt39obJr799lsT6TKxyeCYUqVK2Wv8hPR3PLpbt26d9liOYXLAa/xi1KhRrmHDhq5u3bomHGRaEFBkBot3O++8c1oRHxBlODa+tkahePTRR92RRx5pfRce3V27djWBpVu3brYwGVRoI99/ifhC5I+w9g9e/Ra80REWsVThPcRu7LvssstsHOeXiA8nn3yymz59uuvYsWN0H4IzdnzY9MW2uXLlyiZChl3ELyTdu3e38frIkSNdWODaxGopk7EZx7H5ZRsUtj4CyzoKCTNPo8YZY+ClS5dazQk2HrOP4AqO4VjZ3AnhM36nBAghhCgePPbYY5b2PHDgwOi+r7/+OlKqVKloKnfDhg0tbdtL1Xzqqad8bXNY8M4Z6e/pWLJkiX0OvMZPdtxxR0vNzxSslkqXLh3xi0aNGtl5Y+NclylTJtKpU6fI3LlzI8WVQlrr7LzzztYXZMLGjRvt2LJly0b85JNPPol0797drmPvumA78sgjrb/7888/I0GiZ8+e1r6wpfPDokWLIqNGjTL7DDYes0+IoPZrYesfEsEYjXscG4/DwooVKyJz5syJfPrpp3a/KC4U8p7Mtct9dsyYMZEwcOqpp9q5GTBgQNpj+/fvb9/JU045JeInYekjLrvsMmsfc7S1a9cmPQ77S47hPVx++eUFbaMQoiiy1hFCCJETSNW+55573L777us6d+4c3T9x4kSLqoqNoiFilMJrWK+I9JBiTqo5xWJfe+01i15PBNkOXiQbhcFIjfcLCun98ssvZrdEUeNUYJ+CfRCp0D/++KPziyVLlrhHHnnECrOSvu2lRlMckBR/opDKlSvniguFtNapV6+eRYLOmjXLIipTQcp/48aN3SGHHFIkw8cviEAbP368XRu0Dbg2iBDlmqCAL+/Pb/gsyXLiu/Tmm28m7SeCxKuvvmrFCz/99NOEz3MN3Hrrre60004reNtEOClkvxam/oHxA+2indWrV/e7OaJA1y62gcl46aWXbOxeqVIlKzCcqpgp187jjz/u/IKsi7PPPtvmD3379nV9+vTZxBaIIq1DhgyJzi3iCyP7RdD7iBo1arivvvrKffTRR2kzpRmTkbmKXaIf1odCiP9DQr4QQoi8g6D7+uuvm0c2lhknnniiDQJFZsydO9dqDHDLZsB97bXXuuOPP94WTQDPWMT7YcOGmS8+Ex0mC36mmodx8SG2TUwaSY+eMWOGnXcmXdgbtWnTxtKki0Ma/957720LJ4UQvLhmuT4R6KdOnZrUYufff/+1a4br98orr3TDhw93QSLZYk8QfHCx01q0aJG74IIL7LO95pprLL0/lTgDWFP4AZZrAwcOjPrxck2wmAc///yzXQvAOe7Xr58bMGCAL+0U4aLQQn5Y+ges7rAto06JKDnXrufXHi/5JNqXCO84fvrxnYqFWkrUVKItWEiy+OCNg1euXGk2NojmtJexGjWagkYQ+wj+Hv0DizqZQA0NxsnURBNC+IOEfCGEECIE4GVKVDjiVqoidXhk42VJhI+fhHHxIRFEKSHojx492q1evdr2cf6La5R+vmCSzXVAITXE/LvuumuTCLQPPvjAXXXVVW7mzJk2SSebwy+ROR1cCwgFFFj04LrgWsBj+rrrriv4dZFJDY14aLMnmBeSyZMn2wIe4MVNcWyuC2/BD5GAc3v77bfbYhrtZDH4pJNOKnhbRbjwU8gPcv9A1DXFPylwKkrO4nqHDh2Sjhmz5YknnnB+8s8//1g0/ogRI4os9ELsgvAVV1xh9w4WroJKkPoIAqw4n5ks8nGey5QpY+eWOgRCCH+QkC+EEEKEBIROBC9sMzZu3FjkOYRwMh1uueUWi+wJAmFbfEgF7+GVV15xQ4cOdfPmzYu+H6L0zzvvPBOgKfhcSIiGeuyxx9wbb7zhvvnmGytKxsKDB5MssiFoK1FefkMEGqJCrGhBYTWg/atWrYpG/rFw0r59exc0sAZiYYeUfS/yj0kt3z0m5ESS035EMwozVqtWrWBt29wit/F9SSHgfL311lvunHPOcc8++2zK/oEoTGwJTjjhBLvWhQiqkB/k/oFFZ75rmdjdFRLvHJClydgmdl82cF5j73+FhM+WiOYGDRpkdPz8+fPt+ogvKEy0Offxiy66KE8tLR58//33bsKECRaBz3cd9txzT3f44Ye71q1buwoVKrigEsQ+gjkDtjqZLJZ7i/AEYrz//vt5b5sQIglxnvlCCCGECDhr1qyJTJs2LfLss8/axmP2BZH3338/0rJly8g222wTLSbrbezjuffeey8SdDjHbdu2jRZv9gqXeT+33XbbyBVXXBH577//CtKeDz/8MFK5cuVoG7x2xEIRwJo1a9r+qVOnRoLAq6++Gtlvv/02uRa8rXr16pFJkyZFgsTPP/8cueuuuyIHH3xwkfNdu3btyH333Rf5/fff7bgNGzZEnnjiiUilSpXsuLPPPrug7Vy+fPlmbX5A8T/O0cqVKzMqbMn5zqZ4tii5FLJgaJj6B4pgb7/99pFWrVoFqkCsd764V8Xvy2Yr5Gee6D1UqFAh4+OrVq1q4x9RMgh6HzFw4EBrD3/3s88+S3ocxaW9tt18880FaZsQIjGKyBdCCCFKCHfeeael1t90000F/9tEh5NREBs9Vb9+fUvpDSqkuJNKTtQ7kX7ekInoJVKfKbw2ZcoUd++991okFVFU+H7fcMMNeW0XEVt16tRxP/zwg7WFaHv+LoXe4qNQ8ZinsHTPnj3d3Xff7YIAbcRWac6cORaFz3kjOr9hw4Zmv7S5keW55u233zYvWwp2YwnE54/1CxF/fP7HHHNMwtdxrRx44IFu1113jV7voigU+eNcci1nAt752O1wjQsRhIj8MPYP1H4hKwprOO4L9Lnci3NlvbI5kH0FjAWorRO7L1v8imTnnsU9jEjxTNhvv/2sponfnvMiv4Slj/j999+tsDyWl2SWkCnXrFmzIvUHqG1EFgH34YoVK1qB+nT1d4QQ+UNCvhBCCFFCCIJ3cBgWHxDnmXxhpYMnK0MlioEhmGMVlMi6iON5rnr16m7p0qV5bR/2Svi/MtHCagQRIdlni43CwQcfbEXhsAQS6aFuA4s33ufI58/nSpHjTp06RQuypoKJLgstYfquFRIWoij6hzCPcJAKBBC8gg866CD38ccfF6yNIpzk+z4X1v4hTDU0wka2Qj6LJ4inWKuI4kcY+wiE+VatWrnly5entLpjEerll1824V8I4R8S8oUQQogSQhiF/EK1mchwPP0ff/xxm8h4wyNEcAT6Cy+8MG3hMaKnWHQgYimf1K1b1y1atMj8Yb2CscnOE++DwrFETv300095bVdxwcsIQPhiYkvkHP7s2UChZ6Lbli1blqdWhpvBgwe766+/3hbAOnfunPJYBBEEkEGDBrk+ffoUrI0ifyxcuNCKJeajrkg+CoYWh/5hczKdEPTCNF4Ig5DPAibXPUItUfn5Jlce64WsQUCGIey+++6uW7duRfZlix8ZqGHtIxi/3n///VargT7a++7zPlh8p14N74WMOiGEv0jIF0IIIUoIEvKTQ1Qwf4NhEY9JfUbAb9y4cca/o2rVqm7FihV5byuiPFGSFLv1IqdSnac99tjDrI3yvcBQXEBgofAyW1CL5mHlBGSKUOAvdl+2xBdcLARkupBRwmLUgw8+mNQSY8yYMfY9JKOE1P5tt9224G0VucfLIkKo8iBStXz58paFtSVgJ4Yg1b9/f1dS+4dkNh+bQ5MmTXLelrDz0ksv2eYxatQoK3zfpk2bpK9hbLFmzRo3c+ZM9+uvv5ooOnbsWN8XcBhDJJODYp8r5KIObebvYS/z2WefFdmXLX6Md8PaR8Tfo3/55ZdokAoLr0KI4CAhXwghhCghSMhPDpNEUoYvueQSE5SIBMsWrGtIlc+38FGmTBlrb6xfeKqIfMReovIRD0R6Nm7cGBif/mR4ogZ2M6TEx+4LmnVGskhKLHMeeOABs5ioVKmSO+6446KevAi8CI9ErOKdTVQmC2x+RFeKwkQwZ2tP4hdh6B9Efhk4cKBtqUTwVLC4jqBfo0YNl2+S1RtgPEDfzOLC0Ucf7Zo2bWoCtNf/Tps2zerY7LLLLtbvsshWqBoE3As4t5UrV46239uXLdTjKTTqI4QQ+UZCvhBCCFFCkJCfHLzmTzrpJBcGmPyT4o5/Kl67qc7T/PnzXYMGDdyhhx5qxYZFehA3yHq46qqrMjp+xIgRJoYUUmT2RAIiFhcvXlxk3+aIDvkk3QJDbMRnuv1h6rtEclhc5Logcj5sQn4Y+ocwsTne/X77+RON/+KLL0b/jdhMRP65556b9DVc39jzUWiYjD+Ecb/4888/Lctp9erV7plnnnEnnnhiwuPeeustyzJgfEGgAkEEovj1EdgvMZacO3duRseTqUo/XSirJSHEpkjIF0IIIUoIEvKTQ+QvgoIXEZwOJjGIBkSMFRr8wvHyp+Ct5xme7DydcsopbvLkye6aa65xQ4YMKXhbw0i2giKZHFw/YfpeFZLNjaQMSnSlyD3UHsErHC9mRM0wCflh7R+CKtblKnLZTz//sFy7HjfeeKPVHEHET7X4AHxHsQG64YYb3C233FKwNoaZsPURYWuvEMI5GU0KIYQQosSDv328Z3MqjjnmGPPDL1QEYCxXXHGFFeZFyD/ssMNc8+bNNzmGSLtevXq5SZMmuR122MFdfvnlBW+nEDBjxgy/myACBuL9bbfdZiLibrvtFi2eSJHabIpzFrIAZ9ihiDvWb5mycuXKghRjTbY4R5FP7mFEj5999tkJrV+ef/55ixKnrgL3cL/gPWD9FRY4b14toHRwDGMIXuOnkM+1i0Wg8B/GvbIOEsJfFJEvhBBClBAUkV98IpKGDh3qrrvuOhOy6tWrZwXh8BwnDf6bb75x77//vhUrY5j30EMPWRS/yM+1gIc7E1sEJyFEev766y8T8V977bXQRWGHtX/Itt3UrVi1apXdRwoN93zuaxS3fv31190hhxyS8DjueyeffLJdA1jH4T0v0uPVzfGKmaYDn/y///7b12sYKyIWdC644ILAF2AOWx+RTXvpu/ksWEDL9PoRQuQeReQLIYQQQmxGdBgig19ce+21FsmKZU6s9/24ceOi3uJMtu6++2534YUX+tbO4s748eOt6DBe9UKIzMBP/JVXXjF7nU8++cQErI4dO5qgRZ9VXAhr/4BYh5iOz7cf3HrrrbaIQEZZMhHfs2h65JFHXIsWLSzDozhdO/nEE2GXLl3qDjjggJTHfvHFF+63336z8YafUBT9iSeesA1Lw/bt25uoX4iCwcWtjyAIhQydWFiooQBzshhf9uPjP3bsWFvcq127doFaK4RIhIR8IYQQQogsIGoJCwiv0KxfXHzxxRaBP2HCBDd79mxrF5GJRFZh/XPOOeeYMCZSc88999gWSzqLD29Si7hAVDC1CArJmDFjcva7tNAj/ALxyhOwEPIR+C+66CIXJMLYP4RdrCNTg4jxZEVYY+EYb2HITyGfc0fRW3znFy5caEJ5Kuu9QhbnjYfxwcsvv+wuu+wyO9dY5ySC66Vbt27WVl7jJ4899ph76qmn3Ntvv21Zh1gLslG0l3sYPv677rqrL20LWx/BYggFeWP59ddfrZ5NOmg37b3kkkvy2EIhRDok5AshhBCixPHOO+9s4t39xx9/bDK5STTxItWfx0cddZTzG7ylEb6CJn6FCT7TeMGLBZH4fclo1qyZu+mmm1wh6dChQ04KyPI78i3kd+rUKWqTRdRs7L5s20qRZ1E86d+/f9QrP0iEsX8Iu1jHonQ2nvNkx/3www/OL7C1Q4jFKz8MrsXY8r366qvW3kMPPdQy/I4//ni37777RmsQ8NywYcPc4sWLzXqlb9++vraZewYbtYkQ9Nlo2/z5892CBQusngI2S0Tpn3rqqW677bYrWNvC2EfEXqd819NdtxxTrlw5V6tWLXfppZe68847rwCtFEIkQx75QgghRAmBSG2ihOSR79zAgQNt88RQT7jIBI4lWpCFgCOPPDKn7RKF5+OPP3YfffRR9LNFLEhn8YGw4U1qq1ev7goNhR2TXa98x9etWxcVuDxLhJ9//jkaAYq1wu677x4tKplPOFe0lchrPK1j92UyDfGO88MPXYgw9g+x97gtEevOP/985+d9H5GWgu6poB4MUdl77bWXb2I+CyYDBgywx2eddZY7/fTTXYUKFdLa7/np9T5y5Ej7jLknJLuXcL1ss8027oEHHnBdunRxQQNbQbLTnn32WbtegPeCpz/Zioj6DRo0yHs7wtpHbK6nvxDCfyTkCyGEEAHHi17t16+fFVndXIYPH25R50Q+lvTFB1LgR40aFf036dpEAB599NEZTbyIgN9///1z2iYRDMI8qaWw8RVXXGHZIvQXxx57bNQ2AZsErnP8p+fNm2ciA0JOobIHEOewQojdtzlRxqJk8Omnn7r33nsvKtBhZYZgiy+6n4S1fwhTu1lAwKKGaPEpU6Yk9WfHvqZ58+YmpGKtgiWQH3BNUu+BqOowja8Qwm+88Ub35ptvuo0bN25yvWBbdMstt6RdTPEbxoe8B0R9LIOo8eC9Bz/si8L0XfPux15NJSFEOJCQL4QQQgQcorrYmJzkwk4jTBRq8SGoE69UVj/Z4oe9Q0nmqquuMv/bQtnBTJs2zYSXM844wz333HN2TSeCof+5557rJk6c6N56662MrDaEKBRvvPGGWX0sWrQo4fP4tg8dOjQj//QgU+j+IUxiHaI4Ij6Lj4j4eLknsn5h4ZKFfjLkEKUPOuggX9qLRz81BbBYCaI9VDooZsv5i100q1+/fihr7Hz55Zdm+8IiYNizuArVR2ANxXeOYJZ036HPP//cvpc1a9YsqH2REKIoEvKFEEKIgEOK9vr16y36LCwQrU4qNgUM/S4Km2mEPpNxBM4tYe7cuTbJIRI6F3gWJLkgzBPaMJIvW6hk4NE8efJk8+WtVKlS2kKY2PPgKYxXcj4ZMWKEWflQnFmIVNx3333uyiuvtMUmz9bDs4CKtYaiT+S6uvzyy11YKXT/EDboy4iy94qBJoJrpGzZsha9T1/mF4xx+By5RkXhQYh+6aWX3JNPPmmR+fQTxcGOrVB9BOeNhT7G7CyOpQK7oqefftpqFLRr1y6v7RJCJEdCvhBCCBFwiLB95ZVXTHzzItKCjidAk0mAX2zXrl0tBb64w8SLCMFcpXMTLZ0rIZ8IRlF8hTo8ornuMhWTdt11V4uoW716dcGzXbAIo70sfAkB2KNg4YHFB9ZQZGERhe1ZQyHW0Ydh9fHuu++ayI8/ep06dVwYCZqQ/8knn1iGDt/Xk046ybfo9liIvKdANhlG8YEM9F8svFOENd3CZSEWUckk4fOkXaIwvPPOOyZCP//887bg48la3G+IyqeQe1j7h0L2Ed4cY+bMma5hw4Ypj6U2VNOmTd2ZZ57pJkyYkNd2CSGSIyFfCCGECDiIF4jgRLc/9thjLgzgz40HPRNxQIxGvEPQJ/InDFH6xUGcESXnWihdurT9rbVr11qKfCrIGiGSFTHUK4ybLxAG4wtRBtXKSvgHdUcQ5Vq1auVeeOEFuzYTwTVOQVGEJ14T1roJhe4fsN6iPgbFP71aFR533nmn2Rl5sgDfT/b16NHDBQWKcsdav2xJvaBcM3XqVLN6uv76622hKUyLZ/fff7+bNWuWW7lypfvzzz+THssYzg+/+Xi++OIL88KnHgLBLcB1S0YlgjTi/QknnJDUWi5MFKqPIIN2xYoV9vmnK9CMhRQZdmT08VkIIfwh/D2cEEIIUcwhKvGuu+4y+xci0PAyDTpMZr/55hsrPEa0GpOqr7/+Oho916ZNG4v+E0LkBoQthBZEjnRwDBPyQohhLBgQTavFLZEKCjEjFt5zzz1JRXzgOc/nXVlGmTN+/Hg7xwhwsSDG9enTxzIhWABEEOW7ij/3hx9+6IICfRWZGmyZ9lu8h0JYejVr1swNGTLEDR482MY++V4czZWNFcWj8V/H95xaRJ6lVbLN7/by2ePNPmjQIBtfQpMmTdzIkSMtswxxn2yS4iDiFxIW1KmHkE7EB7L4ODZ2YV4IUXgUkS+EEEIEnGrVqtnPVatWmb0AMNmmCFwywQNB5KuvvnJBmigwYWTC5U3AimOUviLyhV/XAtG2FDSm8OODDz5o0crJRPxLL73U+pKBAwe6G2+8Ma/tIlV/3rx57oorrnCdO3e2YpCIiXvssYcVJMxmKlK5cuW8tlX4B/c0tkxrwWBhQgF4tjBS6P6hbt26VkA4voYGkfjDhg0zQZR6GYj5559/vtmVIII/+uijLqwU6hxjNQIfffSRFY7FDuqQQw6xRcxkMP4hkt8P6I89C5Vu3bpZsAU1BvhOYWPEWJNAC7zQy5UrZ/UoOJdcI34RK84feOCB5tXO5retUnG4fimCzXggk76U+zXZfwj62BkJIfxBQr4QQggRcDYnuiioRb4YdlCM7JFHHjHRgKhgz0uftGiKbYXZS19CvvDrWqAgNuIMYhLfKQQOaix4dTWwuSIiFzsCvoeHHnqomzNnjgn/+QTrEwTB2FoPXiHCbAiKtYPID4iIRDITGZwuMpTrgAUhBKUwFYH3s3/g71E/A8Eu9ruHh/inn35qwi3Zf0AQwAEHHGDbkiVLXFgp1DkO2xiNhRoKBFNYGgulZHZn3EuIcEfMJxM01cJEvqHoNcVVsc4hk6AkUKjrt169em7hwoVmsXT00UenPHb27NmucePGtlBFXQ0hhD+kz58RQgghhK+E1QM42eSViSEbE0YKklGwDEGfCEA2/DqvvvpqE/9SWSyUVDp16pTV8Qi1RFwx8WKRBL9yUfzgcybCk+/Niy++aII9nuOxePE7p512mmXH5FvEB2p7ILYS9RtbWDfbWCLFHhVvsMyg+DH3gLZt26a1iaHOA8VxRWbwHUSQjRXxqaeBiI/ndWy0dfXq1a1vwDddpIfCzGECMZbrgCypVH0si7333nuvfR/vuOMOd/PNNzu/IEsgE+sXkT3UFKBewnXXXWdjiGTnmQVU7DG5dqgJIYTwD0XkCyGEEKKgIDB6NjuI+V50LpNGInyYLPDv+vXru9dff90sOMJCISKoiJzLJpo5NvqZCRqWK0ThEdEqimd2xoIFC9yzzz5r1jWxBSIPP/xwq09x5JFHOj/46aefrKAellp8r+fPn5/V66tUqZK3tgl/wfe+V69etuiIUI/veCKIHD/nnHPM1oF+LF6MDAuF7h/wtSbjgQUQ737wxhtvuJYtW9q5njJlSpHjse4jyydVAdSgowy5xGBhxTUQ6+XP2ICI+19//bXIsQRZMFYgOwNrJlH8rl8W7GrUqGHZOkTbU5OLKP1YyMig5sTMmTNtkY+6CrK6E8I/tKwphBBCiLzDROSVV14xSx0EAwrrITAjFuCPj2c3UYBE7OLvjUDDxIHon8cee8zv5gcKUsuZhFNImEk39hJEpsZaqLz//vs2Sceu4tRTT3Vr1qyx88mEjUWUpUuXmiCmjIfiCdYDQbQfwB6BDbj2JMwLj8suu8z6JiLEifbE4oEMIq9fo+8iWvTdd9+1e0etWrXsNSIzyHTDKgV7LSy34IUXXrB7SaNGjYoci9iP17uEuuIJY4b4YABEfBbHEHPx+PfAC53jvdpGQYCxD4tQtAlf99haAyw8EV3O+0tnEyP+j4oVK7qHH37YxuII9Sz4Y7Pk3Z85z2REeEEhjOPVNwjhLxLyhRBCCJE3KKxHsbxRo0ZFJwKAlzciDJGVFNfzwPZlwIABJj4TNTxp0iQfWx9MOJd43CLOc66IYo2Prmcyy2IIxUwBqxWv0CnFhbEzeuqpp5IWRBUin0yfPr3I935zIXIbIYfFLRFuEA8R58466yzL1KB+A6J9LN7946ijjnITJkzIyTVUUqCg6YcffmjWW7fffrv74Ycf7F4CnPNYOI7Fdol1xRMWx4ioJvvRs1EhkILPnWyu2IUdsiZZ1EHM95sVK1bYtUpQQrJaK/QJeOmz8EcfQl8h0kPhYAI/evToYeN2+ge2WKpVq+buu+8+16JFC9/aKYT4PyTkCyGEECGDyQuR2Ii1qRzy/JyE43NM1M60adOsjWxEfLVv394EfKIpU+FFBCH+i6KwMIJtCmJMnz59Eh6D53G/fv1sUnv99ddbBCbRVgieTMzZR7E7CfnFE0Q4sjKIpCMzI2hCd6wf95bQs2dP9+OPPwbu/YnNo0KFCia+cf8YN25cQmso/Lpbt269WQVGSzIs+I4ePdotW7bMatMA92WstmrXrl3k2JdeeilhpL5IDX0tGYSx0eIUDvZAEH/ttdfs3CI2+1mPgswXrAw9CxXGCAjk+OAT8Y59CpkZ9LEQf40UGsa7ZOpQfJkI8jPOOMPqR8XaA3kZBCxWEeQwceJECflZLvYh0rPQTj/M+JtrlbE4wTcUw1a/K0QwkEe+EEIIERJeffVVN2LECItSjJ+8xMPgm2grv4gd7ON9j3iPeIDAnClVq1a1CKww+dsWwtO0QYMGJtKymJPO5/6PP/5wu+yyi2U3UOAOaB8TM4QxLZTkD84xInOhr1+KE956663mR+8R2wauG3xw6R+w2Qhz8WN5YIuw4kf/gO0ahVkZQ1CLgMy33r17FyluiXhLEADfK2zwktUqCAOF7B+wLTr99NMtEtyTVxiHxf5t9lN0HjGac9u0aVPnB1hYdenSxcTum266yfaxwHPwwQfb58+Y4cADD3RffPGFFUn2svnIBPSLoUOHWjFWaidx32IsmezzxVqHBYpjjjnGrGLCil9jCCFE8FFEvhBCCBECrr32Wjd8+PCUEfix+L1OTzQXkX4I+JtbWJP0XrEppMRTuDCTYrUcU65cOYu+80DA5/VY84hNwXaITAYWTDIBGxCKQh577LFF9rPoRkRmIbn88svdQw89ZN9/PncWcuL7AkQaxJCxY8eaNU337t0L2kYh8gn3m59//rlIJHQuCXP/gKVKupozvDct8GYH1xvRzFiRUK+GaHsi29euXVvkOIR9osVZPCHq3S8hn4wWFhzIgPGgAPnTTz/tOnbsaOK9Z2tFUAbt9VPEB6y0OH9YBqYLCCHjkxosLET4QZj7CCFEOFBEvhBCCBFwJk+e7E4++WRLGR40aJBr2bKlRXXtscceNtli0k10F5G4TLpIN2Yi42chSURiIv5KGvi3EvFManK+QKAlI4NILUTZVNAWrhP8bSlkFyvws9gSG7Ut/g++Q0T6Eb2aCQggZI74mQET209gYUX0JNGhySIWvWNPO+20aP2EMKKIfFHoayKs/UNYFkrC2D/ceOONZnVH9gK2Ot41kuhvsxBP5DvFyOfNm+eCBiL+66+/btcsC/7Y2VAo2W8YTzLuQdhGpE/3+TLu8Yr3FpqS3kcIIfKPIvKFEEKIgPPwww9bJBKe5/jcejCZofgUG/6VRHrhYclP0rz9hIhf2sykNgiTwHRwDolUnzt3bkbHY02C13y8mPHCCy+4fMMiDQIAizqkm6di8ODB5pfOwo8HIgwTYhUyTE62cS5BiIshEp/vHJGgiPipOProo+0nHslCiOLfP+QKBEevboH4P1555RXre7kfp/MQx7KGoIygLoRQ8JRaRkEDQX7HHXeMivjpYIxDsIJflOQ+QgiRf1StQgghhAg4pN0CnqapBv4UALvvvvtskj1kyBDnJ4jcRIyHQcT3bHy+/fbbjI8nLd0v6x+uAz57rJYuueQSK6oXD+/l0ksvdcOGDTOBoWvXrtHnZsyYYT+9Indiy4vwIcz4jRfd2alTp7THEmlJZocsNIQoGf1DSaRQ4ujXX39tVirUA0oH92P63tgMOZEearlgFZeJJSBWgkTuV6pUyYUB9RFCiGyRkC+EEEIEHCKosUaJLUpJVFKigrcnnHCCRSG99tprzk/wXi3OEUakQKeLvMsXeNiee+65dn7xOyabgNRsCrs1atQo+u9HH33Ujjn77LPtNbFeswi5WDSJLYOihdgTkc0RBEsEPlesdTKB65dsDSFE8e8fwgQe45lmx3nBDrwmHjzGR44c6fIN/SgFgxHp08E9GUE6nc+7KApjGxg3blzaY8mM4LMgQzXoqI8QQmwOstYRQgghAg7RW/HemQh2+J8TyRM7IUScY0KZqTdnvmjevLl7/PHH3YcffljsIr+J9CLrIVPBNB9QlI7oP6xziOwjKj8+Mp/rpk+fPlYoOf614v/x0ksv2RbLb7/9ljKyHTGGyMCZM2eaYIDVkt/wedMn/PPPP2mj+xD9eY+xxQ6FEMW3fwgTxx13XFYe423atEnoMc6Cd6GKCGOVw7ggnSC7YMECs4mpWbNmQdpWXOjWrZuNXQYMGGBBC1gMxvP333+7/v37uyeffNLGwpdddllB2qY+QghRaCTkCyGEEAGHSSJe1uvXr496ftaoUcOsNGbPnm3FyDyWLl1q0V5+isxw3XXXuWeffdZ1797dCvGSURAksJ6Jt8ZhEsikKlkmgTfxGjt2rImltWvXdn7BJJVz3LNnT/fmm2+6Dz74wKyMvCJv1CjgugjaeQ8i1JMYNWqUTaa9z57FGvZlAucb8cBvuB7ffvtt6xe86MVkPPPMM/ZeDz/88IK1T4gwUlz6h7ARJo9xFh4Q8p944glbPE/FwIED7Voie1JkDnWgevTo4e69917XoEED16JFCxvrwvXXX2+BDG+99ZZFt3sFiCkqXAjURwghCo2EfCGEECLg1KlTxy1cuNCi270ilUwCST1nAsPze++9twm5+KczmfBboCMrgCK9eLgTOcUEjIkY0WqpipUVqgArE26KgsZCNDMT8nQwUeMc8978BqH+jDPOsE1sHmQ2XHTRRdF/jx492orqpYrmZCGFCHiu7datW7vy5cs7v8FCifoHRCyyuJPM+unjjz82kYNruF27dgVvpxBhorj0D8UZvz3Gr7jiCrPwuf32291hhx1mGYnxrF692vXq1ctNmjTJ7bDDDu7yyy/3pa1h5u6777bvFZmIL7zwgu3jPubVhGJsxtizX79+thUK9RFCiEKzVaQ4G9gKIYQQxQCiZ88//3zXu3fv6ISFFO6DDjrI0ncRxonoYaLo3dbxyCdiyS9SifXJYEIWnxqfL4iKY4v92+mGRF6ROiZeFJLlMxHFDybYLIxRsDlMkCWCjdXixYttQeqqq66y1H5qbHz++eeWgfLKK6+Y5RXRgiwKzpo1KyNf56CC/QZ94X///ed3U0QJuSbC2j+E6TuXzTnGYxybmooVK2ZVsD7X4MtOlhz9Kf3wZ599ZhY62P4QLf7+++9bH80446GHHipSgF5kB+eTaHcyUrlGuBa5XrDc4Z5HnSA/Kel9hBAi/0jIF0IIIQIOottzzz3ndtllF3faaadF97/77rsWURs7ecUvf9iwYb5Hi29uIVi/im9q4iU8sKfZfvvto9kvYRM4WMBD3Eom0DP0x4bnjTfesGs+zEjIF4W+JsLcPwT1/MZ7jCPSEtGMCJ6JxzjZdG3btjXbOz9hkfSaa66xAItEQQJEXRNVfuGFF/rYynDijXPJ6vQsJoNKSe8jhBD5R0K+EEIIEWKYTCPoU+iNArh4YxM17jfxhVczpUqVKs4POnToEJ1khwVsVMjWwHaJ4qVE+yUDMQEPX1H8WbdunRs+fLhZPcR/D6m3gf3W1VdfXaRIdljB0oJiz1hlCQFa3Anf+fUy5DLJjEsEGYkI+tQO8ht82ydMmJAwWvycc86xcZrYvGALNgR9FWkXQpR0JOQLIYQQQoQIhm6kj48ZMyb673QgkEjYKnkgJMWKSX4tlAlRKCTkhzMi/8UXX4z+Wx7jIh4+a+ogYBUnhBAlHQn5QgghhBAhYsSIEe7KK6+0xxTWw26JCDWKvKUithibSA3DY8Sk2IyHVPUbClnfIWy88847Oftdxx57bM5+lyieeIXf8ynkl+T+IWge+UHp47BSadCgQUbHz58/361fv179WRbUqVPHLV261DIeNqcGU6EpyX2EECL/SMgXQgghRN5BWMHmA9uPoE9eV65c6ebMmWM///zzz5QR7zfddJMrNBTSY2LYuXNn9/DDDxf87xd3KFB4yimnuOnTp2ds8xC0jAfaguiBd3QqyyXI9/cRUS4XBXUldBRvEENzcS3Sb3P95yv7pDj0D0FfKAmbxzh9HAsc3333XUbH77fffmaHqP4scxhr3XbbbZa50apVKxdkSnofIYTIPxLyhRBCiADRtGnTnPweJgVTp051fvPyyy+7AQMGuI8//jjartjJK0IjBXth3LhxvvrH/vTTT+7SSy+1iWK64RHP+zXxwtucaD7aSwFkkVtuvvlmu2bhrLPOcqeffnpGGQ9NmjRxfoOIef3117sXXnjBimQHQRzf3MLXQSqGLfIP18lBBx3kunbtasVAd911VxdEwtw/5IJ8L5SEkWwzCBDy8XqXcJs5BFXUr1/fIvInTZpkEfpBpaT3EUKI/CMhXwghhAgQuRK9ghDdM3jwYHfDDTcUEcUTtevMM880wf+RRx5xF198sW+TxKOOOsotXrzYIgHr1q1r6e88PvLII92qVavcl19+acciMNWuXdseE3FVaHbbbTf7Ka/Y/HDwwQe7JUuWWARg//79XVj4+uuvraAithfZDO8ljosg3fu4R+ywww7me05h5qBlcIW1f/j777/tPsY9DdE5FsRRhMcpU6bY53DqqafagiA+9SL3Qv6ee+5pRbpZkBeZQU0gghe4TjlvLVq0sPsd5zKV1Q6LgoUmrH2EECI8SMgXQgghAsTAgQNz9rv8nEDMnTvXJllEIA0dOtRdcMEF7pBDDknorTthwgR3zjnnWGG7Z5991pf20sbrrrvOIkLJZCBNPn5yjjVQnz593PPPP28p3jz2g+OOO87Nnj3bshl22mknX9pQnEG8wo5mzZo1oTq/bdu2dc8995zbY489bBHtpJNOcnvttVco/ISF+Oqrr9yjjz5qvtKrV6+O2jEdeOCBgYrSD2v/8MADD7gePXpYrZSRI0duEgk8a9as6AIg575x48a2UJ0LW6zi7jGejZCPwFuzZk1XsWJFi8oX2Vu0eRmR6fDrmghrHyGECA8S8oUQQgiRc7DLQVTs169fNMU4WZE8oqyIqjrggANskusHePESgY8lCWnQqSbn5513ntkAvfnmm65Zs2YFbysLCSx63H333a5nz54F//vFHa5FrtGwZTzsvvvutrjz1ltvueOPP97v5gixWSC8eRlaXMtkjAQpSj+s/QP3tVdffdW98cYbrnnz5tH9nOszzjjD7nfctxEhiX5GiHziiSd8iWgOusf4Sy+9ZJvHqFGj7Ly1adMm6Wt4Hwi7M2fOtH6ahdexY8cWpL3FgapVq27WotKyZctcoQlrHyGECA8S8oUQQgiRcypXrmyF34isRGBMJeRD2bJl7efatWudH+A1T6o7xXgRjABhAxsbCvvFTwyrV6/uTjvtNPPT9wMiKx977DETu8h2ELkDAQmxi2s1CBHAmeJF/mGTIURxgIhlovQRSr1Cooh5fkbph7V/qFGjhmU9xNdWQVAeP368ZaSRaQYPPfSQ69atmzvxxBPd5MmTC97WoHuMkznJxrW4OVIKWVMI+nwmovgR1j5CCBEeJOQLIYQQIueUKlXKNiLQPFIJ+Yj9iPhE4vkB0XQUkUXk8ChdurRN0hMVDUUI4TWZeuLmkk6dOtlPIgI5v5UqVXJHHHFEdDEkEQgOjz/+eAFbGV6wVkLAwiP6lltucWGBug345FPvIUzg3f3RRx9ZEU3anmpq4kd0sPAfovJfe+01W7x8/fXX7R4SG6VPkXKs3ApBWPsH7llkO8QvlmO/xX2PGjAUYQW+h9xPeO6HH34oeFuD7jHOvTd2ER8LIMYDZMolg8CAcuXKuVq1atk1W758+QK1VhSasPYRQojwICFfCCGEEDmHSHYEA0Rwz6M7mZBPBDGTWqLU/BANvLRt0qBjRY4qVaqYuIg3Pn62HrSfSTtCkh8LD55XbCZDOO+4IBQ/DhPDhg1zffv2NSHp6quvtkWdoHPrrbea6OWX5VO28N2hGDZZJZksPvjpgS2CAdHhXOfvvvvuJkXUGzRoYHZjLGrmmzD2DxS55b7122+/RfctX77cVatWzTLoeBwLkcR8L/24x4XNYzzbYrdiy/n000/de++9Z2NKz87m8MMPt1pMQSCMfYQQIjykzk8TQgghhO8w0c4WhA3S6P0C64N58+ZZkbp69eqlPJbINiIuDz30UOcXCBkrVqywSSETQqA9CPkTJ040K5tYT2EExX333deXthKV7FcBwpJA06ZN7ScRqdg7DBo0yMSBdBkPROH5CWIBNR6wHMFb3IuuDSJ8fyjGi70EgizfOb57CGJYaBAhvH79ejsWIY+FQVEyYXGXbCIKtLKo6gn4jRo1siLpLFxNmjTJxH32YWlBQfB8Edb+AWEemzjEcS8afNq0afazYcOGCb+jfononEsWnsMg4gNe/iyUiPxDnQci3RHyE8F3kcU+rA/9Iqx9hBAiPCgiXwghhAg4iFuZEBul7XcE9uDBg22ydfbZZ1vR22QR+QjlRFIi1jz88MOuc+fOvrS3T58+FkFFW0l7h6efftq1b9/eIqmIdEbY//jjj22SSOT+xRdfbNHEomR+32Lx+/vm8csvv1gxUMRMvnvpLJf8sqvhu37ZZZfZYhg2FfXr1y8S1crCHiI/EfsffPCB+aSff/75BW+n8AfuY1jo8Ll7Vjrsw5qEmiBY6cRG3mIpxfU0ZcoUs9jh2skXYe0fTj75ZOsXhg4daot+fMcaN27s5s6da5749BseCP7Y6tSsWTOpYJpPwuYxjj3YqlWrTMynD4vPOETM5drk2jn11FNtbETWgci+dgK1CbxxLjUTvEVeMiq9jC2+b/369YvWWSg0Ye0jhBDhQUK+EEIIEXDwX00FqfJEvxONSwQbkx3E54suusj5BZNXRABEOQS4a6+91p1wwgk2MSfSljT+V155xQ0ZMsREAyL4id7fbrvtfGkv5+/oo48uUsCWIRIWJTNmzCgSAc9+JuukdRM9LIoXCAWbQxC8nBG9e/bs6ebMmZNR1oZfdjVETCO2PvHEE9GFhET2FAgbLVu2dG+//bZFXCP4i+ILC7te9D2PvWkqnzvi/XnnnZfUooJi5WR24Jsfax+Ta8LaP4wbN861a9fOrO6aN29u9136Cxb6yHSI9WxnLMFCIIVmn3/++YK3NWwe4w888IBl7THm4tqNL8A7a9asIkEWLKAQxa/MuuxstViMgmOPPdbdeOONdh75vnuLKe+88467/fbbo2M2FgHJ/Co0Ye0jhBDhQUK+EEIIUUxYvHixieX4vTORIVrJTyhgySQKwSDZhJVhCGI4E3fE/KCBxz8R+IggWO/svPPOrkWLFrYPOx4hggILYViLeAVjETgoIp2uH1i2bJkrNLTr119/tcwWT5hFyKdOxurVq4scu2jRIlenTh3Xtm1by5IRxRMilYnCJlKc65frok2bNibgZ+p7z72PflqRrckLpY8aNSr6bwrSs3CCwB8L5x0Bf8SIEe7yyy/3oaXh8hg//fTTzfKF65dFklgbvjPOOMP6Ns4xUfhjxowx///YRUyRHhZ2sIzDTuvZZ59NOabkXjF+/HgbD/OZCCFEcUNCvhBCCFGMwKbizDPPtPT5a665xu/mWLo59hjPPPNM1PPagzR0IiyJoIpPRxdCZAffe77/1NTAkoRI0M1J8S8ELDKUKVPGrIBiRUWihRMVvmUBDVsVRFpRPPGuVTK5LrnkEotu5nPPBu55WGwgkorEzJ492zJ2iMAn4yy+Bg+Rzd27dzexGRHdj1obnsc4wQBkV9BfBNljvEaNGlaTiNoeu+yyS3S/Jyhfd9117rbbbrN92Bh169bNhGmizEVmYLHEtfDtt9+mrU9ENg+BFlzjsfcYIYQoLkjIF0IIIYoRXoE6otvxcw8KGzZscO+//77ZZhAtiXBPlGWQo+yCgCdoVKlSJSpOefuyQYXUij94WiMkzZ8/3x122GEuyFSqVMmsUGItUBBnWPijXoZXcBq86Gx+xi8GiuIDEctE37MAJUo2YfMYR7xn7EWGUaI++csvv4wuiLBQyYIEz9HXicxgXMuCDgt1mYB3PotS8Z+JEEIUB/zNuRdCCCFETsFGg8kO0WFBgjY1bNjQ72aEDiyS4KCDDtpkXzbIizd71q1b5x577DFLzcdDGpul2O8VIvRrr71m5zbemsKv9hLlHnQRHypWrGgLDmvWrIl6c9eqVcuEfKJUYy0nuN5ZCMR2RxRfKFYLsddEkAlb/xAmwuYVjjgfX7yWOkDYChIZHpvVQB+tSPHsIXNkyZIlJs6TzZkK7hfUaYodN/mB+gghRL6QkC+EEEIUI7744guLQMrWkiAfXrxMVu+8886MjqcYLpFW+PX6DVkDn3zyiU20sRdIRb49bj1BA0/x+H0if2DpgO9xbMHN+MUQrF6olYC4QHTl5mRK5JL999/fff755xaVikVNkCEbByEfiw+vgCHWQFOmTDF7FESxQw891LKKevXqZefe7/Mr8l8AmeuWguhBJ4z9Q5gI2z0O2xdE+9hFqGnTptnPRAEMXuakyBxsGCl+TI2Bzp07pzz2ySeftLEbr/EL9RFCiHwiax0hhBCimPDdd99ZIbB58+bZhABRzM/UeOxzEMUzgYg1vE/9LFKIeN+jRw83c+bMjI5nUsaEXBQvWFCiuCq2B0S3Eyl388032wJZ/PU5fPhw17t3b9ezZ0939913Oz+56667rCjkhAkTTBQPMohcFIVs3769CTOA8ML5prhtrODBVAXRC+Hf7whLkV97EoR8rEiCTFj7B1my5Q8WI4m6pjYRfTAFmxs3buzmzp1rnvhdunSJHovgj2hLLYhPP/3U13aHCe4P1HR477333IMPPmg1NBLB/cQrkM21m67Yez4Iax8hhAgPEvKFEEKIgEN0eyrwjaYI5IIFC2yyw+SbdN2TTjrJhUXIr1q1qr0Hv4R8IqKOOuoom2gxNCJ1GyuPdJPAZcuWFayNojDceOONVoAZ0QBxhmt5n332sUjh+OuTCPiDDz7YRAMW0PyEtvGdX7hwoRW9Pfroo11Q4TvGwh3fr9jChYhcV155pZs4caL1a/RlxxxzjAkc9evX97XNIr/wHeLapXYCVmxBJaz9Q6a+894iGt9RP33nw8S4ceNMrGUhigVK+rEPPvjAvPCxVIm1inrhhRfc2Wef7c466yz3/PPP+9ruMIEQjq3O/fffb30EdVbI4vHuHwSyvP3223ZfISOVgsLJLHgo4pxPwtpHCCHCg4R8IYQQIuAwCWBCncktm8hVRK904n/QhHzazXv0qzAZk3Am4xUqVLAIupYtWwbWnoTJLF7iTFI5x7HgCztgwADLxuAzOPXUUy0dPd6/VySnbt26FhVO5F+9evVsX7JJON/JUqVKmWDjdyQxQgcLeQgdeO82atTIHXnkkda2VORb1NgcyHRBDMN6AE9pUfzxIlNHjx7tLrjgAhdUwto/DBw4MOXz9BkIie+++64VCqVmAfdAP21uwuQxzphr1KhR0X/zuWMVGN+uNm3amIA/YsQId/nll/vQ0nCPgyGZVU2y/fHke3EqrH2EECI8SMgXQgghAk6HDh1STkyIasWWgMlDq1atTPzym0yFfCbiTNQRcEhFxlfUD2grwiECeNB9Sh944AGzACK1fOTIkUWea9KkiZs1a1aRCS0p/tOnT1fB2wxhQo2QjIjknbNkk3Agc4PrmAWWoAsdiVDErQgCfOfovxDAnnnmmWjthKAR1v4hG9srosWJLPczYjyZx3jsOWb/IYccYhl1Qbh3z5492+p+EIFPNDYFWmPhGujevbstuLKAGlsEV6SG6PtcjWEYD+WT4t5HCCH8R8VuhRBCiIATG+UVVIj2IyI4ltWrV2cc1c5kp3Xr1s4vmERh58BkMegQnQjxhdxefvll8/dH0OU5ovD/v/buBE7Hev3j+GVfsyX70rFEKcmxZEmWSBKRpXTkHEpFnaRSSULpVH+pE1KOsp1CtqhkTYgoS1mTkrFG9rWx/l/f3//1zP+ZMTNmaua57/vxeb9ez+sZ9/xm/Dxm7vu5r9/1uy7Vi9UxNX9L78a80UL1jbU4lpKggQJJ2gXhh6zxevXqsViDwFIpCv0Mq1eJFqQVoFVZpUKFCiV7HYn0jpKgnh9SSsHwf//73y7DXIvsF2ssml41xm+//fZEa4yH0/9Bly5dXCKArn9eB/L186pHUrSLbsSIERGdU7T48ssvLSii/RwBwHsE8gEAQJoI3+SX0lJAoZtblVJ45plnzCvKllJGfkrrCHtp48aN7lkBjnAffvihe92ffvppGzhwoDumuuKqFavPEchPGdXcVfkGZc8piJgc9aWIjY11jQu9FqRAB5CQSoKFXzeUmZ+SZqCRDuQH9fyQGir/ogatXgXy1bhbQfzwGuP/8z//k2jpPQX8FchXSSDADy6FcwQAbxHIBwAAaVL+J5TNrkCMMuMKFChgU6ZMSfJrdHOuMkBXXXWV5zXclQE6dOhQW716dVxNU7/SgkPOnDldOaXEtouHB160QKJA/vfffx/xeQaVfo51Ez5q1Ci3KHKxnSgKPjZu3Dhi8wuaUDZ1xYoV4wKzf6T/hF5nlStAdArKjpJL4fygmt3KEA4tGkfaJ5984l6311577aKL6xUqVLAsWbLEq50PeOlSOEcA8BY18gEA8DkFv55//nm75ppr7KWXXkp2rLLaf/zxR1emQIEzr1x55ZVWuHBh1zwvCJQ5dd1117nXbM6cOa7Mjl9pB4MWPlQOKGTr1q2uHm+pUqXcx+G0oHL8+HGX9YWU/b6p34QCWVqIUq3ohPVtVTaqZ8+erpa3flZUo1mvPS4UCsTpd2vDhg3xjqVGwvrYgBcuhfPDzp07rWTJkq4J/ZEjRyL+91NjHEF2KZwjAHiLjHwAAHxO9c2nT5+eouZ/Cp5rC3pKgv7pKZRlpJsVzclPtm3bluhxZU8pg13laJ588kmrUaOGCygkx4sbLwXmlZV/6NAh11Qv1KBQateufcF4BUQUkEHKqDa3FsK0KHbrrbe6HRqhRRP1HoiJibGVK1e6hoWietLcgCcttFNEu0gSHgOCJtrPDydPnnS7uESL216gxjiCLNrPEQC8R0Y+AAA+V61aNVfyRVlyRYoUSXas6sqqPqe+5ptvvjGvKONWN+IKNocH8Pzgj5T18FOpDy3oqG6wyg488cQTLuhx00032bJly+ydd95xtY1DFPDXQorqr6ak3jT+33vvvecWdMJ3PoTX8NYiyptvvknvAeASFLTzQ8Jm9An9/vvvtn37dndtUbPZUBJBwqbqkaByeypNovczoRrjSWXk633OjTfeaFWqVLFVq1ZFfK5AtJwjAAQHgXwAAHxON7IqixJ+M5Ac1Z1Xdppugr1SsGBB97xv3z7zm7RsaKsgeqRNnDjR7rnnHrcgoS3bCtYrgKHdA8r0CmXpy9SpU61NmzbWunVrmzx5csTnGnTK9NTW+CVLltiuXbtcEEmLaXXq1LG2bdta3rx5vZ5iIC1atMg9V67QmR6nAAA7lElEQVRcOd7PKyAqkTJ37lxbsWKFC96GroPVq1d35zyVF/ODIJ0fdN1LaYa7xvbp08c1IPZC165dXRBUWc2hGuNJBfLV7HbWrFkuYPrqq696Ml8gGs4RAIKDQD4AAAFpPBfKkktJ6RXVllWGnVfq1q3r6uMfPHjQd2VdFOxOK6VLlzYvdO7c2UaPHh3vZ0SBDwX4w7Vv394F8N966y3r3r27BzMFLqRAoRaiFJhL2LQZl7YRI0a4njBJLQJrkVhl48J3HiFlDTiTC+RrB51+F1Xbu127dla+fHnzCjXGAQBIGoF8AAB8rkSJEi67Xjexl19+ebJjFexX5qIeXmbkjxw50mXVDR482Hr06OHZPKKZMryWLl3qMpobNWrkmt0mzGp95JFHXB3Wvn372l/+8hfP5hq0bHFl/KpcQ0qotIMWzerVq5fuc4sWChgqkO/HHTvwjrKvBw0aFFd6QmXidP2THTt2uPJyooD0U089Za+88krE58j5ITJUOk41xvV/rRrjapStnYlanA6vMa6fFZWU0/sNwA84RwBIbwTyAQDwuVatWtmMGTPiaqInR0GQXr16uTrqn376qXlJ24Y17zfeeMPdZCvjDwhCtriyP0NBw4vRAolqS3vRLyGoVCJlzZo1duTIEZdNCyxcuNAaNGjgPr7rrrvsxRdftIoVK8Ybo6xrZetrl5ECvF9++aXrDxJJnB8ihxrjCCLOEQDSG3fUAAD4nMqlTJ8+3QUwrr32Wrv11lsTHac6scq81o3uvffea15S6ReV1FGQ7tFHH3XzUvBOOwWSajareevG3QujRo2yhg0belYqB/6S2jwX8mJS5+6773YZtR999JF17NjR6+nAB4YNG+aeu3TpYv/5z38SHVOhQgX3M6OyOrpWDB06NOKBfOH8EBn6WVAGPjXGETScIwCkJzLyAQDwOV2qVd928eLFLtNHzd2aN28eF3TWNvNPPvnEZs6c6ZqvanuuMhX90FgvJW8zQuP0nLCRXaTnq9dUWaGhh0o74NKinwUFihQ0SgktTimz3MueFEGjzMObb77Z1q1b52pcawcRLm0qofPrr7+63zv9TiVH9dGLFSvmsl5VcieSouH8oNdPuxoSayas3RCFCxf2eopAYEXDOQKAvxHIBwAgAFT7vmXLlq4melIN63RJV5PZadOmXbSWfnr7+9//nmxjveQy472gTM/NmzfH/Tk097Jly7qAvrL1tZhCgCP6peYmXKU+rr76aheE3LZtW0TmFw0GDBhgJ0+edFnYx48ft0qVKrkM2+R27Ih29iA6pbapu65x+tmJdPAryOcHLZRrZ59616i+vIRCAaFrXpYsWVwJP/2OJve7mJ6oMY4gC/I5AkAwEMgHACAgdBM+evRoF+z+9ttv427EdeNdo0YNtw1dZSq8uvkOOt10LViwwL744gv3vHXrVnc8fEFCNZtD2foK7Hu9YII/T2Wr9AjR71iOHDlcSYek6O3zoUOH3C6ZgwcPulIxH3zwQYRmHHyJ7dhJycKfVzt2kP6uuOIKVwtdmakK6idHi0AqqZInT550b5gcTecHldybMGGCm5/K3lWrVi1eM2Fl6KuhrH4XO3ToYOPGjfNkntQYR5BE0zkCQDAQyAcAIIAU0FLmom64CxQoQPA+HSiQr4D+/Pnz3fPu3bvjBRwVbAgtpiC4+vfv7x4pLQWVWABSN+NXXXVVuswvGmkR7I/s2NHvIaJTo0aNXEm4IUOGWLdu3ZIdq50c6r2iBVWdn9NTtJwfPv74Y2vdurX7uGfPntanTx/XLDacFlIGDhxogwYNcv9e7e5r0aKF70uTKJCvbGYW+uCFaDlHAAgOAvkAAAApMG/ePFeWYPny5e7PXtb0R9pRJp2CXCFjxoxx2XTt2rVLNtCkbGA1n1ZN6YQBMQCp8/7779v999/vMsXVxFY7zBIzcuRIe+SRR9wiqhreqoxbeoqW88Mdd9zh+uj07t3bXnzxxWTH6jqngL768aj/TqRRYxxBEi3nCADBQSAfAICA03bytWvXuhuDypUr/6FMV1xIJRtUZif0+Pnnn93x0Fsn1fXW647oktogEoA/T43alZW/cOFCdw1TyZfwhuMq/aIdGSq3EmoAr2z8SF/vgnp+0Jy1i0/XNZUlSo4y81U2rmDBgq4BcaRRYxxBFtRzBIDgyOz1BAAAwMVvVCdOnGhXXnml3XffffE+p1IEqmW7Z88e9+eSJUvahx9+aLVr1zY/UBBAmZZfffWVC8SoOWFSOQQKyISC5V5QRp9ez1Dgfv369e54aL7lypWLa3yrZ2UBIvooWKhGi0g/Y8eOdRmLbdu2TdH4qVOn2rFjxy44/yG6gl/KbO3cubP7/1bN84Q12kPnYmWwKhvfi0XroJ4fVIdbAfyLBfElNE5f40WN8dBign4WUlJjXD8HN910UwRmCkTvOQJAcJCRDwCAzz333HP2yiuvuBqcqmsboptsBZcT3mzrBnzjxo0uI8hLqq/bqVOniwbvQ5/zslSNmgWvXr3aZYWG5lOqVKl4gftQU0BEt1OnTrkFKN2IJ/wdUjC5X79+NnfuXBd4bN68uStVoaA0Uo5mlkjON9984xav1Xx179697pgWTtWcVU0hq1ev7tncgnp+CGXk66GSHn7KyKfGOKJJUM8RAIKDjHwAAHxO2eGhLMRwykhUEL906dKubrBuBB5++GFbt26dvfXWW/byyy97NGOzDRs2uJ0CsbGxrs6uHmpgqEWG119/3d3kqOa8MuAVLNCNTa5cuTybrwJGCiIowNGjRw+X+avgIS49+l1SI00tQmk3STj9HGt3SSjYtGbNGhdAUgYeJa1SJ7UBO3KPLh1aWNXDj4J6ftDih2rkv/HGG/bCCy8kO1ZjtKithZNIqFKlins9Q6gxjiAL6jkCQIAoIx8AAPhXyZIlz2fMmPF8bGxsvON169Z1x8ePHx93bMmSJeczZMhwvmrVque9dP/997t5dOzYMe6Y/ly0aNF442bOnHk+V65c52vUqHH+1KlTHsz0/+cWeug1rVix4vlu3bqdnzx58vl9+/Z5Ni9EXosWLdzPwNy5c+Mdnz59uvv5yJQp0/m//e1v5x944IHz2bJlc2PHjBnj2XyDKLFzQXIKFChwPnv27Ok6J3grJibm/I4dO1I8fufOne5rIi2o54cpU6bEza9Pnz7njx49esGYI0eOnH/uuefcnPWYOnVqIM4PgJ8E9RwBIDgorQMAgM8pMy1nzpxuS3zI6dOn7bLLLnNZPQcOHIiXza7tvPoabY/3Svny5W3Lli1ud4Aa0SXXAOzdd991OwleffVVe+qppzyZr3YIaOeDsqL0/Msvv7jjypDSQ1l/KrGjx8033+xee0QnlWdQrwY1hcyfP3/ccZX0mDRpkj3zzDM2cOBAd+ydd95xO02aNGlis2bN8nDW0dsM8Ouvv7Y6depYmTJl7KefforI/BB5QSm3FOTzg+b40UcfuWta9uzZXZZ+eDNh7Uz7/fff3fuK9u3b2/jx4z2Zpxoe631MrVq1PPn7gUv1HAEgGAjkAwDgcwrSq3a8brDDawjfeOONbuu7Pk5YL/bo0aPxxkeaFh40Z5XWCcmUKZPb/h6+ICEnTpxwJXcqV65sK1euND/Ytm1bXGBfDwU5RAEQ/TuqVq1qjRo1irsZQ/TQjbeCg/odCle4cGF3Y65gcqjskvo/aFFHn9u9e7dHM/Y/lcrQI0QltRSoS64pd6iZpZpO61xy//33u0U/RKfULO6Ifgd1no50X5Ugnx+UAPDss8+60nuhBZBQOY9QSCBz5sz22GOPudJ8WbJk8WSe1BhHkAX5HAEgGAjkAwDgcxUqVHBv/MOz21Xj9sUXX3Q33KpnG6LLujLtFMwPBZ+9oIC9ggC//fZb3DEF63XTogUGBQvCFShQwNXkVeDOjzZv3uwC+qNGjbLly5d73pwX6SexHS1bt251GeFqgKyPE/7s6uc6fNEKiTez/DPnQC2sKWMb0Sm1gXz9LGg3WqR/76Lh/KDXeMqUKYk2E1a9+WLFink6v7fffjvJGuPaERdeY1zX4Ztuuoka4/CNaDhHAPA3mt0CAOBzunFVIPmJJ56w0aNHu5twbcfVTWuzZs3ijd20aZPLuvP6Rlx/v7YWKzivAI1ceeWVbjHi+++/t7/+9a9xY9WwVwF8LUD4jYIcCiCGHiq5o9edPIjopZtqLUDpZzLUQDHUcDqxDHJl3uXOnTvi8wyS+vXrx/uzgvp6zXROS0kzS329dsIAomugfkcVfI60aDg/6PqsQLlfzZ492z136NAh3vEZM2a4xqA6N+hzCpaOHTvWHRs3bpxrUg94LRrOEQD8jUA+AAA+p2CXblJ1cxvKSFUguUqVKta4ceN4Y0M1NmvUqGFe1wjVosIPP/xg11xzjTumOtdr1661QYMGxau926dPn7isW6/pxktlP0KB+40bN8Z9LhS8L1GihDVo0MA9EH1UNkm/a++995773dNilD7WAk7C/3PdrKvUQ2inDJJejNQjYSBfO4twaVq0aJE714bT79KAAQMuWm5p5syZ7uOaNWtapHF+SH+h6274gr98+OGH7nV++umn48ra6f9DNcb1OQL58APOEQDSG4F8AAB8TgFuZaKpIawayCob7ZZbbrGRI0deMFalX8TrILPqx2vOWlgIBfIfeughGzFihGu2p4D+9ddf755VA1s3OJ07d/Zsvr169XKBe+0W0E1XeOBetUuVEazXVM1uy5Ur59k8kf5UzkE/t2pIN2/ePHejvWrVKlfHtm3btvHGKhNUuAlPHe1sIcP+0qZSKFrQCS+HovISKSnBFCohp3rvkcb5If3pNVWfnfBGoaGfGVG/jJCOHTu6QL6u3YAfcI4AkN4I5AMAEADKvFedfN0Q6GYgsTI0KqmjJnZSvXp181K7du3cjUt4w101s33zzTft8ccftw0bNrhHyD333OPpVn/tEgjfFq3sYQXtFbwPLUTg0tC+fXuXTacyVqESD/p9Uzmr0Db5kIkTJyaaZYfklS5d2uspwGMqtRa+S2PhwoWur0qtWrVSVG5JwTIvFlWDcH4I7WooWLCgC3KHH0utvn37WqRpQSdh81rVFdf7H9UYDzUKlVy5crnXXf0SAD8IwjkCQLDR7BYAAESUyu1MnjzZtm/f7hrgNm3a1AXNvdSiRYu4cjnaKUDTPCxZssSWLl3qbry1w0SN6sKdOnXKHnnkEbeApmBXeHAJKaMs2mHDhrnmlWrOrQBeUvQ7qVrCiE6pbXbrNT+fH/Ra6vdFu/lCC+ahY6nlRUN3/RwoaL9///64wKea3ioT/+6773ZldMJpcUeLQBoP+IWfzxEAgo1APgAA8K2dO3e6QIKy8IJg0qRJdvLkSWr1AhcxZMgQVz9Yv98puR1RENKLoCIiY8yYMS4LW7u58OeoFJx+X3Td1Osafiy1QuVsIqlZs2Yuk/m1116LqzF+00032bJly1xW8wMPPBA3VgF/lb9TaRKV6QMAINoRyAcAIGB06T548KDLXk3uMh6U4Hdy1NxXN+pBycQN2nwBLyxfvtxq167tPlbpj9tvv90F71TWSj00fv31V1dbWJm3yrZVyTD9boWXYgEQnVRuROX21EdD/YDCa4zHxMTEK08ydepUa9OmjbVu3drt9AMAINpRIx8AgID49NNPXUDr66+/thMnTiQ7NprKUAQt5yBo8wUiTecx/Z706NHDBg8eHHc8a9ascWW2OnToYP/85z/t1ltvteeff94F8nBp0k6M4cOH29y5c12JmObNm1uXLl28nhbSCTXGAQBIGhn5AAAEQK9evez1119PVZBY29GDTlm4e/fuDUxJjaDNF/Cq0al6ZGzZsiWu8a0CtCqRsXv37nhjlaGvuth9+vT5ww074X+qga6SKcquVnA2nMrtTJkyxX2sa6ACt23btrUJEyZ4NNvgUeN5BcODhBrjAABciEA+AAA+N2vWLFd2Qs3c/vWvf9ltt91mlSpVsiuuuMJl56sMhTIVVXNawbBRo0bZtddeGxcgC7KgBcaDNl/AC6qFrmBs+M6izJkzu9IZKhsWTkG63LlzW/ny5W3dunUezBaRoMUa9RhRqZSWLVvGHf/yyy/jdmnUqVPH/ezMnz/f/TnhWCRNwXAtknTs2JESVQAABFhGrycAAACS9+6777qgl8pL9OzZ0zV1E9WPVYaaak2/8MIL9t1331nevHldyYFs2bJ5PW0ASFTOnDndI5yC+EeOHLHY2Nh4x7WAqbGqjY3opetXKFgfbuzYse5Z2fqLFy+2OXPmWP/+/V1mvkqvIGX0u6VFfi2KKHNd7yd+/PFHr6cFAABSiUA+AAA+980338QFMsIl3FRXokQJGzp0qMsIf/XVVyM6RwBIqeLFi7vAYngfj7Jly7rnb7/9Nt7YXbt22eHDh+k9EeX27dvnFqALFiwY77iaHmshW/0SQrp37+6eV6xYEfF5BtXIkSPjMvG1KPbyyy+7pIAbb7zR3n77bTtw4IDXUwQAAClAIB8AAJ/bv3+/y0hV/egQZeMn1vC2cePGrg7uZ599FuFZAkDKKICo8lNr166NO1a/fn0XrFcdfNXzDtXADgVwr7vuOs/mi/SnhZ2ENdzVL2HHjh1WqFAhV04uJH/+/JYnTx777bffPJhpMHXu3Nm++OIL27p1qw0cONAqVqzoft+UKPDoo49asWLFrHXr1jZt2jRXzgoAAPgTgXwAAHxOAQuVlwinEjrHjh2z48ePxzuuGvmqNb1z584IzxIAUqZJkyYuiPjJJ5/Ey7JWRrbqn2t3kUqsKHNfgUVlZKupJaKXrmnaeRG+QL1w4UL3rPJxiQla81Y/KFmypD377LO2fv16t6NBC2Xqt6NFs48//tjV0VevF/0+Llu2zOvpAgCABAjkAwDgc6EyFKEsVbnqqqvc85IlS+KN3bx5swvwK5gPAH501113ub4eygIOUd3uDz/80NXKV5kPNfLWbiQF8Xv16mX33nuvp3NG+lKDdvnoo4/i1cfX/3/C5qwK+OuaWKRIkYjPM5pUrVrV3nzzTbfwr1187du3d4sj+v0bPny41a1b1+spAgCABLjLBwDA5ypXrmxr1qyx1atXW61ateJK6Chbrnfv3u7zCmiozIDq6CvwUa1aNa+nDQCJypcvnwvkJ9SqVSsXtJ05c6Zt377dZWkre79cuXKezBORc88997gMfGWCL1++3H799VebNWuW26XRrl27eGO1yCPly5f3aLbRRaX6brvtNvf46aefrEOHDi5bn74UAAD4D4F8AAB8rmnTpjZu3Di37T0UyFewY8iQIS64X6pUKbc1fs+ePXE33k899ZTHswaA1CtQoID97W9/83oaiLAuXbrY5MmTXXPbESNGuGuZFqVfeumlCzLvJ02alGimPv6Y2NhYmz59unufMWfOnHhNqAEAgL8QyAcAwOfuvPNOGzVqlGvwF6Lmf9oKryzGbdu2uaaAkitXLhs0aJAL/gMAEJSscGXgjx8/3pYuXep2bTRr1sz1SginWu663tWrV89lkOOPW7RokQveawFFpYpCiQBaOFFW/n333ef1FAEAQAIZzrNnDgCAwDp79qwrMxAqQ6GatmqOGy2qV69u+/bts19++cWC4LHHHnMBES28AADgJz/++KPrPfDBBx+4JABROCBHjhwuaUDBe5Xuy5iRVnoAAPgRgXwAAICLUP+Br776ygU3VM5B2aIAAATB0KFDXfa9at9LqHSRrmcK3rdp08Zy587t9TQBAMBFEMgHAMDnlixZckF5AaQtBTfefvttq1Spkj3xxBPxPjdhwgRXv/n333+PK180ZswY15gTAAC/C8+wr1ChgnXs2NE9SpYs6em8AABA6hDIBwAgADfgZcuWdTfdagJZpkwZ81tt47Sg7ECvmuz17NnT/v3vf7v+Ao8//njc8V27dln58uXt5MmT8cZny5bN1q1b5/5fAAApN2DAAPdcsGBB69atW7xjqdW3b980nVu00mutnjrKvlfJOgAAEEwE8gEACEgmnQLdUqtWLevUqZO1a9fO1cX3WlrV0tW/TzX/vVCtWjVbvXq1qx8cHpzv16+fCzBVrlzZpkyZYtmzZ3eLKWoS+Mgjj7jgPwAgddcMne+VGb5hw4Z4x1LLq2tG0GiRPHPmzF5PAwAA/EkE8gEA8LktW7a42rZqTvfTTz+5Ywp4ZM2a1e644w6Xqd+sWbM0y4xPrYULF6bZ91K9Xi8UL17c9uzZ48rnhAc7lLm4atUqmz59ujVv3twdW7NmjVWpUsWV4Vm7dq0n8wWAoKpfv767hpUqVcqVKQs/lloLFixIhxkCAAD4E4F8AAACZNmyZTZ27Fj76KOP7MCBA+6Ygh+hbfPKFld2OVJHmfZq9Ldv3764YyqnkydPHsuSJYsdOnTILZyEj9fxo0ePejRjAABSb8aMGTZ79myLiYlx17n58+fHfe748eP2/fffu/cV2v0HAAD8hUA+AAABdPr0aZs5c6YL6us5NjY2LpuxYsWKrg7u008/7fU0A0NB/FOnTrlHiMrnKEu0bt267uNwWjhRwCNh7XwAAPxo+/bt1rp1a7fLTBQGSFjSTu8typUrZzt27LClS5dazZo1PZwxAABIKG2K2gIAgIhSNnjLli1d3fbdu3fb8OHDrXbt2u7GfOPGjda7d2+vpxgoV155pQtmfPvtt/GyFhXkqFOnTryxGnf48GErVKiQBzMFACB1tPDcpEkTW7lypSsl1717d8uVK1ei7y26dOni3ktMmzbNk7kCAICk0fEGAICAy5cvn7vxvuKKK1yNd92o+42CAgcPHnTBhOQ2A6pmshcaN27smi4quDFkyBC3ODJixAj3OfUhCKe6+ArmlyhRwpO5AkC0+vnnn13pOPUiUfk4ZYgnRQut4WVhkLRhw4bZpk2brGrVqq6vjYL4kyZNshMnTlwwVkkCavS+ZMkST+YKAACSRiAfAIAA+/rrr10jXAU+FCgPUVDfDz799FN766233DwTCxgkDMqcOXPGvPDkk0+6potaBNHOBtGCQ8OGDeP+HPLZZ59RPxgA0lj//v3tpZdesnPnziW74BvyR5rjXqq0e0+v1+DBgxPNxA937bXXWqZMmezHH3+M2PwAAEDKEMgHACBgtmzZYv/973/dQ9mLoqBHtmzZXPa46uPfdtttXk/TevXqZa+//nqKAjLiZdselRpYsGCBPfHEE27RQbscmjdvbq+99toFcxw1apR7btCggWfzBYBo8sEHH7hAvhQrVsxuvfVW95w5M7eraUHZ+ArOJywVlxiN0zVQTd4BAIC/0OwWAIAA0A21su7V3FaBZgldwnVjruB9u3btLG/evOYHs2bNsmbNmrl6u//617/cwkKlSpXcTgHN/9dff7W5c+e6MjYZM2Z0wXFlAZYuXdr8TCV11AQwFPwnyAQAf552Pi1btsxatGjhrnVZs2b1ekpRJUeOHO41VX+XkKJFi9revXvjNbsNUda+rm/h4wEAgPcI5AMA4HNt2rRx5VxOnToVF7wvW7asdezY0T3+8pe/mN+0atXKNYtVhmWfPn3cMQXsixQpYrt27Yobp6C4MtuPHj1q3333nfs8AODSkidPHtdDZfv27S4TH2nf0F2v7f79+122fXKB/PXr19t1111n11xzja1bt86jGQMAgMRkTPQoAADwjalTp1psbKy7+X7wwQftq6++ss2bN1vfvn19GcSXb775xj0/8MAD8Y4nzB9Qw9ihQ4e6YMKrr75qfqF57tu3z7Zt2+b1VAAg6ql+u4L5BPHTR926dd3zxIkTLzpWJeX0/0H5OAAA/IdAPgAAPqdSA5MmTbLdu3fb8OHDL2i+6kfK+suZM6cVLlw4Xt3dxBreNm7c2LJnz+52HXht1apV1rp1a1eiSHMvU6ZMvM+robAWUx566CE7efKkZ/MEgGhSsWJFd33QojXSXrdu3dwCdb9+/ZLMsteuv2effdbGjRvnAvkPP/xwxOcJAACSRyAfAACf+/jjj+2uu+4KVM1gZVaqPn44BcePHTvmyieEU8kd1eLduXOneUnBi1q1arnXW/NU0CPhDoL8+fO7BsP/+c9/bPr06Z7NFQCiyf3332+nT592i9ZIe0oAePTRR23Pnj124403upJ9us5J79697d5777WSJUvGNXhXSTyV1gEAAP5CIB8AAKQ5NYI9cuSI/f7773HHrrrqKve8ZMmSeGNVJkgBBS8bx27YsMGVAVIg6Z///KetWLHCChYsmOjYTp06uQD/559/HvF5AkA00vlXu890/l20aJHX04lKb775pj333HNu14NK9oUW1VXWbsKECfbbb7+5nXPqbaPMfQAA4D/e3TEDAIBUUfB42rRpNn78eBdoVl15KVSokFWvXt06dOhgLVu2dFvivVa5cmVbs2aNrV692mW5h0roLFu2zGX/6fNqbKvAgQI4mnO1atU8m+/gwYNdWYHu3bu7YIcooJGYRo0aueeVK1dGdI4AEA0GDBiQ6PHrr7/eFi9e7Gqz16lTx2rWrGmXXXZZst9LvWKQMrrOvvjii273w+jRo92iuprPq9mtrsd6zTt37nxBSTkAAOAfGc4n3DMOAAB8R9vhtRV+6dKl7s8JL9+h4L1uxD/66CN3U+4lLTZoq/5TTz0V18RWCw+qg3z48GEXJL/iiivcvyv0b1GN/KZNm3oy37Jly9rWrVstJibGNeCVokWLujkryJFQrly53A4C/VsAACmncmrJLTiHrgkpWZRO7PyMC4Uat2vhXz1pAABAMBHIBwDA55QpXqNGDVu7dq0LcOhjZbeHAs47duywefPm2fLly13gQ9nu33zzzQU16iNJjWC1oKCa8iqXEPL111/bPffcExdUCAXFBw0a5JrIeiVHjhzu9VI5oJDkAvlahFAQX/83AICUq1+/fprtHFuwYEGafJ9LYfFED117ixUr5vV0AADAH0QgHwAAn/v3v/9tjz/+uGsg+9///teaN2+e6LiZM2e68jpHjx515WHU2M6PFBhXQH/79u2uAW7dunXdv81L+fLlc/X8tQARCjAlFchXfeHcuXO7RYpQeSMAAPzegH7//v1eTwUAAPwJNLsFAMDnlNmu4PKwYcOSDOJLs2bN3Bit0atxnV+prI6C98rM15y9DuKLagKr0e2PP/540bGzZ892wf1KlSpFZG4AAPwZV155pZ04cYJSRAAABByBfAAAfG7jxo0uk659+/YXHasxWbNmdV/jJW3hVw35n376yYJACwpaAAk1uk2Kdjs888wzbmElvGQQAAB+deedd7pScNq5BwAAgovSOgAA+Jzqt+tx4MCBFI0vUKCAKxGjh1dU916LD4cOHbIg2Ldvn5UvX97VyO/du7c98cQTdvXVV8eV1tFr+fnnn9tzzz1nmzZtcmV3lL2vfycAAH52/Phxq1q1qh07dsxdy9RLBwAABA+BfAAAArAlXvXkf/nlFytVqlSyY7du3erKxGicPvZKhQoVXBNeBQ+CQg2DW7Zs6WrlazfBuXPn3KNw4cIu0K+Avt42qT6+yuvUqlXL6ykDAHBRY8eOddexfv36uWtc06ZNrU6dOlaoUCFX7i4p9913X0TnCQAAkkcgHwAAn9ONtJrctmrVyiZPnhzXjDUhXdLvuusumz59uv3tb3+zMWPGmFd69uzpmvR+8cUXdvPNN1tQrF271nr06GELFixI9PP169e3IUOGUB8fABAYKncXeu+g9wpJvY8IpzFnzpyJwOwAAEBKEcgHAMDnvvvuO/vrX//qPq5Xr5716dPHPat0jahJ68KFC+2ll16yRYsWuRv2FStWWJUqVTyb82+//WbXXXedK/Mzf/58V4omSGJiYmzJkiW2a9cul4lfpEgRl71Yrlw5r6cGAECqd/alJHifkHYCAgAA/yCQDwBAALzxxhuubnvoRlylXwoWLOg+1nZ5Zc2FLumDBw92WeVe0oLC5s2b7fHHH3fb9jt27JiibfxaoAAAAAAAAPERyAcAICA+/fRT69Wrl/3www+Jfv6aa66xV1991W6//Xbz0zb+lPJyG78WHlhEAAAAAAD4FYF8AAACRnXcVTpn79697s/Kcq9WrZorZeMXCuT/EWou69V8K1asaF27dnU9CVQSCACAaLR+/fpE30fQ/wUAAH8jkA8AgM8NGDDAPf/jH/+wkiVLej2dqBRaeNCugGzZsrmmwQ888ABZ+gCAqNrZ17t3bxfIT4wC+eq306JFi4jPDQAAXByBfAAAfE415fU4fvx4XINbpK2ff/7Z/vOf/9iYMWNsz549cWWBKlSoQJY+ACAqkgL69+8f109HvXYuv/xy9/H+/fvjStvp+vf8889bv379PJ0vAAC4EIF8AAB8rnDhwnb27FnX1BbpS4GMGTNm2IgRI2zevHmu1A9Z+gCAIJs1a5Y1a9bMfaxrWJ8+feymm25y1zY5deqU6xXz8ssv25dffumuezNnzrRbb73V45kDAIBwBPIBAPC5Jk2a2BdffOEyxUPZc0GiYPjKlSstJibGTpw44bLbg2Dbtm0uS3/06NG2c+dOd0zBDbL0AQBBex+hxem2bdvahAkTkmxGr9DA3XffbZMmTbLGjRvb7NmzIz5XAACQNAL5AAD43JQpU9zN97PPPmsDBw60IBkyZIirtxu+m0C7C0IOHjzosgKVCb9w4UK3+8CPCxGfffaZjRw50mUoav7hWfoPPfSQ1alTx+tpAgCQKC06Hz582C1QFy9ePNmxO3bssFKlSlm+fPnswIEDEZsjAAC4uP/r7AYAAHxLweKePXvaK6+8Yr169QpMiZ3u3btbjx497LfffrPLLrss0QzA/PnzW9WqVW3z5s0uA9CvjXDvuOMOe/jhh61mzZru36E8iN9//90++OADV6ZAgfxvv/3W66kCAHABlc5RYP5iQXwpUaKEuzafPn06InMDAAApR0Y+AAA+17BhQ/e8YsUK1/BWgeVy5cpZoUKFXBPcxCjYPH/+fPO6Hq8C+GPHjrWWLVta0aJFbe/evfEy8sPHtmjRwj7++GPzk927d9t7771n77//visNFHrbVLduXbdLYs6cOfb555+7rH01IlYZgvr163s9bQAA4lSuXNk2bdpkR48etaxZsyY7NjY21vLkyWMVK1a077//PmJzBAAAF5c5BWMAAICH1HgunALhuiHXIylJ1b+NlHfeecfNYcCAAS6In5xatWq557Vr15ofKFivEjqqjx8qpaNjCmx07NjRldKpVKmSG/voo4/ali1bXLb+3Llz7fnnn7fFixd7/U8AACBOhw4drHfv3m5h/f7770927Lhx41w2vr4GAAD4Cxn5AAD4XP/+/f/Q173wwgvmlVD2/aFDh1xWfvixhBn5oi3/Chxox4FXVBc4lH2vj0NvkVT6R8F7BTVy5syZ6NceOXLE7ZBQ3XzVIQYAwC90fW3UqJHb2Td8+HDr1KlTouMU6Nf1rnr16m5XX+bM5P0BAOAnBPIBAECaU0A7V65c8RrlJRfIVyO+kydPuocXmjdv7sriqESO3hopYN++ffu4gEZKXHnllbZ9+/ZE/30AAHhFu+NUJ3/YsGFu4blkyZKuDFyoZv7OnTtdw3k1w82bN69169YtyRI8ffv2jfDsAQBACIF8AACQ5q644go7ePCgC8yrdnxygXwF+zW+WLFiLhDuBfUdkKuvvtoefPBBl62oYEZqPPnkk7Z//34bNWpUOs0SAIA/do0LldwL3f4nLMGX1PGEWKwGAMA77JUDAABp7rrrrnPZfcuXL3eNYZMzfvx4F0CoVq2aeSWUfX/zzTf/4e8xaNCgNJ0TAABpoV69ep73zgEAAH8eGfkAAATIypUrbcKECa7OrbLbRbXZFQRXMNrLYHi4t99+2x555BFr2LChzZkzx2UDJpaR//3337vt/drqr4B+u3btLMgef/xx929RrX0AAAAAANIKgXwAAAJADVS7dOli06ZNc39OePkOZdrdeeedNnLkSMufP7953VjvhhtusI0bN7pAvQLcnTt3dqVnfvjhB9u6dat98sknLuCt8ju1atWyr776KvAZg8n1AQAAAAAA4I8ikA8AgM/FxsZa7dq17bvvvnMB/BIlSiTapE715RUIr1Klii1dutQ1nPVSTEyMNW3a1DZt2pRkgF7/HpXhUaPZIkWKWNARyAcAAAAApAdq5AMA4HOqvb569WrLnj27DR061P7xj38kGhgfPXq0devWzQX8X3/9devdu7d5qXTp0q4UkOby/vvvu8B+OC1EPPDAA/bEE09Yrly5PJsnAAAAAAB+R0Y+AAA+d+2117oSNcOHD7euXbsmO3bEiBGuaevVV19t69evNz/ZtWuXeyhbXdn3CvRHGzLyAQAAAADpgUA+AAA+lzNnThcYVhPVi5XLURmePHnyWKZMmezEiRMRmyP+D4F8AAAAAEB6oLQOAAA+lzt3bhcYTknNe43ReAXyAQAAAABAdCCQDwCAz/31r3+1OXPmuLI0xYoVS3asGt8ePHjQbrvtNvOLc+fO2ebNm+3AgQN2+vTpZMfWq1cvYvMCAAAAACAoCOQDAOBzPXv2dIF8NYUdP358smOffPJJ1whXX+O13bt327PPPmuTJ0+2kydPXnS85n3mzJmIzA0AAAAAgCDJ6PUEAABA8ho3bmxDhw61qVOnWqNGjWzBggXxMtsV/NaxW265xaZNm+bGapyXtHugRo0aNm7cOFerXy15LvZQ5j4AAAAAALgQzW4BAPCRMmXKJPk5NVENZbZnzpzZChYs6D7et29fXCa7GuNeccUVLrv9559/Nq907drVRo4caZdddpkNHDjQWrZs6coCRXvtfprdAgAAAADSA4F8AAB8JGPGtNksp0C+l8HkkiVLuqz8iRMnWps2bexSQSAfAAAAAJAeqJEPAICPjBo1yqLBb7/95nYN3HnnneY3M2bMsOzZs1uTJk3S/HuTHwEAAAAASA9k5AMAgDRXqlQpO3LkiB06dMj8uOtBmfM7d+6MO9awYUO7/PLLbdKkSX/qe3/00Ueu/FGnTp3SYKYAAAAAAPwfAvkAACDNde7c2caMGWM//PCDlS9f3vwWyC9SpIgr/ZPcMQAAAAAA/CJtCvECAACE6d27t+XKlcuefvpp8xs1BD548KDX0wAAAAAAIMUI5AMAEBA7duywnj17WqVKlSx37tyuBn04Badffvll+9e//mVnzpwxL5UrV87Vol+4cKE1btzYFixYYMePHzc/uOqqq+zUqVM2ePBgO3HihNfTAQAAAADgoiitAwBAAMydO9fatWvn6s6HLt0ZMmSws2fPxhtXo0YNW7lypU2bNs1atGgRkbllypQpTb6P/j2RWIBQAP/JJ590f1+IXtPwP/tpvgAAAAAAkJEPAIDPbd++3dq0aWOHDx+2O+64wyZPnmz58+dPsja9gtKfffZZxOanvy+tHpHQo0cP6969u9vREP73+nW+AAAAAACQkQ8AgM8p8PzWW2+5jPwJEya4Y0WLFrW9e/dekJH/yy+/WNmyZa1KlSq2atWqiMxP5XPSys0332yRcuzYMdeMVyV/GjRoYAUKFLApU6b4dr4AAAAAgEsXgXwAAHzu6quvth9//NEFncuXL59sIF9y5Mhh2bNnp6FrKmTMmNGKFCliu3bt8noqAAAAAABcIH6XPAAA4Dvbtm1zwflQEP9i1AhXZXiQcqNGjXKvMQAAAAAAfkRGPgAAPnfZZZe5zPsTJ07EHUsqI1/NV3PlyuW+Zt++feYnmuuBAwfcxypjk1ZNcgEAAAAAiHZk5AMA4HOlS5e2jRs3usz8UqVKJTt20aJFdvr06RRn76c31Z9/5513XG3/NWvWuIUGUaPZypUr2913320PPvig20UQKWoIHFoMGThwYLxjqZEhQwZ777330nx+AAAAAAAkREY+AAABaHY7ZMgQe/rpp+3ll19OMiNfAfx69erZN998Yy+88IL17dvXw1mbfffdd9aqVSu3AJHU2w0Fw7U4MXXqVLvhhhsiVg9ff2+FChVsw4YN8Y6l5G1RaJyeE+tRAAAAAABAWiOQDwCAz8XExFjFihXt3Llz9vbbb1uXLl0uCOSvWrXKHn/8cVu8eLHlyZPHfvrpJytYsKBnc969e7ddd911rpRO1qxZrU2bNtawYUMrXry4+/zOnTttwYIFNnnyZIuNjXWldpSxX6xYsXSf29///ncXhNdrGFoYCR37I7X1AQAAAABIbwTyAQAIgA8++MA6derkMsEVoFczW2Xg16xZ0wX6f/31V/c5laxRcLxFixaezvfhhx+2d99915UF+vzzz91CRGI2bdpkTZs2dVn7Xbt2teHDh0d8rgAAAAAA+B2BfAAAAmLu3LnWvXt3l22fmHLlyrl69Mp895oC+Dt27LDZs2fbLbfckuzYefPmWZMmTaxEiRIuoA8AAAAAAOIjkA8AQIDosq2GtkuWLLFdu3a50jpFihSxOnXqWIMGDSxTpkzmB9mzZ3e7A44dO5ai8Wp2q3/LyZMn031uAAAAAAAEDYF8AAB8buzYse751ltvtcKFC1sQlCxZ0o4cOeJKAKWE6vrny5ePjHwAAAAAABKRMbGDAADAP9SI9f7777fLLrvMgqJRo0YuG3/lypUXHbtixQo3Vl8DAAAAAAAuREY+AAA+p+a2sm/fPgsK1fGvWrWqq9uv2v6XX355ouMOHDjgauhv2bLFBfQ1HgAAAAAAxEcgHwAAn6tbt64tX77cDh486GrJB4FK5CxbtswefPBBy5Iliz388MOuhn/x4sXd53fu3GkLFixwzXlPnz5t7777rtWsWTPR71WqVKkIzx4AAAAAAH8hkA8AgM+NHDnSunbtaoMHD7YePXpYEKRV090MGTLYmTNn0uR7AQAAAAAQVATyAQAIgLZt29qMGTPsjTfecEH9zJkzm59lzJh2bXjOnTuXZt8LAAAAAIAgIpAPAIDPde7c2XS5njJlih0/ftzy589v1atXt0KFCiWZ+a5M9vfee8+8EhMTk2bfq3Tp0mn2vQAAAAAACCIC+QAA+Jyy2xWYT8klOzROz2fPno3I/AAAAAAAQPry9758AABg9913nwvMAwAAAACASxMZ+QAAAAAAAAAA+BgZ+QAA4E9ZtGiRe86ZM6dVq1Yt3rHUqlevXprODQAAAACAaEBGPgAASJMa/hUrVrT169fHO5YaGn/mzJl0miUAAAAAAMFFRj4AAAEyY8YMmz17tsXExNjJkydt/vz5cZ87fvy4ff/99y4gXqtWrYjOS3kB586du+BYar8HAAAAAAC4EBn5AAAEwPbt261169a2atUq92ddvhWwP3v2bNyY06dPW7ly5WzHjh22dOlSq1mzpoczBgAAAAAAaSVjmn0nAACQLpRp36RJE1u5cqUVL17cunfvbrly5bpgXJYsWaxLly4uyD9t2jRP5goAAAAAANIegXwAAHxu2LBhtmnTJqtatapt3LjR3nrrLcudO3eiY1u2bOmelyxZYl4aMGCAe2gnAQAAAAAA+HMorQMAgM+pRM6KFStswYIFVq9ePXesaNGitnfv3nildUR/zp49uxUoUMD27Nnj0YzNMmXK5B7aTaCdAgAAAAAA4I+j2S0AAD6nbHwFxevUqXPRsRqXL18+O3TokHmpYMGCblGBID4AAAAAAH8epXUAAPC52NhYy5EjhwvSp8SJEydcVr6Xrr/+ereYsH//fk/nAQAAAABANCCQDwCAzxUuXNiOHTuWoiz79evX28mTJ61kyZLmpQcffNDOnTtngwcP9nQeAAAAAABEAwL5AAD4XN26dd3zxIkTLzr2tddeswwZMliDBg3MS3fddZf17NnTXnnlFevVq5ft27fP0/kAAAAAABBkNLsFAMDnli5d6oL5ysyfO3euXXvttRc0uz116pS98MIL9uqrr1rGjBltzZo1ds0113g254YNG7pnNelVw1vNqVy5claoUKEkSwRpAWL+/PkRnikAAAAAAP5HIB8AgAB47LHHbMiQIZYzZ05r2rSpzZ4929XCf/rppy0mJsbmzZvnst51We/bt6/169fP0/kqcJ9aCuSHFiYAAAAAAMD/I5APAEAAhAL0KlUTCnYr8B3++cyZM9vzzz/vHl7r37//H/o67SoAAAAAAADxEcgHACBAlH0/evRoW7Jkie3atcsF9YsUKWJ16tSxzp07W5kyZbyeIgAAAAAASGME8gEAAAAAAAAA8LHUF7AFAAARpUa2al77ww8/XHSsxmjs6dOnIzI3AAAAAACQ/gjkAwDgcxMnTrQbbrjB3nzzzYuOHThwoBs7efJk8wM15H3rrbfs9ttvt2uvvdbKli0b7/OHDx+2Dz/80MaPH+/ZHAEAAAAA8DtK6wAA4HN33nmnffLJJ7Z48WKrXbt2smO//PJLa9iwobVq1cqmTJliXvruu++sZcuWtmPHDteMN9SgN9SsV3S8UqVKtmnTJps7d66bOwAAAAAAiI+MfAAAfG7dunWWOXNmq1GjxkXHqumtxq5du9a8tH//fpeFv337dqtataoNGjTI8uTJc8E4Bfa7dOniAvozZszwZK4AAAAAAPgdgXwAAHxu165dljdvXhegv5gsWbK4sbt37zYvvfHGG24OjRo1suXLl1vPnj0tR44ciY5VwF++/vrrCM8SAAAAAIBgIJAPAIDPZc2a1Y4ePZqiscpsP3bsmMt095JKAWkOr732mmXMmPzbjQoVKrgFiJ9//jli8wMAAAAAIEgI5AMA4HN/+ctf7NSpUynKWF+6dKnFxsZa6dKlzUtbtmxxCxBVqlS56FgF/FV258iRIxGZGwAAAAAAQUMgHwAAn2vcuLHLtH/mmWfszJkzSY7T55599lkXGG/SpIl56dy5c64UUEp2BoR2EeTKlSsicwMAAAAAIGgI5AMA4HP//Oc/LXv27PbVV1/ZLbfcYqtXr75gzKpVq1w9eo3Jli2bPfbYY+al4sWL24kTJ2zv3r0XHfvtt9+6XQTaeQAAAAAAAC5EIB8AAJ8rUaKEvfvuu+7jxYsXW7Vq1VygvHbt2u6hj6tXr+4+pwz4ESNGWKlSpTydc/369d3zqFGjLjq2f//+bt7aeQAAAAAAAC6U4bz2swMAAN/77LPP7NFHH7WtW7cm+vkyZcrY0KFDrWnTpua19evX2/XXX+/K5UyZMsXtJChatKjL0D979qwbs2fPHuvZs6eNHz/e7SLYtGmT5wsQAAAAAAD4EYF8AAACREHwBQsWuKa2v/76q8tkL1KkiMvMb9CggWXM6J/Ndq+99pqr66853nDDDbZhwwZXQqd9+/YWExNjK1eutNOnT7sa+e+884517drV6ykDAAAAAOBLBPIBAEC6ee+99+zJJ5+0w4cPxx1TYD/09iNfvnz25ptv2n333efhLAEAAAAA8DcC+QAAIF0dO3bMlddZsmSJ7dq1y+0q0C6COnXqWNu2bS1v3rxeTxEAAAAAAF8jkA8AAAAAAAAAgI9l9noCAAAg+qn57YoVK1yzWylUqJBVq1bNKlWq5PXUAAAAAADwPQL5AAAg3Xz66afWu3dvF8hPjAL5L730krVo0SLicwMAAAAAICgyej0BAAAQnQYMGGAtW7a0devWuea2mTJlcpn4euhjHdPnWrVqZf369fN6ugAAAAAA+BaBfAAAkOZmzZrlgvMK1terV8/mzJljR48etd27d7uHGuDqWP369d2YF1980WbPnu31tAEAAAAA8CWa3QIAgDTXpEkTmzdvnrVt29YmTJhgGTJkSHSc3obcfffdNmnSJGvcuDHBfAAAAAAAEkEgHwAApLkCBQrY4cOHbdu2bVa8ePFkx+7YscNKlSpl+fLlswMHDkRsjgAAAAAABAWBfAAAkOZy585t2bJls/3796do/OWXX26nTp1y5XcAAAAAAEB81MgHAABprkyZMq4OvoLzFxMbG+vG6msAAAAAAMCFCOQDAIA016FDBzt9+rSNHTv2omPHjRvnxuprAAAAAADAhSitAwAA0pwC840aNbIVK1bY8OHDrVOnTomOU6D/oYcesurVq9v8+fMtc+bMEZ8rAAAAAAB+RyAfAACkuQEDBriyOsOGDbMjR45YyZIlrX79+nGNb3fu3GkLFy50zXDz5s1r3bp1s6xZsyb6vfr27Rvh2QMAAAAA4C8E8gEAQJrLmDGjZciQwX0ceqsR+nNIUscTOnv2bLrNEwAAAACAIGD/OgAASHP16tW7aIAeAAAAAACkDBn5AAAAAAAAAAD4WEavJwAAAAAAAAAAAJJGIB8AAAAAAAAAAB8jkA8AAAAAAAAAgI8RyAcAAAAAAAAAwMcI5AMAAAAAAAAA4GME8gEAAAAAAAAA8DEC+QAAAAAAAAAA+BiBfAAAAAAAAAAAzL/+F2bTzwp/sqoDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x1400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top highly correlated feature pairs (correlation > 0.4):\n",
      "if_yes_what_type___1 <-> def: 0.7318\n",
      "def <-> stent_type___5: 0.7142\n",
      "ef <-> def: 0.6986\n",
      "anemia <-> def: 0.6942\n",
      "age <-> def: 0.6688\n",
      "anemia <-> stent_type___5: 0.6578\n",
      "if_yes_what_type___1 <-> stent_type___5: 0.6467\n",
      "anemia <-> if_yes_what_type___1: 0.6385\n",
      "age <-> if_yes_what_type___1: 0.6365\n",
      "def <-> cto_bifurc: 0.6358\n",
      "age <-> anemia: 0.6320\n",
      "peripheral_artery_disease <-> def: 0.6211\n",
      "cerebrovascular_disease <-> def: 0.6142\n",
      "ef <-> stent_type___5: 0.6141\n",
      "ef <-> if_yes_what_type___1: 0.6128\n",
      "anemia <-> ef: 0.6125\n",
      "age <-> stent_type___5: 0.6010\n",
      "atrial_fibrilation <-> def: 0.5824\n",
      "age <-> ef: 0.5811\n",
      "stent_type___5 <-> cto_bifurc: 0.5738\n",
      "cerebrovascular_disease <-> stent_type___5: 0.5707\n",
      "peripheral_artery_disease <-> if_yes_what_type___1: 0.5705\n",
      "anemia <-> peripheral_artery_disease: 0.5668\n",
      "cerebrovascular_disease <-> peripheral_artery_disease: 0.5666\n",
      "peripheral_artery_disease <-> stent_type___5: 0.5623\n",
      "ef <-> atrial_fibrilation: 0.5580\n",
      "anemia <-> cerebrovascular_disease: 0.5569\n",
      "cerebrovascular_disease <-> if_yes_what_type___1: 0.5551\n",
      "if_yes_what_type___1 <-> cto_bifurc: 0.5531\n",
      "age <-> atrial_fibrilation: 0.5520\n"
     ]
    }
   ],
   "source": [
    "# Create a copy of the processed DataFrame for analysis\n",
    "temp_df = X_train_combined.copy()\n",
    "\n",
    "# Get correlations with target\n",
    "target_correlations = temp_df.corr()['target'].drop('target')\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "abs_correlations = target_correlations.abs().sort_values(ascending=False)\n",
    "print(f\"Features count: {len(abs_correlations)}\")\n",
    "\n",
    "# Visualization 1: Feature correlations with target\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Plot top 30 features by correlation with target\n",
    "num_features = min(30, len(abs_correlations))\n",
    "top_features = abs_correlations[:num_features].index\n",
    "top_target_correlations = target_correlations[top_features]\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "sns.barplot(x=top_target_correlations.values, y=top_target_correlations.index, \n",
    "            palette='viridis')\n",
    "plt.title(f'Top {num_features} Features by Correlation with Target', fontsize=14)\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Correlation matrix between features (excluding target)\n",
    "# Remove target column for feature-only correlation\n",
    "features_df = X_train_combined.drop('target', axis=1)\n",
    "\n",
    "# If there are too many features, select top 30 by correlation with target\n",
    "if features_df.shape[1] > 30:\n",
    "    top_k_features = abs_correlations[:30].index\n",
    "    features_for_matrix = features_df[top_k_features]\n",
    "    title = 'Correlation Matrix for Top 30 Features'\n",
    "else:\n",
    "    features_for_matrix = features_df\n",
    "    title = 'Correlation Matrix for All Features'\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = features_for_matrix.corr()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(16, 14))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap=cmap, vmax=1.0, vmin=-1.0, \n",
    "            center=0, square=True, linewidths=.5,\n",
    "            annot=False)  # Set annot=True for smaller matrices\n",
    "\n",
    "plt.title(title, fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Set a threshold for high correlation\n",
    "high_corr_threshold = 0.4\n",
    "\n",
    "# Find highly correlated feature pairs - IMPORTANT: use the SAME features as in corr_matrix\n",
    "matrix_columns = corr_matrix.columns  # Use exactly the columns in the correlation matrix\n",
    "high_corr_pairs = []\n",
    "for i in range(len(matrix_columns)):\n",
    "    for j in range(i+1, len(matrix_columns)):\n",
    "        feature1 = matrix_columns[i]\n",
    "        feature2 = matrix_columns[j]\n",
    "        correlation = abs(corr_matrix.loc[feature1, feature2])\n",
    "        if correlation > high_corr_threshold:\n",
    "            high_corr_pairs.append((feature1, feature2, correlation))\n",
    "\n",
    "# Sort pairs by correlation strength\n",
    "high_corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Display the top highly correlated pairs\n",
    "print(f\"\\nTop highly correlated feature pairs (correlation > {high_corr_threshold}):\")\n",
    "for pair in high_corr_pairs[:30]:  # Show top 30 pairs\n",
    "    print(f\"{pair[0]} <-> {pair[1]}: {pair[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedb7266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
